Templates,label
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 4, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 13, in <module> from tensorflow.core.framework.graph_pb2 import *[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/graph_pb2.py, line 16, in <module> from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py, line 16, in <module> from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py, line 16, in <module> from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py, line 22, in <module> serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto \x12\ntensorflow\""d\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tb\x06proto3')[SEP]TypeError: __init__() got an unexpected keyword argument 'syntax'",1
"File classify.py, line 14, in <module> import caffe[SEP]File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver[SEP]File <*>/pycaffe.py, line 13, in <module> from ._caffe import Net, SGDSolver[SEP]ImportError: dynamic module does not define module export function (PyInit__caffe)",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 48, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.19' not found (required by /home/anirudh/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so)",1
"File <*>/census.py, line 73, in <module> df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)[SEP]File <*>python2.7/dist-packages/pandas/core/series.py, line 2023, in apply mapped = lib.map_infer(values, f, convert=convert_dtype)[SEP]File inference.pyx, line 920, in pandas.lib.map_infer (pandas/lib.c:44780)[SEP]File <*>/census.py, line 73, in <lambda> df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)[SEP]TypeError: argument of type 'float' is not iterable",1
"File [FILE], line 1, in <module>() writer = tf.train.SummaryWriter('./my_graph', sess.graph)[SEP]AttributeError: 'module' object has no attribute 'SummaryWriter'",1
"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: 'module' object has no attribute 'FileWriter'",1
"File mnist_test.py, line 19, in <module> cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_, logits=y)[SEP]TypeError: sigmoid_cross_entropy_with_logits() got an unexpected keyword argument 'labels'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in () from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in () _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper() return importlib.import_module('_pywrap_tensorflow_internal' )[SEP]File <*>/importlib__init__.py, line 126, in import_module(name, pac kage) return _bootstrap._gcd_import(name[level:], package, level)[SEP]ImportError: No module named '_pywrap_tensorflow_internal'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal')[SEP]File <*>/importlib__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]ImportError: No module named '_pywrap_tensorflow_internal'",1
"File <*>python2.7/runpy.py, line 174, in _run_module_as_main ""__main__"", fname, loader, pkg_name)[SEP]File <*>python2.7/runpy.py, line 72, in _run_code exec code in run_globals[SEP]File <*>python2.7/site-packages/object_detection/train.py, line 49, in <module> from object_detection import trainer[SEP]File <*>python2.7/site-packages/object_detection/trainer.py, line 27, in <module> from object_detection.builders import preprocessor_builder[SEP]File <*>python2.7/site-packages/object_detection/builders/preprocessor_builder.py, line 21, in <module> from object_detection.protos import preprocessor_pb2[SEP]File <*>python2.7/site-packages/object_detection/protos/preprocessor_pb2.py, line 71, in <module> options=None, file=DESCRIPTOR),[SEP]TypeError: __new__() got an unexpected keyword argument 'file'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 14, in swig_import_helper return importlib.import_module(mname)[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <frozen importlib._bootstrap>, line 994, in _gcd_import [CODE][SEP]File <frozen importlib._bootstrap>, line 971, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 955, in _find_and_load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 658, in _load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 571, in module_from_spec [CODE][SEP]File <frozen importlib._bootstrap_external>, line 922, in create_module [CODE][SEP]File <frozen importlib._bootstrap>, line 219, in _call_with_frames_removed [CODE][SEP]ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.7/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>python3.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 114, in [FUNC] [CODE][SEP]SyntaxError: invalid syntax",1
"File <input>, line 3, in <module> [CODE][SEP]AttributeError: 'Tensor' object has no attribute '_keras_shape'",1
"File <*>/test_callback.py, line 34, in <module> model.evaluate_generator(generator=test_generator, steps=STEP_SIZE_TEST, callbacks=[test_callback])[SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]TypeError: evaluate_generator() got an unexpected keyword argument 'callbacks'",1
"File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.6/imp.py, line 243, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.6/imp.py, line 343, in load_dynamic return _load(spec)[SEP]ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory",1
"File <*>/train.py, line 7, in <module> import models as m[SEP]File <*>/models.py, line 25, in <module> K.set_image_dim_ordering('th')[SEP]AttributeError: module 'tensorflow.python.keras.api._v2.keras.backend' has no attribute 'set_image_dim_ordering'",1
"File train_initialize.py, line 18, in agent = Agent(""horoscope_domain.yml"", policies = [MemoizationPolicy(), KerasPolicy()])[SEP]File <*>/site-packages/rasa_core/policies/keras_policy.py, line 31, in init if KerasPolicy.is_using_tensorflow() and not graph:[SEP]File <*>/site-packages/rasa_core/policies/keras_policy.py, line 48, in is_using_tensorflow return keras.backend._BACKEND == ""tensorflow""[SEP]AttributeError: module 'keras.backend' has no attribute '_BACKEND'",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/deepposekit/__init__.py, line 20, in <module> from deepposekit.io import TrainingGenerator, DataGenerator[SEP]File <*>python3.6/site-packages/deepposekit/io/__init__.py, line 18, in <module> from deepposekit.io.BaseGenerator import BaseGenerator[SEP]File <*>python3.6/site-packages/deepposekit/io/BaseGenerator.py, line 16, in <module> from tensorflow.keras.utils import Sequence[SEP]ModuleNotFoundError: No module named 'tensorflow'",1
"File <*>/model_loggingfinal.py, line 35, in <module> callbacks=[logger][SEP]File <*>python3.7/site-packages/keras/engine/training.py, line 1239, in fit validation_freq=validation_freq)[SEP]File <*>python3.7/site-packages/keras/engine/training_arrays.py, line 119, in fit_loop callbacks.set_model(callback_model)[SEP]File <*>python3.7/site-packages/keras/callbacks/callbacks.py, line 68, in set_model callback.set_model(model)[SEP]File <*>python3.7/site-packages/keras/callbacks/tensorboard_v2.py, line 116, in set_model super(TensorBoard, self).set_model(model)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/callbacks.py, line 1532, in set_model self.log_dir, self.model._get_distribution_strategy()) # pylint: disable=protected-access[SEP]AttributeError: 'Sequential' object has no attribute '_get_distribution_strategy'",1
"File [FILE], line 8, in <module> trainer.trainModel()[SEP]File <*>python3.6/site-packages/imageai/Detection/Custom/__init__.py, line 274, in trainModel(self) class_scale=self.__train_class_scale,[SEP]File <*>python3.6/site-packages/imageai/Detection/Custom/__init__.py, line 553, in _create_model(self, nb_class, anchors, max_box_per_image, max_grid, batch_size, warmup_batches, ignore_thresh, multi_gpu, lr, grid_scales, obj_scale, noobj_scale, xywh_scale, class_scale) class_scale=class_scale[SEP]File <*>python3.6/site-packages/imageai/Detection/Custom/yolo.py, line 294, in create_yolov3_model(nb_class, anchors, max_box_per_image, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scales, obj_scale, noobj_scale, xywh_scale, class_scale) class_scale)([input_image, pred_yolo_1, true_yolo_1, true_boxes])[SEP]File <*>python3.6/site-packages/imageai/Detection/Custom/yolo.py, line 24, in __init__(self, anchors, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scale, obj_scale, noobj_scale, xywh_scale, class_scale, **kwargs) cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(max_grid_w), [max_grid_h]), (1, max_grid_h, max_grid_w, 1, 1)))[SEP]AttributeError: module 'tensorflow' has no attribute 'to_float'",1
"File <*>python3.6/dist-packages/fastai/data_block.py, line 594, in _check_kwargs(ds, tfms, **kwargs) try: x.apply_tfms(tfms, **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 123, in apply_tfms(self, tfms, do_resolve, xtra, size, resize_method, mult, padding_mode, mode, remove_out) else: x = tfm(x)[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 524, in __call__(self, x, *args, **kwargs) return self.tfm(x, *args, **{**self.resolved, **kwargs}) if self.do_run else x[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 470, in __call__(self, p, is_random, use_on_y, *args, **kwargs) if args: return self.calc(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 475, in calc(self, x, *args, **kwargs) if self._wrap: return getattr(x, self._wrap)(self.func, *args, **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 183, in affine(self, func, *args, **kwargs) self.affine_mat = self.affine_mat @ m[SEP]RuntimeError: Expected object of scalar type Float but got scalar type Double for argument #3 'mat2' in call to _th_addmm_out",1
"File <*>/test.py, line 13, in <module> lstm = Bidirectional(lstm_nobi, name=""layerC"")(embedding_layer)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/wrappers.py, line 539, in __call__ return super(Bidirectional, self).__call__(inputs, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 951, in __call__ return self._functional_construction_call(inputs, args, kwargs,[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1090, in _functional_construction_call outputs = self._keras_tensor_symbolic_call([SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 822, in _keras_tensor_symbolic_call return self._infer_output_signature(inputs, args, kwargs, input_masks)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 863, in _infer_output_signature outputs = call_fn(inputs, *args, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/wrappers.py, line 652, in call y = self.forward_layer(forward_inputs,[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 660, in __call__ return super(RNN, self).__call__(inputs, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1012, in __call__ outputs = call_fn(inputs, *args, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py, line 1157, in call inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 859, in _process_inputs initial_state = self.get_initial_state(inputs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 642, in get_initial_state init_state = get_initial_state_fn([SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 2506, in get_initial_state return list(_generate_zero_filled_state_for_cell([SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 2987, in _generate_zero_filled_state_for_cell return _generate_zero_filled_state(batch_size, cell.state_size, dtype)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 3003, in _generate_zero_filled_state return nest.map_structure(create_zeros, state_size)[SEP]File <*>python3.9/site-packages/tensorflow/python/util/nest.py, line 659, in map_structure structure[0], [func(*x) for x in entries],[SEP]File <*>python3.9/site-packages/tensorflow/python/util/nest.py, line 659, in <listcomp> structure[0], [func(*x) for x in entries],[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 3000, in create_zeros return array_ops.zeros(init_state_size, dtype=dtype)[SEP]File <*>python3.9/site-packages/tensorflow/python/util/dispatch.py, line 201, in wrapper return target(*args, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2819, in wrapped tensor = fun(*args, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2868, in zeros output = _constant_if_small(zero, shape, dtype, name)[SEP]File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2804, in _constant_if_small if np.prod(shape) < 1000:[SEP]File <__array_function__ internals>, line 5, in prod [CODE][SEP]File <*>python3.9/site-packages/numpy/core/fromnumeric.py, line 3030, in prod return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,[SEP]File <*>python3.9/site-packages/numpy/core/fromnumeric.py, line 87, in _wrapreduction return ufunc.reduce(obj, axis, dtype, out, **passkwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/framework/ops.py, line 852, in __array__ raise NotImplementedError([SEP]NotImplementedError: Cannot convert a symbolic Tensor (layerC/forward_layerB/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",1
"File train.py, line 29, in <module> policy = tf.keras.mixed_precision.Policy('mixed_float16')[SEP]AttributeError: module 'tensorflow.keras.mixed_precision' has no attribute 'Policy'",1
"File <*>/CNN_Image_Denoising.py, line 15, in <module> from keras.optimizers import SGD, Adam[SEP]ImportError: cannot import name 'SGD' from 'keras.optimizers'",1
"File <*>/script.py, line 654, in <module> prediction_result, (r, t) = cf.to(model_runner.predict(processed_feature_dict, random_seed=seed), ""cpu"")[SEP]File <*>python3.7/site-packages/alphafold/model/model.py, line 134, in predict result, recycles = self.apply(self.params, jax.random.PRNGKey(random_seed), feat)[SEP]File <*>python3.7/site-packages/jax/_src/traceback_util.py, line 183, in reraise_with_filtered_traceback return fun(*args, **kwargs)[SEP]File <*>python3.7/site-packages/jax/_src/api.py, line 402, in cache_miss donated_invars=donated_invars, inline=inline)[SEP]File <*>python3.7/site-packages/jax/core.py, line 1561, in bind return call_bind(self, fun, *args, **params)[SEP]File <*>python3.7/site-packages/jax/core.py, line 1552, in call_bind outs = primitive.process(top_trace, fun, tracers, params)[SEP]File <*>python3.7/site-packages/jax/core.py, line 1564, in process return trace.process_call(self, fun, tracers, params)[SEP]File <*>python3.7/site-packages/jax/core.py, line 607, in process_call return primitive.impl(f, *tracers, **params)[SEP]File <*>python3.7/site-packages/jax/interpreters/xla.py, line 608, in _xla_call_impl *unsafe_map(arg_spec, args))[SEP]File <*>python3.7/site-packages/jax/, line 262, in memoized_fun ans = call(fun, *args)[SEP]File <*>python3.7/site-packages/jax/interpreters/xla.py, line 758, in _xla_callable compiled = compile_or_get_cached(backend, built, options)[SEP]File env/lib/python3.7/site-packages/jax/interpreters/xla.py, line 76, in compile_or_get_cached return backend_compile(backend, computation, compile_options)",1
"File <*>/site-packages/theano/configparser.py, line 327, in __get__ val_str = fetch_val_for_key(self.fullname,[SEP]File <*>/site-packages/theano/configparser.py, line 172, in fetch_val_for_key raise KeyError(key)[SEP]KeyError: 'blas.ldflags'",1
"File [FILE], line 3, in <module>() from keras.applications.resnet50 import preprocess_input, ResNet50[SEP]ModuleNotFoundError: No module named 'keras.applications.resnet50'",1
"File <*>/ai.py, line 15, in <module> from keras.models import Sequential, load_model[SEP]File <*>/site-packages/keras/__init__.py, line 24, in <module> from keras import models[SEP]File <*>/site-packages/keras/models/__init__.py, line 18, in <module> from keras.engine.functional import Functional[SEP]File <*>/site-packages/keras/engine/functional.py, line 24, in <module> from keras.dtensor import layout_map as layout_map_lib[SEP]File <*>/site-packages/keras/dtensor/__init__.py, line 22, in <module> from tensorflow.compat.v2.experimental import dtensor as dtensor_api # pylint: disable=g-import-not-at-top[SEP]ImportError: cannot import name 'dtensor' from 'tensorflow.compat.v2.experimental' (C:\Users\Fynn\AppData\Local\Programs\Python\Python39\lib\site-packages\tensorflow\_api\v2\compat\v2\experimental\__init__.py)",1
"File <*>/site-packages/IPython/core/interactiveshell.py, line 3032, in run_code =============================== C:\Users\aleja_000\AppData\Local\Theano\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.9-64\lazylinker_ext\mod.cpp:1:0: sorry, unimplemented: 64-bit mode not compiled in #include <Python.h> ^ exec(code_obj, self.user_global_ns, self.user_ns)[SEP]File <ipython-input-2-1e86b04c8a9c>, line 6, in <module> from lasagne.layers import DenseLayer[SEP]File <*>/pydev_import_hook.py, line 21, in do_import module = self._system_import(name, *args, **kwargs)[SEP]File <*>/__init__.py, line 5, in <module> from . import nonlinearities[SEP]File <*>/non, line 6, in <module> from theano.tensor.nnet import sigmoid[SEP]File <*>/site-packages/theano/__init__.py, line 55, in <module> from theano.compile import ([SEP]File <*>/site-packages/theano/compile/__init__.py, line 9, in <module> from theano.compile.function_module import *[SEP]File <*>/site-packages/theano/compile/function_module.py, line 17, in <module> import theano.compile.mode[SEP]File <*>/site-packages/theano/compile/mode.py, line 11, in <module> import theano.gof.vm[SEP]File <*>/site-packages/theano/gof/vm.py, line 654, in <module> import lazylinker_c[SEP]File <*>/site-packages/theano/gof/lazylinker_c.py, line 125, in <module> preargs=args)[SEP]File <*>/site-packages/theano/gof/cmodule.py, line 2042, in compile_str (status, compile_stderr.replace('\n', '. ')))[SEP]Exception: Compilation failed (return status=1): C:\Users\aleja_000\AppData\Local\Theano\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.9-64\lazylinker_ext\mod.cpp:1:0: sorry, unimplemented: 64-bit mode not compiled in . #include <Python.h> . ^",0
"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: 'TensorVariable' object has no attribute 'get_value'",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/models.py, line 602, in compile [CODE][SEP]File <*>/advanced_activations.py, line 149, in get_output [CODE][SEP]File <*>/core.py, line 117, in get_input [CODE][SEP]File <*>/core.py, line 1334, in get_output [CODE][SEP]File <*>/core.py, line 1282, in get_output_sum [CODE][SEP]File <*>/core.py, line 1266, in get_output_at [CODE][SEP]File <*>/core.py, line 730, in get_output [CODE][SEP]File <*>/core.py, line 1340, in get_output [CODE][SEP]File <*>/core.py, line 1312, in get_output_dot [CODE][SEP]File <*>python2.7/site-packages/theano/tensor/var.py, line 360, in dimshuffle pattern)[SEP]File <*>python2.7/site-packages/theano/tensor/elemwise.py, line 164, in __init__ (input_broadcastable, new_order))[SEP]ValueError: ('You cannot drop a non-broadcastable dimension.', ((False, False, False, False), (0, 'x')))",0
"File <*>/convolutional.py, line 133, in <module> train_accuracy = accuracy.eval(feed_dict = {x: batch[0], y_: batch[1], keep_prob: 1.0})[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 405, in eval return _eval_using_default_session(self, feed_dict, self.graph, session)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 2728, in _eval_using_default_session return session.run(tensors, feed_dict)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 345, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 419, in _do_run e.code)[SEP]tensorflow.python.framework.errors.InvalidArgumentError: Incompatible shapes: [8] vs. [20] [[Node: Equal = Equal[T=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](ArgMax, ArgMax_1)]]",0
"File <*>/Layer.py, line 113, in <module> train_model(i)[SEP]File <*>python2.7/site-packages/theano/compile/function_module.py, line 595, in __call__ outputs = self.fn()[SEP]File <*>python2.7/site-packages/theano/gof/link.py, line 485, in streamline_default_f raise_with_op(node, thunk)[SEP]File <*>python2.7/site-packages/theano/gof/link.py, line 481, in streamline_default_f thunk()[SEP]File <*>python2.7/site-packages/theano/gof/op.py, line 768, in rval r = p(n, [x[0] for x in i], o)[SEP]File <*>python2.7/site-packages/theano/tensor/nnet/nnet.py, line 896, in perform nll[i] = -row[y_idx[i]] + m + numpy.log(sum_j)[SEP]IndexError: index 1 is out of bounds for axis 0 with size 1",0
"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: No module named tensorflow",0
"File <*>/audiornn.py, line 56, in <module> tf.with_dependencies([expected_output], input_tensor)[SEP]AttributeError: module 'tensorflow' has no attribute 'with_dependencies'",0
"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: cannot import name Nadam",0
"File trainer_deepMnist.py, line 109, in <module> x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 559, in eval return _eval_using_default_session(self, feed_dict, self.graph, session)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 3648, in _eval_using_default_session return session.run(tensors, feed_dict)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 710, in run run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 908, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 958, in _do_run target_list, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 978, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[10000,32,28,28] [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Reshape, Variable_2/read)]]",0
"File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 715, in _do_call return fn(*args)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 697, in _run_fn status, run_metadata)[SEP]File <*>python3.5/contextlib.py, line 66, in __exit__ next(self.gen)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/errors.py, line 450, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value auc/false_positives [[Node: auc/false_positives/read = Identity[T=DT_FLOAT, _class=[""loc:@auc/false_positives""], _device=""/job:localhost/replica:0/task:0/cpu:0""](auc/false_positives)]]",0
"File <*>/gridsearch.py, line 43, in <module> model.fit(x,y)[SEP]File <*>/site-packages/keras/wrappers/scikit_learn.py, line 135, in fit **self.filter_sk_params(self.build_fn.__call__))[SEP]TypeError: __call__() missing 1 required positional argument: 'x'",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 21, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow')[SEP]File <*>python2.7/__init__.py, line 37, in import_module __import__(name)[SEP]ImportError: No module named _pywrap_tensorflow",0
"File <*>/demo.py, line 18, in <module> from fast_rcnn.test import im_detect[SEP]File <*>/test.py, line 16, in <module> import caffe[SEP]File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver[SEP]File <*>/pycaffe.py, line 13, in <module> from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \[SEP]ImportError: No module named _caffe",0
"File test1.py, line 43, in <module> c = sess.run(cost, feed_dict={X: train_X, Y: train_Y})[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 76, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 96, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 10, in [FUNC] [CODE][SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [10000,10] vs. [10000] [[Node: sub = Sub[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](Add, _recv_Placeholder_1_0/_7)]]",0
"File <*>/rock_detector.py, line 155, in <module> main()[SEP]File <*>/rock_detector.py, line 117, in main est_vgg16.train(input_fn=dataset_input_fn, steps=10)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 302, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 711, in _train_model features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 694, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py, line 145, in model_fn labels)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py, line 92, in _clone_and_build_model keras_model, features)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py, line 58, in _create_ordered_io for key in estimator_io_dict:[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 505, in __iter__ raise TypeError(""'Tensor' object is not iterable."")[SEP]TypeError: 'Tensor' object is not iterable.",0
"File <stdin>, line 1, in <module> [CODE][SEP]RuntimeError: t() expects a 2D tensor, but self is 1D",0
"File <*>/LSTM-RNN.py, line 42, in <module> states_series, current_state = tf.contrib.rnn.static_rnn(cell, inputs_series, init_state)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/rnn.py, line 1181, in static_rnn input_shape = first_input.get_shape().with_rank_at_least(2)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/tensor_shape.py, line 670, in with_rank_at_least raise ValueError(""Shape %s must have rank at least %d"" % (self, rank))[SEP]ValueError: Shape () must have rank at least 2",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import *[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 30, in <module> self_check.preload_check()[SEP]File <*>/site-packages/tensorflow/python/platform/self_check.py, line 82, in preload_check % (build_info.cudart_dll_name, build_info.cuda_version_number))[SEP]ImportError: Could not find 'cudart64_80.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 8.0 from this URL: https://developer.nvidia.com/cuda-toolkit",0
"File generate_tfrecord.py, line 192, in <module> tf.app.run()[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough))[SEP]File generate_tfrecord.py, line 184, in main tf_example = create_tf_example(group, path)[SEP]File generate_tfrecord.py, line 173, in create_tf_example 'image/object/class/label': dataset_util.int64_list_feature(classes),[SEP]File <*>/dataset_util.py, line 26, in int64_list_feature return tf.train.Feature(int64_list=tf.train.Int64List(value=value))[SEP]TypeError: None has type NoneType, but expected one of: int, long",0
"File predict.py, line 34, in <module> preds = learn.predict_array(im[None])[SEP]File <*>/learner.py, line 266, in predict_array def predict_array(self, arr): return to_np(self.model(V(T(arr).cuda())))[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 325, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/container.py, line 67, in forward input = module(input)[SEP]File <*>python3.6/site-packages/torch/nn/modules/batchnorm.py, line 37, in forward self.training, self.momentum, self.eps)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1011, in batch_norm raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size))[SEP]ValueError: Expected more than 1 value per channel when training, got input size [1, 1024]",0
"File cnn_base.py, line 1703, in <module> training()[SEP]File cnn_base.py, line 1314, in training _, loss_value = sess.run([train_op, loss])[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: cnn()conv2 : Tensor had Inf values [[Node: tower_7/conv2/CheckNumerics_3 = CheckNumerics[T=DT_FLOAT, message=""NaN: cnn()conv2"", _device=""/job:localhost/replica:0/task:0/device:GPU:7""](tower_7/conv2/conv2)]]",0
"File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1350, in _do_call return fn(*args)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1329, in _run_fn status, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,32,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[Node: FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Preprocessor/sub, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read)]]",0
"File lec5.py, line 97, in <module> train(epoch)[SEP]File lec5.py, line 74, in train loss = criterion(y_pred, labels)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 357, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/loss.py, line 679, in forward self.ignore_index, self.reduce)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1161, in cross_entropy return nll_loss(log_softmax(input, 1), target, weight, size_average, ignore_index, reduce)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1052, in nll_loss return torch._C._nn.nll_loss(input, target, weight, size_average, ignore_index, reduce)[SEP]RuntimeError: multi-target not supported at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/THNN/generic/ClassNLLCriterion.c:22",0
"File processing_2a_1.py, line 96, in <module> model.add(Conv1D(60,32, strides=1, activation='relu',padding='causal',input_shape=(None,64,1)))[SEP]File <*>/models.py, line 442, in add [CODE][SEP]File <*>/topology.py, line 558, in __call__ [CODE][SEP]File <*>/topology.py, line 457, in assert_input_compatibility [CODE][SEP]ValueError: Input 0 is incompatible with layer conv1d_1: expected ndim=3, found ndim=4",0
"File [FILE], line <*>, in [FUNC] [CODE][SEP]AttributeError: module 'tensorflow' has no attribute 'Session'",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1330, in _do_call return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1315, in _run_fn options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1423, in _call_tf_sessionrun status, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,25] vs. shape[1] = [30,100] [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](rnn/while/TensorArrayReadV3, rnn/while/Switch_4:1, rnn/while/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/Const)]]",0
"File <*>/mnist_test.py, line 24, in <module> from official.mnist import mnist[SEP]ModuleNotFoundError: No module named 'official'",0
"File pipe, line 320, in <module> tf.app.run()[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File pipe, line 316, in main train(FLAGS.num_training_iterations, FLAGS.report_interval, FLAGS.report_interval_verbose)[SEP]File pipe, line 120, in train print(sess.run(next_element))[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 905, in run run_metadata_ptr)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1140, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1321, in _do_run run_metadata)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1340, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.UnknownError: exceptions.AttributeError: 'numpy.dtype' object has no attribute 'as_numpy_dtype'",0
"File <ipython-input-17-412a606c772f>, line 1, in <module> dataset = tf.data.Dataset.from_tensor_slices((one_hot_dataset))[SEP]File <*>python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 235, in from_tensor_slices return TensorSliceDataset(tensors)[SEP]File <*>python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1030, in __init__ for i, t in enumerate(nest.flatten(tensors))[SEP]File <*>python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1030, in <listcomp> for i, t in enumerate(nest.flatten(tensors))[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 1014, in convert_to_tensor as_ref=False)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 1104, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/constant_op.py, line 235, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/constant_op.py, line 214, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/tensor_util.py, line 496, in make_tensor_proto [CODE][SEP]""Cannot create a tensor proto whose content is larger than 2GB."") ValueError: Cannot create a tensor proto whose content is larger than 2GB.",0
"File generate_tfrecord.py, line 17, in <module> import tensorflow as tf[SEP]File <*>/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 81, in <module> from tensorflow.python import keras[SEP]File <*>/site-packages/tensorflow/python/keras/__init__.py, line 24, in <module> from tensorflow.python.keras import activations[SEP]File <*>/site-packages/tensorflow/python/keras/activations/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.activations import elu[SEP]File <*>/site-packages/tensorflow/python/keras/_impl/keras/__init__.py, line 21, in <module> from tensorflow.python.keras._impl.keras import activations[SEP]File <*>/site-packages/tensorflow/python/keras/_impl/keras/activations.py, line 23, in <module> from tensorflow.python.keras._impl.keras import backend as K[SEP]File <*>/site-packages/tensorflow/python/keras/_impl/keras/backend.py, line 38, in <module> from tensorflow.python.layers import base as tf_base_layers[SEP]File <*>/site-packages/tensorflow/python/layers/base.py, line 25, in <module> from tensorflow.python.keras.engine import base_layer[SEP]File <*>/site-packages/tensorflow/python/keras/engine/__init__.py, line 21, in <module> from tensorflow.python.keras.engine.base_layer import InputSpec[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 33, in <module> from tensorflow.python.keras import backend[SEP]File <*>/site-packages/tensorflow/python/keras/backend/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.backend import abs[SEP]ImportError: cannot import name 'abs'",0
"File hello-world.py, line 1, in <module> from keras.models import Sequential[SEP]File <*>python3.6/site-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>python3.6/site-packages/keras/utils/__init__.py, line 2, in <module> from . import np_utils[SEP]File <*>python3.6/site-packages/keras/utils/np_utils.py, line 6, in <module> import numpy as np[SEP]File <*>python3.6/site-packages/numpy/__init__.py, line 142, in <module> from . import add_newdocs[SEP]File <*>python3.6/site-packages/numpy/add_newdocs.py, line 13, in <module> from numpy.lib import add_newdoc[SEP]File <*>python3.6/site-packages/numpy/lib/__init__.py, line 8, in <module> from .type_check import *[SEP]File <*>python3.6/site-packages/numpy/lib/type_check.py, line 11, in <module> import numpy.core.numeric as _nx[SEP]File <*>python3.6/site-packages/numpy/core/__init__.py, line 16, in <module> from . import multiarray[SEP]SystemError: initialization of multiarray raised unreported exception",0
"File <*>/predict.py, line 74, in <module> print(get_grad(x_cloned, x))[SEP]File <*>/predict.py, line 68, in get_grad A.backward()[SEP]File <*>python3.5/site-packages/torch/tensor.py, line 93, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>python3.5/site-packages/torch/autograd/__init__.py, line 90, in backward allow_unreachable=True) # allow_unreachable flag[SEP]RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn",0
"File <*>/playground.py, line 22, in <module> print(get_grad(x_cloned, x))[SEP]File <*>/playground.py, line 16, in get_grad A.backward()[SEP]File <*>python3.5/site-packages/torch/tensor.py, line 93, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>python3.5/site-packages/torch/autograd/__init__.py, line 84, in backward grad_tensors = _make_grads(tensors, grad_tensors)[SEP]File <*>python3.5/site-packages/torch/autograd/__init__.py, line 28, in _make_grads raise RuntimeError(""grad can be implicitly created only for scalar outputs"")[SEP]RuntimeError: grad can be implicitly created only for scalar outputs",0
"File <*>/tensor01.py, line 4, in <module> x = torch.Tensor([[.5, .3, 2.1]], requires_grad=False)[SEP]TypeError: new() received an invalid combination of arguments - got (list, requires_grad=bool), but expected one of: * (torch.device device) * (torch.Storage storage) * (Tensor other) * (tuple of ints size, torch.device device) didn't match because some of the keywords were incorrect: requires_grad * (object data, torch.device device) didn't match because some of the keywords were incorrect: requires_grad",0
"File test_loocv.py, line 245, in <module> output = model_ft(test_data)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 477, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/resnet.py, line 139, in forward [CODE][SEP]File <*>python3.6/site-packages/torch/nn/modules/conv.py, line 301, in forward self.padding, self.dilation, self.groups)[SEP]RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[3, 1, 224, 224] to have 3 channels, but got 1 channels instead",0
"File <*>/lesson4-imdb2.py, line 27, in <module> pickle.dump(md, file)[SEP]TypeError: 'generator' object is not callable",0
"File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 204, in _convert_pb_to_mlmodel shape_list = shape.as_list()[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/tensor_shape.py, line 900, in as_list raise ValueError(""as_list() is not defined on an unknown TensorShape."")[SEP]ValueError: as_list() is not defined on an unknown TensorShape.",0
"File model.py, line 7, in <module> class_labels = 'conv_labels.txt'[SEP]File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 586, in convert custom_conversion_functions=custom_conversion_functions)[SEP]File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 153, in _convert_pb_to_mlmodel tf.import_graph_def(gdef, name='')[SEP]File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 316, in new_func return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/importer.py, line 541, in import_graph_def raise ValueError('No op named %s in defined operations.' % node.op)[SEP]ValueError: No op named DecodeWav in defined operations.",0
"File <*>/tst1.py, line 110, in <module> classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)[SEP]File <*>/site-packages/keras/engine/training.py, line 950, in fit batch_size=batch_size)[SEP]File <*>/site-packages/keras/engine/training.py, line 787, in _standardize_user_data exception_prefix='target')[SEP]File <*>/site-packages/keras/engine/training_utils.py, line 137, in standardize_input_data str(data_shape))[SEP]ValueError: Error when checking target: expected dense_3 to have shape (1,) but got array with shape (6,)",0
"File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 3078, in get_loc return self._engine.get_loc(key)[SEP]File <*>/index.pyx, line 140, in pandas._libs.index.IndexEngine.get_loc [CODE][SEP]File <*>/index.pyx, line 162, in pandas._libs.index.IndexEngine.get_loc [CODE][SEP]File <*>/hashtable_class_helper.pxi, line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE][SEP]File <*>/hashtable_class_helper.pxi, line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE][SEP]KeyError: range(418, 419)",0
"File <*>/site-packages/flask/app.py, line 1813, in full_dispatch_request rv = self.dispatch_request()[SEP]File <*>/site-packages/flask/app.py, line 1799, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args)[SEP]File <*>/site-packages/flask_restful/__init__.py, line 458, in wrapper resp = resource(*args, **kwargs)[SEP]File <*>/site-packages/flask/views.py, line 88, in view return self.dispatch_request(*args, **kwargs)[SEP]File <*>/site-packages/flask_restful/__init__.py, line 573, in dispatch_request resp = meth(*args, **kwargs)[SEP]File app.py, line 41, in get print(ann.predict(x_test))[SEP]File <*>/site-packages/keras/engine/training.py, line 1164, in predict self._make_predict_function()[SEP]File <*>/site-packages/keras/engine/training.py, line 554, in _make_predict_function **kwargs)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2744, in function return Function(inputs, outputs, updates=updates, **kwargs)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2546, in __init__ with tf.control_dependencies(self.outputs):[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 5004, in control_dependencies return get_default_graph().control_dependencies(control_inputs)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 4543, in control_dependencies c = self.as_graph_element(c)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 3490, in as_graph_element return self._as_graph_element_locked(obj, allow_tensor, allow_operation)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 3569, in _as_graph_element_locked raise ValueError(""Tensor %s is not an element of this graph."" % obj)[SEP]ValueError: Tensor Tensor(""dense_3/Sigmoid:0"", shape=(?, 1), dtype=float32) is not an element of this graph.",0
"File test.py, line 4, in <module> model = load_model(""test.h5"")[SEP]File <*>python3.7/site-packages/keras/engine/saving.py, line 419, in load_model model = _deserialize_model(f, custom_objects, compile)[SEP]File <*>python3.7/site-packages/keras/engine/saving.py, line 258, in _deserialize_model .format(len(layer_names), len(filtered_layers))[SEP]ValueError: You are trying to load a weight file containing 6 layers into a model with 0 layers",0
"File test.py, line 141, in <module> max_queue_size=2)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 2177, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 147, in fit_generator generator_output = next(output_generator)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py, line 831, in get six.reraise(value.__class__, value, value.__traceback__)[SEP]File <*>python3.6/site-packages/six.py, line 693, in reraise raise value[SEP]TypeError: 'My_Generator' object is not an iterator",0
"File 6_reconstruct_alphabet_image.py, line 17, in <module> import caffe[SEP]File <*>python3/dist-packages/caffe/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer[SEP]File <*>python3/dist-packages/caffe/pycaffe.py, line 15, in <module> import caffe.io[SEP]File <*>python3/dist-packages/caffe/io.py, line 2, in <module> import skimage.io[SEP]File <*>python3/dist-packages/skimage/__init__.py, line 158, in <module> from .util.dtype import *[SEP]File <*>python3/dist-packages/skimage/util/__init__.py, line 7, in <module> from .arraycrop import crop[SEP]File <*>python3/dist-packages/skimage/util/arraycrop.py, line 8, in <module> from numpy.lib.arraypad import _validate_lengths[SEP]ImportError: cannot import name '_validate_lengths'",0
"File <*>/WorkOut.py, line 416, in <module> main()[SEP]File <*>/WorkOut.py, line 412, in main train(args, model, device, train_loader, optimizer, epoch)[SEP]File <*>/WorkOut.py, line 324, in train loss = F.nll_loss(output, target)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1788, in nll_loss .format(input.size(0), target.size(0)))[SEP]ValueError: Expected input batch_size (4) to match target batch_size (64).",0
"File <*>/pydevd.py, line 1741, in <module> main()[SEP]File <*>/pydevd.py, line 1735, in main globals = debugger.run(setup['file'], None, None, is_module)[SEP]File <*>/pydevd.py, line 1135, in run pydev_imports.execfile(file, globals, locals) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/MnistTrainer.py, line 100, in <module> main()[SEP]File <*>/MnistTrainer.py, line 92, in main mnist_trainer.train(train_steps=100, log_interval=1, save_interval=1)[SEP]File <*>/MnistTrainer.py, line 56, in train self.save_models(output_folder_path, i + 1)[SEP]File <*>/MnistTrainer.py, line 69, in save_models os.path.join(output_folder_path, 'discriminator_model_{0}.h5'.format(iteration_no)))[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 1090, in save save_model(self, filepath, overwrite, include_optimizer)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 382, in save_model _serialize_model(model, f, include_optimizer)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 83, in _serialize_model model_config['config'] = model.get_config()[SEP]File <*>python3.6/site-packages/keras/engine/sequential.py, line 278, in get_config 'config': layer.get_config()[SEP]File <*>python3.6/site-packages/keras/layers/convolutional.py, line 493, in get_config config = super(Conv2D, self).get_config()[SEP]File <*>python3.6/site-packages/keras/layers/convolutional.py, line 226, in get_config 'activation': activations.serialize(self.activation),[SEP]File <*>python3.6/site-packages/keras/activations.py, line 176, in serialize return activation.__name__[SEP]AttributeError: 'LeakyReLU' object has no attribute '__name__'",0
"File <*>python3.7/site-packages/conda/exceptions.py, line 819, in __call__ return func(*args, **kwargs)[SEP]File <*>python3.7/site-packages/conda/cli/main.py, line 78, in _main exit_code = do_call(args, p)[SEP]File <*>python3.7/site-packages/conda/cli/conda_argparse.py, line 77, in do_call exit_code = getattr(module, func_name)(args, parser)[SEP]File <*>python3.7/site-packages/conda/cli/main_update.py, line 14, in execute install(args, parser, 'update')[SEP]File <*>python3.7/site-packages/conda/cli/install.py, line 253, in install handle_txn(unlink_link_transaction, prefix, args, newenv)[SEP]File <*>python3.7/site-packages/conda/cli/install.py, line 282, in handle_txn unlink_link_transaction.execute()[SEP]File <*>python3.7/site-packages/conda/core/link.py, line 223, in execute self.verify()[SEP]File <*>python3.7/site-packages/conda/common/io.py, line 46, in decorated return f(*args, **kwds)[SEP]File <*>python3.7/site-packages/conda/core/link.py, line 200, in verify self.prepare()[SEP]File <*>python3.7/site-packages/conda/core/link.py, line 192, in prepare stp.remove_specs, stp.update_specs)[SEP]File <*>python3.7/site-packages/conda/core/link.py, line 282, in _prepare mkdir_p(transaction_context['temp_dir'])[SEP]File <*>python3.7/site-packages/conda/gateways/disk/__init__.py, line 60, in mkdir_p makedirs(path)[SEP]File <*>python3.7/os.py, line 221, in makedirs mkdir(name, mode)[SEP]PermissionError: [Errno 13] Permission denied: '/usr/share/anaconda3/.condatmp'",0
"File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.7/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.7/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: /usr/lib/libcublas.so.10.0: version `libcublas.so.10.0' not found (required by /home/techievin/.local/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)",0
"File <*>/pydevd.py, line 1758, in <module> main()[SEP]File <*>/pydevd.py, line 1752, in main globals = debugger.run(setup['file'], None, None, is_module)[SEP]File <*>/pydevd.py, line 1147, in run pydev_imports.execfile(file, globals, locals) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/deep_test_conv1d.py, line 231, in <module> main()[SEP]File <*>/deep_test_conv1d.py, line 149, in main for i, (images, labels) in enumerate(train_loader):[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 615, in __next__ batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 615, in <listcomp> batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>/deep_test_conv1d.py, line 102, in __getitem__ return self.transform(self.features[index]), self.transform(self.classes[index])[SEP]File <*>/site-packages/torchvision/transforms/transforms.py, line 60, in __call__ img = t(img)[SEP]File <*>/site-packages/torchvision/transforms/transforms.py, line 91, in __call__ return F.to_tensor(pic)[SEP]File <*>/site-packages/torchvision/transforms/functional.py, line 50, in to_tensor raise TypeError('pic should be PIL Image or ndarray. Got {}'.format(type(pic)))[SEP]TypeError: pic should be PIL Image or ndarray. Got <class 'numpy.ndarray'>",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>python3.6/site-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils[SEP]File <*>python3.6/site-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K[SEP]File <*>python3.6/site-packages/keras/backend/__init__.py, line 1, in <module> from .load_backend import epsilon[SEP]File <*>python3.6/site-packages/keras/backend/load_backend.py, line 90, in <module> from .tensorflow_backend import *[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 13, in <module> from tensorflow.python.keras.utils import tf_utils[SEP]ImportError: cannot import name 'tf_utils'",0
"File file.py, line 2, in <module> from torch.utils.data import Dataset, DataLoader[SEP]ModuleNotFoundError: No module named 'torch'",0
"File classify_in_out_tf2.py, line 81, in [FUNC] [CODE][SEP]AttributeError: 'AutoTrackable' object has no attribute 'summary'",0
"File <*>/unet_trainer.py, line 82, in <module> results = model.fit_generator(train_generator, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, validation_data=val_generator, validation_steps=VALIDATION_STEPS, callbacks=callbacks)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 1297, in fit_generator steps_name='steps_per_epoch')[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_generator.py, line 265, in model_iteration batch_outs = batch_function(*batch_data)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 973, in train_on_batch class_weight=class_weight, reset_metrics=reset_metrics)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch output_loss_metrics=model._output_loss_metrics)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch output_loss_metrics=output_loss_metrics))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 252, in _process_single_batch training=training))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 127, in _model_loss outs = model(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 891, in __call__ outputs = self.call(cast_inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 708, in call convert_kwargs_to_constants=base_layer_utils.call_context().saving)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 860, in _run_internal_graph output_tensors = layer(computed_tensors, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/layers/convolutional.py, line 197, in call outputs = self._convolution_op(inputs, self.kernel)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 1134, in __call__ return self.conv_op(inp, filter)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 639, in __call__ return self.call(inp, filter)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 238, in __call__ name=self.name)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 2010, in conv2d name=name)[SEP]File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1031, in conv2d data_format=data_format, dilations=dilations, name=name, ctx=_ctx)[SEP]File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1130, in conv2d_eager_fallback ctx=_ctx, name=name)[SEP]File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,16,1536,1536] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",0
"File <*>/3D_tf_data_generator.py, line 181, in <module> evaluation_ad = model.evaluate(ad_test, ad_test_labels, verbose=0)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 930, in evaluate use_multiprocessing=use_multiprocessing)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 490, in evaluate use_multiprocessing=use_multiprocessing, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 426, in _model_iteration use_multiprocessing=use_multiprocessing)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 646, in _process_inputs x, y, sample_weight=sample_weights)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 2383, in _standardize_user_data batch_size=batch_size)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 2489, in _standardize_tensors y, self._feed_loss_fns, feed_output_shapes)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py, line 810, in check_loss_and_target_compatibility ' while using as loss `' + loss_name + '`. '[SEP]ValueError: A target array with shape (5, 2) was passed for an output of shape (None, 1) while using as loss `binary_crossentropy`. This loss expects targets to have the same shape as the output.",0
"File <*>/rks.py, line 14, in <module> from tf.keras.preprocessing.image import ImageDataGenerator[SEP]ModuleNotFoundError: No module named 'tf'",0
"File <*>python3.6/dist-packages/torch/utils/data/_utils/worker.py, line 178, in _worker_loop data = fetcher.fetch(index)[SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp> data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <ipython-input-114-e0ccd94603fd>, line 31, in __getitem__ xs = label_data[:,0:8:2];[SEP]IndexError: too many indices for array",0
"File <*>python3.6/site-packages/uvicorn/protocols/http/httptools_impl.py, line 385, in run_asgi result = await app(self.scope, self.receive, self.send)[SEP]File <*>python3.6/site-packages/uvicorn/middleware/proxy_headers.py, line 45, in __call__ return await self.app(scope, receive, send)[SEP]File <*>python3.6/site-packages/fastapi/applications.py, line 183, in __call__ await super().__call__(scope, receive, send) # pragma: no cover[SEP]File <*>python3.6/site-packages/starlette/applications.py, line 102, in __call__ await self.middleware_stack(scope, receive, send)[SEP]File <*>python3.6/site-packages/starlette/middleware/errors.py, line 181, in __call__ raise exc from None[SEP]File <*>python3.6/site-packages/starlette/middleware/errors.py, line 159, in __call__ await self.app(scope, receive, _send)[SEP]File <*>python3.6/site-packages/starlette/exceptions.py, line 82, in __call__ raise exc from None[SEP]File <*>python3.6/site-packages/starlette/exceptions.py, line 71, in __call__ await self.app(scope, receive, sender)[SEP]File <*>python3.6/site-packages/starlette/routing.py, line 550, in __call__ await route.handle(scope, receive, send)[SEP]File <*>python3.6/site-packages/starlette/routing.py, line 227, in handle await self.app(scope, receive, send)[SEP]File <*>python3.6/site-packages/starlette/routing.py, line 41, in app response = await func(request)[SEP]File <*>python3.6/site-packages/fastapi/routing.py, line 197, in app dependant=dependant, values=values, is_coroutine=is_coroutine[SEP]File <*>python3.6/site-packages/fastapi/routing.py, line 149, in run_endpoint_function return await run_in_threadpool(dependant.call, **values)[SEP]File <*>python3.6/site-packages/starlette/concurrency.py, line 34, in run_in_threadpool return await loop.run_in_executor(None, func, *args)[SEP]File <*>python3.6/thread.py, line 56, in run result = self.fn(*self.args, **self.kwargs)[SEP]File <*>/main.py, line 155, in API_call raise e[SEP]File <*>/main.py, line 129, in API_call model = pickle.load(open('models/' + current_model, 'rb'))[SEP]File <*>python3.6/site-packages/dill/_dill.py, line 270, in load return Unpickler(file, ignore=ignore, **kwds).load()[SEP]File <*>python3.6/site-packages/dill/_dill.py, line 473, in load obj = StockUnpickler.load(self)[SEP]File <*>python3.6/site-packages/dill/_dill.py, line 463, in find_class return StockUnpickler.find_class(self, module, name)[SEP]AttributeError: Can't get attribute 'Model_II_b' on <module '__mp_main__' from '/opt/apps/env/bin/uvicorn'>",0
"File <*>/site-packages/tensorflow/python/data/util/structure.py, line 93, in normalize_element spec = type_spec_from_value(t, use_fallback=False)[SEP]File <*>/site-packages/tensorflow/python/data/util/structure.py, line 466, in type_spec_from_value (element, type(element).__name__))[SEP]TypeError: Could not build a TypeSpec for 0 Tecmo Koei 1 Nippon Ichi Software 2 Ubisoft 3 Activision 4 Atari ... 6594 Kemco 6595 Infogrames 6596 Activision 6597 7G//AMES 6598 Wanadoo Name: Publisher, Length: 6599, dtype: object with type Series",0
"File <*>/site-packages/IPython/core/interactiveshell.py, line 3331, in run_code exec(code_obj, self.user_global_ns, self.user_ns)[SEP]File <ipython-input-2-d2317d03e1c1>, line 1, in <module> runfile('F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news/bitcoin.py', wdir='F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news')[SEP]File <*>/pydev_umd.py, line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/bitcoin.py, line 41, in <module> model.fit(x=x_train, y=y_train, batch_size=64, epochs=5, shuffle=True, validation_split=0.1)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 819, in fit use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 342, in fit total_epochs=epochs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch batch_outs = execution_function(iterator)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function distributed_function(input_fn))[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__ result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 632, in _call return self._stateless_fn(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2363, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call self.captured_inputs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 545, in call ctx=ctx)[SEP]File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Condition x == y did not hold element-wise:] [x (loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [64 1] [y (loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [64 14] [[node loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news/bitcoin.py:41) ]] [Op:__inference_distributed_function_2970]",0
"File <*>/emotion.py, line 4, in <module> emotion_detector = EmotionRecognition(device='gpu', gpu_id=1)[SEP]File <*>python3.7/site-packages/facial_emotion_recognition/facial_emotion_recognition.py, line 25, in __init__ self.network = NetworkV2(in_c=1, nl=32, out_f=7).to(self.device)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 607, in to return self._apply(convert)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 354, in _apply module._apply(fn)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 376, in _apply param_applied = fn(param)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 605, in convert return t.to(device, dtype if t.is_floating_point() else None, non_blocking)[SEP]RuntimeError: CUDA error: invalid device ordinal",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/tensorflow/__init__.py, line 101, in <module> from tensorflow_core import *[SEP]File <*>/site-packages/tensorflow_core/__init__.py, line 40, in <module> from tensorflow.python.tools import module_util as _module_util[SEP]File <frozen importlib._bootstrap>, line 983, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 959, in _find_and_load_unlocked [CODE][SEP]File <*>/site-packages/tensorflow/__init__.py, line 50, in __getattr__ module = self._load()[SEP]File <*>/site-packages/tensorflow/__init__.py, line 44, in _load module = _importlib.import_module(self.__name__)[SEP]File <*>/__init__.py, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <*>/site-packages/tensorflow_core/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py, line 15, in swig_import_helper import imp[SEP]ValueError: source code string cannot contain null bytes",0
"File model_main_tf2.py, line 113, in <module> tf.compat.v1.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)[SEP]File <*>/site-packages/absl/app.py, line 303, in run _run_main(main, args)[SEP]File <*>/site-packages/absl/app.py, line 251, in _run_main sys.exit(main(argv))[SEP]File model_main_tf2.py, line 104, in main model_lib_v2.train_loop([SEP]File <*>/site-packages/object_detection/model_lib_v2.py, line 639, in train_loop loss = _dist_train_step(train_input_iter)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__ result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 840, in _call return self._stateless_fn(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2829, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1843, in _filtered_call return self._call_flat([SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1923, in _call_flat return self._build_call_outputs(self._inference_function.call([SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 545, in call outputs = execute.execute([SEP]File <*>/site-packages/tensorflow/python/eager/execute.py, line 59, in quick_execute tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found. (0) Resource exhausted: OOM when allocating tensor with shape[64,256,17,17] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[node functional_3/conv2d_160/Conv2D (defined at \site-packages\object_detection\meta_architectures\faster_rcnn_meta_arch.py:1149) ]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. [[Identity_1/_432]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. (1) Resource exhausted: OOM when allocating tensor with shape[64,256,17,17] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[node functional_3/conv2d_160/Conv2D (defined at \site-packages\object_detection\meta_architectures\faster_rcnn_meta_arch.py:1149) ]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. 0 successful operations. 0 derived errors ignored. [Op:__inference__dist_train_step_79248]",0
"File <*>/site-packages/pytorch_lightning/trainer/trainer.py, line 521, in train self.train_loop.run_training_epoch()[SEP]File <*>/site-packages/pytorch_lightning/trainer/training_loop.py, line 588, in run_training_epoch self.trainer.run_evaluation(test_mode=False)[SEP]File <*>/site-packages/pytorch_lightning/trainer/trainer.py, line 613, in run_evaluation self.evaluation_loop.log_evaluation_step_metrics(output, batch_idx)[SEP]File <*>/site-packages/pytorch_lightning/trainer/evaluation_loop.py, line 346, in log_evaluation_step_metrics self.__log_result_step_metrics(step_log_metrics, step_pbar_metrics, batch_idx)[SEP]File <*>/site-packages/pytorch_lightning/trainer/evaluation_loop.py, line 350, in __log_result_step_metrics cached_batch_pbar_metrics, cached_batch_log_metrics = cached_results.update_logger_connector()[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 378, in update_logger_connector batch_log_metrics = self.get_latest_batch_log_metrics()[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 418, in get_latest_batch_log_metrics batch_log_metrics = self.run_batch_from_func_name(""get_batch_log_metrics"")[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 414, in run_batch_from_func_name results = [func(include_forked_originals=False) for func in results][SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 414, in <listcomp> results = [func(include_forked_originals=False) for func in results][SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 122, in get_batch_log_metrics return self.run_latest_batch_metrics_with_func_name(""get_batch_log_metrics"", *args, **kwargs)[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 115, in run_latest_batch_metrics_with_func_name for dl_idx in range(self.num_dataloaders)[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 115, in <listcomp> for dl_idx in range(self.num_dataloaders)[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 100, in get_latest_from_func_name results.update(func(*args, add_dataloader_idx=add_dataloader_idx, **kwargs))[SEP]File <*>/site-packages/pytorch_lightning/core/step_result.py, line 298, in get_batch_log_metrics result[dl_key] = self[k]._forward_cache.detach()[SEP]AttributeError: 'NoneType' object has no attribute 'detach'",0
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 64, in <module> from tensorflow.python._pywrap_tensorflow_internal import *[SEP]ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.",0
"File <stdin>, line 24, in <module> [CODE][SEP]TypeError: expected CPU (got CUDA)",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/smdistributed/dataparallel/__init__.py, line 16, in <module> import smddpcommon as hc[SEP]ImportError: libc10.so: cannot open shared object file: No such file or directory",0
"File [FILE], line 5, in <module>() z = x + y[SEP]File <*>python3.4/site-packages/theano/tensor/var.py, line 128, in __add__(self, other) return theano.tensor.basic.add(self, other)[SEP]File <*>python3.4/site-packages/theano/gof/op.py, line 525, in __call__(self, *inputs, **kwargs) raise ValueError('Cannot compute test value: input %i (%s) of Op %s missing default value' % (i, ins, node))[SEP]ValueError: Cannot compute test value: input 0 (x) of Op Elemwise{add,no_inplace}(x, y) missing default value",0
"File [FILE], line 19, in <module>() rotate_x_axis_theano = theano.function([angle_var],rotate_x_axis_expr(angle_var))[SEP]File [FILE], line 14, in rotate_x_axis_expr(angle) R[1][1] = cosa; R[1][2] = -sina[SEP]TypeError: 'TensorVariable' object does not support item assignment",0
"File [FILE], line 2, in <module>() sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 340, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 564, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_string, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 637, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) target_list, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 659, in _do_call(self, fn, *args) e.code)[SEP]InternalError: Blas SGEMM launch failed : a.shape=(100, 784), b.shape=(784, 10), m=100, n=10, k=784 [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_Placeholder_0/_4, Variable/read)]]",0
"File [FILE], line 1, in <module>() biases = tf.get_variable('biases', [64], tf.constant_initializer(0.0))[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 732, in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape) partitioner=partitioner, validate_shape=validate_shape)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 596, in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape) partitioner=partitioner, validate_shape=validate_shape)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 161, in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape) caching_device=caching_device, validate_shape=validate_shape)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 425, in _get_single_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, validate_shape) dtype = dtypes.as_dtype(dtype)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/dtypes.pyc, line 536, in as_dtype(type_value) if key == type_value:[SEP]TypeError: data type not understood",0
"File [FILE], line 7, in <module>() input_map={'import/pool5':out_pool})[SEP]File <*>python3.4/dist-packages/tensorflow/python/framework/importer.py, line 335, in import_graph_def(graph_def, input_map, return_elements, name, op_dict) ops.set_shapes_for_outputs(op)[SEP]File <*>python3.4/dist-packages/tensorflow/python/framework/ops.py, line 1612, in set_shapes_for_outputs(op) shapes = shape_func(op)[SEP]File <*>/roi_pooling_op_grad.py, line 15, in _roi_pool_shape(op) dims_rois = op.inputs[1].get_shape().as_list()[SEP]File <*>python3.4/dist-packages/tensorflow/python/framework/tensor_shape.py, line 747, in as_list(self) return [dim.value for dim in self._dims][SEP]TypeError: 'NoneType' object is not iterable",0
"File <*>python3.6/dist-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn) input_tensors_as_shapes, status)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]InvalidArgumentError: Negative dimension size caused by subtracting 3 from 1 for 'conv1d_26/convolution/Conv2D' (op: 'Conv2D') with input shapes: [?,1,1,256], [1,3,256,256].",0
"File [FILE], line 35, in <module>() mean , variance = tf.nn.moments(X_train, axes = 1, keep_dims = True)[SEP]File <*>python2.7/nn_impl.pyc, line 666, in moments(x, axes, shift, name, keep_dims) y = math_ops.cast(x, dtypes.float32) if x.dtype == dtypes.float16 else x[SEP]TypeError: data type not understood",0
"File [FILE], line [NUM], in () [CODE][SEP]File [FILE], line [NUM], in [FUNC] [CODE][SEP]File <*>python3.6/site-packages/torch/autograd/variable.py, line [NUM], in setitem(self, key, value) [CODE][SEP]RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata) status, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]InvalidArgumentError: You must feed a value for placeholder tensor 'time_distributed_2_target' with dtype float and shape [?,?,?] [[Node: time_distributed_2_target = Placeholder[dtype=DT_FLOAT, shape=[?,?,?], _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1322, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1307, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1409, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata)[SEP]InvalidArgumentError: slice index 0 of dimension 0 out of bounds. [[Node: lstm_25/strided_slice_13 = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](lstm_25/transpose, loss_11/dense_58_loss/Const_2, lstm_25/strided_slice_9/stack_2, lstm_25/strided_slice_9/stack_2)]]",0
"File [FILE], line 2, in <module>() steps_per_epoch=1, epochs=15, verbose=2)[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/engine/training.py, line 2230, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1877, in train_on_batch(self, x, y, sample_weight, class_weight) class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1480, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size) exception_prefix='target')[SEP]File <*>/site-packages/keras/engine/training.py, line 76, in _standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data][SEP]File <*>/site-packages/keras/engine/training.py, line 76, in <listcomp>(.0) data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data][SEP]AttributeError: 'Tensor' object has no attribute 'ndim'",0
"File [FILE], line 2, in <module>() grid = torchvision.utils.make_grid(w.permute(0,2,3,1), nrow=5)[SEP]File <*>python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/utils.py, line 85, in make_grid(tensor, nrow, padding, normalize, range, scale_each, pad_value) .copy_(tensor[k])[SEP]RuntimeError: The expanded size of the tensor (3) must match the existing size (640) at non-singleton dimension 0",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1330, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1315, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1423, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) status, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]FailedPreconditionError: Attempting to use uninitialized value W_4 [[Node: W_4/read = Identity[T=DT_FLOAT, _class=[""loc:@W_4""], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](W_4)]]",0
"File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1334, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1319, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1407, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata)[SEP]UnimplementedError: File system scheme '[local]' not implemented (file: 'checkpointsBook2Vec5Inputs') [[{{node save/SaveV2}} = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, embeddings, embeddings/Shampoo, embeddings/Shampoo_1, embeddings/Shampoo_2, epochCount, softmax_biases, softmax_weights, softmax_weights/Shampoo, softmax_weights/Shampoo_1, softmax_weights/Shampoo_2)]]",0
"File [FILE], line 50, in <module>() save_path = saver.save(session, ""checkpointsBook2Vec5Inputs/Research2VecCS4.ckpt"") #Save checkpoint[SEP]File <*>python3.6/dist-packages/tensorflow/python/training/saver.py, line 1441, in save(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs) {self.saver_def.filename_tensor_name: checkpoint_file})[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 929, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1152, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1328, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1348, in _do_call(self, fn, *args) raise type(e)(node_def, op, message)[SEP]UnimplementedError: File system scheme '[local]' not implemented (file: 'checkpointsBook2Vec5Inputs') [[node save/SaveV2 (defined at <ipython-input-15-c14caac2081d>:45) = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, embeddings, embeddings/Shampoo, embeddings/Shampoo_1, embeddings/Shampoo_2, epochCount, softmax_biases, softmax_weights, softmax_weights/Shampoo, softmax_weights/Shampoo_1, softmax_weights/Shampoo_2)]]",0
"File [FILE], line 3, in <module>() steps=10)[SEP]File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 354, in train(self, input_fn, hooks, steps, max_steps, saving_listeners) loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1207, in _train_model(self, input_fn, hooks, saving_listeners) return self._train_model_default(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1237, in _train_model_default(self, input_fn, hooks, saving_listeners) features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)[SEP]File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1195, in _call_model_fn(self, features, labels, mode, config) model_fn_results = self._model_fn(features=features, **kwargs)[SEP]File [FILE], line 35, in my_model(features, labels, mode, params) num_classes=vocabulary_size))[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1248, in nce_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name) name=name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1031, in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed) if labels.dtype != dtypes.int64:[SEP]TypeError: data type not understood",0
"File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 511, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1175, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 304, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 245, in constant(value, dtype, shape, name) allow_broadcast=True)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast))[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/tensor_util.py, line 454, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) raise ValueError(""None values not supported."")[SEP]ValueError: None values not supported.",0
"File [FILE], line 1, in () output = model(data)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line [NUM], in call(self, *input, **kwargs) [CODE][SEP]File <*>python3.6/dist-packages/torch/nn/functional.py, line 1354, in linear(input, weight, bias) output = input.matmul(weight.t())[SEP]RuntimeError: size mismatch, m1: [3584 x 28], m2: [784 x 128] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:940",0
"File [FILE], line 6, in <module>() print(char_OneHotEncoding(torch.tensor(x_train, dtype=torch.long).cuda()).shape)[SEP]File [FILE], line 4, in char_OneHotEncoding(x) coded[:,i] = scatter(x[:,i])[SEP]File [FILE], line 9, in scatter(x) return torch.zeros(x.shape[0], 101).scatter_(1, x.view(-1,1), 1)[SEP]RuntimeError: Expected object of backend CPU but got backend CUDA for argument #3 'index'",0
"File [FILE], line 1, in <module> model.fit(dataset, epochs=10, steps_per_epoch=10)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 791, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1515, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch')[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 257, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) batch_outs = batch_function(*batch_data)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1238, in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics) extract_tensors_from_dataset=True)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 2596, in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset) exception_prefix='input')[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 349, in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) str(data_shape))[SEP]ValueError: Error when checking input: expected input_1 to have shape (32,) but got array with shape (1,)",0
"File [FILE], line 32, in <module> loss = loss_func(output, b_y)[SEP]File <*>python3.5/site-packages/torch/nn/modules/module.py, line 489, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.5/site-packages/torch/nn/modules/loss.py, line 504, in forward(self, input, target) return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)[SEP]File <*>python3.5/site-packages/torch/nn/functional.py, line 2027, in binary_cross_entropy(input, target, weight, size_average, reduce, reduction) input, target, weight, reduction_enum)[SEP]RuntimeError: Expected object of scalar type Float but got scalar type Long for argument #2 'target'",0
"File [FILE], line 27, in <module>() grads = sess.run(d_fx)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 929, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1137, in _run(self, handle, fetches, feed_dict, options, run_metadata) self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 471, in __init__(self, graph, fetches, feeds, feed_handles) self._fetch_mapper = _FetchMapper.for_fetch(fetches)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 258, in for_fetch(fetch) type(fetch)))[SEP]TypeError: Fetch argument None has invalid type <class 'NoneType'>",0
"File [FILE], line 42, in <module> autoencoder.compile(optimizer='adadelta', loss=[custom_loss1,custom_loss2])[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 342, in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs) sample_weight, mask)[SEP]File <*>python3.6/site-packages/keras/engine/training_utils.py, line 404, in weighted(y_true, y_pred, weights, mask) score_array = fn(y_true, y_pred)[SEP]File [FILE], line 4, in custom_loss1(y_true, y_pred) dcor = -1*distance_correlation(y_true,encoded_layer)[SEP]File [FILE], line 4, in distance_correlation(y_true, y_pred) pred_d = pred_r - 2*tf.matmul(y_pred,tf.transpose(y_pred))+tf.transpose(pred_r)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/math_ops.py, line 2417, in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name) a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py, line 1423, in batch_mat_mul(x, y, adj_x, adj_y, name) ""BatchMatMul"", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 788, in _apply_op_helper(self, op_type_name, name, **keywords) op_def=op_def)[SEP]File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3300, in create_op(***failed resolving arguments***) op_def=op_def)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1823, in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def) control_input_ops)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1662, in _create_c_op(graph, node_def, inputs, control_inputs) raise ValueError(str(e))[SEP]ValueError: Dimensions must be equal, but are 1 and 64 for 'loss_1/zero_padding2d_5_loss/MatMul' (op: 'BatchMatMul') with input shapes: [?,64,64,1], [1,64,64,?].",0
"File [FILE], line 23, in <module> optimizer = nlp.resume_training()[SEP]TypeError: Model() got multiple values for argument 'nr_class'",0
"File [FILE], line 29, in <module> global_loss_list = global_training(lstm2)[SEP]File [FILE], line 5, in global_training(optimizee) _, global_loss_1 = learn2(LSTM_Optimizee, training_steps, retain_graph_flag=True, reset_theta=True)[SEP]File [FILE], line 45, in learn2(optimizee, unroll_train_steps, retain_graph_flag, reset_theta) loss.backward(retain_graph = retain_graph_flag) #The default is False, when the optimized LSTM is set to True[SEP]File <*>python3.7/site-packages/torch/tensor.py, line 118, in backward(self, gradient, retain_graph, create_graph) torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>python3.7/site-packages/torch/autograd/__init__.py, line 93, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables) allow_unreachable=True) # allow_unreachable flag[SEP]RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 10]] is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",0
"File [FILE], line [NUM], in <module> [CODE][SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 458, in load_wrapper(*args, **kwargs) return load_function(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 550, in load_model(filepath, custom_objects, compile) model = _deserialize_model(h5dict, custom_objects, compile)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 292, in _deserialize_model(h5dict, custom_objects, compile) reshape=False)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 811, in convert_nested_model(weights) original_backend=original_backend))[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 823, in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape) weights = convert_nested_model(weights)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 799, in convert_nested_model(weights) original_backend=original_backend))[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 942, in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape) weights[0] = np.transpose(weights[0], (3, 2, 0, 1))[SEP]File <*>python3.6/site-packages/numpy/core/fromnumeric.py, line 639, in transpose(a, axes) return _wrapfunc(a, 'transpose', axes)[SEP]File <*>python3.6/site-packages/numpy/core/fromnumeric.py, line 56, in _wrapfunc(obj, method, *args, **kwds) return getattr(obj, method)(*args, **kwds)[SEP]ValueError: axes don't match array",0
"File [FILE], line 8, in <module> train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](root='./.data', ngrams=NGRAMS, vocab=None)[SEP]File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 170, in AG_NEWS(*args, **kwargs) return _setup_datasets(*((""AG_NEWS"",) + args), **kwargs)[SEP]File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 128, in _setup_datasets(dataset_name, root, ngrams, vocab, include_unk) vocab = build_vocab_from_iterator(_csv_iterator(train_csv_path, ngrams))[SEP]File <*>python36/site-packages/torchtext/vocab.py, line 557, in build_vocab_from_iterator(iterator) for tokens in iterator:[SEP]File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 35, in _csv_iterator(data_path, ngrams, yield_cls) for row in reader:[SEP]File <*>python36/site-packages/torchtext/utils.py, line 130, in unicode_csv_reader(unicode_csv_data, **kwargs) csv.field_size_limit(sys.maxsize)[SEP]OverflowError: Python int too large to convert to C long",0
"File <*>python3.6/dist-packages/pandas/core/indexes/base.py, line 2657, in get_loc(self, key, method, tolerance) return self._engine.get_loc(key)[SEP]File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE][SEP]File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE][SEP]KeyError: 'filename'",0
"File [FILE], line 20, in <module> subset='training')[SEP]File <*>python3.6/dist-packages/keras/preprocessing/image.py, line 594, in flow_from_dataframe(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs) **kwargs[SEP]File <*>python3.6/dist-packages/keras/preprocessing/image.py, line 235, in __init__(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames) validate_filenames=validate_filenames)[SEP]File <*>python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py, line 129, in __init__(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames) self._check_params(df, x_col, y_col, weight_col, classes)[SEP]File <*>python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py, line 181, in _check_params(self, df, x_col, y_col, weight_col, classes) if not all(df[x_col].apply(lambda x: isinstance(x, str))):[SEP]File <*>python3.6/dist-packages/pandas/core/frame.py, line 2927, in __getitem__(self, key) indexer = self.columns.get_loc(key)[SEP]File <*>python3.6/dist-packages/pandas/core/indexes/base.py, line 2659, in get_loc(self, key, method, tolerance) return self._engine.get_loc(self._maybe_cast_indexer(key))[SEP]File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE][SEP]File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE][SEP]KeyError: 'filename'",0
"File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 2, in [FUNC] from tensorboard.summary.writer.record_writer import RecordWriter # noqa F401[SEP]ModuleNotFoundError: No module named 'tensorboard.summary'; 'tensorboard' is not a package",0
"File [FILE], line 9, in <module>() train(test_net, train_loader, 10, batch_size, optimiser, clip, criterion)[SEP]File [FILE], line 59, in train(SNN, dataloader, epochs, batch_size, optimiser, clip, criterion) loss = criterion(output1, output2, labels)[SEP]File [FILE], line 51, in forward(self, output1, output2, labels) pred, loss = estimate_loss(self.d)[SEP]File [FILE], line 45, in estimate_loss(forward) distance = dimensional_reduction(self.d)[SEP]File [FILE], line 38, in dimensional_reduction(forward) self.d = self.linear(self.d)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/linear.py, line 87, in forward(self, input) return F.linear(input, self.weight, self.bias)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1370, in linear(input, weight, bias) ret = torch.addmm(bias, input, weight.t())[SEP]RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_addmm",0
"File [FILE], line 1001, in <module>() train_step(group, inp, tar, label)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializer_map)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize(self, args, kwds, add_initializers_to) *args, **kwds))[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py, line 905, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]ValueError: in converted code: <ipython-input-1-81054f0385cb>:856 train_step * optimizer.apply_gradients(zip(gradients, transformer.trainable_variables)) /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:427 apply_gradients grads_and_vars = _filter_grads(grads_and_vars) /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:1025 _filter_grads ([v.name for _, v in grads_and_vars],)) ValueError: No gradients provided for any variable: ['transformer_1/encoder_1/embedding_2/embeddings:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_98/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_98/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_99/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_99/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_100/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_100/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_101/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_101/bias:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_102/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_102/bias:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_103/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_103/bias:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_30/gamma:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_30/beta:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_31/gamma:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_31/beta:0', 'transformer_1/encoder_1/encoder_layer_7/multi_head_attention_19/dense_104/kernel:0', 'transformer_1/encoder_1/encoder...",0
"File [FILE], line 2, in <module> model = make_feed_forward_model()[SEP]File [FILE], line 20, in make_feed_forward_model() dense_layer_1 = tf.keras.layers.Dense(HPARAMS.num_fc_units, activation='relu')(inputs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 616, in __call__(self, inputs, *args, **kwargs) self._maybe_build(inputs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1966, in _maybe_build(self, inputs) self.build(input_shapes)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/core.py, line 1005, in build(self, input_shape) raise ValueError('The last dimension of the inputs to `Dense` '[SEP]ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.",0
"File [FILE], line 19, in <module> transformed_dataset, transform_fn = (raw_dataset | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))[SEP]File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 863, in expand(self, dataset) dataset | 'AnalyzeDataset' >> AnalyzeDataset(self._preprocessing_fn))[SEP]File <*>python3.7/site-packages/apache_beam/transforms/ptransform.py, line 989, in __ror__(self, pvalueish, _unused) return self.transform.__ror__(pvalueish, self.label)[SEP]File <*>python3.7/site-packages/apache_beam/transforms/ptransform.py, line 549, in __ror__(self, left, label) result = p.apply(self, pvalueish, label)[SEP]File <*>python3.7/site-packages/apache_beam/pipeline.py, line 536, in apply(self, transform, pvalueish, label) return self.apply(transform, pvalueish)[SEP]File <*>python3.7/site-packages/apache_beam/pipeline.py, line 577, in apply(self, transform, pvalueish, label) pvalueish_result = self.runner.apply(transform, pvalueish, self._options)[SEP]File <*>python3.7/site-packages/apache_beam/runners/runner.py, line 195, in apply(self, transform, input, options) return m(transform, input, options)[SEP]File <*>python3.7/site-packages/apache_beam/runners/runner.py, line 225, in apply_PTransform(self, transform, input, options) return transform.expand(input)[SEP]File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 810, in expand(self, dataset) None, input_metadata))[SEP]File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 683, in expand(self, dataset) output_signature = self._preprocessing_fn(copied_inputs)[SEP]File [FILE], line 11, in preprocessing_fn(inputs) tf.constant(value, shape=outputs[key].shape),[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/constant_op.py, line 258, in constant(value, dtype, shape, name) allow_broadcast=True)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/constant_op.py, line 296, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py, line 448, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) if shape is not None and np.prod(shape, dtype=np.int64) == 0:[SEP]File [FILE], line [NUM], in prod(*args, **kwargs) [CODE][SEP]File <*>python3.7/site-packages/numpy/core/fromnumeric.py, line 2962, in prod(a, axis, dtype, out, keepdims, initial, where) keepdims=keepdims, initial=initial, where=where)[SEP]File <*>python3.7/site-packages/numpy/core/fromnumeric.py, line 90, in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs) return ufunc.reduce(obj, axis, dtype, out, **passkwargs)[SEP]TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'",0
"File [FILE], line 13, in <module> loss = criterion(output, labels)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 532, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/loss.py, line 204, in forward(self, input, target) return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1838, in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction) ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)[SEP]RuntimeError: expected scalar type Long but found Float",0
"File [FILE], line 7, in <module>() print(x[tensor(0)])[SEP]KeyError: tensor(0)",0
"File [FILE], line 8, in <module>() callbacks=[ccall, esd3][SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 813, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) callbacks.on_epoch_end(epoch, epoch_logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 365, in on_epoch_end(self, epoch, logs) callback.on_epoch_end(epoch, logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 1485, in on_epoch_end(self, epoch, logs) self.model.set_weights(self.best_weights)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 1519, in set_weights(self, weights) if expected_num_weights != len(weights):[SEP]TypeError: object of type 'NoneType' has no len()",0
"File [FILE], line 58, in <module>() optimizer.step()[SEP]File <*>python3.6/dist-packages/torch/autograd/grad_mode.py, line 15, in decorate_context(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/torch/optim/adam.py, line 99, in step(self, closure) exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)[SEP]RuntimeError: expected device cpu but got device cuda:0",0
"File [FILE], line 4, in <module>() model = encoder_model(k)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1113, in op(self) ""Tensor.op is meaningless when eager execution is enabled."")[SEP]AttributeError: Tensor.op is meaningless when eager execution is enabled.",0
"File <*>/site-packages/tensorflow_core/python/client/session.py, line 1365, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1350, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) target_list, run_metadata)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1443, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata)[SEP]InvalidArgumentError: indices[24,0] = 335 is not in [0, 304) [[{{node user-embedding-mlp_1/GatherV2}}]]",0
"File [FILE], line 29, in <module> interpreter.allocate_tensors()[SEP]File <*>/interpreter.py, line 242, in allocate_tensors(self) return self._interpreter.AllocateTensors()[SEP]File <*>/tensorflow_wrap_interpreter_wrapper.py, line 110, in AllocateTensors(self) return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)[SEP]RuntimeError: tensorflow/lite/kernels/reshape.cc:66 num_input_elements != num_output_elements (1536 != 768)Node number 3 (RESHAPE) failed to prepare.",0
"File [FILE], line 1, in <module> output = encoder(src, src_mask)[SEP]File <*>python3.7/site-packages/torch/nn/modules/transformer.py, line 167, in forward(self, src, mask, src_key_padding_mask) src_key_padding_mask=src_key_padding_mask)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 547, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.7/site-packages/torch/nn/modules/transformer.py, line 266, in forward(self, src, src_mask, src_key_padding_mask) key_padding_mask=src_key_padding_mask)[0][SEP]File <*>python3.7/site-packages/torch/nn/modules/activation.py, line 783, in forward(self, query, key, value, key_padding_mask, need_weights, attn_mask) attn_mask=attn_mask)[SEP]File <*>python3.7/site-packages/torch/nn/functional.py, line 3252, in multi_head_attention_forward(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v) attn_output_weights += attn_mask[SEP]RuntimeError: The size of tensor a (20) must match the size of tensor b (95) at non-singleton dimension 2",0
"File [FILE], line 21, in <module>() history = m.fit([X, y, W], y, epochs=10)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 819, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 235, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 593, in _process_training_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing) use_multiprocessing=use_multiprocessing)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 646, in _process_inputs(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing) x, y, sample_weight=sample_weights)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 2383, in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset) batch_size=batch_size)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 2469, in _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size) exception_prefix='target')[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_utils.pyc, line 496, in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) 'expected no data, but got:', data)[SEP]ValueError: ('Error when checking model target: expected no data, but got:', array([3.39102071e-01, 1.23122638e-01, 7.54209531e-01, 8.10110230e-01,",0
"File [FILE], line 4, in <module>() y_true = np.argmax(testdata, axis=1)[SEP]File [FILE], line [NUM], in argmax(*args, **kwargs) [CODE][SEP]File <*>python3.6/dist-packages/numpy/core/fromnumeric.py, line 47, in _wrapit(obj, method, *args, **kwds) result = getattr(asarray(obj), method)(*args, **kwds)[SEP]AxisError: axis 1 is out of bounds for array of dimension 1",0
"File [FILE], line 2, in <module> model.save(""network.h5"")[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 1008, in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options) signatures, options)[SEP]File <*>/site-packages/tensorflow_core/python/keras/saving/save.py, line 99, in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options) (h5py is not None and isinstance(filepath, h5py.File)) or[SEP]AttributeError: module 'h5py' has no attribute 'File'",0
"File [FILE], line 22, in [FUNC] train_iter.next()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 345, in __next__(self) data = self._next_data()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 385, in _next_data(self) data = self._dataset_fetcher.fetch(index) # may raise StopIteration[SEP]File <*>/site-packages/torch/utils/data/_utils/fetch.py, line 47, in fetch(self, possibly_batched_index) return self.collate_fn(data)[SEP]File <*>/site-packages/torch/utils/data/_utils/collate.py, line 79, in default_collate(batch) return [default_collate(samples) for samples in transposed][SEP]File <*>/site-packages/torch/utils/data/_utils/collate.py, line 79, in (.0) return [default_collate(samples) for samples in transposed][SEP]File <*>/site-packages/torch/utils/data/_utils/collate.py, line 81, in default_collate(batch) raise TypeError(default_collate_err_msg_format.format(elem_type))[SEP]TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found",0
"File [FILE], line 27, in <module> loss = criterion(pred, y)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 550, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.7/site-packages/torch/nn/modules/loss.py, line 432, in forward(self, input, target) return F.mse_loss(input, target, reduction=self.reduction)[SEP]File <*>python3.7/site-packages/torch/nn/functional.py, line 2530, in mse_loss(input, target, size_average, reduce, reduction) if not (target.size() == input.size()):[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 594, in __getattr__(self, name) type(self).__name__, name))[SEP]AttributeError: 'UNet3D' object has no attribute 'size'",0
"File [FILE], line 1, in <module> writer.add_graph(net, images)[SEP]File <*>/site-packages/tensorboardX/writer.py, line 793, in add_graph(self, model, input_to_model, verbose) from torch.utils.tensorboard._pytorch_graph import graph[SEP]File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 4, in <module> raise ImportError('TensorBoard logging requires TensorBoard version 1.15 or above')[SEP]ImportError: TensorBoard logging requires TensorBoard version 1.15 or above",0
"File [FILE], line 3, in <module> shap_values = explainer.shap_values(X_train)[SEP]File <*>/site-packages/shap/explainers/deep/__init__.py, line 119, in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity) return self.explainer.shap_values(X, ranked_outputs, output_rank_order, check_additivity=check_additivity)[SEP]File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 304, in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity) sample_phis = self.run(self.phi_symbolic(feature_ind), self.model_inputs, joint_input)[SEP]File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 361, in run(self, out, model_inputs, X) return self.execute_with_overridden_gradients(anon)[SEP]File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 397, in execute_with_overridden_gradients(self, f) out = f()[SEP]File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 357, in anon() final_out = out(inputs)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 823, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializers)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 696, in _initialize(self, args, kwds, add_initializers_to) self._stateful_fn._get_concrete_function_internal_garbage_collected( # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2855, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 3213, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 3065, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) func_graph_module.func_graph_from_py_func([SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 986, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 600, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 973, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]StagingError: in user code: C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\shap\explainers\deep\deep_tf.py:244 grad_graph * x_grad = tape.gradient(out, shap_rAnD) C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\backprop.py:1067 gradient ** flat_grad = imperative_grad.imperative_grad( C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\imperative_grad.py:71 imperative_grad return pywrap_tfe.TFE_Py_TapeGradient( C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\backprop.py:151 _gradient_function grad_fn = ops._gradient_registry.lookup(op_name) # pylint: disable=protected-access C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\framework\registry.py:96 lookup raise LookupError( LookupError: gradient registry has no entry for: shap_TensorListStack",0
"File [FILE], line 8, in <module> optimization.train(x_train, y_train, x_val, y_val,[SEP]File [FILE], line 70, in train(self, x_train, y_train, x_val, y_val, batch_size, n_epochs, dropout, do_teacher_forcing) y_pred = self._predict(x_batch, y_batch, seq_len, do_teacher_forcing)[SEP]File [FILE], line 95, in _predict(self, x_batch, y_batch, seq_len, do_teacher_forcing) y_pred = self.model(x_batch)[SEP]File [FILE], line 19, in forward(self, input, future, y) h_t, c_t = self.lstm(input_t, (h_t, c_t))[SEP]File <*>/site-packages/torch/nn/modules/module.py, line 727, in _call_impl(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>/site-packages/torch/nn/modules/rnn.py, line 965, in forward(self, input, hx) self.check_forward_input(input)[SEP]File <*>/site-packages/torch/nn/modules/rnn.py, line 791, in check_forward_input(self, input) raise RuntimeError([SEP]RuntimeError: input has inconsistent input_size: got 1, expected 3",0
"File [FILE], line 16, in <module>() results = p.map(X_power_func, range(8))[SEP]File <*>python3.6/pool.py, line 644, in get(self, timeout) raise self._value[SEP]RuntimeError: CUDA error: initialization error",0
"File [FILE], line 7, in <module>() validation_steps = valid_step , callbacks = [metrics], verbose=2)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 673, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 1433, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch')[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py, line 331, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) callbacks.on_epoch_end(epoch, epoch_logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 311, in on_epoch_end(self, epoch, logs) callback.on_epoch_end(epoch, logs)[SEP]File [FILE], line 16, in on_epoch_end(self, batch, logs) X_val, y_val = self.validation_data[0], self.validation_data[1][SEP]TypeError: 'NoneType' object is not subscriptable",0
