Templates,label
"File <*>python3.5/site-packages/theano/gof/opt.py, line 1772, in process_node replacements = lopt.transform(node)[SEP]File <*>python3.5/site-packages/theano/sandbox/gpuarray/opt.py, line 140, in local_opt new_op = maker(node, context_name)[SEP]File <*>python3.5/site-packages/theano/sandbox/gpuarray/opt.py, line 732, in local_gpua_hgemm if nvcc_compiler.nvcc_version < '7.5':[SEP]TypeError: unorderable types: NoneType() < str()",1
"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: No module named data_utils",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/prettytensor-0.6.0-py2.7.egg/prettytensor/__init__.py, line 25, in <module> from prettytensor import funcs[SEP]File <*>python2.7/site-packages/prettytensor-0.6.0-py2.7.egg/prettytensor/funcs.py, line 25, in <module> from prettytensor.pretty_tensor_image_methods import *[SEP]File <*>python2.7/site-packages/prettytensor-0.6.0-py2.7.egg/prettytensor/pretty_tensor_image_methods.py, line 20, in <module> from prettytensor import layers[SEP]ImportError: cannot import name layers",1
"File <pyshell#0>, line 1, in <module> from keras.layers import Dense[SEP]ImportError: cannot import name 'Dense'",1
"File [FILE], line 4, in `<module>`() tf.global_variables_initializer().run()[SEP]AttributeError: 'module' object has no attribute 'global_variables_initializer'",1
"File [FILE], line 1, in <module>() import keras[SEP]File <*>python3.5/site-packages/keras/__init__.py, line 2, in <module>() from . import backend[SEP]File <*>python3.5/site-packages/keras/backend/__init__.py, line 69, in <module>() from .tensorflow_backend import *[SEP]File <*>python3.5/site-packages/keras/backend/tensorflow_backend.py, line 7, in <module>() import tensorflow.contrib.ctc as ctc[SEP]ImportError: No module named 'tensorflow.contrib.ctc'",1
"File [FILE], line 1, in <module>() writer = tf.train.FileWriter('./my_graph', sess.graph)[SEP]AttributeError: 'module' object has no attribute 'FileWriter'",1
"File <*>python3.6/site-packages/theano/gof/opt.py, line 1772, in process_node replacements = lopt.transform(node)[SEP]File <*>python3.6/site-packages/theano/tensor/opt.py, line 5825, in constant_folding no_recycling=[])[SEP]File <*>python3.6/site-packages/theano/gof/op.py, line 970, in make_thunk no_recycling)[SEP]File <*>python3.6/site-packages/theano/gof/op.py, line 879, in make_c_thunk output_storage=node_output_storage)[SEP]File <*>python3.6/site-packages/theano/gof/cc.py, line 1200, in make_thunk keep_lock=keep_lock)[SEP]File <*>python3.6/site-packages/theano/gof/cc.py, line 1143, in __compile__ keep_lock=keep_lock)[SEP]File <*>python3.6/site-packages/theano/gof/cc.py, line 1595, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock)[SEP]File <*>python3.6/site-packages/theano/gof/cmodule.py, line 1142, in module_from_key module = lnk.compile_cmodule(location)[SEP]File <*>python3.6/site-packages/theano/gof/cc.py, line 1506, in compile_cmodule preargs=preargs)[SEP]File <*>python3.6/site-packages/theano/gof/cmodule.py, line 2213, in compile_str return dlimport(lib_filename)[SEP]File <*>python3.6/site-packages/theano/gof/cmodule.py, line 299, in dlimport rval = __import__(module_name, {}, {}, [module_name])[SEP]ImportError: /home/puck/.theano/compiledir_Linux-4.4--MANJARO-x86_64-with-glibc2.2.5--3.6.0-64/tmpre6vph8g/mdb219947724f79219f7dbd36f0f52c77.so: undefined symbol: _ZdlPvm",1
"File <*>/running_template.py, line 65, in <module> cytoplasm_predictions = run_models_on_directory(data_location,cyto_channel_names, cyto_location, model_fn = cyto_fn,list_of_weights = list_of_cyto_weights, image_size_x = image_size_x, image_size_y = image_size_y,win_x = win_cyto, win_y = win_cyto, std = False, split = False)[SEP]File <*>/cnn_functions.py, line 1491, in run_models_on_directory model = model_fn(batch_input_shape = batch_input_shape, n_features = n_features, weights_path = list_of_weights[0])[SEP]File <*>/model_zoo.py, line 528, in sparse_bn_feature_net_61x61 model.add(sparse_Convolution2D(64, 3, 3, d = d, init = init, batch_input_shape = batch_input_shape, border_mode='valid', W_regularizer = l2(reg)))[SEP]File <*>python2.7/site-packages/keras/models.py, line 436, in add layer(x)[SEP]File <*>python2.7/site-packages/keras/engine/topology.py, line 569, in __call__ self.build(input_shapes[0])[SEP]File <*>/cnn_functions.py, line 1012, in build self.W = self.init(self.W_shape, name='{}_W'.format(self.name))[SEP]TypeError: __call__() got an unexpected keyword argument 'name'",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/keras/models.py, line 243, in load_model model = model_from_config(model_config, custom_objects=custom_objects)[SEP]File <*>python3.6/site-packages/keras/models.py, line 317, in model_from_config return layer_module.deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.6/site-packages/keras/layers/__init__.py, line 55, in deserialize printable_module_name='layer')[SEP]File <*>python3.6/site-packages/keras/utils/generic_utils.py, line 143, in deserialize_keras_object list(custom_objects.items())))[SEP]File <*>python3.6/site-packages/keras/models.py, line 1352, in from_config layer = layer_module.deserialize(conf, custom_objects=custom_objects)[SEP]File <*>python3.6/site-packages/keras/utils/generic_utils.py, line 145, in deserialize_keras_object return cls.from_config(config['config'])[SEP]File <*>python3.6/site-packages/keras/engine/topology.py, line 1269, in from_config return cls(**config)[SEP]File <*>python3.6/site-packages/keras/layers/core.py, line 483, in __init__ super(Flatten, self).__init__(**kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/topology.py, line 292, in __init__ raise TypeError('Keyword argument not understood:', kwarg)[SEP]TypeError: ('Keyword argument not understood:', 'data_format')",1
"File [FILE], line 1, in <module>() from keras.layers import Merge[SEP]ImportError: cannot import name 'Merge'",1
"File model_main.py, line 26, in <module> from object_detection import model_lib[SEP]File <*>/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py, line 28, in <module> from object_detection import eval_util[SEP]File <*>/site-packages/object_detection-0.1-py3.7.egg/object_detection/eval_util.py, line 35, in <module> slim = tf.contrib.slim[SEP]File <*>/site-packages/tensorflow/python/util/lazy_loader.py, line 62, in __getattr__ module = self._load()[SEP]File <*>/site-packages/tensorflow/python/util/lazy_loader.py, line 45, in _load module = importlib.import_module(self.__name__)[SEP]File <*>/__init__.py, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <*>/site-packages/tensorflow/contrib/__init__.py, line 33, in <module> from tensorflow.contrib import compiler[SEP]File <*>/site-packages/tensorflow/contrib/compiler/__init__.py, line 22, in <module> from tensorflow.contrib.compiler import xla[SEP]File <*>/site-packages/tensorflow/contrib/compiler/xla.py, line 22, in <module> from tensorflow.python.estimator import model_fn as model_fn_lib[SEP]File <*>/site-packages/tensorflow/python/estimator/__init__.py, line 26, in <module> from tensorflow_estimator.python import estimator[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/__init__.py, line 25, in <module> import tensorflow_estimator.python.estimator.estimator_lib[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator_lib.py, line 69, in <module> from tensorflow_estimator.python.estimator.tpu.tpu_estimator import TPUEstimator[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py, line 83, in <module> from tensorflow_estimator.python.estimator import estimator as estimator_lib[SEP]File <*>/site-packages/tensorflow_estimator/__init__.py, line 8, in <module> from tensorflow_estimator._api.v1 import estimator[SEP]File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py, line 11, in <module> from tensorflow_estimator._api.v1.estimator import tpu[SEP]File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/tpu/__init__.py, line 8, in <module> from tensorflow_estimator._api.v1.estimator.tpu import experimental[SEP]File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/tpu/experimental/__init__.py, line 8, in <module> from tensorflow_estimator.python.estimator.tpu._tpu_estimator_embedding import EmbeddingConfigSpec[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/tpu/_tpu_estimator_embedding.py, line 32, in <module> from tensorflow.python.tpu import feature_column_v2 as tpu_fc_v2[SEP]ImportError: cannot import name 'feature_column_v2' from 'tensorflow.python.tpu' (C:\Users\Rodolfo\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\tpu\__init__.py)",1
"File <*>/image.py, line 7, in <module> detector = ObjectDetection()[SEP]File <*>python3.5/site-packages/imageai/Detection/__init__.py, line 88, in __init__ self.sess = K.get_session()[SEP]File <*>python3.5/site-packages/keras/backend/tensorflow_backend.py, line 174, in get_session default_session = tf.get_default_session()[SEP]AttributeError: module 'tensorflow' has no attribute 'get_default_session'",1
"File [FILE], line 1, in <module> from tensorflow.python.util.tf_export import keras_export[SEP]ImportError: cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (C:\Users\DILAW\Anaconda3\lib\site-packages\tensorflow\python\util\tf_export.py)",1
"File [FILE], line 9, in <module> from tensorflow import set_random_seed[SEP]ImportError: cannot import name 'set_random_seed' from 'tensorflow' (C:\Users\polon\Anaconda3\lib\site-packages\tensorflow\__init__.py)",1
"File [FILE], line 6, in <module> output = tensorflow.keras.layers.Dropout(dropout_rate, name=""dropout_out"")(vgg_output)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 663, in __call__(self, inputs, *args, **kwargs) inputs, outputs, args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1708, in _set_connectivity_metadata_(self, inputs, outputs, args, kwargs) input_tensors=inputs, output_tensors=outputs, arguments=kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1795, in _add_inbound_node(self, input_tensors, output_tensors, arguments) input_tensors)[SEP]File <*>/site-packages/tensorflow/python/util/nest.py, line 515, in map_structure(func, *structure, **kwargs) structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/util/nest.py, line 515, in <listcomp>(.0) structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1794, in <lambda>(t) inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,[SEP]AttributeError: 'tuple' object has no attribute 'layer'",1
"File [FILE], line 3, in <module> model.add(tensorflow.keras.layers.GlobalMaxPooling2D(name=""gap""))[SEP]File <*>/site-packages/keras/engine/sequential.py, line 133, in add(self, layer) 'Found: ' + str(layer))[SEP]TypeError: The added layer must be an instance of class Layer. Found: <tensorflow.python.keras.layers.core.Flatten object at 0x00000000B74364A8>",1
"File [FILE], line 1, in <module> var_init_1 = tf.get_variable(""var_init_1"", [1, 2], dtype=tf.int32, initializer=tf.zeros_initializer)[SEP]AttributeError: module 'tensorflow' has no attribute 'get_variable'",1
"File <*>/tv-training-code.py, line 166, in <module> main()[SEP]File <*>/tv-training-code.py, line 161, in main evaluate(model, data_loader_test, device=device)[SEP]File <*>python3.6/dist-packages/torch/autograd/grad_mode.py, line 49, in decorate_no_grad return func(*args, **kwargs)[SEP]File <*>/engine.py, line 80, in evaluate coco_evaluator = CocoEvaluator(coco, iou_types)[SEP]File <*>/coco_eval.py, line 28, in __init__ self.coco_eval[iou_type] = COCOeval(coco_gt, iouType=iou_type)[SEP]File <*>/cocoeval.py, line 75, in __init__ self.params = Params(iouType=iouType) # parameters[SEP]File <*>/cocoeval.py, line 527, in __init__ self.setDetParams()[SEP]File <*>/cocoeval.py, line 506, in setDetParams self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)[SEP]File <__array_function__ internals>, line 6, in linspace [CODE][SEP]File <*>python3.6/dist-packages/numpy/core/function_base.py, line 121, in linspace .format(type(num)))[SEP]TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.",1
"File [FILE], line 3, in <module> images_flat = tf.contrib.layers.flatten(x)[SEP]AttributeError: module 'tensorflow_core.compat.v1' has no attribute 'contrib'",1
"File [FILE], line 8, in <module>() data= (src.transform(tfms,size=sz) #Data augmentation[SEP]File <*>python3.6/dist-packages/fastai/data_block.py, line 505, in transform(self, tfms, **kwargs) self.train.transform(tfms[0], **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/data_block.py, line 724, in transform(self, tfms, tfm_y, **kwargs) _check_kwargs(self.x, tfms, **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/data_block.py, line 596, in _check_kwargs(ds, tfms, **kwargs) raise Exception(f""It's not possible to apply those transforms to your dataset:\n {e}"")[SEP]Exception: It's not possible to apply those transforms to your dataset: Expected object of scalar type Float but got scalar type Double for argument #3 'mat2' in call to _th_addmm_out",1
"File [FILE], line 2, in <module> from object_detection.utils import label_map_util[SEP]File <*>/site-packages/object_detection/utils/label_map_util.py, line 27, in <module> from object_detection.protos import string_int_label_map_pb2[SEP]File <*>/site-packages/object_detection/protos/string_int_label_map_pb2.py, line 21, in <module> create_key=_descriptor._internal_create_key,[SEP]AttributeError: module 'google.protobuf.descriptor' has no attribute '_internal_create_key'",1
"File test.py, line 2, in <module> model = load_model(filepath = 'saved_model/model2.h5',custom_objects=None,compile=True, )[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/saving/save.py, line 184, in load_model return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py, line 177, in load_model_from_hdf5 model = model_config_lib.model_from_config(model_config,[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/saving/model_config.py, line 55, in model_from_config return deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/layers/serialization.py, line 105, in deserialize return deserialize_keras_object([SEP]File <*>python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 369, in deserialize_keras_object return cls.from_config([SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/sequential.py, line 397, in from_config layer = layer_module.deserialize(layer_config,[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 375, in deserialize_keras_object return cls.from_config(cls_config)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py, line 655, in from_config return cls(**config)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py, line 582, in __init__ super(Conv2D, self).__init__([SEP]File <*>python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py, line 121, in __init__ super(Conv, self).__init__([SEP]File <*>python3.8/site-packages/tensorflow/python/training/tracking/base.py, line 456, in _method_wrapper result = method(self, *args, **kwargs)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py, line 294, in __init__ generic_utils.validate_kwargs(kwargs, allowed_kwargs)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 792, in validate_kwargs raise TypeError(error_message, kwarg)[SEP]TypeError: ('Keyword argument not understood:', 'groups')",1
"File [FILE], line 1, in <module>() tokenizer = tfds.features.text.VocabTokenizer()[SEP]AttributeError: module 'tensorflow_datasets.core.features' has no attribute 'text'",1
"File main.py, line 60, in <module> main()[SEP]File main.py, line 50, in main train_iters, dev_iters, test_iters, vocab = load_dataset(config)[SEP]File <*>/data.py, line 23, in load_dataset TEXT = data.Field(batch_first=True, eos_token='<eos>')[SEP]AttributeError: module 'torchtext.data' has no attribute 'Field'",1
"File [FILE], line 1, in <module>() from keras.utils import to_categorical[SEP]ImportError: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",1
"File [FILE], line 41, in <module>() from theano.tensor import shared_randomstreams[SEP]File <*>python3.7/dist-packages/theano/gof/cmodule.py, line 37, in <module>() from theano.configdefaults import gcc_version_str, local_bitwidth[SEP]ImportError: cannot import name 'local_bitwidth' from 'theano.configdefaults' (/usr/local/lib/python3.7/dist-packages/theano/configdefaults.py)",1
"File <*>/train_model.py, line 10, in <module> from cancernet.cancernet import CancerNet[SEP]File <*>/cancernet.py, line 2, in <module> from keras.layers.normalization import BatchNormalization[SEP]ImportError: cannot import name 'BatchNormalization' from 'keras.layers.normalization' (C:\Users\Catalin\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\layers\normalization\__init__.py)",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/__init__.py, line 55, in <module> from theano.compile import \[SEP]File <*>/__init__.py, line 6, in <module> from theano.compile.function_module import *[SEP]File <*>/function_module.py, line 18, in <module> import theano.compile.mode[SEP]File <*>/mode.py, line 11, in <module> import theano.gof.vm[SEP]File <*>/vm.py, line 516, in <module> import lazylinker_c[SEP]File <*>/lazylinker_c.py, line 86, in <module> preargs=args)[SEP]File <*>/cmodule.py, line 1975, in compile_str (status, compile_stderr.replace('\n', '. ')))[SEP]Exception: Compilation failed (return status=1): /usr/bin/ld: /home/minh.lengoc/.local/lib/libpython2.7.a(abstract.o): relocation R_X86_64_32 against `.rodata.str1.8' can not be used when making a shared object; recompile with -fPIC. /home/minh.lengoc/.local/lib/libpython2.7.a: could not read symbols: Bad value. collect2: ld returned 1 exit status.",0
"File run_deep_trainer.py, line 404, in <module> main()[SEP]File run_deep_trainer.py, line 400, in main layer_trainers[-1].main_loop()[SEP]File <*>/train.py, line 141, in main_loop self.setup()[SEP]File <*>/train.py, line 121, in setup self.algorithm.setup(model=self.model, dataset=self.dataset)[SEP]File <*>/sgd.py, line 243, in setup inf_params = [param for param in model.get_params()[SEP]File <*>/model.py, line 503, in get_params return list(self._params)[SEP]AttributeError: 'Softmax' object has no attribute '_params'",0
"File tensor_restore.py, line 14, in <module> saver.restore(sess, ""/tmp/model.ckpt"")[SEP]File <*>python2.7/site-packages/tensorflow/python/training/saver.py, line 891, in restore sess.run([self._restore_op_name], {self._filename_tensor_name: save_path})[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 368, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 444, in _do_run e.code)[SEP]tensorflow.python.framework.errors.NotFoundError: Tensor name ""v2"" not found in checkpoint files /tmp/model.ckpt [[Node: save/restore_slice_1 = RestoreSlice[dt=DT_INT32, preferred_shard=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_1/tensor_name, save/restore_slice_1/shape_and_slice)]]",0
"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: No module named sklearn.linear_model",0
"File <*>/teste2.py, line 1479, in Pred model.fit(X=predictor_train, y=target_train, nb_epoch=2, batch_size=90,show_accuracy=True)[SEP]File <*>/site-packages/keras/models.py, line 581, in fit shuffle=shuffle, metrics=metrics)[SEP]File <*>/site-packages/keras/models.py, line 239, in _fit outs = f(ins_batch)[SEP]File <*>/site-packages/keras/backend/theano_backend.py, line 365, in __call__ return self.function(*inputs)[SEP]File <*>/site-packages/theano/compile/function_module.py, line 595, in __call__ outputs = self.fn()[SEP]File <*>/site-packages/theano/gof/vm.py, line 233, in __call__ link.raise_with_op(node, thunk)[SEP]File <*>/site-packages/theano/gof/vm.py, line 229, in __call__ thunk()[SEP]File <*>/site-packages/theano/gof/op.py, line 768, in rval r = p(n, [x[0] for x in i], o)[SEP]File <*>/site-packages/theano/tensor/elemwise.py, line 808, in perform raise ValueError(base_exc_str)[SEP]ValueError: Dimension mismatch; shapes are (98, 10), (98, 1)",0
"File kaggle_otto_nn.py, line 28, in <module> from keras.models import Sequential[SEP]File <*>/models.py, line 15, in <module> [CODE][SEP]File <*>/__init__.py, line 46, in <module> [CODE][SEP]File <*>/theano_backend.py, line 1, in <module> [CODE][SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/__init__.py, line 111, in <module> theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1()[SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/sandbox/cuda/tests/test_driver.py, line 38, in test_nvidia_driver1 if not numpy.allclose(f(), a.sum()):[SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.py, line 871, in __call__ storage_map=getattr(self.fn, 'storage_map', None))[SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/link.py, line 314, in raise_with_op reraise(exc_type, exc_value, exc_trace)[SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.py, line 859, in __call__ outputs = self.fn()[SEP]RuntimeError: Cuda error: kernel_reduce_ccontig_node_97496c4d3cf9a06dc4082cc141f918d2_0: out of memory. (grid: 1 x 1; block: 256 x 1 x 1)",0
"File <ipython-input-1-65016ddab3cd>, line 1, in <module> from keras.utils.visualize_util import plot[SEP]File <*>/site-packages/keras/utils/visualize_util.py, line 8, in <module> raise RuntimeError('Failed to import pydot. You must install pydot'[SEP]RuntimeError: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",0
"File <ipython-input-1-adf2ca85bb77>, line 1, in <module> runfile('/home/kang/Documents/work_code_PC1/py_tensorflow_learning/cifar10CNN_test/cifar10_eval_test.py', wdir='/home/kang/Documents/work_code_PC1/py_tensorflow_learning/cifar10CNN_test')[SEP]File <*>python3/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 685, in runfile execfile(filename, namespace)[SEP]File <*>python3/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 85, in execfile exec(compile(open(filename, 'rb').read(), filename, 'exec'), namespace)[SEP]File <*>/cifar10_eval_test.py, line 107, in <module> tf.app.run()[SEP]File <*>python3.4/dist-packages/tensorflow/python/platform/default/_app.py, line 30, in run sys.exit(main(sys.argv))[SEP]File <*>/cifar10_eval_test.py, line 104, in main evaluate()[SEP]File <*>/cifar10_eval_test.py, line 94, in evaluate eval_once(saver, summary_writer, top_k_op, summary_op)[SEP]File <*>/cifar10_eval_test.py, line 72, in eval_once coord.join(threads, stop_grace_period_secs = 10)[SEP]File <*>python3.4/dist-packages/tensorflow/python/training/coordinator.py, line 264, in join six.reraise(*self._exc_info_to_raise)[SEP]File <*>python3/dist-packages/six.py, line 659, in reraise raise value[SEP]File <*>python3.4/dist-packages/tensorflow/python/training/queue_runner.py, line 185, in _run sess.run(enqueue_op)[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 315, in run return self._run(None, fetches, feed_dict)[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 473, in _run raise RuntimeError('Attempted to use a closed Session.')[SEP]RuntimeError: Attempted to use a closed Session.",0
"File <*>python2.7/dist-packages/pip/basecommand.py, line 122, in main status = self.run(options, args)[SEP]File <*>python2.7/dist-packages/pip/commands/install.py, line 278, in run requirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle)[SEP]File <*>python2.7/dist-packages/pip/req.py, line 1091, in prepare_files req_to_install.check_if_exists()[SEP]File <*>python2.7/dist-packages/pip/req.py, line 811, in check_if_exists self.satisfied_by = pkg_resources.get_distribution(self.req)[SEP]File <*>python2.7/dist-packages/pkg_resources/__init__.py, line 535, in get_distribution dist = get_provider(dist)[SEP]File <*>python2.7/dist-packages/pkg_resources/__init__.py, line 415, in get_provider return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0][SEP]IndexError: list index out of range",0
"File <stdin>, line 1, in <module> [CODE][SEP]File caffepb.py, line 28, in <module> type=None),[SEP]File <*>python2.7/site-packages/google/protobuf/descriptor.py, line 652, in __new__ _message.Message._CheckCalledFromGeneratedFile()[SEP]TypeError: Descriptors should not be created directly, but only retrieved from their parent.",0
"File <*>/model.py, line 109, in <module> output_actual: batch[1][SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 698, in run run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 838, in _run fetch_handler = _FetchHandler(self._graph, fetches)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 355, in __init__ self._fetch_mapper = _FetchMapper.for_fetch(fetches)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 181, in for_fetch return _ListFetchMapper(fetch)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 288, in __init__ self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches][SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 178, in for_fetch (fetch, type(fetch)))[SEP]TypeError: Fetch argument None has invalid type <type 'NoneType'>",0
"File train_lstm.py, line 66, in <module> model.embedding_placeholder: data.glove_vec})[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 382, in run run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 655, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 723, in _do_run target_list, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 743, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors.OutOfRangeError: PaddingFIFOQueue '_0_batching/padding_fifo_queue' is closed and has insufficient elements (requested 50, current size 0) [[Node: batching = QueueDequeueMany[_class=[""loc:@batching/padding_fifo_queue""], component_types=[DT_INT32, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](batching/padding_fifo_queue, batching/n)]] [[Node: batching/_9 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_1191_batching"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]",0
"File test_classifier.py, line 48, in <module> score = model.evaluate(x, y, batch_size=16)[SEP]File <*>/site-packages/keras/models.py, line 655, in evaluate sample_weight=sample_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1131, in evaluate batch_size=batch_size)[SEP]File <*>/site-packages/keras/engine/training.py, line 959, in _standardize_user_data exception_prefix='model input')[SEP]File <*>/site-packages/keras/engine/training.py, line 108, in standardize_input_data str(array.shape))[SEP]Exception: Error when checking model input: expected convolution2d_input_1 to have shape (None, 3, 150, 150) but got array with shape (1, 3, 150, 198)`",0
"File <*>python3.5/dist-packages/tensorflow/python/framework/common_shapes.py, line 594, in call_cpp_shape_fn status)[SEP]File <*>python3.5/contextlib.py, line 66, in exit next(self.gen)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/errors.py, line 463, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors.InvalidArgumentError: Shape must be rank 0 but is rank 1",0
"File my_test.py, line 51, in [FUNC] [CODE][SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/parsing_ops.py, line 640, in parse_single_sequence_example feature_list_dense_defaults, example_name, name)[SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/parsing_ops.py, line 837, in _parse_single_sequence_example_raw name=name)[SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/gen_parsing_ops.py, line 285, in _parse_single_sequence_example name=name)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/op_def_library.py, line 749, in apply_op op_def=op_def)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 2382, in create_op set_shapes_for_outputs(ret)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 1783, in set_shapes_for_outputs shapes = shape_func(op)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/common_shapes.py, line 596, in call_cpp_shape_fn raise ValueError(err.message)[SEP]ValueError: Shape must be rank 0 but is rank 1",0
"File add_1.py, line 13, in <module> saver = tf.train.Saver([y]) raise TypeError(""Variable to save is not a Variable: %s"" % var)[SEP]TypeError: Variable to save is not a Variable: Tensor(""add_3:0"", shape=(), dtype=int32, device=/job:local/task:3)",0
"File <*>python2.7/dist-packages/tensorflow/python/__init__.py, line 61, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory",0
"File Netzwerk_v0.5.1_gamma.py, line 171, in <module> session.run(tf.global_variables_initializer())[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 767, in run run_metadata_ptr)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 965, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1015, in _do_run target_list, options, run_metadata)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1035, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[14525,14000] [[Node: rnn/basic_lstm_cell/weights/Initializer/random_uniform = Add[T=DT_FLOAT, _class=[""loc:@rnn/basic_lstm_cell/weights""], _device=""/job:localhost/replica:0/task:0/gpu:0""](rnn/basic_lstm_cell/weights/Initializer/random_uniform/mul, rnn/basic_lstm_cell/weights/Initializer/random_uniform/min)]]",0
"File main.py, line 36, in <module> model.fit(X,Y, epochs=50, batch_size=100)[SEP]File <*>/site-packages/keras/models.py, line 960, in fit validation_steps=validation_steps)[SEP]File <*>/site-packages/keras/engine/training.py, line 1574, in fit batch_size=batch_size)[SEP]File <*>/site-packages/keras/engine/training.py, line 1407, in _standardize_user_data exception_prefix='input')[SEP]File <*>/site-packages/keras/engine/training.py, line 128, in _standardize_input_data arrays[i] = array[SEP]ValueError: could not broadcast input array from shape (14,1) into shape (14)",0
"File <*>/main.py, line 89, in <module> _ = sess.run([update_step])[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[500,80] [[Node: decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](decoder/while/BasicDecoderStep/basic_lstm_cell/concat, decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul/Enter)]] [[Node: gradients/Add/_282 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_457_gradients/Add"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](^_cloopdecoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y/_181)]]",0
"File <stdin>, line 1, in <module> [CODE][SEP]RuntimeError: invalid argument 2: dimension 1 out of range of 1D tensor at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensor.c:24",0
"File <*>/site-packages/google/protobuf/internal/python_message.py, line 545, in _GetFieldByName return message_descriptor.fields_by_name[field_name][SEP]KeyError: 'layout_optimizer'",0
"File export_inference_graph.py, line 119, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough))[SEP]File export_inference_graph.py, line 115, in main FLAGS.output_directory, input_shape)[SEP]File <*>/site-packages/object_detection-0.1-py3.5.egg/object_detection/exporter.py, line 427, in export_inference_graph input_shape, optimize_graph, output_collection_name)[SEP]File <*>/site-packages/object_detection-0.1-py3.5.egg/object_detection/exporter.py, line 391, in _export_inference_graph initializer_nodes='')[SEP]File <*>/site-packages/object_detection-0.1-py3.5.egg/object_detection/exporter.py, line 72, in freeze_graph_with_def_protos layout_optimizer=rewriter_config_pb2.RewriterConfig.ON)[SEP]File <*>/site-packages/google/protobuf/internal/python_message.py, line 484, in init field = _GetFieldByName(message_descriptor, field_name)[SEP]File <*>/site-packages/google/protobuf/internal/python_message.py, line 548, in _GetFieldByName (message_descriptor.name, field_name))[SEP]ValueError: Protocol message RewriterConfig has no ""layout_optimizer"" field.",0
"File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory",0
"File eval.py, line 146, in <module> tf.app.run()[SEP]File <*>python3.5/dist-packages/tensorflow/python/platform/app.py, line 124, in run _sys.exit(main(argv))[SEP]File eval.py, line 142, in main FLAGS.checkpoint_dir, FLAGS.eval_dir)[SEP]File <*>/evaluator.py, line 240, in evaluate save_graph_dir=(eval_dir if eval_config.save_graph else ''))[SEP]File <*>/eval_util.py, line 407, in repeated_checkpoint_run save_graph_dir)[SEP]File <*>/eval_util.py, line 286, in _run_checkpoint_once result_dict = batch_processor(tensor_dict, sess, batch, counters)[SEP]File <*>/evaluator.py, line 183, in _process_batch result_dict = sess.run(tensor_dict)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 895, in run run_metadata_ptr)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1128, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1344, in _do_run options, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1363, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,32,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[Node: FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Preprocessor/sub, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read)]]",0
"File <*>python3.6/inspect.py, line 1119, in getfullargspec sigcls=Signature)[SEP]File <*>python3.6/inspect.py, line 2186, in _signature_from_callable raise TypeError('{!r} is not a callable object'.format(obj))[SEP]TypeError: (<tf.Tensor 'IteratorGetNext:0' shape=(?, 40, 40, ?) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=int32>) is not a callable object",0
"File <*>/task2_new.py, line 78, in <module> loss = compute_loss(h_fc2, margin)[SEP]File <*>/task2_new.py, line 37, in compute_loss Ltriplet = np.maximum(0, 1 - tf.square(diff_neg)/(tf.square(diff_pos) + margin))[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 614, in __bool__ raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""[SEP]TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",0
"File <*>/main.py, line 6, in <module> watcher = Watcher('res/vid/planet_earth_s01e01/video.mp4', 'res/vid/planet_earth_s01e01/english.srt')[SEP]File <*>/watch.py, line 9, in __init__ self.detector = Detector()[SEP]File <*>/detect.py, line 6, in __init__ self.tfnet = TFNet(self.options)[SEP]File <*>python3.6/site-packages/darkflow/net/build.py, line 75, in __init__ self.build_forward()[SEP]File <*>python3.6/site-packages/darkflow/net/build.py, line 105, in build_forward self.inp = tf.placeholder(tf.float32, inp_size, 'input')[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/array_ops.py, line 1677, in placeholder raise RuntimeError(""tf.placeholder() is not compatible with ""[SEP]RuntimeError: tf.placeholder() is not compatible with eager execution.",0
"File <*>/freeze_graph鈥? line 11, in <module> sys.exit(main())[SEP]TypeError: main() missing 1 required positional argument: 鈥榰nused_args鈥?
308,49760781,0,1,,,File [FILE]",0
"File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 579, in merge_with new_dims.append(dim.merge_with(other[i]))[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 138, in merge_with self.assert_is_compatible_with(other)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 111, in assert_is_compatible_with other))[SEP]ValueError: Dimensions 5 and 4 are not compatible",0
"File <*>python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py, line 602, in gradients in_grad.set_shape(t_in.get_shape())[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 407, in set_shape self._shape = self._shape.merge_with(shape)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 582, in merge_with raise ValueError(""Shapes %s and %s are not compatible"" % (self, other))[SEP]ValueError: Shapes (?, 5, 15, 1) and (?, 4, 15, 1) are not compatible",0
"File train.py, line 167, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File train.py, line 92, in main FLAGS.pipeline_config_path)[SEP]File <*>/config_util.py, line 93, in get_configs_from_pipeline_file text_format.Merge(proto_str, pipeline_config)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 533, in Merge descriptor_pool=descriptor_pool)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 587, in MergeLines return parser.MergeLines(lines, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 620, in MergeLines self._ParseOrMerge(lines, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 635, in _ParseOrMerge self._MergeField(tokenizer, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 735, in _MergeField merger(tokenizer, message, field)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 823, in _MergeMessageField self._MergeField(tokenizer, sub_message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 703, in _MergeField (message_descriptor.full_name, name))[SEP]google.protobuf.text_format.ParseError: 108:7 : Message type ""object_detection.protos.SsdFeatureExtractor"" has no field named ""batch_norm_trainable"".",0
"File main.py, line 69, in <module> main();[SEP]File main.py, line 66, in main train_model(iris_dataset, model, optimizer);[SEP]File main.py, line 41, in train_model gradients = gradient_tune(features, label, model);[SEP]File main.py, line 27, in gradient_tune prediction_loss = prediction_loss_diff(features, targets, model);[SEP]File main.py, line 23, in prediction_loss_diff return tf.losses.sparse_softmax_cross_entropy(label, predicted_label);[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py, line 853, in sparse_softmax_cross_entropy name=""xentropy"")[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/nn_ops.py, line 2050, in sparse_softmax_cross_entropy_with_logits precise_logits, labels, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 7504, in sparse_softmax_cross_entropy_with_logits _six.raise_from(_core._status_to_exception(e.code, message), None)[SEP]File <string>, line 2, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.InternalError: Could not find valid device for node name: ""SparseSoftmaxCrossEntropyWithLogits""",0
"File <*>/TutorialCIFAR10.py, line 36, in <module> dataiter = iter(trainloader)[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 451, in __iter__ return _DataLoaderIter(self)[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 239, in __init__ w.start()[SEP]File <*>/process.py, line 105, in start self._popen = self._Popen(self)[SEP]File <*>/context.py, line 223, in _Popen return _default_context.get_context().Process._Popen(process_obj)[SEP]File <*>/context.py, line 322, in _Popen return Popen(process_obj)[SEP]File <*>/popen_spawn_win32.py, line 65, in __init__ reduction.dump(process_obj, to_child)[SEP]File <*>/reduction.py, line 60, in dump ForkingPickler(file, protocol).dump(obj)[SEP]BrokenPipeError: [Errno 32] Broken pipe",0
"File <*>/label_map_util.py, line 135, in load_labelmap text_format.Merge(label_map_string, label_map)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 525, in Merge descriptor_pool=descriptor_pool)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 579, in MergeLines return parser.MergeLines(lines, message)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 612, in MergeLines self._ParseOrMerge(lines, message)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 627, in _ParseOrMerge self._MergeField(tokenizer, message)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 727, in _MergeField merger(tokenizer, message, field)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 815, in _MergeMessageField self._MergeField(tokenizer, sub_message)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 695, in _MergeField (message_descriptor.full_name, name))[SEP]google.protobuf.text_format.ParseError: 23:20 : Message type ""object_detection.protos.StringIntLabelMapItem"" has no field named ""s"".",0
"File <string>, line 1, in <module> [CODE][SEP]File <*>/setup.py, line 11, in <module> raise RuntimeError(README)[SEP]RuntimeError: PyTorch does not currently provide packages for PyPI (see status at https://github.com/pytorch/pytorch/issues/566).",0
"File model_builder_test.py, line 21, in <module> from object_detection.builders import model_builder[SEP]File <*>/model_builder.py, line 17, in <module> from object_detection.builders import anchor_generator_builder[SEP]File <*>/anchor_generator_builder.py, line 18, in <module> from object_detection.anchor_generators import grid_anchor_generator[SEP]File <*>/grid_anchor_generator.py, line 27, in <module> from object_detection.utils import ops[SEP]File <*>/ops.py, line 282, in <module> dtype=tf.float32):[SEP]AttributeError: module 'tensorflow' has no attribute 'float32'",0
"File [FILE], line <*>, in [FUNC] [CODE][SEP]File <*>/setup.py, line 108, in [FUNC] [CODE][SEP]ImportError: No module named tools.setup_helpers.env",0
"File <ipython-input-7-2ef5e6514df7>, line 33, in data_generator [CODE][SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1530, in __exit__ self._default_graph_context_manager.__exit__(exec_type, exec_value, exec_tb)[SEP]File <*>python3.6/contextlib.py, line 99, in __exit__ self.gen.throw(type, value, traceback)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 5025, in get_controller context.context().context_switches.pop()[SEP]File <*>python3.6/dist-packages/tensorflow/python/eager/context.py, line 136, in pop self.stack.pop()[SEP]IndexError: pop from empty list",0
"File <*>/all_good.py, line 15, in <module> import matplotlib.pyplot as plt[SEP]File <*>/site-packages/matplotlib/pyplot.py, line 115, in <module> _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()[SEP]File <*>/site-packages/matplotlib/backends/__init__.py, line 62, in pylab_setup [backend_name], 0)[SEP]File <*>/site-packages/matplotlib/backends/backend_qt5agg.py, line 15, in <module> from .backend_qt5 import ([SEP]File <*>/site-packages/matplotlib/backends/backend_qt5.py, line 19, in <module> import matplotlib.backends.qt_editor.figureoptions as figureoptions[SEP]File <*>/site-packages/matplotlib/backends/qt_editor/figureoptions.py, line 20, in <module> import matplotlib.backends.qt_editor.formlayout as formlayout[SEP]File <*>/site-packages/matplotlib/backends/qt_editor/formlayout.py, line 54, in <module> from matplotlib.backends.qt_compat import QtGui, QtWidgets, QtCore[SEP]File <*>/site-packages/matplotlib/backends/qt_compat.py, line 158, in <module> raise ImportError(""Failed to import any qt binding"")[SEP]ImportError: Failed to import any qt binding",0
"File <*>python3.6/site-packages/pip/_internal/basecommand.py, line 141, in main status = self.run(options, args)[SEP]File <*>python3.6/site-packages/pip/_internal/commands/install.py, line 330, in run self._warn_about_conflicts(to_install)[SEP]File <*>python3.6/site-packages/pip/_internal/commands/install.py, line 456, in _warn_about_conflicts package_set, _dep_info = check_install_conflicts(to_install)[SEP]File <*>python3.6/site-packages/pip/_internal/operations/check.py, line 98, in check_install_conflicts package_set = create_package_set_from_installed()[SEP]File <*>python3.6/site-packages/pip/_internal/operations/check.py, line 41, in create_package_set_from_installed package_set[name] = PackageDetails(dist.version, dist.requires())[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2607, in requires dm = self._dep_map[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2871, in _dep_map self.__dep_map = self._compute_dependencies()[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2881, in _compute_dependencies reqs.extend(parse_requirements(req))[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2942, in parse_requirements yield Requirement(line)[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2951, in __init__ raise RequirementParseError(str(e))[SEP]pip._vendor.pkg_resources.RequirementParseError: Invalid requirement, parse error at ""'; extra '""",0
"File convolutional_network_raw.py, line 137, in <module> writer.add_summary(summary=summary, global_step=step)[SEP]File <*>python3.6/site-packages/tensorflow/python/summary/writer/writer.py, line 126, in add_summary for value in summary.value:[SEP]AttributeError: 'numpy.float32' object has no attribute 'value'",0
"File <*>/auto_LSTM_try3.py, line 398, in <module> run_experiments(config, search_alg=algo, scheduler=hyperband)[SEP]File <*>python3.6/site-packages/ray/tune/tune.py, line 108, in run_experiments runner.step()[SEP]File <*>python3.6/site-packages/ray/tune/trial_runner.py, line 114, in step next_trial = self._get_next_trial()[SEP]File <*>python3.6/site-packages/ray/tune/trial_runner.py, line 254, in _get_next_trial self._update_trial_queue(blocking=wait_for_trial)[SEP]File <*>python3.6/site-packages/ray/tune/trial_runner.py, line 330, in _update_trial_queue trials = self._search_alg.next_trials()[SEP]File <*>python3.6/site-packages/ray/tune/suggest/suggestion.py, line 67, in next_trials for trial in self._trial_generator:[SEP]File <*>python3.6/site-packages/ray/tune/suggest/suggestion.py, line 88, in _generate_trials suggested_config = self._suggest(trial_id)[SEP]File <*>python3.6/site-packages/ray/tune/suggest/hyperopt.py, line 81, in _suggest self.rstate.randint(2**31 - 1))[SEP]File <*>python3.6/site-packages/hyperopt/tpe.py, line 835, in suggest = tpe_transform(domain, prior_weight, gamma)[SEP]File <*>python3.6/site-packages/hyperopt/tpe.py, line 816, in tpe_transform s_prior_weight[SEP]File <*>python3.6/site-packages/hyperopt/tpe.py, line 690, in build_posterior b_post = fn(*b_args, **dict(named_args))[SEP]TypeError: ap_uniform_sampler() missing 1 required positional argument: 'high'",0
"File <*>/SVM_Stock.py, line 71, in <module> estimator.fit(x,y)[SEP]File <*>/site-packages/keras/wrappers/scikit_learn.py, line 210, in fit return super(KerasClassifier, self).fit(x, y, **kwargs)[SEP]File <*>/site-packages/keras/wrappers/scikit_learn.py, line 139, in fit **self.filter_sk_params(self.build_fn.__call__))[SEP]TypeError: __call__() missing 1 required positional argument: 'inputs'",0
"File <*>/train.py, line 107, in <module> callbacks=[Saver(save_every), Evaluation(evaluate_every)])[SEP]File <*>/site-packages/keras/engine/training.py, line 1039, in fit validation_steps=validation_steps)[SEP]File <*>/site-packages/keras/engine/training_arrays.py, line 204, in fit_loop callbacks.on_batch_end(batch_index, batch_logs)[SEP]File <*>/site-packages/keras/callbacks.py, line 115, in on_batch_end callback.on_batch_end(batch, logs)[SEP]File <*>/train.py, line 83, in on_batch_end self.model.save(name)[SEP]File <*>/site-packages/keras/engine/network.py, line 1090, in save save_model(self, filepath, overwrite, include_optimizer)[SEP]File <*>/site-packages/keras/engine/saving.py, line 382, in save_model _serialize_model(model, f, include_optimizer)[SEP]File <*>/site-packages/keras/engine/saving.py, line 83, in _serialize_model model_config['config'] = model.get_config()[SEP]File <*>/site-packages/keras/engine/network.py, line 931, in get_config return copy.deepcopy(config)[SEP]File <*>/copy.py, line 150, in deepcopy y = copier(x, memo)[SEP]File <*>/copy.py, line 240, in _deepcopy_dict y[deepcopy(key, memo)] = deepcopy(value, memo)[SEP]File <*>/copy.py, line 215, in _deepcopy_list append(deepcopy(a, memo))[SEP]File <*>/copy.py, line 220, in _deepcopy_tuple y = [deepcopy(a, memo) for a in x][SEP]File <*>/copy.py, line 220, in <listcomp> y = [deepcopy(a, memo) for a in x][SEP]File <*>/copy.py, line 180, in deepcopy y = _reconstruct(x, memo, *rv)[SEP]File <*>/copy.py, line 280, in _reconstruct state = deepcopy(state, memo)[SEP]File <*>/copy.py, line 169, in deepcopy rv = reductor(4)[SEP]TypeError: can't pickle _thread.RLock objects",0
"File <*>/testo.py, line 18, in <module> optim.minimize(loss, var_list=network.weights)[SEP]AttributeError: 'Adam' object has no attribute 'minimize'",0
"File pretrain_lm.py, line 7, in <module> import fastai[SEP]File <*>python3.7/site-packages/fastai/__init__.py, line 1, in <module> from .basic_train import *[SEP]File <*>python3.7/site-packages/fastai/basic_train.py, line 2, in <module> from .torch_core import *[SEP]File <*>python3.7/site-packages/fastai/torch_core.py, line 2, in <module> from .imports.torch import *[SEP]File <*>python3.7/site-packages/fastai/imports/__init__.py, line 2, in <module> from .torch import *[SEP]File <*>python3.7/site-packages/fastai/imports/torch.py, line 1, in <module> import torch, torch.nn.functional as F[SEP]File <*>python3.7/site-packages/torch/__init__.py, line 84, in <module> from torch._C import *[SEP]ImportError: libtorch_python.so: cannot open shared object file: No such file or directory",0
"File <*>/vis.py, line 28, in <module> from deeplab import common[SEP]ModuleNotFoundError: No module named 'deeplab'",0
"File <*>/extra_classes.py, line 31, in <module> model_out = MyLayer(2)(model_in)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 746, in __call__ self.build(input_shapes)[SEP]File <*>/extra_classes.py, line 20, in build trainable=True)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 609, in add_weight aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/training/checkpointable/base.py, line 639, in _add_variable_with_custom_getter **kwargs_for_getter)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1977, in make_variable aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 183, in __call__ return cls._variable_v1_call(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 146, in _variable_v1_call aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 125, in <lambda> previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variable_scope.py, line 2437, in default_variable_creator import_scope=import_scope)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 187, in __call__ return super(VariableMetaclass, cls).__call__(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 297, in __init__ constraint=constraint)[SEP]File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 409, in _init_from_args initial_value() if init_from_fn else initial_value,[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1959, in <lambda> shape, dtype=dtype, partition_info=partition_info)[SEP]File <*>/site-packages/tensorflow/python/ops/init_ops.py, line 255, in __call__ shape, self.minval, self.maxval, dtype, seed=self.seed)[SEP]File <*>/site-packages/tensorflow/python/ops/random_ops.py, line 235, in random_uniform shape = _ShapeTensor(shape)[SEP]File <*>/site-packages/tensorflow/python/ops/random_ops.py, line 44, in _ShapeTensor return ops.convert_to_tensor(shape, dtype=dtype, name=""shape"")[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 1050, in convert_to_tensor as_ref=False)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 1146, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 229, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 208, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 531, in make_tensor_proto ""supported type."" % (type(values), values))[SEP]TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (Dimension(4), 2). Consider casting elements to a supported type.",0
"File classifier_model.py, line 115, in <module> model.fit_generator(generator.flow(train_images, train_labels, batch_size=BATCH_SIZE), epochs=num_epochs)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1426, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 191, in model_iteration batch_outs = batch_function(*batch_data)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1191, in train_on_batch outputs = self._fit_function(ins) # pylint: disable=not-callable[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/backend.py, line 3076, in __call__ run_metadata=self.run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1439, in __call__ run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: logits and labels must have the same first dimension, got logits shape [1,7] and labels shape [7] [[{{node loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]",0
"File <*>/site-packages/tensorflow/python/platform/self_check.py, line 62, in preload_check ctypes.WinDLL(build_info.nvcuda_dll_name)[SEP]File <*>/__init__.py, line 356, in __init__ self._handle = _dlopen(self._name, mode)[SEP]OSError: [WinError 126] Das angegebene Modul wurde nicht gefunden",0
"File <*>/bacteria_rcnn_train.py, line 53, in <module> import keras[SEP]File <*>python3.5/dist-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>python3.5/dist-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils[SEP]File <*>python3.5/dist-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K[SEP]File <*>python3.5/dist-packages/keras/backend/__init__.py, line 84, in <module> from .tensorflow_backend import *[SEP]File <*>python3.5/dist-packages/keras/backend/tensorflow_backend.py, line 5, in <module> import tensorflow as tf[SEP]File <*>python3.5/dist-packages/tensorflow/__init__.py, line 28, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>python3.5/dist-packages/tensorflow/python/__init__.py, line 83, in <module> from tensorflow.python import keras[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/__init__.py, line 26, in <module> from tensorflow.python.keras import activations[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/activations/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.activations import elu[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/_impl/keras/__init__.py, line 21, in <module> from tensorflow.python.keras._impl.keras import activations[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/_impl/keras/activations.py, line 23, in <module> from tensorflow.python.keras._impl.keras import backend as K[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py, line 38, in <module> from tensorflow.python.layers import base as tf_base_layers[SEP]File <*>python3.5/dist-packages/tensorflow/python/layers/base.py, line 25, in <module> from tensorflow.python.keras import backend[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/backend/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.backend import abs[SEP]ImportError: cannot import name 'abs'",0
"File test_transform.py, line 87, in <module> for batch_idx, image, mask in enumerate(train_loader):[SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 314, in __next__ batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 314, in <listcomp> batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>python3.6/site-packages/torch/utils/data/dataset.py, line 103, in __getitem__ return self.dataset[self.indices[idx]][SEP]File <*>/data.py, line 164, in __getitem__ img, mask = self.transforms(img, mask)[SEP]File <*>/augmentations.py, line 17, in __call__ img, mask = a(img, mask)[SEP]TypeError: __call__() takes 2 positional arguments but 3 were given",0
"File <*>/prova_bert.py, line 230, in <module> model = baseline_model(output_size, max_seq_len, visualize=True)[SEP]File <*>/prova_bert.py, line 165, in baseline_model )(bert_embeddings)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/wrappers.py, line 473, in __call__ return super(Bidirectional, self).__call__(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 746, in __call__ self.build(input_shapes)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/wrappers.py, line 612, in build self.forward_layer.build(input_shape)[SEP]File <*>/site-packages/tensorflow/python/keras/utils/tf_utils.py, line 149, in wrapper output_shape = fn(instance, input_shape)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/recurrent.py, line 552, in build self.cell.build(step_input_shape)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/recurrent.py, line 1934, in build constraint=self.kernel_constraint)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 609, in add_weight aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/training/checkpointable/base.py, line 639, in _add_variable_with_custom_getter **kwargs_for_getter)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1977, in make_variable aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 183, in __call__ return cls._variable_v1_call(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 146, in _variable_v1_call aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 125, in <lambda> previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variable_scope.py, line 2437, in default_variable_creator import_scope=import_scope)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 187, in __call__ return super(VariableMetaclass, cls).__call__(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 297, in __init__ constraint=constraint)[SEP]File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 409, in _init_from_args initial_value() if init_from_fn else initial_value,[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1959, in <lambda> shape, dtype=dtype, partition_info=partition_info)[SEP]File <*>/site-packages/tensorflow/python/ops/init_ops.py, line 473, in __call__ scale /= max(1., (fan_in + fan_out) / 2.)[SEP]TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'",0
"File <*>/Program.py, line 88, in FitModel model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 224, in fit distribution_strategy=strategy)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 547, in _process_training_inputs use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 606, in _process_inputs use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 479, in __init__ batch_size=batch_size, shuffle=shuffle, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 321, in __init__ dataset_ops.DatasetV2.from_tensors(inputs).repeat()[SEP]File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 414, in from_tensors return TensorDataset(tensors)[SEP]File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 2335, in __init__ element = structure.normalize_element(element)[SEP]File <*>/site-packages/tensorflow_core/python/data/util/structure.py, line 111, in normalize_element ops.convert_to_tensor(t, name=""component_%d"" % i))[SEP]File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1184, in convert_to_tensor return convert_to_tensor_v2(value, dtype, preferred_dtype, name)[SEP]File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1242, in convert_to_tensor_v2 as_ref=False)[SEP]File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1296, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py, line 52, in _default_conversion_function return constant_op.constant(value, dtype, name=name)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 227, in constant allow_broadcast=True)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 235, in _constant_impl t = convert_to_eager_tensor(value, ctx, dtype)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 96, in convert_to_eager_tensor return ops.EagerTensor(value, ctx.device_name, dtype)[SEP]ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float).",0
"File <ipython-input-1-f9d072fc6a73>, line 19, in <module> onnx_model = keras2onnx.convert_keras(model)[SEP]File <*>/site-packages/keras2onnx/main.py, line 67, in convert_keras "" Please set environment variable TF_KERAS = 1."")[SEP]Exception: This is a tensorflow keras model, but keras standalone converter is used. Please set environment variable TF_KERAS = 1.",0
"File tf_1_day_scikit_dnn.py, line 12, in <module> from sklearn import decomposition[SEP]File <*>python3.6/site-packages/sklearn/decomposition/__init__.py, line 19, in <module> from ._online_lda import LatentDirichletAllocation[SEP]ImportError: cannot import name 'LatentDirichletAllocation'",0
"File <*>python37/runpy.py, line 193, in _run_module_as_main ""__main__"", mod_spec)[SEP]File <*>python37/runpy.py, line 85, in _run_code exec(code, run_globals)[SEP]File <*>/__main__.py, line 9, in <module> [CODE][SEP]File <*>/site-packages/flask/cli.py, line 966, in main cli.main(prog_name=""python -m flask"" if as_module else None)[SEP]File <*>/site-packages/flask/cli.py, line 586, in main return super(FlaskGroup, self).main(*args, **kwargs)[SEP]File <*>/site-packages/click/core.py, line 717, in main rv = self.invoke(ctx)[SEP]File <*>/site-packages/click/core.py, line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx))[SEP]File <*>/site-packages/click/core.py, line 956, in invoke return ctx.invoke(self.callback, **ctx.params)[SEP]File <*>/site-packages/click/core.py, line 555, in invoke return callback(*args, **kwargs)[SEP]File <*>/site-packages/click/decorators.py, line 64, in new_func return ctx.invoke(f, obj, *args, **kwargs)[SEP]File <*>/site-packages/flask/cli.py, line 860, in run_command extra_files=extra_files,[SEP]File <*>/site-packages/werkzeug/serving.py, line 1008, in run_simple run_with_reloader(inner, extra_files, reloader_interval, reloader_type)[SEP]File <*>/site-packages/werkzeug/_reloader.py, line 337, in run_with_reloader reloader.run()[SEP]File <*>/site-packages/werkzeug/_reloader.py, line 202, in run for filename in chain(_iter_module_files(), self.extra_files):[SEP]File <*>/site-packages/werkzeug/_reloader.py, line 24, in _iter_module_files filename = getattr(module, ""__file__"", None)[SEP]File <*>/site-packages/tensorflow/__init__.py, line 50, in __getattr__ module = self._load()[SEP]File <*>/site-packages/tensorflow/__init__.py, line 44, in _load module = _importlib.import_module(self.__name__)[SEP]File <*>python37/__init__.py, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <frozen importlib._bootstrap>, line 1006, in _gcd_import [CODE][SEP]File <frozen importlib._bootstrap>, line 983, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 965, in _find_and_load_unlocked [CODE][SEP]ModuleNotFoundError: No module named 'tensorflow_core.keras'",0
"File <*>/N09.py, line 363, in <module> main()[SEP]File <*>/N09.py, line 343, in main args.save_interval)[SEP]File <*>/N09.py, line 92, in train_model verbose=self.verbose)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 1297, in fit_generator steps_name='steps_per_epoch')[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py, line 265, in model_iteration batch_outs = batch_function(*batch_data)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 973, in train_on_batch class_weight=class_weight, reset_metrics=reset_metrics)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch output_loss_metrics=model._output_loss_metrics)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch output_loss_metrics=output_loss_metrics))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 268, in _process_single_batch grads = tape.gradient(scaled_total_loss, trainable_weights)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/backprop.py, line 1014, in gradient unconnected_gradients=unconnected_gradients)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py, line 76, in imperative_grad compat.as_str(unconnected_gradients.value))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 911, in _backward_function_wrapper processed_args, remapped_captures)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1224, in _call_flat ctx, args, cancellation_manager=cancellation_manager)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 511, in call ctx=ctx)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 75, in quick_execute ""tensors, but found {}"".format(keras_symbolic_tensors))[SEP]tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'StridedSliceGrad:0' shape=(16, 64, 64, 3) dtype=float32>]",0
"File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1455, in __del__ self._session._session, self._handle, status)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: No such callable handle: 94697914208640",0
"File <*>/main.py, line 81, in <module> train(epoch)[SEP]File <*>/main.py, line 48, in train for iteration, batch in enumerate(training_data_loader, 1):[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 345, in __next__ data = self._next_data()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 841, in _next_data idx, data = self._get_data()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 808, in _get_data success, data = self._try_get_data()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 774, in _try_get_data raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str))[SEP]RuntimeError: DataLoader worker (pid(s) 16596, 9376, 12756, 9844) exited unexpectedly",0
"File <*>/test2.py, line 73, in <module> grads = gradients(model, x, y)[SEP]File <*>/test2.py, line 58, in gradients print(model.get_layer('minimalrnn').output)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 1553, in output raise AttributeError('Layer ' + self.name + ' has no inbound nodes.')[SEP]AttributeError: Layer minimalrnn has no inbound nodes.",0
"File <*>/site-packages/IPython/core/interactiveshell.py, line 3296, in run_code exec(code_obj, self.user_global_ns, self.user_ns)[SEP]File <ipython-input-2-78553e2886de>, line 1, in <module> runfile('F:/experiment_code/U-net/train.py', wdir='F:/experiment_code/U-net')[SEP]File <*>/pydev_umd.py, line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/train.py, line 99, in <module> loss.backward()[SEP]File <*>/site-packages/torch/tensor.py, line 107, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>/site-packages/torch/autograd/__init__.py, line 93, in backward allow_unreachable=True) # allow_unreachable flag[SEP]RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [4, 2, 224, 224]], which is output 0 of SigmoidBackward, is at version 2; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",0
"File <*>/train.py, line 66, in <module> train(epochs=20, prefix='test_new_loss_fn')[SEP]File <*>/train.py, line 46, in train model = create_model((shape[0], shape[1], 3), backbone=backbone, loss_function=loss_fn, freeze_backbone=backbone_freeze, lr=learning_rate)[SEP]File <*>/__init__.py, line 48, in create_model loss=loss_function, metrics=[mean_relative_percentage_error, metrics.mean_absolute_error])[SEP]File <*>/site-packages/keras/engine/training.py, line 342, in compile sample_weight, mask)[SEP]File <*>/site-packages/keras/engine/training_utils.py, line 404, in weighted score_array = fn(y_true, y_pred)[SEP]File <*>/losses.py, line 8, in mean_relative_percentage_error diff = K.update_sub(ones, e)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 999, in update_sub return tf.assign_sub(x, decrement)[SEP]File <*>/site-packages/tensorflow/python/ops/state_ops.py, line 160, in assign_sub return ref.assign_sub(value)[SEP]AttributeError: 'Tensor' object has no attribute 'assign_sub'",0
"File test_dist_1.py, line 25, in <module> dist.broadcast(tensor=a, src=0)[SEP]File <*>python3.7/site-packages/torch/distributed/distributed_c10d.py, line 806, in broadcast work = _default_pg.broadcast([tensor], opts)[SEP]RuntimeError: NCCL error in: /tmp/pip-req-build-58y_cjjl/torch/lib/c10d/ProcessGroupNCCL.cpp:290, unhandled system error",0
"File <*>/tempCodeRunnerFile.python, line 1234, in <module> df_enc = tensorflow.one_hot(df, 2, on_value=None, off_value=None, axis=None, dtype=None, name=None)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/util/dispatch.py, line 180, in wrapper return target(*args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/ops/array_ops.py, line 3645, in one_hot name)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py, line 5549, in one_hot _ops.raise_from_not_ok_status(e, name)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/ops.py, line 6606, in raise_from_not_ok_status six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.NotFoundError: Could not find valid device for node.",0
"File <*>python3.6/dist-packages/optuna/study.py, line 734, in _run_trial result = func(trial)[SEP]File <*>python3.6/dist-packages/optkeras/optkeras.py, line 130, in fun_tf return fun(trial)[SEP]File <ipython-input-11-45495c9f2ae9>, line 65, in optima_run self.model.fit(self.train_images, self.train_labels, epochs=10, callbacks = self.ok.callbacks(trial), verbose = self.ok.keras_verbose)[SEP]File <*>python3.6/dist-packages/optkeras/optkeras.py, line 172, in callbacks self.synch_with_optuna()[SEP]File <*>python3.6/dist-packages/optkeras/optkeras.py, line 232, in synch_with_optuna self.best_trial = get_trial_default()[SEP]File <*>python3.6/dist-packages/optkeras/optkeras.py, line 367, in get_trial_default num_fields = optuna.structs.FrozenTrial._field_types.__len__()[SEP]AttributeError: type object 'FrozenTrial' has no attribute '_field_types'",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/torch_xla/core/xla_model.py, line 231, in xla_device devkind=devkind if devkind is not None else None)[SEP]File <*>python3.6/site-packages/torch_xla/core/xla_model.py, line 136, in get_xla_supported_devices xla_devices = _DEVICES.value[SEP]File <*>python3.6/site-packages/torch_xla/utils/utils.py, line 32, in value self._value = self._gen_fn()[SEP]File <*>python3.6/site-packages/torch_xla/core/xla_model.py, line 18, in <lambda> _DEVICES = xu.LazyProperty(lambda: torch_xla._XLAC._xla_get_devices())[SEP]RuntimeError: tensorflow/compiler/xla/xla_client/computation_client.cc:274 : Missing XLA configuration",0
"File <ipython-input-39-17211d5a107c>, line 8, in <module> train_loss, _ = modhelper.train(proc.train_dataloader)[SEP]File <*>/model.py, line 71, in train preds = self.model(sent_id, mask)[SEP]File <*>/site-packages/torch/nn/modules/module.py, line 727, in _call_impl result = self.forward(*input, **kwargs)[SEP]File <*>/model.py, line 181, in forward #pass the inputs to the model[SEP]File <*>/site-packages/transformers/modeling_bert.py, line 837, in forward embedding_output = self.embeddings([SEP]File <*>/site-packages/transformers/modeling_bert.py, line 201, in forward embeddings = inputs_embeds + position_embeddings + token_type_embeddings[SEP]RuntimeError: The size of tensor a (4000) must match the size of tensor b (512) at non-singleton dimension 1",0
"File [FILE], line 2, in <module>() y_pred = model.predict(X_nn)[SEP]File <*>/site-packages/keras/models.pyc, line 493, in predict(self, X, batch_size, verbose) return self._predict_loop(self._predict, X, batch_size, verbose)[0][SEP]AttributeError: 'Sequential' object has no attribute '_predict'",0
"File [FILE], line 1, in <module>() audiocnn(input)[SEP]File <*>python2.7/site-packages/torch/nn/modules/module.pyc, line 224, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File [FILE], line 17, in forward(self, x) _, (_, _) = self.lstm(x,(h_0,c_0)) # x dim : 2 x 1 x 256[SEP]File <*>python2.7/site-packages/torch/nn/modules/rnn.pyc, line 162, in forward(self, input, hx) output, hidden = func(input, self.all_weights, hx)[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 351, in forward(input, *fargs, **fkwargs) return func(input, *fargs, **fkwargs)[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 244, in forward(input, weight, hidden) nexth, output = func(input, hidden, weight)[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 84, in forward(input, hidden, weight) hy, output = inner(input, hidden[l], weight[l])[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 113, in forward(input, hidden, weight) hidden = inner(input[i], hidden, *weight)[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 31, in LSTMCell(input, hidden, w_ih, w_hh, b_ih, b_hh) gates = F.linear(input, w_ih, b_ih) + F.linear(hx, w_hh, b_hh)[SEP]File <*>python2.7/site-packages/torch/nn/functional.pyc, line 553, in linear(input, weight, bias) return torch.addmm(bias, input, weight.t())[SEP]File <*>python2.7/site-packages/torch/autograd/variable.pyc, line 924, in addmm(cls, *args) return cls._blas(Addmm, args, False)[SEP]File <*>python2.7/site-packages/torch/autograd/variable.pyc, line 920, in _blas(cls, args, inplace) return cls.apply(*(tensors + (alpha, beta, inplace)))[SEP]RuntimeError: save_for_backward can only save input or output tensors, but argument 0 doesn't satisfy this condition",0
"File [FILE], line 18, in <module>() curr_loss = train(train_loader, model, criterion, epoch, num_epochs)[SEP]File [FILE], line 18, in train(train_loader, model, criterion, epoch, num_epochs) loss = criterion(outputs, labels)[SEP]File <*>python3.5/dist-packages/torch/nn/modules/module.py, line 325, in _ _call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File [FILE], line 11, in forward(self, logits, targets) return self.crossEntropy_loss(probs_flat, targets_flat)[SEP]File <*>python3.5/dist-packages/torch/nn/modules/module.py, line 325, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.5/dist-packages/torch/nn/modules/loss.py, line 601, in f orward(self, input, target) self.ignore_index, self.reduce)[SEP]File <*>python3.5/dist-packages/torch/nn/functional.py, line 1140, in cross_entropy(input, target, weight, size_average, ignore_index, reduce) return nll_loss(log_softmax(input, 1), target, weight, size_average, ignore_index, reduce)[SEP]File <*>python3.5/dist-packages/torch/nn/functional.py, line 786, in log_softmax(input, dim, _stacklevel) return torch._C._nn.log_softmax(input, dim)[SEP]RuntimeError: dimension out of range (expected to be in range of [-1, 0], but got 1)",0
"File [FILE], line 1, in <module>() for batch_idx, (data, target) in enumerate(train_loader):[SEP]File <*>python2.7/dist-packages/torch/utils/data/dataloader.pyc, line 259, in __next__(self) batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>python2.7/dist-packages/torch/utils/data/dataloader.pyc, line 135, in default_collate(batch) return [default_collate(samples) for samples in transposed][SEP]File <*>python2.7/dist-packages/torch/utils/data/dataloader.pyc, line 112, in default_collate(batch) return torch.stack(batch, 0, out=out)[SEP]File <*>python2.7/dist-packages/torch/functional.pyc, line 64, in stack(sequence, dim, out) return torch.cat(inputs, dim)[SEP]RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 400 and 487 in dimension 2 at /pytorch/torch/lib/TH/generic/THTensorMath.c:2897",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 282, in __init__(self, fetches, contraction_fn) fetch, allow_tensor=True, allow_operation=True))[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3590, in as_graph_element(self, obj, allow_tensor, allow_operation) return self._as_graph_element_locked(obj, allow_tensor, allow_operation)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3679, in _as_graph_element_locked(self, obj, allow_tensor, allow_operation) types_str))[SEP]TypeError: Can not convert a Iterator into a Tensor or Operation.",0
"File [FILE], line 57, in <module>() feed_dict=feed_dict)[SEP]TypeError: 'NoneType' object is not iterable",0
"File [FILE], line 7, in <module>() X = AttentionLayer()(X)[SEP]File <*>python3.6/site-packages/keras/engine/topology.py, line 619, in __call__(self, inputs, **kwargs) output = self.call(inputs, **kwargs)[SEP]File <*>/attention.py, line 51, in call(self, x) flatten_g = hw_flatten(g)[SEP]File <*>/attention.py, line 41, in hw_flatten(x) return K.reshape(x, shape=[x.shape[0], x.shape[1]*x.shape[2], x.shape[-1]])[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 1898, in reshape(x, shape) return tf.reshape(x, shape)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py, line 6113, in reshape(tensor, shape, name) ""Reshape"", tensor=tensor, shape=shape, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 513, in _apply_op_helper(self, op_type_name, name, **keywords) raise err[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 510, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1104, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 235, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 214, in constant(value, dtype, shape, name, verify_shape) value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 521, in make_tensor_proto(values, dtype, shape, verify_shape) ""supported type."" % (type(values), values))[SEP]TypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [Dimension(None), Dimension(64), Dimension(8)]. Consider casting elements to a supported type.",0
"File [FILE], line 48, in <module>() labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1349, in sampled_softmax_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name, seed) seed=seed)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1128, in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed) true_logits -= math_ops.log(true_expected_count)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/math_ops.py, line 862, in binary_op_wrapper(x, y) return func(x, y, name=name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 8318, in sub(x, y, name) ""Sub"", x=x, y=y, name=name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 546, in _apply_op_helper(self, op_type_name, name, **keywords) inferred_from[input_arg.type_attr]))[SEP]TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type float16 of argument 'x'.",0
"File [FILE], line 8, in <module>() concat = tf.keras.layers.Concatenate()((features['a'], features['b']))[SEP]File <*>/base_layer.py, line 753, in __call__(self, inputs, *args, **kwargs) self.build(input_shapes)[SEP]File <*>/tf_utils.py, line 150, in wrapper(instance, input_shape) input_shape = tuple(tensor_shape.TensorShape(input_shape).as_list())[SEP]File <*>/tensor_shape.py, line 690, in __init__(self, dims) self._dims = [as_dimension(d) for d in dims_iter][SEP]File <*>/tensor_shape.py, line 632, in as_dimension(value) return Dimension(value)[SEP]File <*>/tensor_shape.py, line 185, in __init__(self, value) self._value = int(value)[SEP]TypeError: int() argument must be a string or a number, not 'TensorShapeV1'",0
"File [FILE], line 3, in <module>() epochs = range(epochs)[SEP]NameError: name 'epochs' is not defined",0
"File [FILE], line 16, in <module>() dataset = dataset.padded_batch(2, padded_shapes=([None],[None]), padding_values=-1)[SEP]File <*>python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py, line 945, in padded_batch(self, batch_size, padded_shapes, padding_values, drop_remainder) drop_remainder)[SEP]File <*>python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py, line 2528, in __init__(self, input_dataset, batch_size, padded_shapes, padding_values, drop_remainder) input_dataset.output_types)[SEP]File <*>python3.6/dist-packages/tensorflow/python/data/util/nest.py, line 467, in map_structure_up_to(shallow_tree, func, *inputs) assert_shallow_structure(shallow_tree, input_tree)[SEP]File <*>python3.6/dist-packages/tensorflow/python/data/util/nest.py, line 301, in assert_shallow_structure(shallow_tree, input_tree, check_types) ""Input has type: %s."" % type(input_tree))[SEP]TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'int'>.",0
"File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 525, in _apply_op_helper(self, op_type_name, name, **keywords) values, as_ref=input_arg.is_ref).dtype.name[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1175, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 304, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 245, in constant(value, dtype, shape, name) allow_broadcast=True)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast))[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/tensor_util.py, line 454, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) raise ValueError(""None values not supported."")[SEP]ValueError: None values not supported.",0
"File [FILE], line 14, in <module>() random_search.fit(X_train, y_train)[SEP]File <*>python3.6/site-packages/sklearn/model_selection/_search.py, line 677, in fit(self, X, y, groups, **fit_params) base_estimator = clone(self.estimator)[SEP]File <*>python3.6/site-packages/sklearn/base.py, line 58, in clone(estimator, safe) % (repr(estimator), type(estimator)))[SEP]TypeError: Cannot clone object '<keras.engine.sequential.Sequential object at 0x7fc268d8abe0>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods.",0
"File [FILE], line 1, in <module> modl(x)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 477, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File [FILE], line 223, in forward(self, x) de2 = torch.cat([en6add,de2_],1)[SEP]RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 5 and 4 in dimension 2 at /opt/conda/conda-bld/pytorch_1535491974311/work/aten/src/TH/generic/THTensorMath.cpp:3616",0
"File [FILE], line 23, in <module>() print(model(torch.tensor(X)).size)[SEP]File [FILE], line 14, in forward(self, x) x = self.layer1(x)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 489, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/conv.py, line 187, in forward(self, input) self.padding, self.dilation, self.groups)[SEP]RuntimeError: Expected 3-dimensional input for 3-dimensional weight [20, 7, 5], but got 2-dimensional input of size [10, 7] instead",0
"File <*>python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py, line 612, in __call__(self, inputs, *args, **kwargs) outputs = self.call(inputs, *args, **kwargs)[SEP]File [FILE], line 8, in call(self, data_input) model = self.input_layer(data_input)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/input_layer.py, line 233, in Input(shape, batch_size, name, dtype, sparse, tensor, **kwargs) input_tensor=tensor)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/input_layer.py, line 94, in __init__(self, input_shape, batch_size, dtype, input_tensor, sparse, name, **kwargs) batch_input_shape = (batch_size,) + tuple(input_shape)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 449, in __iter__(self) ""Tensor objects are only iterable when eager execution is ""[SEP]TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.",0
"File [FILE], line 5, in <module>() train_step(x_sample=x_point, y_sample=y_point)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 418, in __call__(self, *args, **kwds) results = self._stateful_fn(*args, **kwds)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1287, in __call__(self, *args, **kwargs) graph_function, args, kwargs = self._maybe_define_function(args, kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1611, in _maybe_define_function(self, args, kwargs) args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1512, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/func_graph.py, line 694, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 317, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/func_graph.py, line 686, in wrapper(*args, **kwargs) ), args, kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/autograph/impl/api.py, line 392, in converted_call(f, owner, options, args, kwargs) result = converted_f(*effective_args, **kwargs)[SEP]File <*>/tmpluzodr7d.py, line 4, in tf__train_step(x_sample, y_sample) predictions = ag__.converted_call(nn_regressor, None, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (x_sample,), {})[SEP]File <*>python3.6/site-packages/tensorflow/python/autograph/impl/api.py, line 267, in converted_call(f, owner, options, args, kwargs) return _call_unconverted(f, args, kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/autograph/impl/api.py, line 188, in _call_unconverted(f, args, kwargs) return f(*args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py, line 625, in __call__(self, inputs, *args, **kwargs) exception_str + '\n""""""')[SEP]TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.",0
"File [FILE], line 3, in <module> act([a,b])[SEP]File <*>python36/site-packages/keras/engine/base_layer.py, line 431, in __call__(self, inputs, **kwargs) self.build(unpack_singleton(input_shapes))[SEP]TypeError: build() takes 1 positional argument but 2 were given",0
"File [FILE], line 9, in <module>() for i in train_iter:[SEP]File <*>python3.6/site-packages/torchtext/data/iterator.py, line 157, in __iter__(self) yield Batch(minibatch, self.dataset, self.device)[SEP]File <*>python3.6/site-packages/torchtext/data/batch.py, line 34, in __init__(self, data, dataset, device) setattr(self, name, field.process(batch, device=device))[SEP]File <*>python3.6/site-packages/torchtext/data/field.py, line 201, in process(self, batch, device) tensor = self.numericalize(padded, device=device)[SEP]File <*>python3.6/site-packages/torchtext/data/field.py, line 302, in numericalize(self, arr, device) arr = [self.vocab.stoi[x] for x in arr][SEP]File <*>python3.6/site-packages/torchtext/data/field.py, line 302, in <listcomp>(.0) arr = [self.vocab.stoi[x] for x in arr][SEP]AttributeError: 'Field' object has no attribute 'vocab'",0
"File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1659, in _create_c_op(graph, node_def, inputs, control_inputs) c_op = c_api.TF_FinishOperation(op_desc)[SEP]InvalidArgumentError: Dimensions must be equal, but are 1 and 64 for 'loss_1/zero_padding2d_5_loss/MatMul' (op: 'BatchMatMul') with input shapes: [?,64,64,1], [1,64,64,?].",0
"File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 1969, in __setattr__(self, name, value) super(tracking.AutoTrackable, self).__setattr__(name, value)[SEP]AttributeError: can't set attribute",0
"File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 1974, in __setattr__(self, name, value) 'different name.').format(name))[SEP]AttributeError: Can't set the attribute ""name"", likely because it conflicts with an existing read-only @property of the object. Please choose a different name.",0
"File [FILE], line 1, in <module> import tensorflow_probability as tfp[SEP]ModuleNotFoundError: No module named 'tensorflow_probability'.",0
"File [FILE], line 1, in <module>() process_image('IMG_PATH')[SEP]File [FILE], line 5, in process_image(img_path) pImg = MobileNetV2.preprocess_input(img_array)[SEP]AttributeError: 'function' object has no attribute 'preprocess_input'",0
"File [FILE], line 2, in <module> x.forward(torch.tensor([0,2,5,8]), higgs_bosson=2)[SEP]TypeError: forward() got an unexpected keyword argument 'higgs_bosson'",0
"File <*>python3.6/site-packages/keras/engine/topology.py, line 425, in assert_input_compatibility(self, inputs) K.is_keras_tensor(x)[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 400, in is_keras_tensor(x) raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '[SEP]ValueError: Unexpectedly found an instance of type `<class 'keras.layers.normalization.BatchNormalization'>`. Expected a symbolic tensor instance.",0
"File [FILE], line 4, in <module>() feature_extractor = hub.KerasLayer(_URL, input_shape=(_TARGET_SIZE, _TARGET_SIZE,3))[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py, line 167, in _variable_handle_from_shape_and_dtype(shape, dtype, shared_name, name, graph_mode, initial_value) handle_data.shape_and_type.append([SEP]AttributeError: 'google.protobuf.pyext._message.RepeatedCompositeCo' object has no attribute 'append'",0
"File [FILE], line 1, in <module> loaded_model.summary()[SEP]AttributeError: 'NoneType' object has no attribute 'summary'",0
"File [FILE], line 4, in <module>() pred = model(x)[SEP]File <*>python3.6/sequential.py, line 256, in call(self, inputs, training, mask) return super(Sequential, self).call(inputs, training=training, mask=mask)[SEP]File <*>python3.6/network.py, line 708, in call(self, inputs, training, mask) convert_kwargs_to_constants=base_layer_utils.call_context().saving)[SEP]File <*>python3.6/network.py, line 860, in _run_internal_graph(self, inputs, training, mask, convert_kwargs_to_constants) output_tensors = layer(computed_tensors, **kwargs)[SEP]File <*>python3.6/wrappers.py, line 528, in __call__(self, inputs, initial_state, constants, **kwargs) return super(Bidirectional, self).__call__(inputs, **kwargs)[SEP]File <*>python3.6/base_layer.py, line 891, in __call__(self, inputs, *args, **kwargs) outputs = self.call(cast_inputs, *args, **kwargs)[SEP]File <*>python3.6/wrappers.py, line 642, in call(self, inputs, training, mask, initial_state, constants) initial_state=forward_state, **kwargs)[SEP]File <*>python3.6/recurrent.py, line 623, in __call__(self, inputs, initial_state, constants, **kwargs) return super(RNN, self).__call__(inputs, **kwargs)[SEP]File <*>python3.6/recurrent_v2.py, line 961, in call(self, inputs, mask, training, initial_state) **cudnn_lstm_kwargs)[SEP]File <*>python3.6/recurrent_v2.py, line 1174, in cudnn_lstm(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards) rnn_mode='lstm')[SEP]File <*>python3.6/gen_cudnn_rnn_ops.py, line 109, in cudnn_rnn(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name) ctx=_ctx)[SEP]File <*>python3.6/gen_cudnn_rnn_ops.py, line 198, in cudnn_rnn_eager_fallback(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx) attrs=_attrs, ctx=_ctx, name=name)[SEP]File <*>python3.6/execute.py, line 67, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <*>python3.6/dist-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE][SEP]InvalidArgumentError: Invalid input_h shape: [1,64,1024] [1,54,1024] [Op:CudnnRNN]",0
"File [FILE], line 48, in <module> prediction = model(X)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 493, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/parallel/data_parallel.py, line 146, in forward(self, *inputs, **kwargs) ""them on device: {}"".format(self.src_device_obj, t.device))[SEP]RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:2",0
"File [FILE], line 4, in <module> model.fit(train_encoded, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(test_encoded,test_labels))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 324, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs) total_epochs=epochs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 123, in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs) batch_outs = execution_function(iterator)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 86, in execution_function(input_fn) distributed_function(input_fn))[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializer_map)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize(self, args, kwds, add_initializers_to) *args, **kwds))[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>/site-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 73, in distributed_function(input_iterator) per_replica_function, args=(model, x, y, sample_weights))[SEP]File <*>/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 760, in experimental_run_v2(self, fn, args, kwargs) return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 1787, in call_for_each_replica(self, fn, args, kwargs) return self._call_for_each_replica(fn, args, kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 2132, in _call_for_each_replica(self, fn, args, kwargs) return fn(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/autograph/impl/api.py, line 292, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics) output_loss_metrics=model._output_loss_metrics)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics) output_loss_metrics=output_loss_metrics))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 252, in _process_single_batch(model, inputs, targets, output_loss_metrics, sample_weights, training) training=training))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 127, in _model_loss(model, inputs, targets, output_loss_metrics, sample_weights, training) outs = model(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 847, in __call__(self, inputs, *args, **kwargs) outputs = call_fn(cast_inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/sequential.py, line 270, in call(self, inputs, training, mask) outputs = layer(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 812, in __call__(self, inputs, *args, **kwargs) self.name)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/input_spec.py, line 213, in assert_input_compatibility(input_spec, inputs, layer_name) ' but received input with shape ' + str(shape))[SEP]ValueError: Input 0 of layer dense_3 is incompatible with the layer: expected axis -1 of input shape to have value 6022 but received input with shape [None, 512]",0
"File [FILE], line 9, in <module> train_loss, train_acc = train(model, train_iterator, optimizer, criterion)[SEP]File [FILE], line 8, in train(model, iterator, optimizer, criterion) for batch in iterator:[SEP]File <*>python3.7/site-packages/torchtext/data/iterator.py, line 142, in __iter__(self) for idx, minibatch in enumerate(self.batches):[SEP]File <*>python3.7/site-packages/torchtext/data/iterator.py, line 286, in pool(data, batch_size, key, batch_size_fn, random_shuffler, shuffle, sort_within_batch) if sort_within_batch \[SEP]TypeError: '<' not supported between instances of 'Example' and 'Example'",0
"File [FILE], line 70, in <module>() loss = torch.nn.MSELoss(out, target)[SEP]File <*>python3.6/dist-packages/torch/nn/_reduction.py, line 36, in legacy_get_string(size_average, reduce, emit_warning) if size_average and reduce:[SEP]RuntimeError: bool value of Tensor with more than one value is ambiguous",0
"File [FILE], line 16, in <module> model.fit(X_train, y_train, epochs=3)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 819, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 342, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) total_epochs=epochs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs) batch_outs = execution_function(iterator)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function(input_fn) distributed_function(input_fn))[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 632, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2363, in __call__(self, *args, **kwargs) return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call(self, args, kwargs) self.captured_inputs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat(self, args, captured_inputs, cancellation_manager) ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 545, in call(self, ctx, args, cancellation_manager) ctx=ctx)[SEP]File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <*>/site-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE][SEP]UnimplementedError: Cast string to int64 is not supported [[node loss/output_1_loss/Cast (defined at <ipython-input-111-1a89f1d94518>:16) ]] [Op:__inference_distributed_function_544280]",0
"File [FILE], line 5, in <module> verbose = 1)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 872, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) return_dict=True)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1081, in evaluate(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict) tmp_logs = test_function(iterator)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 618, in _call(self, *args, **kwds) results = self._stateful_fn(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2419, in __call__(self, *args, **kwargs) graph_function, args, kwargs = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2774, in _maybe_define_function(self, args, kwargs) return self._define_function_with_shape_relaxation(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2706, in _define_function_with_shape_relaxation(self, args, kwargs) args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2667, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 981, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 441, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]AssertionError: in user code: c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\training.py:941 test_function * outputs = self.distribute_strategy.run( c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:951 run ** return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2290 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2649 _call_for_each_replica return fn(*args, **kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\training.py:909 test_step ** y_pred = self(x, training=False) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:927 __call__ outputs = call_fn(cast_inputs, *args, **kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\ etwork.py:719 call convert_kwargs_to_constants=base_layer_utils.call_context().saving) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\ etwork.py:899 _run_internal_graph assert str(id(x)) in tensor_dict, 'Could not compute output ' + str(x) AssertionError: Could not compute output Tensor(""O1_6/Identity:0"", shape=(None, 2), dtype=float32)",0
"File [FILE], line 9, in <module>() model.save(outdir+'model.h5')[SEP]File <*>python3.6/dist-packages/h5py/_hl/group.py, line 373, in __setitem__(self, name, obj) h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl)[SEP]File <*>/_objects.pyx, line [NUM], in h5py._objects.with_phil.wrapper() [CODE][SEP]File <*>/h5o.pyx, line [NUM], in h5py.h5o.link() [CODE][SEP]RuntimeError: Unable to create link (name already exists)",0
"File [FILE], line 1, in <module> history = model.fit([train.id, train.user_id], train.user_like, nb_epoch=3)[SEP]File <*>/site-packages/keras/engine/training.py, line 1657, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs) validation_steps=validation_steps)[SEP]File <*>/site-packages/keras/engine/training.py, line 1213, in _fit_loop(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps) outs = f(ins_batch)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2357, in __call__(self, inputs) **self.session_kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 956, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1180, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1359, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1384, in _do_call(self, fn, *args) session_config.graph_options.rewrite_options.' raise type(e)(node_def, op, message)[SEP]InvalidArgumentError: indices[24,0] = 335 is not in [0, 304) [[node user-embedding-mlp_1/GatherV2 (defined at E:\My\Ananconda\envs\tensor\lib\site-packages\tensorflow_core\python\framework\ops.py:1748) ]]",0
"File [FILE], line 3, in <module> validation_data=validation_batches)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 848, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) tmp_logs = train_function(iterator)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 611, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) # pylint: disable=not-callable[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2420, in __call__(self, *args, **kwargs) return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1665, in _filtered_call(self, args, kwargs) self.captured_inputs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1746, in _call_flat(self, args, captured_inputs, cancellation_manager) ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 598, in call(self, ctx, args, cancellation_manager) ctx=ctx)[SEP]File <*>/site-packages/tensorflow/python/eager/execute.py, line 60, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) inputs, attrs, num_outputs)[SEP]InvalidArgumentError: 2 root error(s) found. (0) Invalid argument: Invalid JPEG data or crop window, data size 34228 [[{{node DecodeJpeg}}]] [[IteratorGetNext]] (1) Invalid argument: Invalid JPEG data or crop window, data size 34228 [[{{node DecodeJpeg}}]] [[IteratorGetNext]] [[IteratorGetNext/_4]]",0
"File [FILE], line 30, in <module>() attn_out, attn_states = tf.keras.layers.Attention()([encoder_output, decoder_output])[SEP]File <*>python3.6/site-packages/tensorflow_core/python/framework/ops.py, line 548, in __iter__(self) ""Cannot iterate over a tensor with unknown first dimension."")[SEP]TypeError: Cannot iterate over a tensor with unknown first dimension.",0
"File [FILE], line 16, in <module>() abc = model.predict(img)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py, line 971, in select_data_adapter(x, y) _type_name(x), _type_name(y)))[SEP]ValueError: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>",0
"File [FILE], line 8, in <module> from keras.models import Sequential[SEP]File <*>/site-packages/keras/__init__.py, line 6, in <module> 'Keras requires TensorFlow 2.2 or higher. '[SEP]ImportError: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow",0
"File [FILE], line 3, in <module>() loss = keras.losses.categorical_crossentropy()[SEP]File <*>python3.6/dist-packages/tensorflow/python/util/dispatch.py, line 201, in wrapper(*args, **kwargs) return target(*args, **kwargs)[SEP]TypeError: categorical_crossentropy() missing 2 required positional arguments: 'y_true' and 'y_pred'",0
"File [FILE], line 1, in <module> import deeplabcut as dlc[SEP]File <*>python3.7/site-packages/deeplabcut/__init__.py, line 38, in <module> from deeplabcut import generate_training_dataset[SEP]File <*>python3.7/site-packages/deeplabcut/generate_training_dataset/__init__.py, line 18, in <module> from deeplabcut.generate_training_dataset.labeling_toolbox import *[SEP]File <*>python3.7/site-packages/deeplabcut/generate_training_dataset/labeling_toolbox.py, line 33, in <module> from deeplabcut.utils import auxiliaryfunctions[SEP]File <*>python3.7/site-packages/deeplabcut/utils/__init__.py, line 6, in <module> from deeplabcut.utils.make_labeled_video import *[SEP]File <*>python3.7/site-packages/deeplabcut/utils/make_labeled_video.py, line 28, in <module> from matplotlib.animation import FFMpegWriter[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 737, in <module> class ImageMagickWriter(ImageMagickBase, MovieWriter):[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 120, in wrapper(writerClass) if writerClass.isAvailable():[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 730, in isAvailable(cls) return super().isAvailable()[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 427, in isAvailable(cls) return shutil.which(cls.bin_path()) is not None[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 724, in bin_path(cls) binpath = mpl._get_executable_info('magick').executable[SEP]File <*>python3.7/site-packages/matplotlib/__init__.py, line 385, in _get_executable_info(name) return impl([path, ""--version""], r""^Version: ImageMagick (\S*)"")[SEP]File <*>python3.7/site-packages/matplotlib/__init__.py, line 330, in impl(args, regex, min_ver, ignore_exit_code) raise _cpe[SEP]File <*>python3.7/site-packages/matplotlib/__init__.py, line 325, in impl(args, regex, min_ver, ignore_exit_code) universal_newlines=True, errors=""replace"")[SEP]File <*>python3.7/subprocess.py, line 411, in check_output(timeout, *popenargs, **kwargs) **kwargs).stdout[SEP]File <*>python3.7/subprocess.py, line 512, in run(input, capture_output, timeout, check, *popenargs, **kwargs) output=stdout, stderr=stderr)[SEP]CalledProcessError: Command '['convert', '--version']' returned non-zero exit status 1.",0
"File [FILE], line 3, in <module> torch.load(cachefile)[SEP]File <*>python3.8/site-packages/torch/serialization.py, line 584, in load(f, map_location, pickle_module, **pickle_load_args) return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)[SEP]File <*>python3.8/site-packages/torch/serialization.py, line 839, in _load(zip_file, map_location, pickle_module, **pickle_load_args) data_file = io.BytesIO(zip_file.get_record('data.pkl'))[SEP]RuntimeError: [enforce fail at inline_container.cc:209] . file not found: archive/data.pkl",0
"File [FILE], line 1, in <module>() x = build_img_encod()[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py, line 166, in assert_input_compatibility(input_spec, inputs, layer_name) if x.shape.ndims is None:[SEP]AttributeError: 'Functional' object has no attribute 'shape'",0
"File <*>python3.6/dist-packages/tensorflow/python/util/nest.py, line 402, in assert_same_structure(nest1, nest2, check_types, expand_composites) % (str(e), str1, str2))[SEP]ValueError: The two structures don't have the same nested structure.",0
"File [FILE], line 7, in <module>() gen.load_state_dict(torch.load(os.path.join(workspace_dir, 'dcgan_g.pth')))[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 1052, in load_state_dict(self, state_dict, strict) self.__class__.__name__, ""\n\t"".join(error_msgs)))[SEP]***RuntimeError: Error(s) in loading state_dict for Generator: Missing key(s) in state_dict***: ""gen.0.0.weight"", ""gen.0.1.weight"", ""gen.0.1.bias"", ""gen.0.1.running_mean"", ""gen.0.1.running_var"", ""gen.1.0.weight"", ""gen.1.1.weight"", ""gen.1.1.bias"", ""gen.1.1.running_mean"", ""gen.1.1.running_var"", ""gen.2.0.weight"", ""gen.2.1.weight"", ""gen.2.1.bias"", ""gen.2.1.running_mean"", ""gen.2.1.running_var"", ""gen.3.0.weight"", ""gen.3.1.weight"", ""gen.3.1.bias"", ""gen.3.1.running_mean"", ""gen.3.1.running_var"", ""gen.4.weight"", ""gen.4.bias"". Unexpected key(s) in state_dict: ""disc.0.weight"", ""disc.0.bias"", ""disc.2.0.weight"", ""disc.2.1.weight"", ""disc.2.1.bias"", ""disc.2.1.running_mean"", ""disc.2.1.running_var"", ""disc.2.1.num_batches_tracked"", ""disc.3.0.weight"", ""disc.3.1.weight"", ""disc.3.1.bias"", ""disc.3.1.running_mean"", ""disc.3.1.running_var"", ""disc.3.1.num_batches_tracked"", ""disc.4.0.weight"", ""disc.4.1.weight"", ""disc.4.1.bias"", ""disc.4.1.running_mean"", ""disc.4.1.running_var"", ""disc.4.1.num_batches_tracked"", ""disc.5.weight"", ""disc.5.bias"".",0
"File [FILE], line 8, in <module> model.save(""temp_model"")[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1979, in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options) signatures, options)[SEP]File <*>/site-packages/tensorflow/python/keras/saving/save.py, line 134, in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options) signatures, options)[SEP]File <*>/site-packages/tensorflow/python/keras/saving/saved_model/save.py, line 80, in save(model, filepath, overwrite, include_optimizer, signatures, options) save_lib.save(model, filepath, signatures, options)[SEP]File <*>/site-packages/tensorflow/python/saved_model/save.py, line 976, in save(obj, export_dir, signatures, options) obj, export_dir, signatures, options, meta_graph_def)[SEP]File <*>/site-packages/tensorflow/python/saved_model/save.py, line 1061, in _build_meta_graph(obj, export_dir, signatures, options, meta_graph_def) _ = _SaveableView(checkpoint_graph_view)[SEP]File <*>/site-packages/tensorflow/python/saved_model/save.py, line 178, in __init__(self, checkpoint_view, wrapped_functions) self.checkpoint_view.objects_ids_and_slot_variables())[SEP]File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 426, in objects_ids_and_slot_variables(self) object_names[obj] = _object_prefix_from_path(path)[SEP]File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 64, in _object_prefix_from_path(path_to_root) for trackable in path_to_root))[SEP]File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 64, in <genexpr>(.0) for trackable in path_to_root))[SEP]File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 57, in _escape_local_name(name) return (name.replace(_ESCAPE_CHAR, _ESCAPE_CHAR + _ESCAPE_CHAR)[SEP]AttributeError: 'NoneType' object has no attribute 'replace'",0
"File [FILE], line 7, in <module>() validation_steps = valid_step , callbacks = [metrics], verbose=2)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 673, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 1433, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch')[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py, line 260, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) callbacks._call_batch_hook(mode, 'begin', step, batch_logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 247, in _call_batch_hook(self, mode, hook, batch, logs) batch_hook = getattr(callback, hook_name)[SEP]AttributeError: 'Metrics' object has no attribute 'on_train_batch_begin'",0
