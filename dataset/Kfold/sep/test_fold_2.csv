Templates,label
"File <pyshell#146>, line 1, in <module> that[~(that>=5).nonzero()].max().eval()[SEP]AttributeError: 'TensorVariable' object has no attribute 'nonzero'",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow import contrib[SEP]File <*>python2.7/site-packages/tensorflow/contrib/__init__.py, line 23, in <module> from tensorflow.contrib import layers[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/__init__.py, line 68, in <module> from tensorflow.contrib.layers.python.layers import *[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/__init__.py, line 22, in <module> from tensorflow.contrib.layers.python.layers.initializers import *[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/initializers.py, line 24, in <module> from tensorflow.python.ops import random_ops[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/random_ops.py, line 23, in <module> from tensorflow.python.framework import ops[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 39, in <module> from tensorflow.python.framework import versions[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/versions.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory",1
"File <*>/test3.py, line 5, in [FUNC] [CODE][SEP]AttributeError: module 'tensorflow.contrib.learn' has no attribute 'TensorFlowDNNClassifier'",1
"File DA_test_pred.py, line 24, in <module> logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False)[SEP]File <*>/inception_v1.py, line 290, in inception_v1 net, end_points = inception_v1_base(inputs, scope=scope)[SEP]File <*>/inception_v1.py, line 96, in inception_v1_base net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])[SEP]File <*>python2.7/dist-packages/tensorflow/python/ops/array_ops.py, line 1053, in concat dtype=dtypes.int32).get_shape([SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 651, in convert_to_tensor as_ref=False)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 716, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/constant_op.py, line 176, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/constant_op.py, line 165, in constant tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/tensor_util.py, line 367, in make_tensor_proto _AssertCompatible(values, dtype)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/tensor_util.py, line 302, in _AssertCompatible (dtype.name, repr(mismatch), type(mismatch).__name__))[SEP]TypeError: Expected int32, got list containing Tensors of type '_Message' instead.",1
"File ptb_word_lm.py, line 374, in <module> tf.app.run()[SEP]File <*>python3.6/site-packages/tensorflow/python/platform/app.py, line 43, in run sys.exit(main(sys.argv[:1] + flags_passthrough))[SEP]File ptb_word_lm.py, line 334, in main train_input = PTBInput(config=config, data=train_data, name=""TrainInput"")[SEP]File ptb_word_lm.py, line 94, in __init__ data, batch_size, num_steps, name=name)[SEP]File <*>/reader.py, line 117, in ptb_producer [batch_size, (i + 1) * num_steps])[SEP]TypeError: strided_slice() missing 1 required positional argument: 'strides'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper() return importlib.import_module(mname)[SEP]File <*>/importlib__init__.py, line 126, in import_module(name, package) return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <*>/importlib_bootstrap.py, line [NUM], in _gcd_import(name, package, level) [CODE][SEP]File <*>/importlib_bootstrap.py, line [NUM], in _find_and_load(name, import_) [CODE][SEP]File <*>/importlib_bootstrap.py, line [NUM], in _find_and_load_unlocked(name, import_) [CODE][SEP]File <*>/importlib_bootstrap.py, line [NUM], in _load_unlocked(spec) [CODE][SEP]File <*>/importlib_bootstrap.py, line [NUM], in module_from_spec(spec ) [CODE][SEP]File <*>/importlib_bootstrap_external.py, line [NUM], in create_module(self, spec) [CODE][SEP]File <*>/importlib_bootstrap.py, line [NUM], in _call_with_frames_removed(f, *args, **kwds) [CODE][SEP]ImportError: DLL load failed: The specified module could not be found.",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper return importlib.import_module(mname)[SEP]File <*>/importlib__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File [FILE], line 126, in [FUNC] [CODE][SEP]ImportError: DLL load failed: The specified module could not be found.",1
"File <*>python3.5/site-packages/tensorflow/python/framework/op_def_library.py, line 491, in apply_op(self, op_type_name, name, **keywords) preferred_dtype=default_dtype)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 704, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 577, in _TensorTensorConversionFunction(t, dtype, name, as_ref) % (dtype.name, t.dtype.name, str(t)))[SEP]ValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(""nce_loss/Reshape_1:0"", shape=(?, 1, ?), dtype=float32)'",1
"File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.6/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.6/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: dlopen(/Users/joson/tensorflow/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 10): Library not loaded: @rpath/libcublas.8.0.dylib",1
"File <string>, line 1, in <module> [CODE][SEP]File <*>python3.4/site-packages/pandas/__init__.py, line 35, in <module> ""the C extensions first."".format(module))[SEP]ImportError: C extension: numpy.core.multiarray failed to import not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer[SEP]File <*>/pycaffe.py, line 15, in <module> import caffe.io[SEP]File <*>/io.py, line 2, in <module> import skimage.io[SEP]File <*>python3.6/site-packages/skimage/io/__init__.py, line 15, in <module> reset_plugins()[SEP]File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 93, in reset_plugins _load_preferred_plugins()[SEP]File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 73, in _load_preferred_plugins _set_plugin(p_type, preferred_plugins['all'])[SEP]File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 85, in _set_plugin use_plugin(plugin, kind=plugin_type)[SEP]File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 255, in use_plugin _load(name)[SEP]File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 299, in _load fromlist=[modname])[SEP]File <*>python3.6/site-packages/skimage/io/_plugins/matplotlib_plugin.py, line 3, in <module> import matplotlib.pyplot as plt[SEP]File <*>python3.6/site-packages/matplotlib/pyplot.py, line 40, in <module> from matplotlib.figure import Figure, figaspect[SEP]File <*>python3.6/site-packages/matplotlib/figure.py, line 39, in <module> from matplotlib.axes import Axes, SubplotBase, subplot_class_factory[SEP]File <*>python3.6/site-packages/matplotlib/axes/__init__.py, line 4, in <module> from ._subplots import *[SEP]File <*>python3.6/site-packages/matplotlib/axes/_subplots.py, line 10, in <module> from matplotlib.axes._axes import Axes[SEP]File <*>python3.6/site-packages/matplotlib/axes/_axes.py, line 23, in <module> import matplotlib.dates as _ # <-registers a date unit converter[SEP]File <*>python3.6/site-packages/matplotlib/dates.py, line 148, in <module> from dateutil.rrule import (rrule, MO, TU, WE, TH, FR, SA, SU, YEARLY,[SEP]File <*>python3.6/site-packages/dateutil/rrule.py, line 55, in [FUNC] [CODE][SEP]SyntaxError: invalid syntax",1
"File [FILE], line 9, in <module>() features, label = iter(train_dataset).next()[SEP]TypeError: 'BatchDataset' object is not iterable",1
"File kerasbottleneck.py, line 104, in <module> train_top_model()[SEP]File kerasbottleneck.py, line 82, in train_top_model train_data = np.load(open('bottleneck_features_train.npy'))[SEP]File <*>python3.6/site-packages/numpy/lib/npyio.py, line 404, in load magic = fid.read(N)[SEP]File <*>python3.6/codecs.py, line 321, in decode (result, consumed) = self._buffer_decode(data, self.errors, final)[SEP]UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte",1
"File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.6/imp.py, line 243, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.6/imp.py, line 343, in load_dynamic return _load(spec)[SEP]ImportError: dlopen(/Users/me/tensorflow/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation",1
"File tSNE-images.py, line 95, in <module> run_tsne(images_path, output_path, tsne_dimensions, tsne_perplexity, tsne_learning_rate)[SEP]File tSNE-images.py, line 75, in run_tsne images, pca_features = analyze_images(images_path)[SEP]File tSNE-images.py, line 50, in analyze_images feat_extractor = Model(inputs=model.input, outputs=model.get_layer(""fc2"").output)[SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 91, in __init__ self._init_graph_network(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 251, in _init_graph_network input_shapes=[x._keras_shape for x in self.inputs],[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 251, in <listcomp> input_shapes=[x._keras_shape for x in self.inputs],[SEP]AttributeError: 'Tensor' object has no attribute '_keras_shape'",1
"File [FILE], line 2, in <module>() from keras.utils import model_to_dot[SEP]ImportError: cannot import name 'model_to_dot'",1
"File tuto.py, line 85, in <module> estimator.train(input_fn=get_input_fn(num_epochs=None,n_batch = 128,shuffle=True),steps=1000)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 354, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 1207, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 1237, in _train_model_default features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 1195, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/, line 537, in _model_fn sparse_combiner=sparse_combiner)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/, line 215, in _linear_model_fn logits=logits)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 239, in create_estimator_spec regularization_losses))[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 1482, in _create_tpu_estimator_spec features=features, mode=mode, logits=logits, labels=labels)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 1381, in create_loss expected_labels_dimension=self._logits_dimension)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 305, in _check_dense_labels_match_logits_and_reshape labels = sparse_tensor.convert_to_tensor_or_sparse_tensor(labels)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/sparse_tensor.py, line 279, in convert_to_tensor_or_sparse_tensor value, dtype=dtype, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1146, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 229, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 208, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 531, in make_tensor_proto ""supported type."" % (type(values), values))[SEP]TypeError: Failed to convert object of type <class 'dict'> to Tensor. Contents: {'DispositionSoldAmount': <tf.Tensor 'random_shuffle_queue_DequeueMany:4' shape=(128,) dtype=float64>}. Consider casting elements to a supported type.",1
"File <*>/train.py, line 326, in <module> batch_size=params.batch_size, is_binary=params.is_b_binary)[SEP]File <*>/models.py, line 378, in g_unet i = Input(shape=(in_ch, 512, 512))[SEP]File <*>/site-packages/keras/engine/input_layer.py, line 178, in Input input_tensor=tensor)[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/engine/input_layer.py, line 39, in __init__ name = prefix + '_' + str(K.get_uid(prefix))[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 74, in get_uid graph = tf.get_default_graph()[SEP]AttributeError: module 'tensorflow' has no attribute 'get_default_graph'",1
"File [FILE], line 4, in <module>() model =load_model('Leavesnet Model.h5')[SEP]File <*>python3.6/dist-packages/keras/backend/tensorflow_backend.py, line 541, in placeholder(shape, ndim, dtype, sparse, name) x = tf.placeholder(dtype, shape=shape, name=name)[SEP]AttributeError: module 'tensorflow' has no attribute 'placeholder'",1
"File <*>python3.6/dist-packages/numpy/core/function_base.py, line 117, in linspace num = operator.index(num)[SEP]TypeError: 'numpy.float64' object cannot be interpreted as an integer",1
"File <*>/train.py, line 165, in <module> main()[SEP]File <*>/train.py, line 65, in main tf.set_random_seed(args.random_seed)[SEP]AttributeError: 'module' object has no attribute 'set_random_seed'",1
"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: module 'tensorflow' has no attribute 'random_normal'",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.7/site-packages/torch/__init__.py, line 81, in <module> from torch._C import *[SEP]ImportError: /lib/arm-linux-gnueabihf/libc.so.6: version `GLIBC_2.28' not found (required by /usr/local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/tensorflow/__init__.py, line 101, in <module> from tensorflow_core import *[SEP]File <*>/site-packages/tensorflow_core/__init__.py, line 46, in <module> from . _api.v2 import compat[SEP]File <*>/site-packages/tensorflow_core/_api/v2/compat/__init__.py, line 39, in <module> from . import v1[SEP]File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/__init__.py, line 32, in <module> from . import compat[SEP]File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/compat/__init__.py, line 39, in <module> from . import v1[SEP]File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/compat/v1/__init__.py, line 29, in <module> from tensorflow._api.v2.compat.v1 import app[SEP]File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/compat/v1/__init__.py, line 667, in <module> from tensorflow_estimator.python.estimator.api._v1 import estimator[SEP]File <*>/site-packages/tensorflow_estimator/__init__.py, line 10, in <module> from tensorflow_estimator._api.v1 import estimator[SEP]File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py, line 10, in <module> from tensorflow_estimator._api.v1.estimator import experimental[SEP]File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py, line 10, in <module> from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py, line 33, in <module> from tensorflow_estimator.python.estimator import estimator[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 53, in <module> from tensorflow_estimator.python.estimator import util as estimator_util[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/util.py, line 75, in <module> class _DatasetInitializerHook(tf.compat.v1.train.SessionRunHook):[SEP]AttributeError: module 'tensorflow' has no attribute 'compat'",1
"File <*>/site-packages/keras/models.py, line 1211, in from_config if 'class_name' not in config[0] or config[0]['class_name'] == 'Merge':[SEP]KeyError: 0",1
"File <*>/coco.py, line 456, in <module> model_dir=args.logs)[SEP]File <*>/site-packages/mrcnn/model.py, line 1832, in __init__ self.keras_model = self.build(mode=mode, config=config)[SEP]File <*>/site-packages/mrcnn/model.py, line 1871, in build x, K.shape(input_image)[1:3]))(input_gt_boxes)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 952, in __call__ input_list)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1091, in _functional_construction_call inputs, input_masks, args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 822, in _keras_tensor_symbolic_call return self._infer_output_signature(inputs, args, kwargs, input_masks)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 869, in _infer_output_signature keras_tensor.keras_tensor_from_tensor, outputs)[SEP]File <*>/site-packages/tensorflow/python/util/nest.py, line 659, in map_structure structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/util/nest.py, line 659, in <listcomp> structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/keras/engine/keras_tensor.py, line 606, in keras_tensor_from_tensor out = keras_tensor_cls.from_tensor(tensor)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/keras_tensor.py, line 205, in from_tensor type_spec = type_spec_module.type_spec_from_value(tensor)[SEP]File <*>/site-packages/tensorflow/python/framework/type_spec.py, line 554, in type_spec_from_value (value, type(value).__name__))[SEP]TypeError: Could not build a TypeSpec for <KerasTensor: shape=(None, None, 4) dtype=float32 (created by layer 'tf.math.truediv')> with type KerasTensor",1
"File <*>/script.py, line 654, in <module> prediction_result, (r, t) = cf.to(model_runner.predict(processed_feature_dict, random_seed=seed), ""cpu"")[SEP]File <*>python3.7/site-packages/alphafold/model/model.py, line 134, in predict result, recycles = self.apply(self.params, jax.random.PRNGKey(random_seed), feat)[SEP]File <*>python3.7/site-packages/jax/interpreters/xla.py, line 373, in backend_compile return backend.compile(built_c, compile_options=options)[SEP]RuntimeError: Resource exhausted: Out of memory while trying to allocate 4649385984 bytes.",1
"File <*>/site-packages/theano/configparser.py, line 168, in fetch_val_for_key return theano_cfg.get(section, option)[SEP]File <*>/configparser.py, line 781, in get d = self._unify_values(section, vars)[SEP]File <*>/configparser.py, line 1149, in _unify_values raise NoSectionError(section) from None[SEP]configparser.NoSectionError: No section: 'blas'",1
"File <*>/io.py, line 2, in <module> import skimage.io[SEP]File <*>python2.7/dist-packages/skimage/io/__init__.py, line 11, in <module> from ._io import *[SEP]File <*>python2.7/dist-packages/skimage/io/_io.py, line 1, in <module> from io import BytesIO[SEP]ImportError: cannot import name BytesIO",0
"File <*>/output.py, line 13, in <module> import caffe[SEP]File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver[SEP]File <*>/pycaffe.py, line 10, in <module> from ._caffe import Net, SGDSolver[SEP]ImportError: No module named _caffe",0
"File <*>/classify.py, line 130, in <module> main(sys.argv)[SEP]File <*>/classify.py, line 103, in main channel_swap=channel_swap)[SEP]TypeError: __init__() got an unexpected keyword argument 'gpu'",0
"File las_mnist.py, line 39, in <module> net1.fit(X[i], y[i])[SEP]File <*>python2.7/dist-packages/nolearn/lasagne.py, line 266, in fit self.train_loop(X, y)[SEP]File <*>python2.7/dist-packages/nolearn/lasagne.py, line 273, in train_loop X, y, self.eval_size)[SEP]File <*>python2.7/dist-packages/nolearn/lasagne.py, line 377, in train_test_split kf = KFold(y.shape[0], round(1. / eval_size))[SEP]IndexError: tuple index out of range",0
"File <*>python2.7/site-packages/pip/basecommand.py, line 211, in main status = self.run(options, args)[SEP]File <*>python2.7/site-packages/pip/commands/install.py, line 311, in run root=options.root_path,[SEP]File <*>python2.7/site-packages/pip/req/req_set.py, line 640, in install requirement.uninstall(auto_confirm=True)[SEP]File <*>python2.7/site-packages/pip/req/req_install.py, line 716, in uninstall paths_to_remove.remove(auto_confirm)[SEP]File <*>python2.7/site-packages/pip/req/req_uninstall.py, line 125, in remove renames(path, new_path)[SEP]File <*>python2.7/site-packages/pip/utils/__init__.py, line 315, in renames shutil.move(old, new)[SEP]File <*>python2.7/shutil.py, line 303, in move os.unlink(src)[SEP]OSError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/site-packages/six-1.9.0.dist-info/DESCRIPTION.rst'",0
"File cifar10.py, line 54, in <module> """"""Number of images to process in a batch."""""")[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/default/_flags.py, line 86, in DEFINE_integer _define_helper(flag_name, default_value, docstring, int)[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/default/_flags.py, line 60, in _define_helper type=flagtype)[SEP]File <*>python2.7/argparse.py, line 1297, in add_argument return self._add_action(action)[SEP]File <*>python2.7/argparse.py, line 1671, in _add_action self._optionals._add_action(action)[SEP]File <*>python2.7/argparse.py, line 1498, in _add_action action = super(_ArgumentGroup, self)._add_action(action)[SEP]File <*>python2.7/argparse.py, line 1311, in _add_action self._check_conflict(action)[SEP]File <*>python2.7/argparse.py, line 1449, in _check_conflict conflict_handler(action, confl_optionals)[SEP]File <*>python2.7/argparse.py, line 1456, in _handle_conflict_error raise ArgumentError(action, message % conflict_string)[SEP]argparse.ArgumentError: argument --batch_size: conflicting option string(s): --batch_size",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/theano/__init__.py, line 111, in <module> theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1()[SEP]File <*>/site-packages/theano/sandbox/cuda/tests/test_driver.py, line 31, in test_nvidia_driver1 profile=False)[SEP]File <*>/site-packages/theano/compile/function.py, line 320, in function output_keys=output_keys)[SEP]File <*>/site-packages/theano/compile/pfunc.py, line 479, in pfunc output_keys=output_keys)[SEP]File <*>/site-packages/theano/compile/function_module.py, line 1776, in orig_function output_keys=output_keys).create([SEP]File <*>/site-packages/theano/compile/function_module.py, line 1456, in __init__ optimizer_profile = optimizer(fgraph)[SEP]File <*>/site-packages/theano/gof/opt.py, line 101, in __call__ return self.optimize(fgraph)[SEP]File <*>/site-packages/theano/gof/opt.py, line 89, in optimize ret = self.apply(fgraph, *args, **kwargs)[SEP]File <*>/site-packages/theano/gof/opt.py, line 230, in apply sub_prof = optimizer.optimize(fgraph)[SEP]File <*>/site-packages/theano/sandbox/cuda/dnn.py, line 2508, in apply dnn_available.msg)[SEP]AssertionError: cuDNN optimization was enabled, but Theano was not able to use it. We got this error: Theano can not compile with cuDNN.",0
"File main.py, line 6, in <module> connection.start_socket(8089, callback=handler.message_processor)[SEP]File <*>/python_socket_server.py, line 13, in start_socket process_message(connection, callback=callback)[SEP]File <*>/python_socket_server.py, line 38, in process_message result = callback(general_proto)[SEP]File <*>/proto_handler.py, line 39, in message_processor return train_shape(general_proto.template)[SEP]File <*>/proto_handler.py, line 23, in train_shape rec.add_training_data(recognition_template.interpretation.label, recognition_template.shape)[SEP]File <*>/recognition_manager.py, line 98, in add_training_data self.recognizers[label].train(label, points)[SEP]File <*>/recognizer.py, line 78, in train self.classifier.fit(x=reshaped_tensor, y=target, steps=1)[SEP]File <*>python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py, line 173, in fit input_fn, feed_fn = _get_input_fn(x, y, batch_size)[SEP]File <*>python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py, line 67, in _get_input_fn x, y, n_classes=None, batch_size=batch_size)[SEP]File <*>python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py, line 117, in setup_train_data_feeder X, y, n_classes, batch_size, shuffle=shuffle, epochs=epochs)[SEP]File <*>python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py, line 239, in __init__ self.X.shape, None if self.y is None else self.y.shape, n_classes,[SEP]AttributeError: 'Tensor' object has no attribute 'shape'",0
"File <*>/theano_multiprocess_debug.py, line 36, in <module> Y = MPjob(xlist)[SEP]File <*>/theano_multiprocess_debug.py, line 29, in MPjob for y in Results:[SEP]File <*>/pool.py, line 695, in next raise value[SEP]TypeError: func1() got multiple values for argument 'func'",0
"File <*>/xxx.py, line 262, in <module> model.add(SimpleRNN(output_dim=vocab_size, input_shape=train_x.shape))[SEP]File <*>/site-packages/keras/models.py, line 275, in add layer.create_input_layer(batch_input_shape, input_dtype)[SEP]File <*>/site-packages/keras/engine/topology.py, line 367, in create_input_layer self(x)[SEP]File <*>/site-packages/keras/engine/topology.py, line 467, in __call__ self.assert_input_compatibility(x)[SEP]File <*>/site-packages/keras/engine/topology.py, line 408, in assert_input_compatibility str(K.ndim(x)))[SEP]Exception: Input 0 is incompatible with layer simplernn_1: expected ndim=3, found ndim=4",0
"File dummy.py, line 16, in <module> features = tf.pack([col1, col2, col3])[SEP]File <*>python2.7/dist-packages/tensorflow/python/ops/array_ops.py, line 487, in pack return gen_array_ops._pack(values, axis=axis, name=name)[SEP]File <*>python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py, line 1462, in _pack result = _op_def_lib.apply_op(""Pack"", values=values, axis=axis, name=name)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/op_def_library.py, line 437, in apply_op raise TypeError(""%s that don't all match."" % prefix)[SEP]TypeError: Tensors in list passed to 'values' of 'Pack' Op have types [int32, int32, float32] that don't all match.",0
"File <*>/__init__.py, line 79, in <module> model = baseline_model()[SEP]File <*>/training_module.py, line 31, in baseline_model model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(3, IMG_WIDTH, IMG_HEIGHT)))[SEP]File <*>python2.7/site-packages/keras/models.py, line 276, in add layer.create_input_layer(batch_input_shape, input_dtype)[SEP]File <*>python2.7/site-packages/keras/engine/topology.py, line 370, in create_input_layer self(x)[SEP]File <*>python2.7/site-packages/keras/engine/topology.py, line 514, in __call__ self.add_inbound_node(inbound_layers, node_indices, tensor_indices)[SEP]File <*>python2.7/site-packages/keras/engine/topology.py, line 572, in add_inbound_node Node.create_node(self, inbound_layers, node_indices, tensor_indices)[SEP]File <*>python2.7/site-packages/keras/engine/topology.py, line 149, in create_node output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))[SEP]File <*>python2.7/site-packages/keras/layers/convolutional.py, line 466, in call filter_shape=self.W_shape)[SEP]File <*>python2.7/site-packages/keras/backend/tensorflow_backend.py, line 1579, in conv2d x = tf.nn.conv2d(x, kernel, strides, padding=padding)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 394, in conv2d data_format=data_format, name=name)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/op_def_library.py, line 703, in apply_op op_def=op_def)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 2319, in create_op set_shapes_for_outputs(ret)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 1711, in set_shapes_for_outputs shapes = shape_func(op)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/common_shapes.py, line 246, in conv2d_shape padding)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/common_shapes.py, line 184, in get2d_conv_output_size (row_stride, col_stride), padding_type)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/common_shapes.py, line 149, in get_conv_output_size ""Filter: %r Input: %r"" % (filter_size, input_size))[SEP]ValueError: Filter must not be larger than the input: Filter: (5, 5) Input: (3, 350)",0
"File single_model_conv.py, line 108, in <module> gan = GAN(num_latent, 28, 'single')[SEP]File single_model_conv.py, line 23, in __init__ self.adversary(self.gen_image)[SEP]File single_model_conv.py, line 93, in adversary h2_flattened = tf.reshape(h2, [-1, num_units])[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py, line 1977, in reshape name=name)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/op_def_library.py, line 490, in apply_op preferred_dtype=default_dtype)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 657, in convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/constant_op.py, line 180, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/constant_op.py, line 163, in constant tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/tensor_util.py, line 422, in make_tensor_proto tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])[SEP]File <*>python2.7/site-packages/tensorflow/python/util/compat.py, line 64, in as_bytes (bytes_or_text,))[SEP]TypeError: Expected binary or unicode string, got -1",0
"File mnist_tensorflow.py, line 60, in <module> x: batch[0], y_: batch[1], keep_prob1: 1.0, keep_prob2: 1.0})[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 559, in eval return _eval_using_default_session(self, feed_dict, self.graph, session)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 3761, in _eval_using_default_session return session.run(tensors, feed_dict)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 717, in run run_metadata_ptr)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 915, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 965, in _do_run target_list, options, run_metadata)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 985, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors.InvalidArgumentError: Input to reshape is a tensor with 313600 values, but the requested shape requires a multiple of 4608 [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](dropout/mul, Reshape_1/shape)]]",0
"File <*>python3.4/site-packages/pip/basecommand.py, line 215, in main status = self.run(options, args)[SEP]File <*>python3.4/site-packages/pip/commands/install.py, line 342, in run prefix=options.prefix_path,[SEP]File <*>python3.4/site-packages/pip/req/req_set.py, line 784, in install **kwargs[SEP]File <*>python3.4/site-packages/pip/req/req_install.py, line 851, in install self.move_wheel_files(self.source_dir, root=root, prefix=prefix)[SEP]File <*>python3.4/site-packages/pip/req/req_install.py, line 1064, in move_wheel_files isolated=self.isolated,[SEP]File <*>python3.4/site-packages/pip/wheel.py, line 345, in move_wheel_files clobber(source, lib_dir, True)[SEP]File <*>python3.4/site-packages/pip/wheel.py, line 329, in clobber os.utime(destfile, (st.st_atime, st.st_mtime))[SEP]PermissionError: [Errno 1] Operation not permitted",0
"File <*>/testing.py, line 31, in [FUNC] [CODE][SEP]File <*>python3.5/site-packages/tensorflow/python/ops/functional_ops.py, line 390, in map_fn swap_memory=swap_memory)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py, line 2636, in while_loop result = context.BuildLoop(cond, body, loop_vars, shape_invariants)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py, line 2469, in BuildLoop pred, body, original_loop_vars, loop_vars, shape_invariants)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py, line 2419, in _BuildLoop body_result = body(*packed_vars_for_body)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/functional_ops.py, line 380, in compute packed_fn_values = fn(packed_values)[SEP]TypeError: () missing 1 required positional argument: 'crop'",0
"File <*>/test_counter.py, line 61, in <module> saver = tf.train.Saver({'w':temp})[SEP]File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 1043, in __init__ self.build()[SEP]File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 1073, in build restore_sequentially=self._restore_sequentially)[SEP]File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 649, in build saveables = self._ValidateAndSliceInputs(names_to_saveables)[SEP]File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 578, in _ValidateAndSliceInputs variable)[SEP]TypeError: names_to_saveables must be a dict mapping string names to Tensors/Variables. Not a variable: Tensor(""TransformFeatureToIndex:0"", shape=(100,), dtype=string)",0
"File <*>/test_placeholder.py, line 5, in <module> input = tf.placeholder(tf.int32, tf.pack([batchSize, 5]))[SEP]File <*>/site-packages/tensorflow/python/ops/array_ops.py, line 1579, in placeholder shape = tensor_shape.as_shape(shape)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 821, in as_shape return TensorShape(shape)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 454, in __init__ self._dims = [as_dimension(dims)][SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 378, in as_dimension return Dimension(value)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 33, in __init__ self._value = int(value)[SEP]TypeError: int() argument must be a string, a bytes-like object or a number, not 'Tensor'",0
"File mnist.py, line 154, in <module> input_shape=(1, img_rows, img_cols)))[SEP]File <*>python2.7/dist-packages/keras/models.py, line 276, in add layer.create_input_layer(batch_input_shape, input_dtype)[SEP]File <*>python2.7/dist-packages/keras/engine/topology.py, line 370, in create_input_layer self(x)[SEP]File <*>python2.7/dist-packages/keras/engine/topology.py, line 514, in __call__ self.add_inbound_node(inbound_layers, node_indices, tensor_indices)[SEP]File <*>python2.7/dist-packages/keras/engine/topology.py, line 572, in add_inbound_node Node.create_node(self, inbound_layers, node_indices, tensor_indices)[SEP]File <*>python2.7/dist-packages/keras/engine/topology.py, line 149, in create_node output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))[SEP]File <*>python2.7/dist-packages/keras/layers/convolutional.py, line 466, in call filter_shape=self.W_shape)[SEP]File <*>python2.7/dist-packages/keras/backend/tensorflow_backend.py, line 1579, in conv2d x = tf.nn.conv2d(x, kernel, strides, padding=padding)[SEP]File <*>python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py, line 396, in conv2d data_format=data_format, name=name)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/op_def_library.py, line 759, in apply_op op_def=op_def)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 2242, in create_op set_shapes_for_outputs(ret)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 1617, in set_shapes_for_outputs shapes = shape_func(op)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 1568, in call_with_requiring return call_cpp_shape_fn(op, require_shape_fn=True)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/common_shapes.py, line 610, in call_cpp_shape_fn debug_python_shape_fn, require_shape_fn)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/common_shapes.py, line 675, in _call_cpp_shape_fn_impl raise ValueError(err.message)[SEP]ValueError: Negative dimension size caused by subtracting 3 from 1 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,1,28,28], [3,3,28,32].",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/sklearn/model_selection/_validation.py, line 140, in cross_val_score for train, test in cv_iter)[SEP]File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 758, in __call__ while self.dispatch_one_batch(iterator):[SEP]File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 603, in dispatch_one_batch tasks = BatchedCalls(itertools.islice(iterator, batch_size))[SEP]File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 127, in __init__ self.items = list(iterator_slice)[SEP]File <*>/site-packages/sklearn/model_selection/_validation.py, line 140, in <genexpr> for train, test in cv_iter)[SEP]File <*>/site-packages/sklearn/base.py, line 67, in clone new_object_params = estimator.get_params(deep=False)[SEP]TypeError: get_params() got an unexpected keyword argument 'deep'",0
"File <*>/fine-tune-v3-new-classes.py, line 75, in <module> nb_val_samples=nb_validation_samples) #1020[SEP]File <*>python2.7/site-packages/keras/engine/training.py, line 1508, in fit_generator class_weight=class_weight)[SEP]File <*>python2.7/site-packages/keras/engine/training.py, line 1261, in train_on_batch check_batch_dim=True)[SEP]File <*>python2.7/site-packages/keras/engine/training.py, line 985, in _standardize_user_data exception_prefix='model target')[SEP]File <*>python2.7/site-packages/keras/engine/training.py, line 113, in standardize_input_data str(array.shape))[SEP]ValueError: Error when checking model target: expected dense_2 to have shape (None, 200) but got array with shape (16, 2)",0
"File <*>python2.7/threading.py, line 810, in __bootstrap_inner self.run()[SEP]File <*>python2.7/threading.py, line 763, in run self.__target(*self.__args, **self.__kwargs)[SEP]File <*>python2.7/site-packages/keras/engine/training.py, line 409, in data_generator_task generator_output = next(generator)[SEP]File <*>python2.7/site-packages/keras/preprocessing/image.py, line 691, in next target_size=self.target_size)[SEP]File <*>python2.7/site-packages/keras/preprocessing/image.py, line 191, in load_img img = img.convert('RGB')[SEP]File <*>python2.7/site-packages/PIL/Image.py, line 844, in convert self.load()[SEP]File <*>python2.7/site-packages/PIL/ImageFile.py, line 248, in load return Image.Image.load(self)[SEP]AttributeError: 'NoneType' object has no attribute 'Image'",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import *[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 63, in <module> from tensorflow.core.framework.graph_pb2 import *[SEP]File <*>/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in <module> from google.protobuf import descriptor as _descriptor[SEP]ImportError: No module named 'google'",0
"File helloWorld.py, line 10, in <module> import matplotlib.pyplot as plt[SEP]ImportError: No module named 'matplotlib'",0
"File <*>python2.7/threading.py, line 801, in __bootstrap_inner self.run()[SEP]File <*>python2.7/threading.py, line 754, in run self.__target(*self.__args, **self.__kwargs)[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 409, in data_generator_task generator_output = next(generator)[SEP]File <*>/load_gluc_data.py, line 198, in generate yield self.next_batch()[SEP]File <*>/load_gluc_data.py, line 192, in next_batch X, y, l = self.process_image(json_im, X, y, l)[SEP]File <*>/load_gluc_data.py, line 131, in process_image im.augment_with_tf(self.tf_sess)[SEP]File <*>/load_gluc_data.py, line 85, in augment_with_tf self.im = sess.run(saturation, {im_placeholder: np.asarray(self.im)})[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 766, in run run_metadata_ptr)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 921, in _run + e.args[0])[SEP]TypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(""Placeholder:0"", shape=(96, 96, 3), dtype=float32) is not an element of this graph.",0
"File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 62, in _pin_memory_loop batch = pin_memory_batch(batch)[SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 123, in pin_memory_batch return [pin_memory_batch(sample) for sample in batch][SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 123, in <listcomp> return [pin_memory_batch(sample) for sample in batch][SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 117, in pin_memory_batch return batch.pin_memory()[SEP]File <*>python3.6/site-packages/torch/tensor.py, line 82, in pin_memory return type(self)().set_(storage.pin_memory()).view_as(self)[SEP]File <*>python3.6/site-packages/torch/storage.py, line 83, in pin_memory allocator = torch.cuda._host_allocator()[SEP]File <*>python3.6/site-packages/torch/cuda/__init__.py, line 220, in _host_allocator _lazy_init()[SEP]File <*>python3.6/site-packages/torch/cuda/__init__.py, line 84, in _lazy_init _check_driver()[SEP]File <*>python3.6/site-packages/torch/cuda/__init__.py, line 51, in _check_driver raise AssertionError(""Torch not compiled with CUDA enabled"")[SEP]AssertionError: Torch not compiled with CUDA enabled",0
"File <ipython-input-6-06fadd69ae8f>, line 1, in <module> runfile('C:/Users/1/Desktop/transfer_learning_tutorial-master/MCVE.py', wdir='C:/Users/1/Desktop/transfer_learning_tutorial-master')[SEP]File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 710, in runfile execfile(filename, namespace)[SEP]File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 101, in execfile exec(compile(f.read(), filename, 'exec'), namespace)[SEP]File <*>/MCVE.py, line 77, in <module> tf.app.run(main=main, argv=[sys.argv[0]])[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough))[SEP]File <*>/MCVE.py, line 68, in main steps=1000)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 302, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 780, in _train_model log_step_count_steps=self._config.log_step_count_steps) as mon_sess:[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 368, in MonitoredTrainingSession stop_grace_period_secs=stop_grace_period_secs)[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 673, in __init__ stop_grace_period_secs=stop_grace_period_secs)[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 493, in __init__ self._sess = _RecoverableSession(self._coordinated_creator)[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 851, in __init__ _WrappedSession.__init__(self, self._create_session())[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 856, in _create_session return self._sess_creator.create_session()[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 554, in create_session self.tf_sess = self._session_creator.create_session()[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 428, in create_session init_fn=self._scaffold.init_fn)[SEP]File <*>/site-packages/tensorflow/python/training/session_manager.py, line 279, in prepare_session sess.run(init_op, feed_dict=init_feed_dict)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message)[SEP]InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [900] rhs shape= [1001] [[Node: Assign_1145 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionResnetV2/Logits/Logits/biases""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionResnetV2/Logits/Logits/biases, checkpoint_initializer_1145)]]",0
"File testJan17.py, line 13, in <module> sample_model()[SEP]File testJan17.py, line 8, in sample_model att_mull = Multiply([dense_all, dense_att]) #merge([dense_all, dense_att], output_shape=10, mode='mul')[SEP]TypeError: __init__() takes exactly 1 argument (2 given)",0
"File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.5/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.5/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.5/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory",0
"File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.5/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.5/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow9ConcatCPUINS_8bfloat16EEEvPNS_10DeviceBaseERKSt6vectorISt10unique_ptrINS_6TTypesIT_Li2EiE11ConstMatrixESt14default_deleteIS9_EESaISC_EEPNS8_6MatrixE",0
"File <*>/new_main.py, line 35, in <module> b = sess.run(correct_prediction, feed_dict={a: a1, b: b1, y: y1})[SEP]TypeError: unhashable type: 'numpy.ndarray'",0
"File <*>/try2.py, line 45, in <module> classifier.train(input_fn=lambda: my_input_fn(is_shuffle=True, repeat_count=100))[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 352, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 812, in _train_model features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 793, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py, line 354, in _model_fn config=config)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py, line 161, in _dnn_model_fn 'Given type: {}'.format(type(features)))[SEP]ValueError: features should be a dictionary of `Tensor`s. Given type: <class 'tensorflow.python.framework.ops.Tensor'>",0
"File <*>/generate_tfrecord.py, line 99, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File <*>/generate_tfrecord.py, line 85, in main writer = tf.python_io.TFRecordWriter(FLAGS.output_path)[SEP]File <*>/site-packages/tensorflow/python/lib/io/tf_record.py, line 111, in __init__ compat.as_bytes(path), compat.as_bytes(compression_type), status)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a NewWriteableFile: : The system cannot find the path specified.",0
"File <*>/lstm.py, line 128, in <module> main()[SEP]File <*>/lstm.py, line 108, in main model.fit_generator(generator=training_sequence)[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/models.py, line 1253, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>/site-packages/keras/engine/training.py, line 2244, in fit_generator class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1884, in train_on_batch class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1487, in _standardize_user_data exception_prefix='target')[SEP]File <*>/site-packages/keras/engine/training.py, line 113, in _standardize_input_data 'with shape ' + str(data_shape))[SEP]ValueError: Error when checking target: expected dense_1 to have 5 dimensions, but got array with shape (1, 1939, 9)",0
"File train.py, line 167, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File train.py, line 163, in main worker_job_name, is_chief, FLAGS.train_dir)[SEP]File <*>/trainer.py, line 275, in train clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])[SEP]File <*>/model_deploy.py, line 193, in create_clones outputs = model_fn(*args, **kwargs)[SEP]File <*>/trainer.py, line 198, in _create_losses prediction_dict = detection_model.predict(images, true_image_shapes)[SEP]File <*>/ssd_meta_arch.py, line 384, in predict preprocessed_inputs)[SEP]File <*>/ssd_mobilenet_v2_feature_extractor.py, line 123, in extract_features scope=scope)[SEP]File <*>/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py, line 183, in func_with_args return func(*args, **current_args)[SEP]File <*>/mobilenet_v2.py, line 162, in mobilenet_base base_only=True, **kwargs)[SEP]File <*>/mobilenet_v2.py, line 154, in mobilenet **kwargs)[SEP]File <*>/mobilenet.py, line 325, in mobilenet net, end_points = mobilenet_base(inputs, scope=scope, **mobilenet_args)[SEP]File <*>/mobilenet.py, line 244, in mobilenet_base net = opdef.op(net, **params)[SEP]File <*>/site-packages/tensorflow/contrib/layers/python/layers/layers.py, line 1058, in convolution outputs = normalizer_fn(outputs, **normalizer_params)[SEP]File <*>/site-packages/tensorflow/contrib/layers/python/layers/layers.py, line 650, in batch_norm outputs = layer.apply(inputs, training=is_training)[SEP]File <*>/site-packages/tensorflow/python/layers/base.py, line 825, in apply return self.__call__(inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/layers/base.py, line 714, in __call__ outputs = self.call(inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/layers/normalization.py, line 549, in call training_value = utils.constant_value(training)[SEP]File <*>/site-packages/tensorflow/python/layers/utils.py, line 232, in constant_value return smart_module.smart_constant_value(pred)[SEP]File <*>/site-packages/tensorflow/python/framework/smart_cond.py, line 93, in smart_constant_value ""Found instead: %s"" % pred)[SEP]TypeError: `pred` must be a Tensor, or a Python bool, or 1 or 0. Found instead: None",0
"File <*>/scratch_4.py, line 11, in <module> assert type(elem) == tf.python.framework.ops.EagerTensor[SEP]AttributeError: module 'tensorflow' has no attribute 'python'",0
"File train.py, line 167, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File train.py, line 163, in main worker_job_name, is_chief, FLAGS.train_dir)[SEP]File <*>/trainer.py, line 284, in train train_config.optimizer)[SEP]File <*>/optimizer_builder.py, line 50, in build learning_rate = _create_learning_rate(config.learning_rate)[SEP]File <*>/optimizer_builder.py, line 109, in _create_learning_rate learning_rate_sequence, config.warmup)[SEP]File <*>/learning_schedules.py, line 156, in manual_stepping raise ValueError('First step cannot be zero.')[SEP]ValueError: First step cannot be zero.",0
"File <*>python2.7/site-packages/tensorflow/python/ops/script_ops.py, line 147, in __call__ ret = func(*args)[SEP]File <*>python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 378, in generator_py_func nest.flatten_up_to(output_types, values), flattened_types)[SEP]AttributeError: 'numpy.dtype' object has no attribute 'as_numpy_dtype'",0
"File train.py, line 184, in <module> tf.app.run()[SEP]File <*>python3.6/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File train.py, line 180, in main graph_hook_fn=graph_rewriter_fn)[SEP]File <*>/trainer.py, line 264, in train train_config.prefetch_queue_capacity, data_augmentation_options)[SEP]File <*>/trainer.py, line 59, in create_input_queue tensor_dict = create_tensor_dict_fn()[SEP]File train.py, line 121, in get_next dataset_builder.build(config)).get_next()[SEP]File <*>/dataset_builder.py, line 155, in build label_map_proto_file=label_map_proto_file)[SEP]File <*>/tf_example_decoder.py, line 245, in init use_display_name)[SEP]File <*>/label_map_util.py, line 152, in get_label_map_dict label_map = load_labelmap(label_map_path)[SEP]File <*>/label_map_util.py, line 137, in load_labelmap label_map.ParseFromString(label_map_string)[SEP]TypeError: a bytes-like object is required, not 'str'",0
"File seq2seq_train.py, line 5, in <module> from keras_text_summarization.library.utility.plot_utils import plot_and_save_history[SEP]ModuleNotFoundError: No module named 'keras_text_summarization'",0
"File model.py, line 91, in <module> model = Model(inputs=[x1, x2], outputs=[out])[SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 91, in __init__ self._init_graph_network(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 183, in _init_graph_network 'The tensor that caused the issue was: ' +[SEP]AttributeError: 'Model' object has no attribute 'name'",0
"File train_v2.py, line 110, in <module> main()[SEP]File train_v2.py, line 81, in main model.update(batch)[SEP]File <*>/model.py, line 131, in update loss_adv = self.adversarial_loss(batch, loss, self.network.lexicon_encoder.embedding.weight, y)[SEP]File <*>/model.py, line 94, in adversarial_loss adv_embedding = torch.LongTensor(adv_embedding)[SEP]TypeError: expected torch.LongTensor (got torch.cuda.FloatTensor)",0
"File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 712, in __del__ [CODE][SEP]File <*>python3.5/site-packages/tensorflow/python/framework/c_api_util.py, line 31, in __init__ [CODE][SEP]TypeError: 'NoneType' object is not callable",0
"File app.py, line 16, in <module> from modules.xvision import Xvision[SEP]File <*>/xvision.py, line 84, in <module> tf.import_graph_def(net['graph_def'], name='vgg')[SEP]TypeError: 'Model' object has no attribute '__getitem__'",0
"File <*>/main.py, line 94, in <module> data_menu()[SEP]File <*>/main.py, line 42, in data_menu data_menu()[SEP]File <*>/main.py, line 56, in data_menu nn_menu()[SEP]File <*>/main.py, line 76, in nn_menu nn.nn_gen(pre_processed_data)[SEP]File <*>/nn.py, line 33, in nn_gen x, y = train[0][SEP]File <*>python3.6/site-packages/keras_preprocessing/sequence.py, line 378, in __getitem__ samples[j] = self.data[indices][SEP]File <*>python3.6/site-packages/pandas/core/frame.py, line 2688, in __getitem__ return self._getitem_column(key)[SEP]File <*>python3.6/site-packages/pandas/core/frame.py, line 2695, in _getitem_column return self._get_item_cache(key)[SEP]File <*>python3.6/site-packages/pandas/core/generic.py, line 2489, in _get_item_cache values = self._data.get(item)[SEP]File <*>python3.6/site-packages/pandas/core/internals.py, line 4115, in get loc = self.items.get_loc(item)[SEP]File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 3080, in get_loc return self._engine.get_loc(self._maybe_cast_indexer(key))[SEP]File <*>/index.pyx, line 140, in pandas._libs.index.IndexEngine.get_loc [CODE][SEP]File <*>/index.pyx, line 162, in pandas._libs.index.IndexEngine.get_loc [CODE][SEP]File <*>/hashtable_class_helper.pxi, line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE][SEP]File <*>/hashtable_class_helper.pxi, line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE][SEP]KeyError: range(418, 419)",0
"File test.py, line 7, in <module> print(model.summary())[SEP]AttributeError: 'NoneType' object has no attribute 'summary'",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.5/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>python3.5/site-packages/tensorflow/python/__init__.py, line 47, in <module> import numpy as np[SEP]File <*>python3.5/site-packages/numpy/__init__.py, line 142, in <module> from . import core[SEP]File <*>python3.5/site-packages/numpy/core/__init__.py, line 57, in <module> from . import numerictypes as nt[SEP]File <*>python3.5/site-packages/numpy/core/numerictypes.py, line 111, in <module> from ._type_aliases import ([SEP]File <*>python3.5/site-packages/numpy/core/_type_aliases.py, line 63, in <module> _concrete_types = {v.type for k, v in _concrete_typeinfo.items()}[SEP]File <*>python3.5/site-packages/numpy/core/_type_aliases.py, line 63, in <setcomp> _concrete_types = {v.type for k, v in _concrete_typeinfo.items()}[SEP]AttributeError: 'tuple' object has no attribute 'type'",0
"File <frozen importlib._bootstrap>, line 980, in _find_and_load [CODE][SEP]SystemError: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set ImportError: numpy.core._multiarray_umath failed to import ImportError: numpy.core.umath failed to import",0
"File <frozen importlib._bootstrap>, line 968, in _find_and_load [CODE][SEP]SystemError: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set ImportError: numpy.core._multiarray_umath failed to import ImportError: numpy.core.umath failed to import",0
"File <*>/textClassfierHATT2D.py, line 187, in <module> nb_epoch=10, batch_size=50,verbose=2)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1631, in fit validation_steps=validation_steps)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1213, in _fit_loop outs = f(ins_batch)[SEP]File <*>python3.6/site-packages/keras/backend/theano_backend.py, line 1223, in __call__ return self.function(*inputs)[SEP]File <*>python3.6/site-packages/theano/compile/function_module.py, line 898, in __call__ storage_map=getattr(self.fn, 'storage_map', None))[SEP]File <*>python3.6/site-packages/theano/gof/link.py, line 325, in raise_with_op reraise(exc_type, exc_value, exc_trace)[SEP]File <*>python3.6/site-packages/six.py, line 692, in reraise raise value.with_traceback(tb)[SEP]File <*>python3.6/site-packages/theano/compile/function_module.py, line 884, in __call__ self.fn() if output_subset is None else\[SEP]ValueError: Input dimension mis-match. (input[0].shape[1] = 50, input[1].shape[1] = 100)",0
"File <*>/min_working_example.py, line 37, in <module> model.fit(data_generator)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 880, in fit validation_steps=validation_steps)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 310, in model_iteration ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]][SEP]File <*>python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 526, in slice_arrays return [None if x is None else x[start] for x in arrays][SEP]File <*>python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 526, in <listcomp> return [None if x is None else x[start] for x in arrays][SEP]File <*>python3.6/site-packages/tensorflow/python/ops/array_ops.py, line 654, in _slice_helper name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/array_ops.py, line 820, in strided_slice shrink_axis_mask=shrink_axis_mask)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py, line 9334, in strided_slice _six.raise_from(_core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Attr shrink_axis_mask has value 4294967295 out of range for an int32 [Op:StridedSlice] name: strided_slice/",0
"File <*>/min_working_example.py, line 37, in <module> model.fit_generator(data_generator)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1426, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 115, in model_iteration shuffle=shuffle)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 377, in convert_to_generator_like num_samples = int(nest.flatten(data)[0].shape[0])[SEP]TypeError: __int__ returned non-int (type NoneType)",0
"File <*>/main.py, line 182, in <module> batch_size=128, epochs=1)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 880, in fit validation_steps=validation_steps)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 329, in model_iteration batch_outs = f(ins_batch)[SEP]File <*>/site-packages/tensorflow/python/keras/backend.py, line 3076, in __call__ run_metadata=self.run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1439, in __call__ run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [10,2] vs. [10] [[{{node metrics/acc/Equal}}]] [[{{node loss/mul}}]]",0
"File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in make_tensor_proto str_values = [compat.as_bytes(x) for x in proto_values][SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in <listcomp> str_values = [compat.as_bytes(x) for x in proto_values][SEP]File <*>/site-packages/tensorflow/python/util/compat.py, line 61, in as_bytes (bytes_or_text,))[SEP]TypeError: Expected binary or unicode string, got Dimension(4)",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1334, in _do_call return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1319, in _run_fn options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1407, in _call_tf_sessionrun run_metadata)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[51200,2304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[{{node model/h0/attn/c_attn/MatMul}}]]",0
"File TestServe.py, line 62, in <module> ts.train()[SEP]File TestServe.py, line 56, in train epochs=2, verbose=1, callbacks=callbacks, steps_per_epoch=20) #The steps_per_epoch is typically samples_per_epoch / batch_size[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 880, in fit validation_steps=validation_steps)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 364, in model_iteration validation_in_fit=True)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 202, in model_iteration steps_per_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 76, in _get_num_samples_or_steps 'steps_per_epoch')[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 230, in check_num_samples if check_steps_argument(ins, steps, steps_name):[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 960, in check_steps_argument input_type=input_type_str, steps_name=steps_name))[SEP]ValueError: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument.",0
"File <*>/toco, line 11, in <module> sys.exit(main())[SEP]File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 503, in main app.run(main=run_main, argv=sys.argv[:1])[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)[SEP]File <*>python2.7/site-packages/absl/app.py, line 300, in run _run_main(main, args)[SEP]File <*>python2.7/site-packages/absl/app.py, line 251, in _run_main sys.exit(main(argv))[SEP]File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 499, in run_main _convert_tf1_model(tflite_flags)[SEP]File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 124, in _convert_tf1_model converter = _get_toco_converter(flags)[SEP]File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 111, in _get_toco_converter return converter_fn(**converter_kwargs)[SEP]File <*>python2.7/site-packages/tensorflow/lite/python/lite.py, line 628, in from_frozen_graph _import_graph_def(graph_def, name="""")[SEP]File <*>python2.7/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func return func(*args, **kwargs)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/importer.py, line 431, in import_graph_def raise ValueError(str(e))[SEP]ValueError: Input 0 of node dense_1/weights_quant/AssignMinLast was passed float from dense_1/weights_quant/min:0 incompatible with expected float_ref.",0
"File test_model.py, line 5, in <module> import tensorflow as tf[SEP]File <*>/site-packages/tensorflow/__init__.py, line 28, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 30, in <module> self_check.preload_check()[SEP]File <*>/site-packages/tensorflow/python/platform/self_check.py, line 70, in preload_check % build_info.nvcuda_dll_name)[SEP]ImportError: Could not find 'nvcuda.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Typically it is installed in 'C:\Windows\System32'. If it is not present, ensure that you have a CUDA-capable GPU with the correct driver installed.",0
"File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1473, in __del__ self._session._session, self._handle)[SEP]tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')",0
"File <*>/script3.py, line 9, in <module> model = load_model(model_path, custom_objects={'MyMeanPooling': MyMeanPooling})[SEP]File <*>/site-packages/keras/engine/saving.py, line 419, in load_model model = _deserialize_model(f, custom_objects, compile)[SEP]File <*>/site-packages/keras/engine/saving.py, line 225, in _deserialize_model model = model_from_config(model_config, custom_objects=custom_objects)[SEP]File <*>/site-packages/keras/engine/saving.py, line 458, in model_from_config return deserialize(config, custom_objects=custom_objects)[SEP]File <*>/site-packages/keras/layers/__init__.py, line 55, in deserialize printable_module_name='layer')[SEP]File <*>/site-packages/keras/utils/generic_utils.py, line 145, in deserialize_keras_object list(custom_objects.items())))[SEP]File <*>/site-packages/keras/engine/network.py, line 1022, in from_config process_layer(layer_data)[SEP]File <*>/site-packages/keras/engine/network.py, line 1008, in process_layer custom_objects=custom_objects)[SEP]File <*>/site-packages/keras/utils/generic_utils.py, line 147, in deserialize_keras_object return cls.from_config(config['config'])[SEP]File <*>/site-packages/keras/engine/base_layer.py, line 1109, in from_config return cls(**config)[SEP]TypeError: __init__() missing 1 required positional argument: 'pool_size'",0
"File <*>/main.py, line 41, in <module> predics = nmodel.predict([x_test])[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 821, in predict use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 705, in predict x, check_steps=True, steps_name='steps', steps=steps)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 2335, in _standardize_user_data self._set_inputs(cast_inputs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 2553, in _set_inputs outputs = self(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 662, in __call__ outputs = call_fn(inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/sequential.py, line 262, in call outputs = layer(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/core.py, line 580, in call inputs, (tensor_shape.dimension_value(inputs.shape[0]) or[SEP]AttributeError: 'list' object has no attribute 'shape'",0
"File <*>/pathtoproject, line 75, in predict cm_prediction = self.model.predict([face, reye, leye, fg])[0][SEP]File <*>/pathtoproject, line 1462, in predict callbacks=callbacks)[SEP]File <*>/site-packages/keras/engine/training_arrays.py, line 276, in predict_loop callbacks.model.stop_training = False[SEP]File <*>/site-packages/keras/engine/network.py, line 323, in __setattr__ super(Network, self).__setattr__(name, value)[SEP]File <*>/site-packages/keras/engine/base_layer.py, line 1215, in __setattr__ if not _DISABLE_TRACKING.value:[SEP]AttributeError: '_thread._local' object has no attribute 'value'",0
"File train.py, line 6, in <module> import keras.backend as K[SEP]File <*>/site-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>/site-packages/keras/utils/__init__.py, line 27, in <module> from .multi_gpu_utils import multi_gpu_model[SEP]File <*>/site-packages/keras/utils/multi_gpu_utils.py, line 7, in <module> from ..layers.merge import concatenate[SEP]File <*>/site-packages/keras/layers/__init__.py, line 4, in <module> from ..engine.base_layer import Layer[SEP]File <*>/site-packages/keras/engine/__init__.py, line 8, in <module> from .training import Model[SEP]File <*>/site-packages/keras/engine/training.py, line 21, in <module> from . import training_arrays[SEP]File <*>/site-packages/keras/engine/training_arrays.py, line 14, in <module> from .. import callbacks as cbks[SEP]File <*>/site-packages/keras/callbacks/__init__.py, line 19, in <module> if K.backend() == 'tensorflow' and not K.tensorflow_backend._is_tf_1():[SEP]AttributeError: module 'keras.backend.tensorflow_backend' has no attribute '_is_tf_1'",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 738, in __del__ [CODE][SEP]TypeError: 'NoneType' object is not callable",0
"File <input>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 495, in ResNet50V2 **kwargs)[SEP]File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 348, in ResNet data_format=backend.image_data_format(),[SEP]AttributeError: 'NoneType' object has no attribute 'image_data_format'",0
"File main.py, line 69, in <module> pickle.dump(history, f)[SEP]TypeError: can't pickle _thread._local objects",0
"File model_main.py, line 109, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 125, in run _sys.exit(main(argv))[SEP]File model_main.py, line 105, in main tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 471, in train_and_evaluate return executor.run()[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 610, in run return self.run_local()[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 711, in run_local saving_listeners=saving_listeners)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 354, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 1207, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 1241, in _train_model_default saving_listeners)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 1471, in _train_with_estimator_spec _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 783, in exit self._close_internal(exception_type)[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 816, in _close_internal h.end(self._coordinated_creator.tf_sess)[SEP]File <*>/site-packages/tensorflow/python/training/basic_session_run_hooks.py, line 590, in end l.end(session, last_step)[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 531, in end self._evaluate(global_step_value)[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 537, in _evaluate self._evaluator.evaluate_and_export())[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 924, in evaluate_and_export is_the_final_export)[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 957, in _export_eval_result is_the_final_export=is_the_final_export))[SEP]File <*>/site-packages/tensorflow/python/estimator/exporter.py, line 418, in export is_the_final_export)[SEP]File <*>/site-packages/tensorflow/python/estimator/exporter.py, line 126, in export strip_default_attrs=self._strip_default_attrs)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 663, in export_savedmodel mode=model_fn_lib.ModeKeys.PREDICT)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 789, in _export_saved_model_for_mode strip_default_attrs=strip_default_attrs)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 883, in _export_all_saved_models builder = saved_model_builder.SavedModelBuilder(temp_export_dir)[SEP]File <*>/site-packages/tensorflow/python/saved_model/builder_impl.py, line 97, in init file_io.recursive_create_dir(self._export_dir)[SEP]File <*>/site-packages/tensorflow/python/lib/io/file_io.py, line 379, in recursive_create_dir pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in exit c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: training/export\Servo\temp-b'1576742954'; No such file or directory",0
"File <*>/maxmem.py, line 11, in <module> dic[x]=tf.random.normal((nn,dd))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/ops/random_ops.py, line 76, in random_normal value = math_ops.add(mul, mean_tensor, name=name)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py, line 391, in add _six.raise_from(_core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1000,250000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add] name: random_normal/",0
"File DL_Ensemble.py, line 145, in <module> fused = concatenate([graph, graph_1], axis= 1 )[SEP]File <*>python3.8/site-packages/tensorflow_core/python/keras/layers/merge.py, line 705, in concatenate return Concatenate(axis=axis, **kwargs)(inputs)[SEP]File <*>python3.8/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 887, in __call__ self._maybe_build(inputs)[SEP]File <*>python3.8/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 2141, in _maybe_build self.build(input_shapes)[SEP]File <*>python3.8/site-packages/tensorflow_core/python/keras/utils/tf_utils.py, line 306, in wrapper output_shape = fn(instance, input_shape)[SEP]File <*>python3.8/site-packages/tensorflow_core/python/keras/layers/merge.py, line 378, in build raise ValueError('A `Concatenate` layer should be called '[SEP]ValueError: A `Concatenate` layer should be called on a list of at least 2 inputs",0
"File tf2_main.py, line 50, in <module> model = CycleGAN(args)[SEP]File <*>/tf2_model.py, line 55, in __init__ self._build_model(args)[SEP]File <*>/tf2_model.py, line 63, in _build_model name='Generator_A2B')[SEP]File <*>/tf2_module.py, line 154, in build_generator name='IN_1')(x)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 773, in __call__ outputs = call_fn(cast_inputs, *args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/keras/layers/core.py, line 847, in call self._check_variables(created_variables, tape.watched_variables())[SEP]File <*>python3.6/site-packages/tensorflow_core/python/keras/layers/core.py, line 873, in _check_variables raise ValueError(error_str)[SEP]ValueError: The following Variables were created within a Lambda layer (IN_1) but are not tracked by said layer: <tf.Variable 'IN_1/SCALE:0' shape=(64,) dtype=float32> <tf.Variable 'IN_1/OFFSET:0' shape=(64,) dtype=float32> The layer cannot safely ensure proper Variable reuse across multiple calls, and consquently this behavior is disallowed for safety. Lambda layers are not well suited to stateful computation; instead, writing a subclassed Layer is the recommend way to define layers with Variables.",0
"File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 61, in quick_execute num_outputs)[SEP]TypeError: An op outside of the function building code is being passed a ""Graph"" tensor. It is possible to have Graph tensors leak out of the function building context by including a tf.init_scope in your function building code.",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 1013, in predict use_multiprocessing=use_multiprocessing)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 498, in predict workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 475, in _model_iteration total_epochs=1)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch batch_outs = execution_function(iterator)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function distributed_function(input_fn))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__ result = self._call(*args, **kwds)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 638, in _call return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds) # pylint: disable=protected-access[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call self.captured_inputs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 545, in call ctx=ctx)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 75, in quick_execute ""tensors, but found {}"".format(keras_symbolic_tensors))[SEP]tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'conv_name_base_1/Identity:0' shape=(None, 160, 160, 64) dtype=float32>]",0
"File pytorch_test.py, line 14, in <module> a_copy.resize_(1, 1)[SEP]RuntimeError: set_sizes_contiguous is not allowed on a Tensor created from .data or .detach().",0
"File <*>python2.7/process.py, line 267, in _bootstrap self.run()[SEP]File <*>python2.7/process.py, line 114, in run self._target(*self._args, **self._kwargs)[SEP]File <*>python2.7/pool.py, line 102, in worker task = get()[SEP]File <*>python2.7/queues.py, line 376, in get return recv()[SEP]AttributeError: 'module' object has no attribute 'prediction'",0
"File stackoverflow.py, line 47, in <module> with multiprocessing.Pool() as p:[SEP]AttributeError: __exit__",0
"File the_other_end-mp.py, line 216, in <module> predops=p.map(prediction,modelon)[SEP]File <*>python2.7/pool.py, line 253, in map return self.map_async(func, iterable, chunksize).get()[SEP]File <*>python2.7/pool.py, line 572, in get raise self._value[SEP]ValueError: Resource handles are not convertible to numpy.",0
"File <*>/site-packages/torch/_utils_internal.py, line 46, in get_source_lines_and_file [CODE][SEP]File inspect.py, line 967, in getsourcelines [CODE][SEP]File inspect.py, line 798, in findsource [CODE][SEP]OSError: could not get source code",0
"File extractor.py, line 3, in <module> import torch[SEP]File <frozen importlib._bootstrap>, line 991, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 975, in _find_and_load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 671, in _load_unlocked [CODE][SEP]File <*>/site-packages/PyInstaller/loader/pyimod03_importers.py, line 623, in exec_module exec(bytecode, module.__dict__)[SEP]File <*>/site-packages/torch/__init__.py, line 367, in <module> [CODE][SEP]File <*>/site-packages/torch/distributions/__init__.py, line 112, in <module> [CODE][SEP]File <*>/site-packages/torch/distributions/von_mises.py, line 55, in <module> [CODE][SEP]File <*>/site-packages/torch/jit/__init__.py, line 1287, in script [CODE][SEP]File <*>/site-packages/torch/jit/frontend.py, line 164, in get_jit_def [CODE][SEP]File <*>/site-packages/torch/_utils_internal.py, line 53, in get_source_lines_and_file [CODE][SEP]OSError: Can't get source for <function _rejection_sample at 0x0000000006892F70>. TorchScript requires source access in order to carry out compilation, make sure original .py files are available.",0
"File plot_parametric_pytorch_cifar100.py, line 130, in <module> loss_fn = F.nll_loss(ops, tgts)[SEP]File <*>python3.7/site-packages/torch/nn/functional.py, line 2115, in nll_loss ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)[SEP]IndexError: Target 42 is out of bounds.",0
"File trainer.py, line 629, in <module> clear_outputs=True[SEP]File <*>/utils.py, line 62, in wrapper result = func(*args, **kwargs)[SEP]File trainer.py, line 490, in train validation_data=valid_dataset,[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper return method(self, *args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1090, in fit tmp_logs = train_function(iterator)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 766, in __call__ result = self._call(*args, **kwds)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 826, in _call return self._stateless_fn(*args, **kwds)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 2811, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1838, in _filtered_call cancellation_manager=cancellation_manager)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1914, in _call_flat ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 549, in call ctx=ctx)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/execute.py, line 60, in quick_execute inputs, attrs, num_outputs)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [4,76,76,3,1] vs. [4,19,19,3,1] [[node yolo_loss/logistic_loss/mul (defined at ../Helpers/utils.py:260) ]] [Op:__inference_train_function_38735]",0
"File <*>/trainer.py, line 693, in <module> clear_outputs=True,[SEP]File <*>/utils.py, line 62, in wrapper result = func(*args, **kwargs)[SEP]File <*>/trainer.py, line 526, in train validation_data=valid_dataset,[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper return method(self, *args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 848, in fit tmp_logs = train_function(iterator)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__ result = self._call(*args, **kwds)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/def_function.py, line 644, in _call return self._stateless_fn(*args, **kwds)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 2420, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 1665, in _filtered_call self.captured_inputs)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 1746, in _call_flat ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 598, in call ctx=ctx)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/execute.py, line 60, in quick_execute inputs, attrs, num_outputs)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [8,13,13,3,2] vs. [8,52,52,3,2] [[node gradient_tape/yolo_loss/sub_5/BroadcastGradientArgs (defined at Users/emadboctor/Desktop/Code/yolov3-keras-tf2/Main/trainer.py:526) ]] [Op:__inference_train_function_42744]",0
"File imdb_classification.py, line 65, in <module> history = model.fit(x_train,y_train,epochs=50,batch_size=32,verbose=1)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 819, in fit use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 235, in fit use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 593, in _process_training_inputs use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 706, in _process_inputs use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 357, in __init__ dataset = self.slice_inputs(indices_dataset, inputs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 383, in slice_inputs dataset_ops.DatasetV2.from_tensors(inputs).repeat()[SEP]File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 566, in from_tensors return TensorDataset(tensors)[SEP]File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 2765, in __init__ element = structure.normalize_element(element)[SEP]File <*>/site-packages/tensorflow_core/python/data/util/structure.py, line 113, in normalize_element ops.convert_to_tensor(t, name=""component_%d"" % i))[SEP]File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1314, in convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py, line 52, in _default_conversion_function return constant_op.constant(value, dtype, name=name)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 258, in constant allow_broadcast=True)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 266, in _constant_impl t = convert_to_eager_tensor(value, ctx, dtype)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 96, in convert_to_eager_tensor return ops.EagerTensor(value, ctx.device_name, dtype)[SEP]ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list)",0
"File <*>/convert.py, line 13, in <module> tflite_model = converter.convert()[SEP]File <*>/site-packages/tensorflow/lite/python/lite.py, line 1076, in convert return super(TFLiteConverterV2, self).convert()[SEP]File <*>/site-packages/tensorflow/lite/python/lite.py, line 899, in convert return super(TFLiteFrozenGraphConverterV2,[SEP]File <*>/site-packages/tensorflow/lite/python/lite.py, line 629, in convert result = _toco_convert_impl([SEP]File <*>/site-packages/tensorflow/lite/python/convert.py, line 569, in toco_convert_impl data = toco_convert_protos([SEP]File <*>/site-packages/tensorflow/lite/python/convert.py, line 202, in toco_convert_protos raise ConverterError(str(e))[SEP]tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types <unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x?x?x3x!tf.quint8>) -> tensor<1x?x?x3xui8>",0
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 64, in <module> from tensorflow.python._pywrap_tensorflow_internal import *[SEP]ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.",0
"File <*>/model_main_tf2.py, line 113, in <module> tf.compat.v1.app.run()[SEP]File <*>python3.6/dist-packages/tensorflow/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)[SEP]File <*>python3.6/dist-packages/absl/app.py, line 300, in run _run_main(main, args)[SEP]File <*>python3.6/dist-packages/absl/app.py, line 251, in _run_main sys.exit(main(argv))[SEP]File <*>/model_main_tf2.py, line 110, in main record_summaries=FLAGS.record_summaries)[SEP]File <*>python3.6/dist-packages/object_detection/model_lib_v2.py, line 630, in train_loop manager.save()[SEP]File <*>python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py, line 819, in save self._record_state()[SEP]File <*>python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py, line 728, in _record_state save_relative_paths=True)[SEP]File <*>python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py, line 248, in update_checkpoint_state_internal text_format.MessageToString(ckpt))[SEP]File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 570, in atomic_write_string_to_file rename(temp_pathname, filename, overwrite)[SEP]File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 529, in rename rename_v2(oldname, newname, overwrite)[SEP]File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 546, in rename_v2 compat.as_bytes(src), compat.as_bytes(dst), overwrite)[SEP]tensorflow.python.framework.errors_impl.FailedPreconditionError: /content/drive/My Drive/Tensorflow/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint.tmp91048f3bf67645619be6603094546de1; Is a directory",0
"File ml_model.py, line 1, in <module> import torch[SEP]File <*>/site-packages/torch/__init__.py, line 117, in <module> import torch[SEP]File <*>/site-packages/torch/__init__.py, line 117, in <module> raise err[SEP]OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading ""C:\Users\user\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\lib\cudnn_cnn_infer64_8.dll"" or one of its dependencies. raise err",0
"File [FILE], line 14, in <module>() p.fit(x=df_train, y=df_train, steps=10, batch_size=100)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 173, in fit(self, x, y, input_fn, steps, batch_size, monitors) input_fn, feed_fn = _get_input_fn(x, y, batch_size)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 67, in _get_input_fn(x, y, batch_size) x, y, n_classes=None, batch_size=batch_size)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.pyc, line 99, in setup_train_data_feeder(X, y, n_classes, batch_size, shuffle, epochs) X, y = _data_type_filter(X, y)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.pyc, line 67, in _data_type_filter(X, y) X = extract_pandas_data(X)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/pandas_io.pyc, line 53, in extract_pandas_data(data) raise ValueError('Data types for data must be int, float, or bool.')[SEP]ValueError: Data types for data must be int, float, or bool.",0
"File [FILE], line 7, in <module>() hidden1 = tf.nn.relu(tf.matmul(images_placeholder, weights) + biases)[SEP]File <*>python3.4/site-packages/tensorflow/python/ops/math_ops.py, line 1325, in matmul(a, b, transpose_a, transpose_b, a_is_sparse, b_is_sparse, name) with ops.op_scope([a, b], name, ""MatMul"") as name:[SEP]File <*>python3.4/contextlib.py, line 59, in __enter__(self) return next(self.gen)[SEP]File <*>python3.4/site-packages/tensorflow/python/framework/ops.py, line 4016, in op_scope(values, name, default_name) g = _get_graph_from_inputs(values)[SEP]File <*>python3.4/site-packages/tensorflow/python/framework/ops.py, line 3814, in _get_graph_from_inputs(op_input_list, graph) _assert_same_graph(original_graph_element, graph_element)[SEP]File <*>python3.4/site-packages/tensorflow/python/framework/ops.py, line 3759, in _assert_same_graph(original_item, item) ""%s must be from the same graph as %s."" % (item, original_item))[SEP]ValueError: Tensor(""weights:0"", shape=(1024, 200), dtype=float32_ref) must be from the same graph as Tensor(""Placeholder:0"", shape=(100, 1024), dtype=float32).`",0
"File [FILE], line 27, in () train = model.train(images, labels)[SEP]File [FILE], line 62, in train(self, images, labels) logits = model._create_model(images)[SEP]File [FILE], line 41, in _create_model(self, inputs) inputs = self._create_dense_layer(name, inputs, n_in, n_out)[SEP]File [FILE], line 27, in _create_dense_layer(self, name, inputs, n_in, n_out, activation) weights = self._weights([n_in, n_out])[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/template.py, line 267, in __call__(self, *args, **kwargs) return self._call_func(args, kwargs, check_for_new_variables=False)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/template.py, line 208, in _call_func(self, args, kwargs, check_for_new_variables) result = self._func(*args, **kwargs)[SEP]TypeError: _real_weights() missing 1 required positional argument: 'shape'",0
"File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn) input_tensors_as_shapes, status)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 4096 and 1000 for 'Assign_30' (op: 'Assign') with input shapes: [4096,3], [1000,3].",0
"File <*>/train.py, line 58, in <module>() flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.')[SEP]File <*>python3.6/dist-packages/tensorflow/python/platform/flags.py, line 58, in wrapper(*args, **kwargs) return original_function(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/absl/flags/_defines.py, line 241, in DEFINE_string(name, default, help, flag_values, **args) DEFINE(parser, name, default, help, flag_values, serializer, **args)[SEP]File <*>python3.6/dist-packages/absl/flags/_defines.py, line 82, in DEFINE(parser, name, default, help, flag_values, serializer, module_name, **args) flag_values, module_name)[SEP]File <*>python3.6/dist-packages/absl/flags/_defines.py, line 104, in DEFINE_flag(flag, flag_values, module_name) fv[flag.name] = flag[SEP]File <*>python3.6/dist-packages/absl/flags/_flagvalues.py, line 427, in __setitem__(self, name, flag) raise _exceptions.DuplicateFlagError.from_flag(name, self)[SEP]DuplicateFlagError: The flag 'master' is defined twice. First from object_detection/train.py, Second from object_detection/train.py. Description from first occurrence: Name of the TensorFlow master to use.",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1322, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1307, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1409, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata)[SEP]InvalidArgumentError: Matrix size-incompatible: In[0]: [1,16384], In[1]: [1024,10] [[Node: dense_251/MatMul = MatMul[T=DT_FLOAT, _class=[""loc:@training_22/RMSprop/gradients/dense_251/MatMul_grad/MatMul""], transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](flatten_153/Reshape, dense_251/kernel/read)]] [[Node: loss_26/mul/_579 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1108_loss_26/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]",0
"File [FILE], line 87, in <module>() initial_epoch=initial_epoch)[SEP]File <*>python36/site-packages/keras/legacy/interfaces.py, line 87, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python36/site-packages/keras/engine/training.py, line 2042, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) class_weight=class_weight)[SEP]File <*>python36/site-packages/keras/engine/training.py, line 1756, in train_on_batch(self, x, y, sample_weight, class_weight) check_batch_axis=True)[SEP]File <*>python36/site-packages/keras/engine/training.py, line 1378, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size) exception_prefix='input')[SEP]File <*>python36/site-packages/keras/engine/training.py, line 58, in _standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) 'expected no data, but got:', data)[SEP]ValueError: ('Error when checking model input: expected no data, but got:', [array([[[[1.62046947e+01, 0.00000000e+00, 0.00000000e+00, ...",0
"File [FILE], line 4, in <module>() model = torch.load('checkpoint.pth')[SEP]File <*>python3.6/site-packages/torch/serialization.py, line 303, in load(f, map_location, pickle_module) return _load(f, map_location, pickle_module)[SEP]File <*>python3.6/site-packages/torch/serialization.py, line 469, in _load(f, map_location, pickle_module) result = unpickler.load()[SEP]AttributeError: Can't get attribute 'Network' on <module '__main__'>",0
"File [FILE], line [NUM], in <module> [CODE][SEP]File <*>python3.7/site-packages/keras/engine/training.py, line 952, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs) batch_size=batch_size)[SEP]File <*>python3.7/site-packages/keras/engine/training.py, line 677, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size) self._set_inputs(x)[SEP]File <*>python3.7/site-packages/keras/engine/training.py, line 589, in _set_inputs(self, inputs, outputs, training) self.build(input_shape=(None,) + inputs.shape[1:])[SEP]File <*>python3.7/site-packages/keras/engine/sequential.py, line 221, in build(self, input_shape) x = layer(x)[SEP]File <*>python3.7/site-packages/keras/engine/base_layer.py, line 457, in __call__(self, inputs, **kwargs) output = self.call(inputs, **kwargs)[SEP]File <*>python3.7/site-packages/keras/layers/core.py, line 126, in call(self, inputs, training) training=training)[SEP]File <*>python3.7/site-packages/keras/backend/tensorflow_backend.py, line 3105, in in_train_phase(x, alt, training) training = learning_phase()[SEP]File <*>python3.7/site-packages/keras/backend/tensorflow_backend.py, line 135, in learning_phase() name='keras_learning_phase')[SEP]File <*>python3.7/site-packages/tensorflow/python/ops/array_ops.py, line 2093, in placeholder_with_default(input, shape, name) return gen_array_ops.placeholder_with_default(input, shape, name)[SEP]File <*>python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py, line 5925, in placeholder_with_default(input, shape, name) ""PlaceholderWithDefault"", input=input, shape=shape, name=name)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 511, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1175, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 304, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 245, in constant(value, dtype, shape, name) allow_broadcast=True)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast))[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/tensor_util.py, line 573, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) append_fn(tensor_proto, proto_values)[SEP]File <*>/fast_tensor_util.pyxintensorflow.python, line [NUM], in tensorflow.python.framework.fast_tensor_util.AppendBoolArrayToTensorProto() [CODE][SEP]File <*>python3.7/site-packages/numpy/lib/type_check.py, line 547, in asscalar(***failed resolving arguments***) return a.item()[SEP]UnboundLocalError: local variable 'a' referenced before assignment",0
"File [FILE], line 11, in <module>() model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])[SEP]File <*>python3.6/dist-packages/tensorflow/python/training/checkpointable/base.py, line 442, in _method_wrapper(self, *args, **kwargs) method(self, *args, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 449, in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs) output_loss = weighted_loss(y_true, y_pred, sample_weight, mask)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py, line 676, in weighted(y_true, y_pred, weights, mask) score_array = math_ops.div_no_nan(score_array, weights)[SEP]File <*>python3.6/dist-packages/tensorflow/python/util/dispatch.py, line 180, in wrapper(*args, **kwargs) return target(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/math_ops.py, line 1027, in div_no_nan(x, y, name) return gen_math_ops.div_no_nan(x, y, name=name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 3022, in div_no_nan(x, y, name) ""DivNoNan"", x=x, y=y, name=name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 610, in _apply_op_helper(self, op_type_name, name, **keywords) param_name=input_name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 60, in _SatisfiesTypeConstraint(dtype, attr_def, param_name) "", "".join(dtypes.as_dtype(x).name for x in allowed_list)))[SEP]TypeError: Value passed to parameter 'x' has DataType float16 not in list of allowed values: float32, float64",0
"File [FILE], line 1, in <module> train_image_ds = train_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1146, in map(self, map_func, num_parallel_calls) self, map_func, num_parallel_calls, preserve_cardinality=True)[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 3264, in __init__(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function) use_legacy_function=use_legacy_function)[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 2591, in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs) self._function = wrapper_fn._get_concrete_function_internal()[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1366, in _get_concrete_function_internal(self, *args, **kwargs) *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1360, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1648, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1541, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 716, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 2585, in wrapper_fn(*args) ret = _wrapper_helper(*args)[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 2530, in _wrapper_helper(*args) ret = func(*nested_args)[SEP]File [FILE], line 3, in load_and_preprocess_image(path) return preprocess_image(image)[SEP]File [FILE], line 13, in preprocess_image(image) image = tf.image.central_crop(image, hor_scale_factor)[SEP]File <*>/site-packages/tensorflow/python/ops/image_ops_impl.py, line 643, in central_crop(image, central_fraction) if central_fraction <= 0.0 or central_fraction > 1.0:[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 698, in __bool__(self) raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""[SEP]TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",0
"File [FILE], line 17, in <module>() opt.minimize(lambda: loss_function(intercept,slope,price_batch,size_batch),var_list=[intercept,slope])[SEP]File <*>python3.6/dist-packages/tensorflow/python/eager/tape.py, line 59, in watch(tape, tensor) pywrap_tensorflow.TFE_Py_TapeWatch(tape._tape, tensor) # pylint: disable=protected-access[SEP]SystemError: <built-in function TFE_Py_TapeWatch> returned a result with an error set",0
"File [FILE], line 7, in <module>() A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')[SEP]File [FILE], line 45, in identity_block(X, f, filters, stage, block) X = Add()([X_shortcut,X])[SEP]File <*>python3.6/site-packages/keras/engine/topology.py, line 558, in __call__(self, inputs, **kwargs) self.assert_input_compatibility(inputs)[SEP]File <*>python3.6/site-packages/keras/engine/topology.py, line 431, in assert_input_compatibility(self, inputs) str(inputs) + '. All inputs to the layer '[SEP]ValueError: Layer add_1 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.normalization.BatchNormalization'>. Full input: [<tf.Tensor 'Placeholder:0' shape=(3, 4, 4, 6) dtype=float32>, <keras.layers.normalization.BatchNormalization object at 0x7f169c6d9668>]. All inputs to the layer should be tensors.",0
"File [FILE], line 1, in <module> import acgan[SEP]File <*>/acgan.py, line 3, in <module> from keras.datasets import mnist[SEP]File <*>python3.6/site-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>python3.6/site-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils[SEP]File <*>python3.6/site-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K[SEP]File <*>python3.6/site-packages/keras/backend/__init__.py, line 1, in <module> from .load_backend import epsilon[SEP]File <*>python3.6/site-packages/keras/backend/load_backend.py, line 90, in <module> from .tensorflow_backend import *[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 54, in <module> get_graph = tf_keras_backend.get_graph[SEP]File [FILE], line [NUM], in [FUNC] [CODE][SEP]AttributeError: module 'tensorflow.python.keras.backend' has no attribute 'get_graph'",0
"File [FILE], line 28, in <module> loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]TypeError: forward() got an unexpected keyword argument 'labels'",0
"File [FILE], line 1, in <module> for batch_idx, (data, _) in enumerate(trainDL):[SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 346, in __next__(self) data = self._dataset_fetcher.fetch(index) # may raise StopIteration[SEP]File <*>python3.6/site-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch(self, possibly_batched_index) data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <*>python3.6/site-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp>(.0) data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <*>python3.6/site-packages/pandas/core/frame.py, line 2995, in __getitem__(self, key) indexer = self.columns.get_loc(key)[SEP]File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 2899, in get_loc(self, key, method, tolerance) return self._engine.get_loc(self._maybe_cast_indexer(key))[SEP]File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE][SEP]File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE][SEP]KeyError: 40592",0
"File <*>/tensorboard.py, line 1, in [FUNC] from torch.utils.tensorboard import SummaryWriter[SEP]File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 4, in [FUNC] raise ImportError('TensorBoard logging requires TensorBoard with Python summary writer installed. '[SEP]ImportError: TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above.",0
"File [FILE], line 10, in <module>() scan_object = ta.Scan(x_train, y_train, params=p, model=iris_model, experiment_name='test', x_val=x_val, y_val=y_val, fraction_limit=0.1)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 1815, in _validate_or_infer_batch_size(self, batch_size, steps, x) x, batch_size))[SEP]ValueError: The `batch_size` argument must not be specified for the given input type. Received input: <DatasetV1Adapter shapes: ((512, 4), (512, 3)), types: (tf.float32, tf.float32)>, batch_size: 512",0
"File [FILE], line 3, in <module> epochs=10)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 324, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs) total_epochs=epochs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 123, in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs) batch_outs = execution_function(iterator)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 86, in execution_function(input_fn) distributed_function(input_fn))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializer_map)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize(self, args, kwds, add_initializers_to) *args, **kwds))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 73, in distributed_function(input_iterator) per_replica_function, args=(model, x, y, sample_weights))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 760, in experimental_run_v2(self, fn, args, kwargs) return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 1787, in call_for_each_replica(self, fn, args, kwargs) return self._call_for_each_replica(fn, args, kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 2132, in _call_for_each_replica(self, fn, args, kwargs) return fn(*args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py, line 292, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics) output_loss_metrics=model._output_loss_metrics)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 315, in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics) model, outs, targets, sample_weights=sample_weights, masks=masks)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 74, in _eager_metrics_fn(model, outputs, targets, sample_weights, masks) skip_target_masks=model._prepare_skip_target_masks())[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 2063, in _handle_metrics(self, outputs, targets, skip_target_masks, sample_weights, masks, return_weighted_metrics, return_weighted_and_unweighted_metrics) target, output, output_mask))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 2014, in _handle_per_output_metrics(self, metrics_dict, y_true, y_pred, mask, weights) metric_fn, y_true, y_pred, weights=weights, mask=mask)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py, line 1067, in call_metric_function(metric_fn, y_true, y_pred, weights, mask) return metric_fn(y_true, y_pred, sample_weight=weights)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/metrics.py, line 193, in __call__(self, *args, **kwargs) replica_local_fn, *args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py, line 1135, in call_replica_local_fn(fn, *args, **kwargs) return fn(*args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/metrics.py, line 176, in replica_local_fn(*args, **kwargs) update_op = self.update_state(*args, **kwargs) # pylint: disable=not-callable[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py, line 75, in decorated(metric_obj, *args, **kwargs) update_op = update_state_fn(*args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/metrics.py, line 883, in update_state(self, y_true, y_pred, sample_weight) sample_weight=sample_weight)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py, line 278, in update_confusion_matrix_variables(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight) y_pred.shape.assert_is_compatible_with(y_true.shape)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py, line 1115, in assert_is_compatible_with(self, other) raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))[SEP]ValueError: Shapes (None, 4) and (None, 1) are incompatible",0
"File [FILE], line 8, in <module> es.tell(X, eval_all(X, NPARAMS))[SEP]File [FILE], line 16, in _evaluate2(self, X, *args) return [job.get() for job in jobs][SEP]File [FILE], line 16, in <listcomp>(.0) return [job.get() for job in jobs][SEP]File <*>python3.7/pool.py, line 657, in get(self, timeout) raise self._value[SEP]File <*>python3.7/pool.py, line 431, in _handle_tasks(taskqueue, put, outqueue, pool, cache) put(task)[SEP]File <*>python3.7/connection.py, line 206, in send(self, obj) self._send_bytes(_ForkingPickler.dumps(obj))[SEP]File <*>python3.7/reduction.py, line 51, in dumps(cls, obj, protocol) cls(buf, protocol).dump(obj)[SEP]TypeError: can't pickle _thread.lock objects",0
"File [FILE], line 3, in <module> cocoBuilder.download_and_prepare()[SEP]File <*>/site-packages/tensorflow_datasets/core/api_utils.py, line 52, in disallow_positional_args_dec(fn, instance, args, kwargs) return fn(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow_datasets/core/dataset_builder.py, line 287, in download_and_prepare(self, download_dir, download_config) download_config=download_config)[SEP]File <*>/site-packages/tensorflow_datasets/core/dataset_builder.py, line 948, in _download_and_prepare(self, dl_manager, download_config) max_examples_per_split=download_config.max_examples_per_split,[SEP]File <*>/site-packages/tensorflow_datasets/core/dataset_builder.py, line 804, in _download_and_prepare(self, dl_manager, **prepare_split_kwargs) for split_generator in self._split_generators(dl_manager):[SEP]File <*>/site-packages/tensorflow_datasets/image/coco.py, line 239, in _split_generators(self, dl_manager) key: root_url + url for key, url in urls.items()[SEP]File <*>/site-packages/tensorflow_datasets/core/download/download_manager.py, line 359, in download_and_extract(self, url_or_urls) return _map_promise(self._download_extract, url_or_urls)[SEP]File <*>/site-packages/tensorflow_datasets/core/download/download_manager.py, line 395, in _map_promise(map_fn, all_inputs) res = utils.map_nested(_wait_on_promise, all_promises)[SEP]File <*>/site-packages/tensorflow_datasets/core/utils/py_utils.py, line 129, in map_nested(function, data_struct, dict_only, map_tuple) for k, v in data_struct.items()[SEP]File <*>/site-packages/tensorflow_datasets/core/utils/py_utils.py, line 129, in <dictcomp>(.0) for k, v in data_struct.items()[SEP]File <*>/site-packages/tensorflow_datasets/core/utils/py_utils.py, line 143, in map_nested(function, data_struct, dict_only, map_tuple) return function(data_struct)[SEP]File <*>/site-packages/tensorflow_datasets/core/download/download_manager.py, line 379, in _wait_on_promise(p) return p.get()[SEP]File <*>/site-packages/promise/promise.py, line 510, in get(self, timeout) return self._target_settled_value(_raise=True)[SEP]File <*>/site-packages/promise/promise.py, line 514, in _target_settled_value(self, _raise) return self._target()._settled_value(_raise)[SEP]File <*>/site-packages/promise/promise.py, line 224, in _settled_value(self, _raise) reraise(type(raise_val), raise_val, self._traceback)[SEP]File <*>/site-packages/six.py, line 696, in reraise(tp, value, tb) raise value[SEP]File <*>/site-packages/promise/promise.py, line 842, in handle_future_result(future) resolve(future.result())[SEP]File <*>/_base.py, line 425, in result(self, timeout) return self.__get_result()[SEP]File <*>/_base.py, line 384, in __get_result(self) raise self._exception[SEP]File <*>/thread.py, line 56, in run(self) result = self.fn(*self.args, **self.kwargs)[SEP]File <*>/site-packages/tensorflow_datasets/core/download/extractor.py, line 94, in _sync_extract(self, from_path, method, to_path) raise ExtractError(msg)[SEP]ExtractError: Error while extracting C:\Users\%user%\tensorflow_datasets\downloads\images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip to C:\Users\%user%\tensorflow_datasets\downloads\extracted\ZIP.images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip : C:\Users\%user%\tensorflow_datasets\downloads\images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip; Unknown error",0
"File [FILE], line 1, in <module>() addn = tf.add(mul, div)[SEP]File <*>python3.5/site-packages/tensorflow_core/python/ops/gen_math_ops.py, line 343, in add(x, y, name) _ops.raise_from_not_ok_status(e, name)[SEP]File <*>python3.5/site-packages/tensorflow_core/python/framework/ops.py, line 6606, in raise_from_not_ok_status(e, name) six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <*>python3.5/site-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE][SEP]InvalidArgumentError: cannot compute Add as input #1(zero-based) was expected to be a int32 tensor but is a double tensor [Op:Add]",0
"File [FILE], line 13, in <module> model = FullyConnectedLayer (512, dist, 0.99, 0.5 ) # 4 LAYERS[SEP]File [FILE], line 58, in FullyConnectedLayer(denseUnits, seluDistribution, batchMomentum, alphaDropRate) model.add(Activation(gelu(x=seluDistribution)))[SEP]File <*>/site-packages/tensorflow_core/python/keras/layers/core.py, line 378, in __init__(self, activation, **kwargs) self.activation = activations.get(activation)[SEP]File <*>/site-packages/tensorflow_core/python/keras/activations.py, line 454, in get(identifier) repr(identifier)))[SEP]TypeError: Could not interpret activation function identifier: <tf.Tensor: shape=(5, 5, 1, 32), dtype=float32, numpy= array([[[[-1.26586094e-01, -1.02963023e-01, 3.14652212e-02, -1.39087364e-01, 1.13992631e-01, 1.52557418e-01, -1.09972686e-01, -5.12595251e-02, -1.58538278e-02, -1.29528284e-01, 1.63152684e-02, 1.01518132e-01, -4.35875840e-02, 1.46785110e-01, -2.23108958e-02, -2.09968127e-02, -8.54036435e-02, 9.01642349e-03, -4.25574742e-02, 4.80710454e-02]], [[ 9.34263412e-03, 1.06001608e-01, -7.65870064e-02, -8.02185014e-02, 6.67698979e-02, -8.98385793e-02, -6.12295903e-02, 7.36039877e-02, -1.33156419e-01, [[-1.38585389e-01, 1.03538044e-01, 1.76681668e-01, -6.94317510e-03, 6.14152141e-02, -3.92788239e-02, -5.83523549e-02, 6.68111816e-02, 5.49897328e-02, -5.77139147e-02, -7.64194950e-02, -7.55715296e-02, -4.95074578e-02, 7.71198049e-02, 5.40203564e-02, -9.74030495e-02, -1.00650810e-01, 1.23783059e-01, -8.46874043e-02, -1.04908131e-01, -2.63819955e-02, -1.31487399e-01, 1.30674899e-01]], [[ 6.60606772e-02, 1.46065757e-01, 1.59279909e-02, -1.20391339e-01, -7.02986643e-02, -2.74278801e-02, -1.29030854e-01, -7.62277395e-02, -1.19075023e-01, -9.22646299e-02, 7.98776373e-02, 6.54103830e-02, -6.72401339e-02, -4.81364317e-02, -6.03620708e-02, -2.84200851e-02, -9.10447016e-02]], [[-1.23140588e-01, 1.10491589e-01, -9.61843282e-02, -8.91052186e-02, 4.01075035e-01, 1.94666237e-02, -2.61222124e-02, -1.56512097e-01, 9.74281505e-02, -3.66279632e-02, 6.65708026e-03, 9.61058680e-03, -1.21156186e-01, -2.98077669e-02, 1.66137442e-02, -3.38280275e-02, -9.28360224e-02, -7.76154548e-02, -7.96113610e-02, -2.57881228e-02, -1.58247918e-01, [[[-1.13160208e-01, -1.98329911e-02, 1.20878376e-01, -1.13716172e-02, -5.21509871e-02, 7.25255907e-02, -1.12730011e-01, -7.29970336e-02, 6.37045652e-02, -8.64603445e-02, -2.22087242e-02, -2.47925967e-02, -6.44451613e-03, -1.73095725e-02, -6.07393086e-02, -4.96991165e-02, -3.15147117e-02, 2.43039820e-02, -7.35211000e-02, -6.92363605e-02]], [[ 3.96580771e-02, 1.26118317e-01, 1.16271339e-01, -5.80145419e-02, -2.15136074e-03, -9.12490934e-02, -1.27457187e-01, 3.60154063e-02, 9.91806835e-02, -4.64559309e-02, -2.11531147e-02, 4.10205543e-01, -4.43787202e-02, 4.39099297e-02, 3.06370091e-02, -9.87873599e-02, -5.10304309e-02]], [[ 2.13202462e-02, 1.41525701e-01, -4.84775938e-02, -1.43082231e-01, 4.21900637e-02, -1.17563821e-01, -3.71489525e-02, -1.45584494e-01, -1.12884097e-01, -7.87854716e-02, -2.01713406e-02, -3.49416770e-02, -6.53499886e-02, -2.09143162e-02, 2.94101406e-02, -5.27165644e-02, 1.19348057e-02, -4.39126566e-02, -6.26288429e-02, 4.20925207e-02]], [[-8.23830441e-02, 2.23106906e-01, 8.56178179e-02, -5.99831380e-02, -1.71386788e-03, -3.62357125e-02, -1.59021363e-01, -2.17766548e-03, 2.16864720e-01, -5.73305860e-02, -1.80698894e-02, 1.36940643e-01, -1.97473206e-02, 8.14313069e-02, 1.96376622e-01, -6.43103570e-02, -3.85615453e-02]], [[-3.53560485e-02, 4.35038935e-03, -7.06349090e-02, -2.80691660e-03, -6.92954510e-02, 1.11481667e-01, -4.58219610e-02, -2.38394644e-02, -7.87800774e-02, -1.67009607e-02, 6.01479635e-02, 1.56740978e-01, -9.78638828e-02, -4.29860055e-02, 1.38192121e-02, -1.36006713e-01, -1.05418041e-01, -2.51792613e-02, -1.22639257e-02, -1.21888302e-01, -5.46660051e-02, -7.12147309e-03, -6.58531636e-02, -7.14808479e-02, [[[ 6.32937178e-02, 2.72242278e-01, -3.74731459e-02, -2.62564681e-02, -1.54855132e-01, 7.81283434e-03, -8.01301673e-02, 7.47360140e-02, -5.00108190e-02, -7.64894933e-02, 8.45131949e-02, -3.27355303e-02, -3.79370786e-02, -6.93783676e-03, -4.87477183e-02, [[-7.98909813e-02, 2.59152979e-01, 1.75541520e-01, -8.12215135e-02, -9.54297185e-02, 1.99518725e-03, -3.72358635e-02, -1.39946237e-01, -5.76626435e-02, -7.13582858e-02, 5.86171262e-02, -1.39267772e-01, -1.00216493e-01, 2.68728107e-01, 1.63495377e-01, -2.24205833e-02, 1.44553408e-01, -9.67240557e-02, -1.24277532e-01, -1.40620157e-01]], [[-5.69531657e-02, 1.71630532e-01, 2.86230773e-01, -5.93378842e-02, -1.71954520e-02, -3.26295868e-02, -3.98173966e-02, 7.21049905e-02, -6.91456124e-02, -1.23138815e-01, 1.33402884e-01, -1.02245316e-01, -4.69203852e-02, -1.75676849e-02, 1.40360445e-01, -3.40559036e-02, 3.35928686e-02, -1.04908220e-01, [[-7.85556585e-02, -1.18466914e-01, 1.53003752e-01, -4.67218924e-03, -1.16112582e-01, 5.51390201e-02, -1.52055770e-02, 3.54320277e-03, 3.42624858e-02, -1.05386212e-01, 1.98949352e-02, 2.73315758e-02, -7.58572146e-02, 1.03625186e-01, 2.05493998e-03, -1.01805991e-02, 2.19766423e-02]], [[-1.00509115e-02, 2.22494956e-02, -9.08879191e-02, -8.11229870e-02, 9.98405516e-02, -5.72074987e-02, -1.33951874e-02, 3.92576605e-02, 1.16789080e-01, -1.89318452e-02, -1.59033425e-02, 9.48152542e-02, -2.66773477e-02, 1.37753570e-02, 1.79445334e-02, -6.62883669e-02, -9.37851295e-02, 1.94142580e-01, -1.28269400e-02, 1.25869989e-01, 1.50878415e-01, -2.11219154e-02, -1.05045862e-01, -2.73662023e-02, [[[ 1.83003962e-01, -4.02955636e-02, 7.92874582e-03, -1.04859909e-02, 1.41754048e-02, -1.52763631e-02, -9.11424682e-02, 3.24082047e-01, 1.05546042e-02, -1.30687788e-01, -3.98224816e-02, 1.38061410e-02, [[ 2.33758405e-01, -9.26907063e-02, 1.65917858e-01, -1.22203723e-01, -2.83196904e-02, 1.02213569e-01, -5.63387433e-03, -3.08787469e-02, 1.96257643e-02, -7.37890229e-02, -1.93086471e-02, 1.30984381e-01, [[-5.09779751e-02, 6.08728305e-02, -8.07061568e-02, -1.26804784e-01, -1.43676013e-01, -3.28507088e-02, -1.66144117e-03, -7.41888210e-03, 1.42028257e-01, -4.99214791e-02, -1.86899900e-02, -1.09298825e-02, -8.03249031e-02, -1.00237548e-01]], [[-7.80191123e-02, 4.05082256e-02, 7.47731477e-02, -8.76973122e-02, -2.91744564e-02, 1.23694569e-01, -1.49070352e-01, 2.42730626e-03, 3.52480598e-02, -5.62792830e-03, -2.28355639e-02, -1.27415329e-01, -8.48858505e-02, -3.52028869e-02, -7.95315206e-02, -3.92727107e-02, -4.16678861e-02, 2.39140958e-01, -1.44019471e-02, -8.69576260e-03]], [[-1.67441964e-02, -1.43177100e-02, -9.23768803e-02, -2.72830930e-02, 7.51334131e-02, -2.28366554e-02, -5.57800010e-02, -1.31770581e-01, 9.31192283e-03, -1.38517320e-02, -1.41043484e-01, -6.42404705e-02, -4.86476049e-02, -1.12639852e-01, 7.89660513e-02, -1.09081008e-01, -3.03610712e-02]]], [[[-1.40361011e-01, 1.21919084e-02, 4.36685272e-02, -3.61564793e-02, -1.11773185e-01, 2.25092173e-02, -1.02469876e-01, 1.76996499e-01, 4.30173017e-02, -2.26258971e-02, 2.11037025e-01, 9.66922417e-02, -4.83587980e-02, 4.68245940e-04, -1.47096828e-01, -2.91392524e-02, 8.22411999e-02, 2.07852814e-02, -4.12134677e-02, 5.33621386e-02, 9.24792588e-02, [[ 1.66879535e-01, 6.54919222e-02, -3.27483788e-02, -1.43241754e-03, -1.14416316e-01, -2.12962832e-02, -4.46583293e-02, 2.71647628e-02, -5.61558232e-02, -1.24854170e-01, 1.25476092e-01, -7.09585026e-02, -4.40548174e-02, 7.21732453e-02, 7.45785460e-02, -1.17296316e-01, -1.46051958e-01, 1.88378561e-02, [[ 2.60874778e-01, -1.45940065e-01, -9.79427770e-02, -8.68195742e-02, 2.04389215e-01, -2.24198923e-02, -8.38927086e-03, -4.99465019e-02, 4.69646640e-02, -7.15569034e-02, -1.78242605e-02, -8.51068646e-03, -3.08227092e-02, -4.82530929e-02, 8.31630453e-02, -4.16018628e-02, -7.55471215e-02]], [[ 2.24076852e-01, -1.39667824e-01, 7.93220941e-03, -1.78845283e-02, -5.64770252e-02, -7.84719810e-02, -1.81565285e-02, 1.24106847e-01, -6.28474308e-03, -1.72791779e-02, -3.47166769e-02, -4.92920280e-02, -9.12440866e-02, 6.42236844e-02, -1.16013244e-01, -7.96606317e-02, 1.50838092e-01, -4.71229590e-02, -4.02066261e-02, 1.17019311e-01]], [[-3.95799540e-02, -4.35096361e-02, -9.93420109e-02, -6.20126911e-02, 1.93700612e-01, 5.02851121e-02, -9.00325775e-02, 1.32245719e-01, 2.68575907e-01, -8.08344856e-02, -4.56905663e-02, 1.26069590e-01, -6.64912462e-02, 9.61613879e-02, -1.48803489e-02, "", 'Error', 'Error', '', '')",0
"File [FILE], line 8, in <module>() ds = ds.filter(filter_fn)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]OperatorNotAllowedInGraphError: in user code: <ipython-input-52-52131b5369b6>:5 filter_fn * return features['department'] in ['FERRAMENTAS', 'MERCEARIA', 'MOVEIS'] /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:778 __bool__ self._disallow_bool_casting() /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:545 _disallow_bool_casting ""using a `tf.Tensor` as a Python `bool`"") /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:532 _disallow_when_autograph_enabled "" decorating it directly with @tf.function."".format(task)) OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.",0
"File [FILE], line 11, in <module> validation_steps=nb_val_steps)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1063, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) steps_per_execution=self._steps_per_execution)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/data_adapter.py, line 1110, in __init__(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution) model=model)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/data_adapter.py, line 798, in __init__(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs) output_shapes = nest.map_structure(_get_dynamic_shape, peek)[SEP]File <*>/site-packages/tensorflow/python/util/est.py, line 635, in map_structure(func, *structure, **kwargs) structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/util/est.py, line 635, in <listcomp>(.0) structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/keras/engine/data_adapter.py, line 794, in _get_dynamic_shape(t) if shape.rank is None:[SEP]AttributeError: 'tuple' object has no attribute 'rank'",0
"File [FILE], line 1, in <module>() load_image('/content/train2017/000000000009.jpg')[SEP]File [FILE], line 4, in load_image(image_path) img = tf.image.resize(img, (299, 299))[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py, line 1517, in resize_images_v2(images, size, method, preserve_aspect_ratio, antialias, name) skip_resize_if_same=False)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py, line 1185, in _resize_images_common(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same) if images.get_shape().ndims is None:[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1073, in get_shape(self) return self.shape[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1067, in shape(self) six.raise_from(core._status_to_exception(e.code, e.message), None)[SEP]File <*>python3.6/dist-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE][SEP]UnimplementedError: File system scheme '[local]' not implemented (file: '/content/train2017/000000000009.jpg')",0
"File [FILE], line 1, in <module>() X_prime_class_split = np.array_split(X_prime_class.numpy(),[SEP]TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",0
"File [FILE], line 6, in <module> train_step(image_x, image_y)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 823, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializers)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 696, in _initialize(self, args, kwds, add_initializers_to) self._stateful_fn._get_concrete_function_internal_garbage_collected( # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2855, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 3213, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 3065, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) func_graph_module.func_graph_from_py_func([SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 986, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 600, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 973, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]OperatorNotAllowedInGraphError: in user code: <ipython-input-160-538af916a6fd>:28 train_step * total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_losss(real_y, cycled_y) <ipython-input-151-74a790ebcddf>:2 calc_cycle_loss * loss1 = tf.reduce_mean(tf.abs(real_image, cycled_image)) C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\util\dispatch.py:201 wrapper ** return target(*args, **kwargs) C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\ops\math_ops.py:388 abs with ops.name_scope(name, ""Abs"", [x]) as name: C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:6492 __enter__ return self._name_scope.__enter__() c:\users\astro\appdata\local\programs\python\python38\lib\contextlib.py:113 __enter__ return next(self.gen) C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:4176 name_scope if name: C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:877 __bool__ self._disallow_bool_casting() C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:486 _disallow_bool_casting self._disallow_when_autograph_enabled( C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:472 _disallow_when_autograph_enabled raise errors.OperatorNotAllowedInGraphError( OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.",0
"File [FILE], line [NUM], in apache_beam.runners.common.DoFnRunner.process() [CODE][SEP]File [FILE], line [NUM], in apache_beam.runners.common.PerWindowInvoker.invoke_process() [CODE][SEP]File [FILE], line [NUM], in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window() [CODE][SEP]File [FILE], line [NUM], in apache_beam.runners.common._OutputProcessor.process_outputs() [CODE][SEP]File [FILE], line [NUM], in apache_beam.runners.worker.operations.SingletonConsumerSet.receive() [CODE][SEP]File [FILE], line [NUM], in apache_beam.runners.worker.operations.PGBKCVOperation.process() [CODE][SEP]File <*>python3.7/site-packages/tensorflow_model_analysis/evaluators/metrics_and_plots_evaluator_v2.py, line 356, in add_input(self, accumulator, element) result = c.add_input(a, get_combiner_input(elements[0], i))[SEP]File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/calibration_histogram.py, line 142, in add_input(self, accumulator, element) class_weights=self._class_weights)):[SEP]File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py, line 284, in to_label_prediction_example_weight(inputs, eval_config, model_name, output_name, sub_key, class_weights, flatten, squeeze, allow_none) label, prediction = select_top_k(sub_key.top_k, label, prediction)[SEP]File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py, line 622, in select_top_k(top_k, labels, predictions, scores) labels = one_hot(labels, predictions)[SEP]File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py, line 672, in one_hot(tensor, target) tensor = np.delete(np.eye(target.shape[-1] + 1)[tensor], -1, axis=-1)[SEP]IndexError: arrays used as indices must be of integer (or boolean) type",0
"File <*>/site-packages/keras/__init__.py, line 3, in <module> from tensorflow.keras.layers.experimental.preprocessing import RandomRotation[SEP]ModuleNotFoundError: No module named 'tensorflow.keras.layers.experimental.preprocessing'",0
"File [FILE], line 1, in <module> batch_first[:,1:].view(-1, embedding) # slicing out the first time step[SEP]RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",0
"File [FILE], line 49, in <module> logps = model(images) #log probabilities[SEP]File <*>python3.8/site-packages/torch/nn/modules/container.py, line 117, in forward(self, input) input = module(input)[SEP]File <*>python3.8/site-packages/torch/nn/modules/module.py, line 727, in _call_impl(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.8/site-packages/torch/nn/modules/linear.py, line 93, in forward(self, input) return F.linear(input, self.weight, self.bias)[SEP]File <*>python3.8/site-packages/torch/nn/functional.py, line 1690, in linear(input, weight, bias) ret = torch.addmm(bias, input, weight.t())[SEP]RuntimeError: expected scalar type Float but found Byte",0
