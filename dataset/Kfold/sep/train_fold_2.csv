Templates,label
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 4, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 13, in <module> from tensorflow.core.framework.graph_pb2 import *[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/graph_pb2.py, line 16, in <module> from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py, line 16, in <module> from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py, line 16, in <module> from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py, line 22, in <module> serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto \x12\ntensorflow\""d\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tb\x06proto3')[SEP]TypeError: __init__() got an unexpected keyword argument 'syntax'",1
"File [FILE], line 1, in <module>() import tensorflow[SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 4, in <module>() from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 13, in <module>() from tensorflow.core.framework.graph_pb2 import *[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/graph_pb2.py, line 8, in <module>() from google.protobuf import reflection as _reflection[SEP]File <*>python2.7/site-packages/google/protobuf/reflection.py, line 58, in <module>() from google.protobuf.internal import python_message as message_impl[SEP]File <*>python2.7/site-packages/google/protobuf/internal/python_message.py, line 59, in <module>() import six.moves.copyreg as copyreg[SEP]ImportError: No module named copyreg",1
"File multiply.py, line 2, in <module> import tensorflow as tf[SEP]File <*>python2.7.10/site-packages/tensorflow/__init__.py, line 4, in <module> from tensorflow.python import *[SEP]File <*>python2.7.10/site-packages/tensorflow/python/__init__.py, line 22, in <module> from tensorflow.python.client.client_lib import *[SEP]File <*>python2.7.10/site-packages/tensorflow/python/client/client_lib.py, line 35, in <module> from tensorflow.python.client.session import InteractiveSession[SEP]File <*>python2.7.10/site-packages/tensorflow/python/client/session.py, line 11, in <module> from tensorflow.python import pywrap_tensorflow as tf_session[SEP]File <*>python2.7.10/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7.10/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory",1
"File classify.py, line 14, in <module> import caffe[SEP]File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver[SEP]File <*>/pycaffe.py, line 13, in <module> from ._caffe import Net, SGDSolver[SEP]ImportError: dynamic module does not define module export function (PyInit__caffe)",1
"File <*>python3.5/site-packages/theano/gof/opt.py, line 1772, in process_node replacements = lopt.transform(node)[SEP]File <*>python3.5/site-packages/theano/sandbox/gpuarray/opt.py, line 140, in local_opt new_op = maker(node, context_name)[SEP]File <*>python3.5/site-packages/theano/sandbox/gpuarray/opt.py, line 732, in local_gpua_hgemm if nvcc_compiler.nvcc_version < '7.5':[SEP]TypeError: unorderable types: NoneType() < str()",1
"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: No module named data_utils",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/prettytensor-0.6.0-py2.7.egg/prettytensor/__init__.py, line 25, in <module> from prettytensor import funcs[SEP]File <*>python2.7/site-packages/prettytensor-0.6.0-py2.7.egg/prettytensor/funcs.py, line 25, in <module> from prettytensor.pretty_tensor_image_methods import *[SEP]File <*>python2.7/site-packages/prettytensor-0.6.0-py2.7.egg/prettytensor/pretty_tensor_image_methods.py, line 20, in <module> from prettytensor import layers[SEP]ImportError: cannot import name layers",1
"File <*>/fully_connected_feed.py, line 27, in [FUNC] [CODE][SEP]File <*>/input_data.py, line 29, in [FUNC] [CODE][SEP]ImportError: No module named contrib.learn.python.learn.datasets.mnist",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tflearn/__init__.py, line 22, in <module> from . import activations[SEP]File <*>python2.7/site-packages/tflearn/activations.py, line 7, in <module> from . import initializations[SEP]File <*>python2.7/site-packages/tflearn/initializations.py, line 5, in <module> from tensorflow.contrib.layers.python.layers.initializers import \[SEP]ImportError: cannot import name variance_scaling_initializer",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/dist-packages/theano/__init__.py, line 74, in <module> from theano.printing import pprint, pp[SEP]File <*>python2.7/dist-packages/theano/printing.py, line 35, in <module> if pd.find_graphviz():[SEP]AttributeError: 'module' object has no attribute 'find_graphviz'",1
"File <*>/worker.py, line 98, in main command = pickleSer._read_with_length(infile)[SEP]File <*>/serializers.py, line 164, in _read_with_length return self.loads(obj)[SEP]File <*>/serializers.py, line 422, in loads return pickle.loads(obj)[SEP]File <*>python2.7/site-packages/six.py, line 118, in __getattr__ _module = self._resolve()[SEP]File <*>python2.7/site-packages/six.py, line 115, in _resolve return _import_module(self.mod)[SEP]RuntimeError: maximum recursion depth exceeded",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 48, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.19' not found (required by /home/anirudh/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so)",1
"File <*>/census.py, line 73, in <module> df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)[SEP]File <*>python2.7/dist-packages/pandas/core/series.py, line 2023, in apply mapped = lib.map_infer(values, f, convert=convert_dtype)[SEP]File inference.pyx, line 920, in pandas.lib.map_infer (pandas/lib.c:44780)[SEP]File <*>/census.py, line 73, in <lambda> df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)[SEP]TypeError: argument of type 'float' is not iterable",1
"File <pyshell#0>, line 1, in <module> from keras.layers import Dense[SEP]ImportError: cannot import name 'Dense'",1
"File mnist_softmax.py, line 78, in <module> tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)[SEP]TypeError: run() got an unexpected keyword argument 'argv'",1
"File [FILE], line 4, in `<module>`() tf.global_variables_initializer().run()[SEP]AttributeError: 'module' object has no attribute 'global_variables_initializer'",1
"File <*>python3.5/site-packages/keras/backend/tensorflow_backend.py, line 5, in <module>() from tensorflow.python.ops import ctc_ops as ctc[SEP]ImportError: cannot import name 'ctc_ops'",1
"File [FILE], line 1, in <module>() import keras[SEP]File <*>python3.5/site-packages/keras/__init__.py, line 2, in <module>() from . import backend[SEP]File <*>python3.5/site-packages/keras/backend/__init__.py, line 69, in <module>() from .tensorflow_backend import *[SEP]File <*>python3.5/site-packages/keras/backend/tensorflow_backend.py, line 7, in <module>() import tensorflow.contrib.ctc as ctc[SEP]ImportError: No module named 'tensorflow.contrib.ctc'",1
"File [FILE], line 1, in <module>() writer = tf.train.SummaryWriter('./my_graph', sess.graph)[SEP]AttributeError: 'module' object has no attribute 'SummaryWriter'",1
"File [FILE], line 1, in <module>() writer = tf.train.FileWriter('./my_graph', sess.graph)[SEP]AttributeError: 'module' object has no attribute 'FileWriter'",1
"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: 'module' object has no attribute 'FileWriter'",1
"File <*>python2.7/dist-packages/pip/basecommand.py, line 122, in main status = self.run(options, args)[SEP]File <*>python2.7/dist-packages/pip/commands/install.py, line 278, in run requirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle)[SEP]File /usr/lib/python2.7/dist-packages/pip/req.py, line 1178, in prepare_files url = finder.find_requirement(req_to_install, upgrade=self.upgrade)",1
"File fully_connected_feed.py, line 229, in <module> tf.app.run()[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 44, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough))[SEP]File fully_connected_feed.py, line 225, in main run_training()[SEP]File fully_connected_feed.py, line 154, in run_training summary_op = tf.merge_all_summaries()[SEP]AttributeError: 'module' object has no attribute 'merge_all_summaries'",1
"File mnist_test.py, line 19, in <module> cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_, logits=y)[SEP]TypeError: sigmoid_cross_entropy_with_logits() got an unexpected keyword argument 'labels'",1
"File <*>python3.6/site-packages/theano/gof/opt.py, line 1772, in process_node replacements = lopt.transform(node)[SEP]File <*>python3.6/site-packages/theano/tensor/opt.py, line 5825, in constant_folding no_recycling=[])[SEP]File <*>python3.6/site-packages/theano/gof/op.py, line 970, in make_thunk no_recycling)[SEP]File <*>python3.6/site-packages/theano/gof/op.py, line 879, in make_c_thunk output_storage=node_output_storage)[SEP]File <*>python3.6/site-packages/theano/gof/cc.py, line 1200, in make_thunk keep_lock=keep_lock)[SEP]File <*>python3.6/site-packages/theano/gof/cc.py, line 1143, in __compile__ keep_lock=keep_lock)[SEP]File <*>python3.6/site-packages/theano/gof/cc.py, line 1595, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock)[SEP]File <*>python3.6/site-packages/theano/gof/cmodule.py, line 1142, in module_from_key module = lnk.compile_cmodule(location)[SEP]File <*>python3.6/site-packages/theano/gof/cc.py, line 1506, in compile_cmodule preargs=preargs)[SEP]File <*>python3.6/site-packages/theano/gof/cmodule.py, line 2213, in compile_str return dlimport(lib_filename)[SEP]File <*>python3.6/site-packages/theano/gof/cmodule.py, line 299, in dlimport rval = __import__(module_name, {}, {}, [module_name])[SEP]ImportError: /home/puck/.theano/compiledir_Linux-4.4--MANJARO-x86_64-with-glibc2.2.5--3.6.0-64/tmpre6vph8g/mdb219947724f79219f7dbd36f0f52c77.so: undefined symbol: _ZdlPvm",1
"File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 61, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: dlopen(/Users/smahesh/src/tensorflow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.8.0.dylib",1
"File cnn.py, line 258, in <module> models = run_cross_validation_create_models(num_folds)[SEP]File cnn.py, line 205, in run_cross_validation_create_models validation_data=(X_valid, Y_valid))[SEP]TypeError: fit_generator() takes at least 4 arguments (5 given)",1
"File <*>/test_model.py, line 2, in <module> from models import NN_with_EntityEmbedding[SEP]File <*>/models.py, line 8, in <module> from keras.layers.core import Dense, Dropout, Activation, Merge, Reshape[SEP]ImportError: cannot import name Merge",1
"File convnet.py, line 6, in <module> model.add(Conv2D(32, (3, 3), input_shape=(3, 150, 150)))[SEP]TypeError: __init__() missing 1 required positional argument: 'nb_col'",1
"File <*>/CNNTest-one.py, line 7, in <module> import lasagne[SEP]File <*>/site-packages/lasagne/__init__.py, line 19, in <module> from . import layers[SEP]File <*>/site-packages/lasagne/layers/__init__.py, line 7, in <module> from .pool import *[SEP]File <*>/site-packages/lasagne/layers/pool.py, line 6, in <module> from theano.tensor.signal import downsample[SEP]ImportError: cannot import name 'downsample'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in () from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in () _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper() return importlib.import_module('_pywrap_tensorflow_internal' )[SEP]File <*>/importlib__init__.py, line 126, in import_module(name, pac kage) return _bootstrap._gcd_import(name[level:], package, level)[SEP]ImportError: No module named '_pywrap_tensorflow_internal'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal')[SEP]File <*>/importlib__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]ImportError: No module named '_pywrap_tensorflow_internal'",1
"File [FILE], line 44, in <module>() num_sampled, vocabulary_size))[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/nn_impl.py, line 1166, in nce_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name) name=name)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/nn_impl.py, line 1001, in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name) array_ops.reshape(true_w, new_true_w_shape))[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/math_ops.py, line 278, in multiply(x, y, name) return gen_math_ops._mul(x, y, name)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py, line 1434, in _mul(x, y, name) result = _op_def_lib.apply_op(""Mul"", x=x, y=y, name=name)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/op_def_library.py, line 527, in apply_op(self, op_type_name, name, **keywords) inferred_from[input_arg.type_attr]))[SEP]TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int32 of argument 'x'.",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal')[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]ImportError: No module named '_pywrap_tensorflow_internal'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper return importlib.import_module(mname)[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <frozen importlib._bootstrap>, line 986, in _gcd_import [CODE][SEP]File <frozen importlib._bootstrap>, line 969, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 958, in _find_and_load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 666, in _load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 577, in module_from_spec [CODE][SEP]File <frozen importlib._bootstrap_external>, line 906, in create_module [CODE][SEP]File <frozen importlib._bootstrap>, line 222, in _call_with_frames_removed [CODE][SEP]ImportError: DLL load failed: The specified module could not be found.",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper return importlib.import_module(mname)[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <frozen importlib._bootstrap>, line 986, in _gcd_import [CODE][SEP]File <frozen importlib._bootstrap>, line 969, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 958, in _find_and_load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 666, in _load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 577, in module_from_spec [CODE][SEP]File <frozen importlib._bootstrap_external>, line 919, in create_module [CODE][SEP]File <frozen importlib._bootstrap>, line 222, in _call_with_frames_removed [CODE][SEP]ImportError: DLL load failed: The specified module could not be found.",1
"File <*>/tensorboard, line 7, in <module> from tensorflow.tensorboard.tensorboard import main[SEP]ModuleNotFoundError: No module named 'tensorflow.tensorboard.tensorboard'",1
"File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]ImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory Failed to load the native TensorFlow runtime.",1
"File <*>/running_template.py, line 65, in <module> cytoplasm_predictions = run_models_on_directory(data_location,cyto_channel_names, cyto_location, model_fn = cyto_fn,list_of_weights = list_of_cyto_weights, image_size_x = image_size_x, image_size_y = image_size_y,win_x = win_cyto, win_y = win_cyto, std = False, split = False)[SEP]File <*>/cnn_functions.py, line 1491, in run_models_on_directory model = model_fn(batch_input_shape = batch_input_shape, n_features = n_features, weights_path = list_of_weights[0])[SEP]File <*>/model_zoo.py, line 528, in sparse_bn_feature_net_61x61 model.add(sparse_Convolution2D(64, 3, 3, d = d, init = init, batch_input_shape = batch_input_shape, border_mode='valid', W_regularizer = l2(reg)))[SEP]File <*>python2.7/site-packages/keras/models.py, line 436, in add layer(x)[SEP]File <*>python2.7/site-packages/keras/engine/topology.py, line 569, in __call__ self.build(input_shapes[0])[SEP]File <*>/cnn_functions.py, line 1012, in build self.W = self.init(self.W_shape, name='{}_W'.format(self.name))[SEP]TypeError: __call__() got an unexpected keyword argument 'name'",1
"File <*>/site-packages/tensorflow/python/platform/self_check.py, line 75, in preload_check ctypes.WinDLL(build_info.cudart_dll_name)[SEP]File <*>/__init__.py, line 347, in __init__ self._handle = _dlopen(self._name, mode)[SEP]OSError: [WinError 126] The specified module could not be found",1
"File <pyshell#6>, line 1, in <module> import tensorflow as tf[SEP]File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import *[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 30, in <module> self_check.preload_check()[SEP]File <*>/site-packages/tensorflow/python/platform/self_check.py, line 82, in preload_check % (build_info.cudart_dll_name, build_info.cuda_version_number))[SEP]ImportError: Could not find 'cudart64_90.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 9.0 from this URL: https://developer.nvidia.com/cuda-toolkit",1
"File <*>python2.7/runpy.py, line 174, in _run_module_as_main ""__main__"", fname, loader, pkg_name)[SEP]File <*>python2.7/runpy.py, line 72, in _run_code exec code in run_globals[SEP]File <*>python2.7/site-packages/object_detection/train.py, line 49, in <module> from object_detection import trainer[SEP]File <*>python2.7/site-packages/object_detection/trainer.py, line 27, in <module> from object_detection.builders import preprocessor_builder[SEP]File <*>python2.7/site-packages/object_detection/builders/preprocessor_builder.py, line 21, in <module> from object_detection.protos import preprocessor_pb2[SEP]File <*>python2.7/site-packages/object_detection/protos/preprocessor_pb2.py, line 71, in <module> options=None, file=DESCRIPTOR),[SEP]TypeError: __new__() got an unexpected keyword argument 'file'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal')[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper return importlib.import_module(mname)[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <frozen importlib._bootstrap>, line 994, in _gcd_import [CODE][SEP]File <frozen importlib._bootstrap>, line 971, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 955, in _find_and_load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 658, in _load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 571, in module_from_spec [CODE][SEP]File <frozen importlib._bootstrap_external>, line 922, in create_module [CODE][SEP]File <frozen importlib._bootstrap>, line 219, in _call_with_frames_removed [CODE][SEP]ImportError: DLL load failed with error code -1073741795",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 14, in swig_import_helper return importlib.import_module(mname)[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <frozen importlib._bootstrap>, line 994, in _gcd_import [CODE][SEP]File <frozen importlib._bootstrap>, line 971, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 955, in _find_and_load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 658, in _load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 571, in module_from_spec [CODE][SEP]File <frozen importlib._bootstrap_external>, line 922, in create_module [CODE][SEP]File <frozen importlib._bootstrap>, line 219, in _call_with_frames_removed [CODE][SEP]ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 17, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 16, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal')[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'",1
"File kerasbottleneck.py, line 103, in <module> save_bottlebeck_features()[SEP]File kerasbottleneck.py, line 69, in save_bottlebeck_features np.save(open('bottleneck_features_train.npy', 'w'),bottleneck_features_train)[SEP]File <*>python3.6/site-packages/numpy/lib/npyio.py, line 511, in save pickle_kwargs=pickle_kwargs)[SEP]File <*>python3.6/site-packages/numpy/lib/format.py, line 565, in write_array version)[SEP]File <*>python3.6/site-packages/numpy/lib/format.py, line 335, in _write_array_header fp.write(header_prefix)[SEP]TypeError: write() argument must be str, not bytes",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/keras/models.py, line 243, in load_model model = model_from_config(model_config, custom_objects=custom_objects)[SEP]File <*>python3.6/site-packages/keras/models.py, line 317, in model_from_config return layer_module.deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.6/site-packages/keras/layers/__init__.py, line 55, in deserialize printable_module_name='layer')[SEP]File <*>python3.6/site-packages/keras/utils/generic_utils.py, line 143, in deserialize_keras_object list(custom_objects.items())))[SEP]File <*>python3.6/site-packages/keras/models.py, line 1352, in from_config layer = layer_module.deserialize(conf, custom_objects=custom_objects)[SEP]File <*>python3.6/site-packages/keras/utils/generic_utils.py, line 145, in deserialize_keras_object return cls.from_config(config['config'])[SEP]File <*>python3.6/site-packages/keras/engine/topology.py, line 1269, in from_config return cls(**config)[SEP]File <*>python3.6/site-packages/keras/layers/core.py, line 483, in __init__ super(Flatten, self).__init__(**kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/topology.py, line 292, in __init__ raise TypeError('Keyword argument not understood:', kwarg)[SEP]TypeError: ('Keyword argument not understood:', 'data_format')",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.7/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>python3.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 114, in [FUNC] [CODE][SEP]SyntaxError: invalid syntax",1
"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: module 'tensorflow.python.keras.datasets.fashion_mnist' has no attribute 'load_data'",1
"File <*>/train_network.py, line 109, in <module> model = LeNet.build(width=100, height=100, depth=3, classes=5)[SEP]File <*>/lenet.py, line 39, in build output = model(pretrainedOutput)[SEP]File <*>python3.6/dist-packages/keras/engine/base_layer.py, line 443, in __call__ previous_mask = _collect_previous_mask(inputs)[SEP]File <*>python3.6/dist-packages/keras/engine/base_layer.py, line 1311, in _collect_previous_mask mask = node.output_masks[tensor_index][SEP]AttributeError: 'Node' object has no attribute 'output_masks'",1
"File [FILE], line 1, in <module>() from keras.layers import Merge[SEP]ImportError: cannot import name 'Merge'",1
"File <input>, line 3, in <module> [CODE][SEP]AttributeError: 'Tensor' object has no attribute '_keras_shape'",1
"File serialize_model.py, line 60, in <module> traced_script_module.save(""model.pt"")[SEP]AttributeError: 'function' object has no attribute 'save'",1
"File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in make_tensor_proto str_values = [compat.as_bytes(x) for x in proto_values][SEP]File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in <listcomp> str_values = [compat.as_bytes(x) for x in proto_values][SEP]File <*>python3.6/site-packages/tensorflow/python/util/compat.py, line 61, in as_bytes (bytes_or_text,))[SEP]TypeError: Expected binary or unicode string, got {'DispositionSoldAmount': <tf.Tensor 'random_shuffle_queue_DequeueMany:4' shape=(128,) dtype=float64>}",1
"File <*>/test_callback.py, line 34, in <module> model.evaluate_generator(generator=test_generator, steps=STEP_SIZE_TEST, callbacks=[test_callback])[SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]TypeError: evaluate_generator() got an unexpected keyword argument 'callbacks'",1
"File <*>python3.6/threading.py, line 916, in _bootstrap_inner self.run()[SEP]File <*>python3.6/threading.py, line 864, in run self._target(*self._args, **self._kwargs)[SEP]File <*>python3.6/site-packages/keras/utils/data_utils.py, line 671, in _run executor.apply_async(next_sample, (self.uid,)), block=True)[SEP]File <*>python3.6/queue.py, line 127, in put if self.maxsize > 0:[SEP]TypeError: '>' not supported between instances of 'list' and 'int'",1
"File [FILE], line 19, in <module>() history = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=0, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_split=0.25)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 880, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs) validation_steps=validation_steps)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py, line 325, in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs) callbacks._call_batch_hook(mode, 'begin', batch_index, batch_logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 196, in _call_batch_hook(self, mode, hook, batch, logs) batch_hook = getattr(callback, hook_name)[SEP]AttributeError: 'EarlyStopping' object has no attribute 'on_train_batch_begin'",1
"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: module 'tensorflow' has no attribute 'Session'",1
"File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.6/imp.py, line 243, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.6/imp.py, line 343, in load_dynamic return _load(spec)[SEP]ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory",1
"File [FILE], line 2, in () model = InceptionV3(include_top=True,weights='imagenet')[SEP]File <*>python3.6/site-packages/keras/applications/__init__.py, line 28, in wrapper(*args, **kwargs) return base_fun(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/applications/inception_v3.py, line 11, in InceptionV3(*args, **kwargs) return inception_v3.InceptionV3(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras_applications/inception_v3.py, line 157, in InceptionV3(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs) img_input = layers.Input(shape=input_shape)[SEP]File <*>python3.6/site-packages/keras/engine/input_layer.py, line 178, in Input(shape, batch_shape, name, dtype, sparse, tensor) input_tensor=tensor)[SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/input_layer.py, line 39, in __init__(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name) name = prefix + '_' + str(K.get_uid(prefix))[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 74, in get_uid(prefix) graph = tf.get_default_graph()[SEP]AttributeError: module 'tensorflow' has no attribute 'get_default_graph'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.",1
"File <*>/train.py, line 7, in <module> import models as m[SEP]File <*>/models.py, line 25, in <module> K.set_image_dim_ordering('th')[SEP]AttributeError: module 'tensorflow.python.keras.api._v2.keras.backend' has no attribute 'set_image_dim_ordering'",1
"File model_main.py, line 26, in <module> from object_detection import model_lib[SEP]File <*>/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py, line 28, in <module> from object_detection import eval_util[SEP]File <*>/site-packages/object_detection-0.1-py3.7.egg/object_detection/eval_util.py, line 35, in <module> slim = tf.contrib.slim[SEP]File <*>/site-packages/tensorflow/python/util/lazy_loader.py, line 62, in __getattr__ module = self._load()[SEP]File <*>/site-packages/tensorflow/python/util/lazy_loader.py, line 45, in _load module = importlib.import_module(self.__name__)[SEP]File <*>/__init__.py, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <*>/site-packages/tensorflow/contrib/__init__.py, line 33, in <module> from tensorflow.contrib import compiler[SEP]File <*>/site-packages/tensorflow/contrib/compiler/__init__.py, line 22, in <module> from tensorflow.contrib.compiler import xla[SEP]File <*>/site-packages/tensorflow/contrib/compiler/xla.py, line 22, in <module> from tensorflow.python.estimator import model_fn as model_fn_lib[SEP]File <*>/site-packages/tensorflow/python/estimator/__init__.py, line 26, in <module> from tensorflow_estimator.python import estimator[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/__init__.py, line 25, in <module> import tensorflow_estimator.python.estimator.estimator_lib[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator_lib.py, line 69, in <module> from tensorflow_estimator.python.estimator.tpu.tpu_estimator import TPUEstimator[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py, line 83, in <module> from tensorflow_estimator.python.estimator import estimator as estimator_lib[SEP]File <*>/site-packages/tensorflow_estimator/__init__.py, line 8, in <module> from tensorflow_estimator._api.v1 import estimator[SEP]File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py, line 11, in <module> from tensorflow_estimator._api.v1.estimator import tpu[SEP]File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/tpu/__init__.py, line 8, in <module> from tensorflow_estimator._api.v1.estimator.tpu import experimental[SEP]File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/tpu/experimental/__init__.py, line 8, in <module> from tensorflow_estimator.python.estimator.tpu._tpu_estimator_embedding import EmbeddingConfigSpec[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/tpu/_tpu_estimator_embedding.py, line 32, in <module> from tensorflow.python.tpu import feature_column_v2 as tpu_fc_v2[SEP]ImportError: cannot import name 'feature_column_v2' from 'tensorflow.python.tpu' (C:\Users\Rodolfo\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\tpu\__init__.py)",1
"File <*>/image.py, line 7, in <module> detector = ObjectDetection()[SEP]File <*>python3.5/site-packages/imageai/Detection/__init__.py, line 88, in __init__ self.sess = K.get_session()[SEP]File <*>python3.5/site-packages/keras/backend/tensorflow_backend.py, line 174, in get_session default_session = tf.get_default_session()[SEP]AttributeError: module 'tensorflow' has no attribute 'get_default_session'",1
"File [FILE], line 28, in () callbacks=callbacks_list[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 247, in _call_batch_hook(self, mode, hook, batch, logs) batch_hook = getattr(callback, hook_name)[SEP]AttributeError: 'ModelCheckpoint' object has no attribute 'on_train_batch_begin'",1
"File [FILE], line 3, in <module> model.add(Embedding(vocabulary_size, embedding_size, input_length=MAXLEN))[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/layers/embeddings.py, line 90, in __init__(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, activity_regularizer, embeddings_constraint, mask_zero, input_length, **kwargs) super(Embedding, self).__init__(**kwargs)[SEP]File <*>/site-packages/keras/engine/base_layer.py, line 132, in __init__(self, **kwargs) name = _to_snake_case(prefix) + '_' + str(K.get_uid(prefix))[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 74, in get_uid(prefix) graph = tf.get_default_graph()[SEP]AttributeError: module 'tensorflow' has no attribute 'get_default_graph'",1
"File [FILE], line 1, in <module> from tensorflow.python.util.tf_export import keras_export[SEP]ImportError: cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (C:\Users\DILAW\Anaconda3\lib\site-packages\tensorflow\python\util\tf_export.py)",1
"File [FILE], line 1, in <module>() plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)[SEP]File <*>python3.6/dist-packages/keras/utils/vis_utils.py, line 132, in plot_model(model, to_file, show_shapes, show_layer_names, rankdir) dot = model_to_dot(model, show_shapes, show_layer_names, rankdir)[SEP]File <*>python3.6/dist-packages/keras/utils/vis_utils.py, line 109, in model_to_dot(model, show_shapes, show_layer_names, rankdir) for inbound_layer in node.inbound_layers:[SEP]TypeError: 'InputLayer' object is not iterable",1
"File <*>/Testing.py, line 82, in <module> model.fit(x_train, y_train, batch_size=50, epochs = 3, callbacks= [tensorboard])[SEP]File <*>/site-packages/keras/engine/training.py, line 1178, in fit validation_freq=validation_freq)[SEP]File <*>/site-packages/keras/engine/training_arrays.py, line 125, in fit_loop callbacks.set_model(callback_model)[SEP]File <*>/site-packages/keras/callbacks.py, line 68, in set_model callback.set_model(model)[SEP]File <*>/site-packages/tensorflow/python/keras/callbacks.py, line 1509, in set_model if not model.run_eagerly:[SEP]AttributeError: 'Sequential' object has no attribute 'run_eagerly'",1
"File <*>/script.py, line 150, in <module> callbacks=[cb_checkpointer, cb_early_stopper][SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1418, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/keras/engine/training_generator.py, line 264, in fit_generator callbacks.on_train_end()[SEP]File <*>python3.6/site-packages/keras/callbacks.py, line 142, in on_train_end callback.on_train_end(logs)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/callbacks.py, line 940, in on_train_end if self.model._ckpt_saved_epoch is not None:[SEP]AttributeError: 'Sequential' object has no attribute '_ckpt_saved_epoch'",1
"File [FILE], line 9, in <module> from tensorflow import set_random_seed[SEP]ImportError: cannot import name 'set_random_seed' from 'tensorflow' (C:\Users\polon\Anaconda3\lib\site-packages\tensorflow\__init__.py)",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/dist-packages/torch/cuda/__init__.py, line 386, in current_device _lazy_init()[SEP]File <*>python3.6/dist-packages/torch/cuda/__init__.py, line 192, in _lazy_init _check_driver()[SEP]File <*>python3.6/dist-packages/torch/cuda/__init__.py, line 111, in _check_driver of the CUDA driver."""""".format(str(torch._C._cuda_getDriverVersion())))[SEP]AssertionError: The NVIDIA driver on your system is too old (found version 10000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",1
"File train_initialize.py, line 18, in agent = Agent(""horoscope_domain.yml"", policies = [MemoizationPolicy(), KerasPolicy()])[SEP]File <*>/site-packages/rasa_core/policies/keras_policy.py, line 31, in init if KerasPolicy.is_using_tensorflow() and not graph:[SEP]File <*>/site-packages/rasa_core/policies/keras_policy.py, line 48, in is_using_tensorflow return keras.backend._BACKEND == ""tensorflow""[SEP]AttributeError: module 'keras.backend' has no attribute '_BACKEND'",1
"File [FILE], line 6, in <module> output = tensorflow.keras.layers.Dropout(dropout_rate, name=""dropout_out"")(vgg_output)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 663, in __call__(self, inputs, *args, **kwargs) inputs, outputs, args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1708, in _set_connectivity_metadata_(self, inputs, outputs, args, kwargs) input_tensors=inputs, output_tensors=outputs, arguments=kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1795, in _add_inbound_node(self, input_tensors, output_tensors, arguments) input_tensors)[SEP]File <*>/site-packages/tensorflow/python/util/nest.py, line 515, in map_structure(func, *structure, **kwargs) structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/util/nest.py, line 515, in <listcomp>(.0) structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1794, in <lambda>(t) inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,[SEP]AttributeError: 'tuple' object has no attribute 'layer'",1
"File [FILE], line 3, in <module> model.add(tensorflow.keras.layers.GlobalMaxPooling2D(name=""gap""))[SEP]File <*>/site-packages/keras/engine/sequential.py, line 133, in add(self, layer) 'Found: ' + str(layer))[SEP]TypeError: The added layer must be an instance of class Layer. Found: <tensorflow.python.keras.layers.core.Flatten object at 0x00000000B74364A8>",1
"File <*>/keras-script.py, line 18, in <module> model = load_model(MODEL_PATH)[SEP]File <*>python3.7/dist-packages/keras/engine/saving.py, line 492, in load_wrapper return load_function(*args, **kwargs)[SEP]File <*>python3.7/dist-packages/keras/engine/saving.py, line 584, in load_model model = _deserialize_model(h5dict, custom_objects, compile)[SEP]File <*>python3.7/dist-packages/keras/engine/saving.py, line 274, in _deserialize_model model = model_from_config(model_config, custom_objects=custom_objects)[SEP]File <*>python3.7/dist-packages/keras/engine/saving.py, line 627, in model_from_config return deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.7/dist-packages/keras/layers/__init__.py, line 168, in deserialize printable_module_name='layer')[SEP]File <*>python3.7/dist-packages/keras/utils/generic_utils.py, line 147, in deserialize_keras_object list(custom_objects.items())))[SEP]File <*>python3.7/dist-packages/keras/engine/sequential.py, line 301, in from_config custom_objects=custom_objects)[SEP]File <*>python3.7/dist-packages/keras/engine/network.py, line 1056, in from_config process_layer(layer_data)[SEP]File <*>python3.7/dist-packages/keras/engine/network.py, line 1042, in process_layer custom_objects=custom_objects)[SEP]File <*>python3.7/dist-packages/keras/utils/generic_utils.py, line 149, in deserialize_keras_object return cls.from_config(config['config'])[SEP]File <*>python3.7/dist-packages/keras/engine/base_layer.py, line 1179, in from_config return cls(**config)[SEP]File <*>python3.7/dist-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]TypeError: __init__() got an unexpected keyword argument 'ragged'",1
"File <ipython-input-3-0715decb6662>, line 1, in <module> runfile('G:/Traffic Violation Detection/object_detection.py', wdir='G:/Traffic Violation Detection')[SEP]File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 710, in runfile execfile(filename, namespace)[SEP]File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 101, in execfile exec(compile(f.read(), filename, 'exec'), namespace)[SEP]File <*>/object_detection.py, line 6, in <module> from keras.layers.merge import add, concatenate[SEP]File <*>/site-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>/site-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils[SEP]File <*>/site-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K[SEP]File <*>/site-packages/keras/backend/__init__.py, line 1, in <module> from .load_backend import epsilon[SEP]File <*>/site-packages/keras/backend/load_backend.py, line 90, in <module> from .tensorflow_backend import *[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 54, in <module> get_graph = tf_keras_backend.get_graph[SEP]AttributeError: module 'tensorflow.python.keras.backend' has no attribute 'get_graph'",1
"File [FILE], line 1, in <module> var_init_1 = tf.get_variable(""var_init_1"", [1, 2], dtype=tf.int32, initializer=tf.zeros_initializer)[SEP]AttributeError: module 'tensorflow' has no attribute 'get_variable'",1
"File <stdin>, line 1, in <module> [CODE][SEP]ModuleNotFoundError: No module named 'tensorflow'",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/deepposekit/__init__.py, line 20, in <module> from deepposekit.io import TrainingGenerator, DataGenerator[SEP]File <*>python3.6/site-packages/deepposekit/io/__init__.py, line 18, in <module> from deepposekit.io.BaseGenerator import BaseGenerator[SEP]File <*>python3.6/site-packages/deepposekit/io/BaseGenerator.py, line 16, in <module> from tensorflow.keras.utils import Sequence[SEP]ModuleNotFoundError: No module named 'tensorflow'",1
"File <*>/tv-training-code.py, line 166, in <module> main()[SEP]File <*>/tv-training-code.py, line 161, in main evaluate(model, data_loader_test, device=device)[SEP]File <*>python3.6/dist-packages/torch/autograd/grad_mode.py, line 49, in decorate_no_grad return func(*args, **kwargs)[SEP]File <*>/engine.py, line 80, in evaluate coco_evaluator = CocoEvaluator(coco, iou_types)[SEP]File <*>/coco_eval.py, line 28, in __init__ self.coco_eval[iou_type] = COCOeval(coco_gt, iouType=iou_type)[SEP]File <*>/cocoeval.py, line 75, in __init__ self.params = Params(iouType=iouType) # parameters[SEP]File <*>/cocoeval.py, line 527, in __init__ self.setDetParams()[SEP]File <*>/cocoeval.py, line 506, in setDetParams self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)[SEP]File <__array_function__ internals>, line 6, in linspace [CODE][SEP]File <*>python3.6/dist-packages/numpy/core/function_base.py, line 121, in linspace .format(type(num)))[SEP]TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.",1
"File [FILE], line 3, in <module> images_flat = tf.contrib.layers.flatten(x)[SEP]AttributeError: module 'tensorflow_core.compat.v1' has no attribute 'contrib'",1
"File <*>/model_loggingfinal.py, line 35, in <module> callbacks=[logger][SEP]File <*>python3.7/site-packages/keras/engine/training.py, line 1239, in fit validation_freq=validation_freq)[SEP]File <*>python3.7/site-packages/keras/engine/training_arrays.py, line 119, in fit_loop callbacks.set_model(callback_model)[SEP]File <*>python3.7/site-packages/keras/callbacks/callbacks.py, line 68, in set_model callback.set_model(model)[SEP]File <*>python3.7/site-packages/keras/callbacks/tensorboard_v2.py, line 116, in set_model super(TensorBoard, self).set_model(model)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/callbacks.py, line 1532, in set_model self.log_dir, self.model._get_distribution_strategy()) # pylint: disable=protected-access[SEP]AttributeError: 'Sequential' object has no attribute '_get_distribution_strategy'",1
"File <*>/NN_Training.py, line 128, in <module> history = model.fit(X, Y, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[tensorboard]) # Feed in the trainset for X and y and run the model!!![SEP]File <*>/site-packages/keras/engine/training.py, line 1239, in fit validation_freq=validation_freq)[SEP]File <*>/site-packages/keras/engine/training_arrays.py, line 119, in fit_loop callbacks.set_model(callback_model)[SEP]File <*>/site-packages/keras/callbacks/callbacks.py, line 68, in set_model callback.set_model(model)[SEP]File <*>/site-packages/keras/callbacks/tensorboard_v2.py, line 116, in set_model super(TensorBoard, self).set_model(model)[SEP]File <*>/site-packages/tensorflow_core/python/keras/callbacks.py, line 1532, in set_model self.log_dir, self.model._get_distribution_strategy()) # pylint: disable=protected-access[SEP]AttributeError: 'Sequential' object has no attribute '_get_distribution_strategy'",1
"File [FILE], line 8, in <module> trainer.trainModel()[SEP]File <*>python3.6/site-packages/imageai/Detection/Custom/__init__.py, line 274, in trainModel(self) class_scale=self.__train_class_scale,[SEP]File <*>python3.6/site-packages/imageai/Detection/Custom/__init__.py, line 553, in _create_model(self, nb_class, anchors, max_box_per_image, max_grid, batch_size, warmup_batches, ignore_thresh, multi_gpu, lr, grid_scales, obj_scale, noobj_scale, xywh_scale, class_scale) class_scale=class_scale[SEP]File <*>python3.6/site-packages/imageai/Detection/Custom/yolo.py, line 294, in create_yolov3_model(nb_class, anchors, max_box_per_image, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scales, obj_scale, noobj_scale, xywh_scale, class_scale) class_scale)([input_image, pred_yolo_1, true_yolo_1, true_boxes])[SEP]File <*>python3.6/site-packages/imageai/Detection/Custom/yolo.py, line 24, in __init__(self, anchors, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scale, obj_scale, noobj_scale, xywh_scale, class_scale, **kwargs) cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(max_grid_w), [max_grid_h]), (1, max_grid_h, max_grid_w, 1, 1)))[SEP]AttributeError: module 'tensorflow' has no attribute 'to_float'",1
"File [FILE], line 2, in () from bert import run_classifier_with_tfhub # run_classifier[SEP]File <*>python3.6/dist-packages/bert/optimization.py, line [NUM], in [FUNC] [CODE][SEP]File [FILE], line 87, in () class AdamWeightDecayOptimizer(tf.train.Optimizer):[SEP]AttributeError: module 'tensorflow._api.v2.train' has no attribute 'Optimizer'",1
"File <*>python3.6/dist-packages/fastai/data_block.py, line 594, in _check_kwargs(ds, tfms, **kwargs) try: x.apply_tfms(tfms, **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 123, in apply_tfms(self, tfms, do_resolve, xtra, size, resize_method, mult, padding_mode, mode, remove_out) else: x = tfm(x)[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 524, in __call__(self, x, *args, **kwargs) return self.tfm(x, *args, **{**self.resolved, **kwargs}) if self.do_run else x[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 470, in __call__(self, p, is_random, use_on_y, *args, **kwargs) if args: return self.calc(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 475, in calc(self, x, *args, **kwargs) if self._wrap: return getattr(x, self._wrap)(self.func, *args, **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 183, in affine(self, func, *args, **kwargs) self.affine_mat = self.affine_mat @ m[SEP]RuntimeError: Expected object of scalar type Float but got scalar type Double for argument #3 'mat2' in call to _th_addmm_out",1
"File [FILE], line 8, in <module>() data= (src.transform(tfms,size=sz) #Data augmentation[SEP]File <*>python3.6/dist-packages/fastai/data_block.py, line 505, in transform(self, tfms, **kwargs) self.train.transform(tfms[0], **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/data_block.py, line 724, in transform(self, tfms, tfm_y, **kwargs) _check_kwargs(self.x, tfms, **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/data_block.py, line 596, in _check_kwargs(ds, tfms, **kwargs) raise Exception(f""It's not possible to apply those transforms to your dataset:\n {e}"")[SEP]Exception: It's not possible to apply those transforms to your dataset: Expected object of scalar type Float but got scalar type Double for argument #3 'mat2' in call to _th_addmm_out",1
"File [FILE], line 2, in <module> from object_detection.utils import label_map_util[SEP]File <*>/site-packages/object_detection/utils/label_map_util.py, line 27, in <module> from object_detection.protos import string_int_label_map_pb2[SEP]File <*>/site-packages/object_detection/protos/string_int_label_map_pb2.py, line 21, in <module> create_key=_descriptor._internal_create_key,[SEP]AttributeError: module 'google.protobuf.descriptor' has no attribute '_internal_create_key'",1
"File PATH, line 1, in <module> import tensorflow_probability[SEP]File PATH, line 75, in <module> from tensorflow_probability.python import * # pylint: disable=wildcard-import[SEP]File PATH, line 24, in <module> from tensorflow_probability.python import edward2[SEP]File PATH, line 32, in <module> from tensorflow_probability.python.experimental.edward2.generated_random_variables import *[SEP]File PATH, line 34, in <module> from tensorflow_probability.python.experimental import auto_batching[SEP]File PATH, line 24, in <module> from tensorflow_probability.python.experimental.auto_batching import frontend[SEP]File PATH, line 46, in <module> from tensorflow.python.autograph.pyct import compiler[SEP]ImportError: cannot import name 'compiler' from 'tensorflow.python.autograph.pyct' (PATH)",1
"File test.py, line 2, in <module> model = load_model(filepath = 'saved_model/model2.h5',custom_objects=None,compile=True, )[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/saving/save.py, line 184, in load_model return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py, line 177, in load_model_from_hdf5 model = model_config_lib.model_from_config(model_config,[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/saving/model_config.py, line 55, in model_from_config return deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/layers/serialization.py, line 105, in deserialize return deserialize_keras_object([SEP]File <*>python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 369, in deserialize_keras_object return cls.from_config([SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/sequential.py, line 397, in from_config layer = layer_module.deserialize(layer_config,[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 375, in deserialize_keras_object return cls.from_config(cls_config)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py, line 655, in from_config return cls(**config)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py, line 582, in __init__ super(Conv2D, self).__init__([SEP]File <*>python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py, line 121, in __init__ super(Conv, self).__init__([SEP]File <*>python3.8/site-packages/tensorflow/python/training/tracking/base.py, line 456, in _method_wrapper result = method(self, *args, **kwargs)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py, line 294, in __init__ generic_utils.validate_kwargs(kwargs, allowed_kwargs)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 792, in validate_kwargs raise TypeError(error_message, kwarg)[SEP]TypeError: ('Keyword argument not understood:', 'groups')",1
"File [FILE], line 1, in <module>() tokenizer = tfds.features.text.VocabTokenizer()[SEP]AttributeError: module 'tensorflow_datasets.core.features' has no attribute 'text'",1
"File object_detection_test.py, line 15, in <module> from utils import label_map_util[SEP]File <*>/label_map_util.py, line 27, in <module> import tensorflow.compat.v1 as tf[SEP]ModuleNotFoundError: No module named 'tensorflow.compat.v1'",1
"File file.py, line 537, in <Module> params,tuner = search_model(X_train,y_train,trials=t,executions=e)[SEP]File file.py, line 503, in search_model verbose = 0[SEP]File <*>python3.6/dist-packages/kerastuner/engine/base_tuner.py, line 131, in search self.run_trial(trial, *fit_args, **fit_kwargs)[SEP]File file.py, line 476, in run_trial super(MyTuner, self).run_trial(trial, *args, **kwargs)[SEP]File <*>python3.6/dist-packages/kerastuner/engine/multi_execution_tuner.py, line 78, in [FUNC] [CODE][SEP]File <*>python3.6/dist-packages/kerastuner/engine/tuner.py, line 317, in _get_checkp if (isinstance(self.distribution_strategy, tf.distribute.TPUStrategy) and[SEP]AttributeError: module 'tensorflow._api.v2.distribute' has no attribute 'TPUStrategy'",1
"File <*>/test.py, line 13, in <module> lstm = Bidirectional(lstm_nobi, name=""layerC"")(embedding_layer)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/wrappers.py, line 539, in __call__ return super(Bidirectional, self).__call__(inputs, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 951, in __call__ return self._functional_construction_call(inputs, args, kwargs,[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1090, in _functional_construction_call outputs = self._keras_tensor_symbolic_call([SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 822, in _keras_tensor_symbolic_call return self._infer_output_signature(inputs, args, kwargs, input_masks)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 863, in _infer_output_signature outputs = call_fn(inputs, *args, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/wrappers.py, line 652, in call y = self.forward_layer(forward_inputs,[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 660, in __call__ return super(RNN, self).__call__(inputs, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1012, in __call__ outputs = call_fn(inputs, *args, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py, line 1157, in call inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 859, in _process_inputs initial_state = self.get_initial_state(inputs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 642, in get_initial_state init_state = get_initial_state_fn([SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 2506, in get_initial_state return list(_generate_zero_filled_state_for_cell([SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 2987, in _generate_zero_filled_state_for_cell return _generate_zero_filled_state(batch_size, cell.state_size, dtype)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 3003, in _generate_zero_filled_state return nest.map_structure(create_zeros, state_size)[SEP]File <*>python3.9/site-packages/tensorflow/python/util/nest.py, line 659, in map_structure structure[0], [func(*x) for x in entries],[SEP]File <*>python3.9/site-packages/tensorflow/python/util/nest.py, line 659, in <listcomp> structure[0], [func(*x) for x in entries],[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 3000, in create_zeros return array_ops.zeros(init_state_size, dtype=dtype)[SEP]File <*>python3.9/site-packages/tensorflow/python/util/dispatch.py, line 201, in wrapper return target(*args, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2819, in wrapped tensor = fun(*args, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2868, in zeros output = _constant_if_small(zero, shape, dtype, name)[SEP]File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2804, in _constant_if_small if np.prod(shape) < 1000:[SEP]File <__array_function__ internals>, line 5, in prod [CODE][SEP]File <*>python3.9/site-packages/numpy/core/fromnumeric.py, line 3030, in prod return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,[SEP]File <*>python3.9/site-packages/numpy/core/fromnumeric.py, line 87, in _wrapreduction return ufunc.reduce(obj, axis, dtype, out, **passkwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/framework/ops.py, line 852, in __array__ raise NotImplementedError([SEP]NotImplementedError: Cannot convert a symbolic Tensor (layerC/forward_layerB/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",1
"File main.py, line 60, in <module> main()[SEP]File main.py, line 50, in main train_iters, dev_iters, test_iters, vocab = load_dataset(config)[SEP]File <*>/data.py, line 23, in load_dataset TEXT = data.Field(batch_first=True, eos_token='<eos>')[SEP]AttributeError: module 'torchtext.data' has no attribute 'Field'",1
"File [FILE], line 1, in <module> last_hidden_state.shape[SEP]AttributeError: 'str' object has no attribute 'shape'",1
"File <*>/main.py, line 217, in Processing y_predict = model(x) # [batch size, fc3 output][SEP]File <*>/site-packages/torch/nn/modules/module.py, line 722, in _call_impl result = self.forward(*input, **kwargs)[SEP]File <*>/cnn.py, line 104, in forward x = self.fc1(x)[SEP]File <*>/site-packages/torch/nn/modules/, line 91, in forward return F.linear(input, self.weight, self.bias)[SEP]File <*>/site-packages/torch/nn/functional.py, line 1674, in linear ret = torch.addmm(bias, input, weight.t())[SEP]RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",1
"File [FILE], line 9, in <module>() from keras.preprocessing import image[SEP]File <*>python3.7/dist-packages/keras/backend.py, line 37, in <module>() from tensorflow.python.eager.context import get_config[SEP]ImportError: cannot import name 'get_config' from 'tensorflow.python.eager.context' (/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/context.py)",1
"File <*>/main_dist_maml_l2l.py, line 1423, in <module> main()[SEP]File <*>/main_dist_maml_l2l.py, line 1365, in main train(args=args)[SEP]File <*>/main_dist_maml_l2l.py, line 1385, in train args.opt = move_opt_to_cherry_opt_and_sync_params(args) if is_running_parallel(args.rank) else args.opt[SEP]File <*>/distributed.py, line 456, in move_opt_to_cherry_opt_and_sync_params args.opt = cherry.optim.Distributed(args.model.parameters(), opt=args.opt, sync=syn)[SEP]File <*>python3.9/site-packages/cherry/optim.py, line 62, in __init__ self.sync_parameters()[SEP]File <*>python3.9/site-packages/cherry/optim.py, line 78, in sync_parameters dist.broadcast(p.data, src=root)[SEP]File <*>python3.9/site-packages/torch/distributed/distributed_c10d.py, line 1090, in broadcast work = default_pg.broadcast([tensor], opts)[SEP]RuntimeError: NCCL error in: ../torch/lib/c10d/ProcessGroupNCCL.cpp:911, unhandled system error, NCCL version 2.7.8",1
"File train.py, line 28, in <module> tf.keras.mixed_precision.set_global_policy('mixed_float16')[SEP]AttributeError: module 'tensorflow.keras.mixed_precision' has no attribute 'set_global_policy'",1
"File train.py, line 29, in <module> policy = tf.keras.mixed_precision.Policy('mixed_float16')[SEP]AttributeError: module 'tensorflow.keras.mixed_precision' has no attribute 'Policy'",1
"File <*>/CNN_Image_Denoising.py, line 15, in <module> from keras.optimizers import SGD, Adam[SEP]ImportError: cannot import name 'SGD' from 'keras.optimizers'",1
"File [FILE], line 1, in <module>() from keras.utils import to_categorical[SEP]ImportError: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",1
"File <*>/script.py, line 654, in <module> prediction_result, (r, t) = cf.to(model_runner.predict(processed_feature_dict, random_seed=seed), ""cpu"")[SEP]File <*>python3.7/site-packages/alphafold/model/model.py, line 134, in predict result, recycles = self.apply(self.params, jax.random.PRNGKey(random_seed), feat)[SEP]File <*>python3.7/site-packages/jax/_src/traceback_util.py, line 183, in reraise_with_filtered_traceback return fun(*args, **kwargs)[SEP]File <*>python3.7/site-packages/jax/_src/api.py, line 402, in cache_miss donated_invars=donated_invars, inline=inline)[SEP]File <*>python3.7/site-packages/jax/core.py, line 1561, in bind return call_bind(self, fun, *args, **params)[SEP]File <*>python3.7/site-packages/jax/core.py, line 1552, in call_bind outs = primitive.process(top_trace, fun, tracers, params)[SEP]File <*>python3.7/site-packages/jax/core.py, line 1564, in process return trace.process_call(self, fun, tracers, params)[SEP]File <*>python3.7/site-packages/jax/core.py, line 607, in process_call return primitive.impl(f, *tracers, **params)[SEP]File <*>python3.7/site-packages/jax/interpreters/xla.py, line 608, in _xla_call_impl *unsafe_map(arg_spec, args))[SEP]File <*>python3.7/site-packages/jax/, line 262, in memoized_fun ans = call(fun, *args)[SEP]File <*>python3.7/site-packages/jax/interpreters/xla.py, line 758, in _xla_callable compiled = compile_or_get_cached(backend, built, options)[SEP]File env/lib/python3.7/site-packages/jax/interpreters/xla.py, line 76, in compile_or_get_cached return backend_compile(backend, computation, compile_options)",1
"File [FILE], line 41, in <module>() from theano.tensor import shared_randomstreams[SEP]File <*>python3.7/dist-packages/theano/gof/cmodule.py, line 37, in <module>() from theano.configdefaults import gcc_version_str, local_bitwidth[SEP]ImportError: cannot import name 'local_bitwidth' from 'theano.configdefaults' (/usr/local/lib/python3.7/dist-packages/theano/configdefaults.py)",1
"File <*>/train_model.py, line 10, in <module> from cancernet.cancernet import CancerNet[SEP]File <*>/cancernet.py, line 2, in <module> from keras.layers.normalization import BatchNormalization[SEP]ImportError: cannot import name 'BatchNormalization' from 'keras.layers.normalization' (C:\Users\Catalin\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\layers\normalization\__init__.py)",1
"File <*>/model_main_tf2.py, line 32, in <module> from object_detection import model_lib_v2[SEP]File <*>python3.7/dist-packages/object_detection/model_lib_v2.py, line 29, in <module> from object_detection import eval_util[SEP]File <*>python3.7/dist-packages/object_detection/eval_util.py, line 36, in <module> from object_detection.metrics import lvis_evaluation[SEP]File <*>python3.7/dist-packages/object_detection/metrics/lvis_evaluation.py, line 23, in <module> from lvis import results as lvis_results[SEP]File <*>python3.7/dist-packages/lvis/__init__.py, line 5, in <module> from lvis.vis import LVISVis[SEP]File <*>python3.7/dist-packages/lvis/vis.py, line 1, in <module> import cv2[SEP]File <*>python3.7/dist-packages/cv2/__init__.py, line 9, in <module> from .cv2 import _registerMatType[SEP]ImportError: cannot import name '_registerMatType' from 'cv2.cv2' (/usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so)",1
"File <*>/site-packages/theano/configparser.py, line 327, in __get__ val_str = fetch_val_for_key(self.fullname,[SEP]File <*>/site-packages/theano/configparser.py, line 172, in fetch_val_for_key raise KeyError(key)[SEP]KeyError: 'blas.ldflags'",1
"File <*>/test.py, line 156, in <module> import network3[SEP]File <*>/network3.py, line 37, in <module> import theano[SEP]File <*>/site-packages/theano/__init__.py, line 124, in <module> from theano.scan_module import (scan, map, reduce, foldl, foldr, clone,[SEP]File <*>/site-packages/theano/scan_module/__init__.py, line 41, in <module> from theano.scan_module import scan_opt[SEP]File <*>/site-packages/theano/scan_module/scan_opt.py, line 60, in <module> from theano import tensor, scalar[SEP]File <*>/site-packages/theano/tensor/__init__.py, line 17, in <module> from theano.tensor import blas[SEP]File <*>/site-packages/theano/tensor/blas.py, line 155, in <module> from theano.tensor.blas_headers import blas_header_text[SEP]File <*>/site-packages/theano/tensor/blas_headers.py, line 987, in <module> if not config.blas.ldflags:[SEP]File <*>/site-packages/theano/configparser.py, line 332, in __get__ val_str = self.default()[SEP]File <*>/site-packages/theano/configdefaults.py, line 1284, in default_blas_ldflags blas_info = np.distutils.__config__.blas_opt_info[SEP]AttributeError: module 'numpy.distutils.__config__' has no attribute 'blas_opt_info'",1
"File [FILE], line 3, in <module>() from keras.applications.resnet50 import preprocess_input, ResNet50[SEP]ModuleNotFoundError: No module named 'keras.applications.resnet50'",1
"File <*>/ai.py, line 15, in <module> from keras.models import Sequential, load_model[SEP]File <*>/site-packages/keras/__init__.py, line 24, in <module> from keras import models[SEP]File <*>/site-packages/keras/models/__init__.py, line 18, in <module> from keras.engine.functional import Functional[SEP]File <*>/site-packages/keras/engine/functional.py, line 24, in <module> from keras.dtensor import layout_map as layout_map_lib[SEP]File <*>/site-packages/keras/dtensor/__init__.py, line 22, in <module> from tensorflow.compat.v2.experimental import dtensor as dtensor_api # pylint: disable=g-import-not-at-top[SEP]ImportError: cannot import name 'dtensor' from 'tensorflow.compat.v2.experimental' (C:\Users\Fynn\AppData\Local\Programs\Python\Python39\lib\site-packages\tensorflow\_api\v2\compat\v2\experimental\__init__.py)",1
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/__init__.py, line 55, in <module> from theano.compile import \[SEP]File <*>/__init__.py, line 6, in <module> from theano.compile.function_module import *[SEP]File <*>/function_module.py, line 18, in <module> import theano.compile.mode[SEP]File <*>/mode.py, line 11, in <module> import theano.gof.vm[SEP]File <*>/vm.py, line 516, in <module> import lazylinker_c[SEP]File <*>/lazylinker_c.py, line 86, in <module> preargs=args)[SEP]File <*>/cmodule.py, line 1975, in compile_str (status, compile_stderr.replace('\n', '. ')))[SEP]Exception: Compilation failed (return status=1): /usr/bin/ld: /home/minh.lengoc/.local/lib/libpython2.7.a(abstract.o): relocation R_X86_64_32 against `.rodata.str1.8' can not be used when making a shared object; recompile with -fPIC. /home/minh.lengoc/.local/lib/libpython2.7.a: could not read symbols: Bad value. collect2: ld returned 1 exit status.",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 540, in runfile execfile(filename, namespace)[SEP]File <*>/untitled4.py, line 603, in <module> params = test_mlp()[SEP]File <*>/untitled4.py, line 553, in test_mlp minibatch_avg_cost = train_model(minibatch_index)[SEP]File <*>/site-packages/theano-0.6.0-py2.7.egg/theano/compile/function_module.py, line 588, in __call__ self.fn.thunks[self.fn.position_of_error])[SEP]File <*>/site-packages/theano-0.6.0-py2.7.egg/theano/compile/function_module.py, line 579, in __call__ outputs = self.fn()[SEP]ValueError: y_i value out of bounds Apply node that caused the error: CrossentropySoftmaxArgmax1HotWithBias(Dot22.0, b, Elemwise{Cast{int32}}.0) Inputs shapes: [(10L, 1L), (1L,), (10L,)] Inputs strides: [(8L, 8L), (8L,), (4L,)] Inputs types: [TensorType(float64, matrix), TensorType(float64, vector), TensorType(int32, vector)] Use the Theano flag 'exception_verbosity=high' for a debugprint of this apply node.",0
"File <string>, line 1, in <module> [CODE][SEP]ImportError: No module named caffe",0
"File <*>python2.7/dist-packages/apport_python_hook.py, line 66, in apport_excepthook from apport.fileutils import likely_packaged, get_recent_crashes[SEP]File <*>python2.7/dist-packages/apport/__init__.py, line 1, in <module> from apport.report import Report[SEP]File <*>python2.7/dist-packages/apport/report.py, line 18, in <module> import problem_report[SEP]File <*>python2.7/dist-packages/problem_report.py, line 14, in <module> import zlib, base64, time, sys, gzip, struct, os[SEP]File <*>python2.7/gzip.py, line 10, in <module> import io[SEP]File <*>/io.py, line 2, in <module> import skimage.io[SEP]File <*>python2.7/dist-packages/skimage/io/__init__.py, line 11, in <module> from ._io import *[SEP]File <*>python2.7/dist-packages/skimage/io/_io.py, line 1, in <module> from io import BytesIO[SEP]ImportError: cannot import name BytesIO",0
"File <*>/site-packages/IPython/core/interactiveshell.py, line 3032, in run_code =============================== C:\Users\aleja_000\AppData\Local\Theano\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.9-64\lazylinker_ext\mod.cpp:1:0: sorry, unimplemented: 64-bit mode not compiled in #include <Python.h> ^ exec(code_obj, self.user_global_ns, self.user_ns)[SEP]File <ipython-input-2-1e86b04c8a9c>, line 6, in <module> from lasagne.layers import DenseLayer[SEP]File <*>/pydev_import_hook.py, line 21, in do_import module = self._system_import(name, *args, **kwargs)[SEP]File <*>/__init__.py, line 5, in <module> from . import nonlinearities[SEP]File <*>/non, line 6, in <module> from theano.tensor.nnet import sigmoid[SEP]File <*>/site-packages/theano/__init__.py, line 55, in <module> from theano.compile import ([SEP]File <*>/site-packages/theano/compile/__init__.py, line 9, in <module> from theano.compile.function_module import *[SEP]File <*>/site-packages/theano/compile/function_module.py, line 17, in <module> import theano.compile.mode[SEP]File <*>/site-packages/theano/compile/mode.py, line 11, in <module> import theano.gof.vm[SEP]File <*>/site-packages/theano/gof/vm.py, line 654, in <module> import lazylinker_c[SEP]File <*>/site-packages/theano/gof/lazylinker_c.py, line 125, in <module> preargs=args)[SEP]File <*>/site-packages/theano/gof/cmodule.py, line 2042, in compile_str (status, compile_stderr.replace('\n', '. ')))[SEP]Exception: Compilation failed (return status=1): C:\Users\aleja_000\AppData\Local\Theano\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.9-64\lazylinker_ext\mod.cpp:1:0: sorry, unimplemented: 64-bit mode not compiled in . #include <Python.h> . ^",0
"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: No module named lmdb",0
"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: No module named deepdish",0
"File cnn_age_gender_demo.py, line 25, in [FUNC] [CODE][SEP]File <*>/classifier.py, line 34, in init self.transformer.set_mean(in_, mean)[SEP]File <*>/io.py, line 255, in set_mean raise ValueError('Mean shape incompatible with input shape.')[SEP]ValueError: Mean shape incompatible with input shape.",0
"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: 'TensorVariable' object has no attribute 'get_value'",0
"File word2vec_basic.py, line 171, in <module> _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 345, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 419, in _do_run e.code)[SEP]tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'GradientDescent/update_Variable_2/ScatterSub': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/GPU:0' [[Node: GradientDescent/update_Variable_2/ScatterSub = ScatterSub[T=DT_FLOAT, Tindices=DT_INT64, use_locking=false](Variable_2, gradients/concat_1, GradientDescent/update_Variable_2/mul)]]",0
"File <*>/convolutional.py, line 13, in <module> import tensorflow.python.platform[SEP]File <*>/__init__.py, line 4, in <module> from tensorflow.python import *[SEP]File <*>/__init__.py, line 13, in <module> from tensorflow.core.framework.graph_pb2 import *[SEP]ImportError: No module named core.framework.graph_pb2",0
"File <*>/translate.py, line 28, in <module> from tensorflow.models.rnn.translate import data_utils[SEP]ImportError: No module named translate",0
"File run_deep_trainer.py, line 404, in <module> main()[SEP]File run_deep_trainer.py, line 400, in main layer_trainers[-1].main_loop()[SEP]File <*>/train.py, line 141, in main_loop self.setup()[SEP]File <*>/train.py, line 121, in setup self.algorithm.setup(model=self.model, dataset=self.dataset)[SEP]File <*>/sgd.py, line 243, in setup inf_params = [param for param in model.get_params()[SEP]File <*>/model.py, line 503, in get_params return list(self._params)[SEP]AttributeError: 'Softmax' object has no attribute '_params'",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/py1053173el, line 12, in <module> [CODE][SEP]File <*>python2.7/dist-packages/tensorflow/models/rnn/seq2seq.py, line 82, in basic_rnn_seq2seq _, enc_states = rnn.rnn(cell, encoder_inputs, dtype=dtype)[SEP]File <*>python2.7/dist-packages/tensorflow/models/rnn/rnn.py, line 85, in rnn output_state = cell(input_, state)[SEP]File <*>python2.7/dist-packages/tensorflow/models/rnn/rnn_cell.py, line 161, in __call__ concat = linear.linear([inputs, h], 4 * self._num_units, True)[SEP]File <*>python2.7/dist-packages/tensorflow/models/rnn/, line 32, in linear raise ValueError(""Linear is expecting 2D arguments: %s"" % str(shapes))[SEP]ValueError: Linear is expecting 2D arguments: [[None], [None, 512]]",0
"File ae.py, line 330, in <module> main()[SEP]File ae.py, line 305, in main ae.train(n_epochs=n_epochs, mini_batch_size=100, learning_rate=0.002, train_data= train_sentence_embeddings, test_data= test_sentence_embeddings)[SEP]File ae.py, line 87, in train givens={x:self.X[index:index+mini_batch_size,:]})[SEP]File <*>python2.7/dist-packages/theano/compile/function.py, line 266, in function profile=profile)[SEP]File <*>python2.7/dist-packages/theano/compile/pfunc.py, line 489, in pfunc no_default_updates=no_default_updates)[SEP]File <*>python2.7/dist-packages/theano/compile/pfunc.py, line 194, in rebuild_collect_shared store_into)[SEP]TypeError: ('update target must be a SharedVariable', Subtensor{::, int64}.0)",0
"File test_theano.py, line 9, in <module> for iter in range(n_iters):[SEP]TypeError: range() integer end argument expected, got TensorVariable.",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 8, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 34, in <module> from tensorflow.python.client.client_lib import *[SEP]File <*>python2.7/site-packages/tensorflow/python/client/client_lib.py, line 39, in <module> from tensorflow.python.client.session import InteractiveSession[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 16, in <module> from tensorflow.python import pywrap_tensorflow as tf_session[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 26, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 22, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: /home/zjuese/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: clock_gettime",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/models.py, line 602, in compile [CODE][SEP]File <*>/advanced_activations.py, line 149, in get_output [CODE][SEP]File <*>/core.py, line 117, in get_input [CODE][SEP]File <*>/core.py, line 1334, in get_output [CODE][SEP]File <*>/core.py, line 1282, in get_output_sum [CODE][SEP]File <*>/core.py, line 1266, in get_output_at [CODE][SEP]File <*>/core.py, line 730, in get_output [CODE][SEP]File <*>/core.py, line 1340, in get_output [CODE][SEP]File <*>/core.py, line 1312, in get_output_dot [CODE][SEP]File <*>python2.7/site-packages/theano/tensor/var.py, line 360, in dimshuffle pattern)[SEP]File <*>python2.7/site-packages/theano/tensor/elemwise.py, line 164, in __init__ (input_broadcastable, new_order))[SEP]ValueError: ('You cannot drop a non-broadcastable dimension.', ((False, False, False, False), (0, 'x')))",0
"File <*>/convolutional.py, line 133, in <module> train_accuracy = accuracy.eval(feed_dict = {x: batch[0], y_: batch[1], keep_prob: 1.0})[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 405, in eval return _eval_using_default_session(self, feed_dict, self.graph, session)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 2728, in _eval_using_default_session return session.run(tensors, feed_dict)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 345, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 419, in _do_run e.code)[SEP]tensorflow.python.framework.errors.InvalidArgumentError: Incompatible shapes: [8] vs. [20] [[Node: Equal = Equal[T=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](ArgMax, ArgMax_1)]]",0
"File <string>, line 1, in <module> [CODE][SEP]AttributeError: 'module' object has no attribute 'getsitepackages'",0
"File <*>/convolutional_network_batch_2d2c_clean_64f.py, line 213, in <module> pred = conv_net(x, weights, biases, keep_prob)[SEP]File <*>/convolutional_network_batch_2d2c_clean_64f.py, line 153, in conv_net conv1 = max_pool(conv1, k=2) # Normally K=2[SEP]File <*>/convolutional_network_batch_2d2c_clean_64f.py, line 135, in max_pool return tf.nn.max_pool(img, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/nn_ops.py, line 235, in max_pool name=name)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 449, in _max_pool strides=strides, padding=padding, name=name)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/op_def_library.py, line 430, in apply_op (prefix, dtypes.as_dtype(input_arg.type).name))[SEP]TypeError: Input 'input' of 'MaxPool' Op has type float64 that does not match expected type of float32.",0
"File <*>/Layer.py, line 113, in <module> train_model(i)[SEP]File <*>python2.7/site-packages/theano/compile/function_module.py, line 595, in __call__ outputs = self.fn()[SEP]File <*>python2.7/site-packages/theano/gof/link.py, line 485, in streamline_default_f raise_with_op(node, thunk)[SEP]File <*>python2.7/site-packages/theano/gof/link.py, line 481, in streamline_default_f thunk()[SEP]File <*>python2.7/site-packages/theano/gof/op.py, line 768, in rval r = p(n, [x[0] for x in i], o)[SEP]File <*>python2.7/site-packages/theano/tensor/nnet/nnet.py, line 896, in perform nll[i] = -row[y_idx[i]] + m + numpy.log(sum_j)[SEP]IndexError: index 1 is out of bounds for axis 0 with size 1",0
"File [FILE], line <*>, in [FUNC] [CODE][SEP]File <*>/site-packages/nolearn/lasagne/base.py, line 457, in fit self.initialize()[SEP]File <*>/site-packages/nolearn/lasagne/base.py, line 303, in initialize self.y_tensor_type,[SEP]File <*>/site-packages/nolearn/lasagne/base.py, line 435, in _create_iter_funcs allow_input_downcast=True,[SEP]File <*>/site-packages/theano/compile/function.py, line 317, in function output_keys=output_keys)[SEP]File <*>/site-packages/theano/compile/pfunc.py, line 526, in pfunc output_keys=output_keys)[SEP]File <*>/site-packages/theano/compile/function_module.py, line 1778, in orig_function defaults)[SEP]File <*>/site-packages/theano/compile/function_module.py, line 1642, in create input_storage=input_storage_lists, storage_map=storage_map)[SEP]File <*>/site-packages/theano/gof/link.py, line 690, in make_thunk storage_map=storage_map)[:3][SEP]File <*>/site-packages/theano/gof/vm.py, line 1037, in make_all no_recycling))[SEP]File <*>/site-packages/theano/gof/op.py, line 932, in make_thunk no_recycling)[SEP]File <*>/site-packages/theano/gof/op.py, line 850, in make_c_thunk output_storage=node_output_storage)[SEP]File <*>/site-packages/theano/gof/cc.py, line 1207, in make_thunk keep_lock=keep_lock)[SEP]File <*>/site-packages/theano/gof/cc.py, line 1152, in __compile__ keep_lock=keep_lock)[SEP]File <*>/site-packages/theano/gof/cc.py, line 1602, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock)[SEP]File <*>/site-packages/theano/gof/cmodule.py, line 1174, in module_from_key module = lnk.compile_cmodule(location)[SEP]File <*>/site-packages/theano/gof/cc.py, line 1513, in compile_cmodule preargs=preargs)[SEP]File <*>/site-packages/theano/gof/cmodule.py, line 2187, in compile_str (status, compile_stderr.replace('\n', '. ')))[SEP]Exception: ('The following error happened while compiling the node', CorrMM{valid, (1, 1)}(input.input, Subtensor{::, ::, ::int64, ::int64}.0), '\n', ""Compilation failed (return status=1): C:\\Users\\Michal\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64\\tmpgdh7ov2i\\mod.cpp: In member function 'int {anonymous}::__struct_compiled_op_mf217e5b3a6b61b4ef70844368439f6cb::run()':\r. C:\\Users\\Michal\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64\\tmpgdh7ov2i\\mod.cpp:947:16: warning: converting to non-pointer type 'int' from NULL [-Wconversion-null]\r. kH = NULL;\r. ^\r. C:\\Users\\Michal\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64\\tmpgdh7ov2i\\mod.cpp:958:16: warning: converting to non-pointer type 'int' from NULL [-Wconversion-null]\r. kW = NULL;\r. ^\r. C:\\Users\\Michal\\AppData\\Local\\Temp\\cc67su6o.o: In function `corrMM(tagPyArrayObject*, tagPyArrayObject*, tagPyArrayObject*, int, int, int, int, int)':\r. C:/Users/Michal/AppData/Local/Theano/compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64/tmpgdh7ov2i/mod.cpp:431: undefined reference to `dgemm_'\r. C:/Users/Michal/AppData/Local/Theano/compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64/tmpgdh7ov2i/mod.cpp:528: undefined reference to `dgemm_'\r. C:/Users/Michal/AppData/Local/Theano/compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64/tmpgdh7ov2i/mod.cpp:483: undefined reference to `dgemm_'\r. collect2.exe: error: ld returned 1 exit status\r. "", '[CorrMM{valid, (1, 1)}(input.input, )]')",0
"File mnist_mlp.py, line 13, in <module> from keras.models import Sequential[SEP]File <*>python3.5/site-packages/Keras-0.3.1-py3.5.egg/keras/models.py, line 15, in <module> [CODE][SEP]File <*>python3.5/site-packages/Keras-0.3.1-py3.5.egg/keras/backend/__init__.py, line 46, in <module> [CODE][SEP]File <*>python3.5/site-packages/Keras-0.3.1-py3.5.egg/keras/backend/theano_backend.py, line 4, in <module> [CODE][SEP]File <*>python3.5/site-packages/Theano-0.8.0.dev0-py3.5.egg/theano/tensor/signal/downsample.py, line 2, in <module> import pool[SEP]ImportError: No module named 'pool'",0
"File <*>/lstmNetwork.py, line 54, in <module> model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=3, validation_data=(X_test, Y_test), show_accuracy=True)[SEP]File <*>python2.7/dist-packages/keras/models.py, line 581, in fit shuffle=shuffle, metrics=metrics)[SEP]File <*>python2.7/dist-packages/keras/models.py, line 239, in _fit outs = f(ins_batch)[SEP]File <*>python2.7/dist-packages/keras/backend/theano_backend.py, line 365, in __call__ return self.function(*inputs)[SEP]File <*>/function_module.py, line 786, in __call__ allow_downcast=s.allow_downcast)[SEP]File <*>/type.py, line 177, in filter data.shape))[SEP]TypeError: ('Bad input argument to theano function with name ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py:362"" at index 1(0-based)', 'Wrong number of dimensions: expected 3, got 2 with shape (5, 10).')",0
"File tensor_restore.py, line 14, in <module> saver.restore(sess, ""/tmp/model.ckpt"")[SEP]File <*>python2.7/site-packages/tensorflow/python/training/saver.py, line 891, in restore sess.run([self._restore_op_name], {self._filename_tensor_name: save_path})[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 368, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 444, in _do_run e.code)[SEP]tensorflow.python.framework.errors.NotFoundError: Tensor name ""v2"" not found in checkpoint files /tmp/model.ckpt [[Node: save/restore_slice_1 = RestoreSlice[dt=DT_INT32, preferred_shard=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_1/tensor_name, save/restore_slice_1/shape_and_slice)]]",0
"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: No module named sklearn.linear_model",0
"File <*>/teste2.py, line 1479, in Pred model.fit(X=predictor_train, y=target_train, nb_epoch=2, batch_size=90,show_accuracy=True)[SEP]File <*>/site-packages/keras/models.py, line 581, in fit shuffle=shuffle, metrics=metrics)[SEP]File <*>/site-packages/keras/models.py, line 239, in _fit outs = f(ins_batch)[SEP]File <*>/site-packages/keras/backend/theano_backend.py, line 365, in __call__ return self.function(*inputs)[SEP]File <*>/site-packages/theano/compile/function_module.py, line 595, in __call__ outputs = self.fn()[SEP]File <*>/site-packages/theano/gof/vm.py, line 233, in __call__ link.raise_with_op(node, thunk)[SEP]File <*>/site-packages/theano/gof/vm.py, line 229, in __call__ thunk()[SEP]File <*>/site-packages/theano/gof/op.py, line 768, in rval r = p(n, [x[0] for x in i], o)[SEP]File <*>/site-packages/theano/tensor/elemwise.py, line 808, in perform raise ValueError(base_exc_str)[SEP]ValueError: Dimension mismatch; shapes are (98, 10), (98, 1)",0
"File kaggle_otto_nn.py, line 28, in <module> from keras.models import Sequential[SEP]File <*>/models.py, line 15, in <module> [CODE][SEP]File <*>/__init__.py, line 46, in <module> [CODE][SEP]File <*>/theano_backend.py, line 1, in <module> [CODE][SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/__init__.py, line 111, in <module> theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1()[SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/sandbox/cuda/tests/test_driver.py, line 38, in test_nvidia_driver1 if not numpy.allclose(f(), a.sum()):[SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.py, line 871, in __call__ storage_map=getattr(self.fn, 'storage_map', None))[SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/link.py, line 314, in raise_with_op reraise(exc_type, exc_value, exc_trace)[SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.py, line 859, in __call__ outputs = self.fn()[SEP]RuntimeError: Cuda error: kernel_reduce_ccontig_node_97496c4d3cf9a06dc4082cc141f918d2_0: out of memory. (grid: 1 x 1; block: 256 x 1 x 1)",0
"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: No module named tensorflow",0
"File <*>/tensorboard, line 4, in <module> import tensorflow.tensorboard.tensorboard[SEP]ImportError: No module named 'tensorflow.tensorboard.tensorboard'",0
"File <ipython-input-1-65016ddab3cd>, line 1, in <module> from keras.utils.visualize_util import plot[SEP]File <*>/site-packages/keras/utils/visualize_util.py, line 8, in <module> raise RuntimeError('Failed to import pydot. You must install pydot'[SEP]RuntimeError: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",0
"File <*>/tensorflow.py, line 2, in <module> import tensorflow as tf[SEP]File <*>/tensorflow.py, line 53, in <module> tf_in = tf.placeholder(""float"", [None, A]) # Features[SEP]AttributeError: 'module' object has no attribute 'placeholder'",0
"File detectGoNo.py, line 95, in <module> sess.run(train_step, feed_dict={x: image_batch, y_: label_batch})[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 340, in run run_metadata_ptr)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 545, in _run raise TypeError('The value of a feed cannot be a tf.Tensor object. '[SEP]TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, or numpy ndarrays.",0
"File <ipython-input-1-adf2ca85bb77>, line 1, in <module> runfile('/home/kang/Documents/work_code_PC1/py_tensorflow_learning/cifar10CNN_test/cifar10_eval_test.py', wdir='/home/kang/Documents/work_code_PC1/py_tensorflow_learning/cifar10CNN_test')[SEP]File <*>python3/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 685, in runfile execfile(filename, namespace)[SEP]File <*>python3/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 85, in execfile exec(compile(open(filename, 'rb').read(), filename, 'exec'), namespace)[SEP]File <*>/cifar10_eval_test.py, line 107, in <module> tf.app.run()[SEP]File <*>python3.4/dist-packages/tensorflow/python/platform/default/_app.py, line 30, in run sys.exit(main(sys.argv))[SEP]File <*>/cifar10_eval_test.py, line 104, in main evaluate()[SEP]File <*>/cifar10_eval_test.py, line 94, in evaluate eval_once(saver, summary_writer, top_k_op, summary_op)[SEP]File <*>/cifar10_eval_test.py, line 72, in eval_once coord.join(threads, stop_grace_period_secs = 10)[SEP]File <*>python3.4/dist-packages/tensorflow/python/training/coordinator.py, line 264, in join six.reraise(*self._exc_info_to_raise)[SEP]File <*>python3/dist-packages/six.py, line 659, in reraise raise value[SEP]File <*>python3.4/dist-packages/tensorflow/python/training/queue_runner.py, line 185, in _run sess.run(enqueue_op)[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 315, in run return self._run(None, fetches, feed_dict)[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 473, in _run raise RuntimeError('Attempted to use a closed Session.')[SEP]RuntimeError: Attempted to use a closed Session.",0
"File <*>python2.7/dist-packages/pip/basecommand.py, line 122, in main status = self.run(options, args)[SEP]File <*>python2.7/dist-packages/pip/commands/install.py, line 278, in run requirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle)[SEP]File <*>python2.7/dist-packages/pip/req.py, line 1091, in prepare_files req_to_install.check_if_exists()[SEP]File <*>python2.7/dist-packages/pip/req.py, line 811, in check_if_exists self.satisfied_by = pkg_resources.get_distribution(self.req)[SEP]File <*>python2.7/dist-packages/pkg_resources/__init__.py, line 535, in get_distribution dist = get_provider(dist)[SEP]File <*>python2.7/dist-packages/pkg_resources/__init__.py, line 415, in get_provider return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0][SEP]IndexError: list index out of range",0
"File <*>/audiornn.py, line 56, in <module> tf.with_dependencies([expected_output], input_tensor)[SEP]AttributeError: module 'tensorflow' has no attribute 'with_dependencies'",0
"File <ipython-input-29-4e06de0b7af3>, line 1, in <module> sess.run(edit_distances, feed_dict=feed_dict)[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 372, in run run_metadata_ptr)[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 597, in _run for subfeed, subfeed_val in _feed_fn(feed, feed_val):[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 558, in _feed_fn return feed_fn(feed, feed_val)[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 268, in <lambda> [feed.indices, feed.values, feed.shape], feed_val)),[SEP]TypeError: zip argument #2 must support iteration",0
"File <*>/pool.py, line 119, in worker result = (True, func(*args, **kwds))[SEP]TypeError: func1() got multiple values for argument 'func'",0
"File <stdin>, line 1, in <module> [CODE][SEP]File caffepb.py, line 28, in <module> type=None),[SEP]File <*>python2.7/site-packages/google/protobuf/descriptor.py, line 652, in __new__ _message.Message._CheckCalledFromGeneratedFile()[SEP]TypeError: Descriptors should not be created directly, but only retrieved from their parent.",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.4/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import *[SEP]File <*>python3.4/site-packages/tensorflow/python/__init__.py, line 48, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python3.4/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python3.4/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]File <*>python3.4/imp.py, line 243, in load_module return load_dynamic(name, filename, file)[SEP]ImportError: dlopen(/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.7.5.dylib",0
"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: cannot import name Nadam",0
"File custom_op.py, line 19, in <module> grad = tf.gradients(my_op(a), [a])[0][SEP]File <*>python3.5/site-packages/tensorflow/python/framework/function.py, line 528, in __call__ return call_function(self._definition, *args, **kwargs)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/function.py, line 267, in call_function compute_shapes=False)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 2285, in create_op raise TypeError(""Input #%d is not a tensor: %s"" % (idx, a))[SEP]TypeError: Input #0 is not a tensor: <tensorflow.python.ops.variables.Variable object at 0x1080d2710>",0
"File trainer_deepMnist.py, line 109, in <module> x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 559, in eval return _eval_using_default_session(self, feed_dict, self.graph, session)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 3648, in _eval_using_default_session return session.run(tensors, feed_dict)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 710, in run run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 908, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 958, in _do_run target_list, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 978, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[10000,32,28,28] [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Reshape, Variable_2/read)]]",0
"File <*>/model.py, line 109, in <module> output_actual: batch[1][SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 698, in run run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 838, in _run fetch_handler = _FetchHandler(self._graph, fetches)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 355, in __init__ self._fetch_mapper = _FetchMapper.for_fetch(fetches)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 181, in for_fetch return _ListFetchMapper(fetch)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 288, in __init__ self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches][SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 178, in for_fetch (fetch, type(fetch)))[SEP]TypeError: Fetch argument None has invalid type <type 'NoneType'>",0
"File <*>python2.7/site-packages/theano/sandbox/gpuarray/__init__.py, line 20, in <module> import pygpu[SEP]File <*>/__init__.py, line 7, in <module> from . import gpuarray, elemwise, reduction[SEP]File <*>/elemwise.py, line 3, in <module> from .dtypes import dtype_to_ctype, get_common_dtype[SEP]File <*>/dtypes.py, line 6, in <module> from . import gpuarray[SEP]ImportError: cannot import name gpuarray",0
"File train_lstm.py, line 66, in <module> model.embedding_placeholder: data.glove_vec})[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 382, in run run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 655, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 723, in _do_run target_list, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 743, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors.OutOfRangeError: PaddingFIFOQueue '_0_batching/padding_fifo_queue' is closed and has insufficient elements (requested 50, current size 0) [[Node: batching = QueueDequeueMany[_class=[""loc:@batching/padding_fifo_queue""], component_types=[DT_INT32, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](batching/padding_fifo_queue, batching/n)]] [[Node: batching/_9 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_1191_batching"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]",0
"File test_classifier.py, line 48, in <module> score = model.evaluate(x, y, batch_size=16)[SEP]File <*>/site-packages/keras/models.py, line 655, in evaluate sample_weight=sample_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1131, in evaluate batch_size=batch_size)[SEP]File <*>/site-packages/keras/engine/training.py, line 959, in _standardize_user_data exception_prefix='model input')[SEP]File <*>/site-packages/keras/engine/training.py, line 108, in standardize_input_data str(array.shape))[SEP]Exception: Error when checking model input: expected convolution2d_input_1 to have shape (None, 3, 150, 150) but got array with shape (1, 3, 150, 198)`",0
"File <*>/main, line 132, in <module> apply_weights_OP = tf.matmul(activation_OP, Weights, name=""apply_weights"")[SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/math_ops.py, line 1346, in matmul name=name)[SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 1271, in _mat_mul transpose_b=transpose_b, name=name)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/op_def_library.py, line 703, in apply_op op_def=op_def)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 2312, in create_op set_shapes_for_outputs(ret)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 1704, in set_shapes_for_outputs shapes = shape_func(op)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/common_shapes.py, line 94, in matmul_shape inner_a.assert_is_compatible_with(inner_b)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 108, in assert_is_compatible_with % (self, other))[SEP]ValueError: Dimensions 3 and 4 are not compatible",0
"File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 715, in _do_call return fn(*args)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 697, in _run_fn status, run_metadata)[SEP]File <*>python3.5/contextlib.py, line 66, in __exit__ next(self.gen)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/errors.py, line 450, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value auc/false_positives [[Node: auc/false_positives/read = Identity[T=DT_FLOAT, _class=[""loc:@auc/false_positives""], _device=""/job:localhost/replica:0/task:0/cpu:0""](auc/false_positives)]]",0
"File <*>/mlp_.py, line 152, in <module> train_auc = sess.run(auc, feed_dict={X: batch_xs, y: batch_ys, dropout_keep_prob:1.})[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 372, in run run_metadata_ptr)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 636, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 708, in _do_run target_list, options, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 728, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value auc/false_positives [[Node: auc/false_positives/read = Identity[T=DT_FLOAT, _class=[""loc:@auc/false_positives""], _device=""/job:localhost/replica:0/task:0/cpu:0""](auc/false_positives)]]",0
"File <*>/gridsearch.py, line 43, in <module> model.fit(x,y)[SEP]File <*>/site-packages/keras/wrappers/scikit_learn.py, line 135, in fit **self.filter_sk_params(self.build_fn.__call__))[SEP]TypeError: __call__() missing 1 required positional argument: 'x'",0
"File <*>/main.py, line 13, in <module> autoencoder1.train()[SEP]File <*>/AutoEncoder.py, line 74, in train _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})[SEP]TypeError: unhashable type: 'numpy.ndarray'",0
"File <*>python2.7/dist-packages/django/core/handlers/base.py, line 149, in get_response response = self.process_exception_by_middleware(e, request)[SEP]File <*>python2.7/dist-packages/django/core/handlers/base.py, line 147, in get_response response = wrapped_callback(request, *callback_args, **callback_kwargs)[SEP]File <*>/views.py, line 27, in home output=loaded_model.predict(img_np)[SEP]File <*>python2.7/dist-packages/keras/models.py, line 671, in predict return self.model.predict(x, batch_size=batch_size, verbose=verbose)[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 1161, in predict check_batch_dim=False)[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 108, in standardize_input_data str(array.shape))[SEP]Exception: Error when checking : expected dense_input_1 to have shape (None, 784) but got array with shape (784, 1)",0
"File <*>python3.5/dist-packages/tensorflow/python/framework/common_shapes.py, line 594, in call_cpp_shape_fn status)[SEP]File <*>python3.5/contextlib.py, line 66, in exit next(self.gen)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/errors.py, line 463, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors.InvalidArgumentError: Shape must be rank 0 but is rank 1",0
"File my_test.py, line 51, in [FUNC] [CODE][SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/parsing_ops.py, line 640, in parse_single_sequence_example feature_list_dense_defaults, example_name, name)[SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/parsing_ops.py, line 837, in _parse_single_sequence_example_raw name=name)[SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/gen_parsing_ops.py, line 285, in _parse_single_sequence_example name=name)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/op_def_library.py, line 749, in apply_op op_def=op_def)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 2382, in create_op set_shapes_for_outputs(ret)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 1783, in set_shapes_for_outputs shapes = shape_func(op)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/common_shapes.py, line 596, in call_cpp_shape_fn raise ValueError(err.message)[SEP]ValueError: Shape must be rank 0 but is rank 1",0
"File <string>, line 1, in <module> [CODE][SEP]File <*>/setup.py, line 339, in <module> cmdclass=cmdclass,[SEP]File <*>python3.5/core.py, line 148, in setup dist.run_commands()[SEP]File <*>python3.5/dist.py, line 955, in run_commands self.run_command(cmd)[SEP]File <*>python3.5/dist.py, line 974, in run_command cmd_obj.run()[SEP]File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/egg_info.py, line 279, in run [CODE][SEP]File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/egg_info.py, line 306, in find_sources [CODE][SEP]File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/egg_info.py, line 533, in run [CODE][SEP]File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/egg_info.py, line 562, in add_defaults [CODE][SEP]File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/py36compat.py, line 36, in add_defaults [CODE][SEP]File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/py36compat.py, line 119, in _add_defaults_ext [CODE][SEP]File <*>python3.5/cmd.py, line 299, in get_finalized_command cmd_obj.ensure_finalized()[SEP]File <*>python3.5/cmd.py, line 107, in ensure_finalized self.finalize_options()[SEP]File <*>python3.5/site-packages/Cython/Distutils/build_ext.py, line 19, in finalize_options self.distribution.ext_modules)[SEP]File <*>python3.5/site-packages/Cython/Build/Dependencies.py, line 809, in cythonize aliases=aliases)[SEP]File <*>python3.5/site-packages/Cython/Build/Dependencies.py, line 752, in create_extension_list **kwds))[SEP]TypeError: __init__() missing 3 required positional arguments: 'feature_name', 'feature_description', and 'feature_check'",0
"File test.py, line 45, in <module> (x_train, _), (x_test, _) = data[SEP]ValueError: too many values to unpack (expected 2)",0
"File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 972, in _do_call return fn(*args)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 954, in _run_fn status, run_metadata)[SEP]File <*>python3/contextlib.py, line 66, in __exit__ next(self.gen)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/errors.py, line 463, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors.InvalidArgumentError: Input to reshape is a tensor with 313600 values, but the requested shape requires a multiple of 4608 [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](dropout/mul, Reshape_1/shape)]]",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 21, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow')[SEP]File <*>python2.7/__init__.py, line 37, in import_module __import__(name)[SEP]ImportError: No module named _pywrap_tensorflow",0
"File <*>/demo.py, line 18, in <module> from fast_rcnn.test import im_detect[SEP]File <*>/test.py, line 16, in <module> import caffe[SEP]File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver[SEP]File <*>/pycaffe.py, line 13, in <module> from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \[SEP]ImportError: No module named _caffe",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1021, in _do_call return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1003, in _run_fn status, run_metadata)[SEP]File <*>/contextlib.py, line 66, in __exit__ next(self.gen)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 469, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(100, 784), b.shape=(784, 256), m=100, n=256, k=784 [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_Placeholder_0/_7, Variable/read)]] [[Node: Mean/_15 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_35_Mean"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]",0
"File <*>python35/site-packages/tensorflow/python/client/session.py, line 972, in _do_call return fn(*args)[SEP]File <*>python35/site-packages/tensorflow/python/client/session.py, line 954, in _run_fn status, run_metadata)[SEP]File <*>python35/contextlib.py, line 66, in __exit__ next(self.gen)[SEP]File <*>python35/site-packages/tensorflow/python/framework/errors.py, line 463, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype float [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]",0
"File neural_network.py, line 48, in <module> print(sess.run(loss), feed_dict={xs:x_data, ys:y_data})[SEP]File <*>python35/site-packages/tensorflow/python/client/session.py, line 717, in run run_metadata_ptr)[SEP]File <*>python35/site-packages/tensorflow/python/client/session.py, line 915, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python35/site-packages/tensorflow/python/client/session.py, line 965, in _do_run target_list, options, run_metadata)[SEP]File <*>python35/site-packages/tensorflow/python/client/session.py, line 985, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype float [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]",0
"File add_1.py, line 13, in <module> saver = tf.train.Saver([y]) raise TypeError(""Variable to save is not a Variable: %s"" % var)[SEP]TypeError: Variable to save is not a Variable: Tensor(""add_3:0"", shape=(), dtype=int32, device=/job:local/task:3)",0
"File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 451, in __init__ dims_iter = iter(dims)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 510, in __iter__ raise TypeError(""'Tensor' object is not iterable."")[SEP]TypeError: 'Tensor' object is not iterable.",0
"File <*>/test_placeholder.py, line 5, in <module> input = tf.placeholder(tf.int32, [batchSize, 5])[SEP]File <*>/site-packages/tensorflow/python/ops/array_ops.py, line 1579, in placeholder shape = tensor_shape.as_shape(shape)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 821, in as_shape return TensorShape(shape)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 457, in __init__ self._dims = [as_dimension(d) for d in dims_iter][SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 457, in <listcomp> self._dims = [as_dimension(d) for d in dims_iter][SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 378, in as_dimension return Dimension(value)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 33, in __init__ self._value = int(value)[SEP]TypeError: int() argument must be a string, a bytes-like object or a number, not 'Tensor'",0
"File <*>python2.7/dist-packages/tensorflow/python/__init__.py, line 61, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory",0
"File test_keras.py, line 52, in <module> model.fit(x_train, y_train, validation_data=(x_test, y_test), nb_epoch=epochs, batch_size=32)[SEP]File <*>python2.7/dist-packages/keras/models.py, line 664, in fit sample_weight=sample_weight)[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 1068, in fit batch_size=batch_size)[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 981, in _standardize_user_data exception_prefix='model input')[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 113, in standardize_input_data str(array.shape))[SEP]ValueError: Error when checking model input: expected convolution2d_input_1 to have shape (None, 3, 32, 32) but got array with shape (50000, 32, 32, 3)",0
"File <string>, line 1, in <module> [CODE][SEP]IOError: [Errno 2] No such file or directory: '/private/var/folders/1p/7km73m0s2cvdfb1js3ct8_mh0000gn/T/pip-JMMIRP-build/setup.py'",0
"File convolutional.py, line 339, in <module> tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)[SEP]File <*>python2.7/dist-packages/tensorflow/python/platform/app.py, line 44, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough))[SEP]File convolutional.py, line 284, in main with tf.Session() as sess:[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 1187, in __init__ super(Session, self).__init__(target, graph, config=config)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 552, in __init__ self._session = tf_session.TF_NewDeprecatedSession(opts, status)[SEP]File <*>python2.7/contextlib.py, line 24, in __exit__ self.gen.next()[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/errors_impl.py, line 469, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors_impl.InternalError: Failed to create session.",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 10, in [FUNC] [CODE][SEP]File <*>/contextlib.py, line 66, in __exit__ next(self.gen)[SEP]File <*>/contextlib.py, line 66, in [FUNC] [CODE][SEP]n_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [10000,10] vs. [10000] [[Node: sub = Sub[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](Add, _recv_Placeholder_1_0/_7)]]",0
"File test1.py, line 43, in <module> c = sess.run(cost, feed_dict={X: train_X, Y: train_Y})[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 76, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 96, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 10, in [FUNC] [CODE][SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [10000,10] vs. [10000] [[Node: sub = Sub[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](Add, _recv_Placeholder_1_0/_7)]]",0
"File board.py, line 3, in <module> mnist = input_data.read_data_sets(r'Z:/downloads/MNIST dataset', one_hot=True)[SEP]File <*>/input_data.py, line 150, in read_data_sets train_images = extract_images(local_file)[SEP]File <*>/input_data.py, line 40, in extract_images buf = bytestream.read(rows * cols * num_images)[SEP]File <*>/gzip.py, line 274, in read return self._buffer.read(size)[SEP]TypeError: only integer scalar arrays can be converted to a scalar index",0
"File <*>python2.7/dist-packages/tensorflow/python/__init__.py, line 61, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory Failed to load the native TensorFlow runtime.",0
"File train.py, line 6, in <module> vgg19.fit(nb_epoch=1)[SEP]File <*>/vgg19.py, line 84, in fit nb_val_samples=8[SEP]File <*>python2.7/dist-packages/keras/models.py, line 907, in fit_generator pickle_safe=pickle_safe)[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 1378, in fit_generator callbacks._set_model(callback_model)[SEP]File <*>python2.7/dist-packages/keras/callbacks.py, line 32, in _set_model callback._set_model(model)[SEP]File <*>python2.7/dist-packages/keras/callbacks.py, line 493, in _set_model self.sess = KTF.get_session()[SEP]File <*>python2.7/dist-packages/keras/backend/tensorflow_backend.py, line 111, in get_session _initialize_variables()[SEP]File <*>python2.7/dist-packages/keras/backend/tensorflow_backend.py, line 200, in _initialize_variables sess.run(tf.variables_initializer(uninitialized_variables))[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 766, in run run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 964, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 1014, in _do_run target_list, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 1034, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[4096] [[Node: Variable_43/Assign = Assign[T=DT_FLOAT, _class=[""loc:@Variable_43""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Variable_43, Const_59)]]",0
"File pymask.py, line 303, in <module> main(sys.argv)[SEP]File pymask.py, line 285, in main keras.callbacks.ProgbarLogger()[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1557, in fit_generator class_weight=class_weight)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1314, in train_on_batch check_batch_axis=True)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1029, in _standardize_user_data exception_prefix='model input')[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 52, in standardize_input_data str(names))[SEP]ValueError: No data provided for ""input_1"". Need data for each key in: ['input_1']",0
"File <*>/tfclass.py, line 36, in <module> summary_writer = tf.summary.FileWriter('/home/sergo/work/logs',graph_def = sess.graph_def)[SEP]File <*>python3.6/site-packages/tensorflow/python/summary/writer/writer.py, line 308, in __init__ event_writer = EventFileWriter(logdir, max_queue, flush_secs)[SEP]File <*>python3.6/site-packages/tensorflow/python/summary/writer/event_file_writer.py, line 69, in __init__ gfile.MakeDirs(self._logdir)[SEP]File <*>python3.6/site-packages/tensorflow/python/lib/io/file_io.py, line 301, in recursive_create_dir pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status)[SEP]File <*>python3.6/contextlib.py, line 89, in __exit__ next(self.gen)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 469, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors_impl.UnimplementedError: /home/sergo",0
"File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1022, in _do_call return fn(*args)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1004, in _run_fn status, run_metadata)[SEP]File <*>python3.5/contextlib.py, line 66, in __exit__ next(self.gen)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/errors_impl.py, line 469, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[14525,14000] [[Node: rnn/basic_lstm_cell/weights/Initializer/random_uniform = Add[T=DT_FLOAT, _class=[""loc:@rnn/basic_lstm_cell/weights""], _device=""/job:localhost/replica:0/task:0/gpu:0""](rnn/basic_lstm_cell/weights/Initializer/random_uniform/mul, rnn/basic_lstm_cell/weights/Initializer/random_uniform/min)]]",0
"File Netzwerk_v0.5.1_gamma.py, line 171, in <module> session.run(tf.global_variables_initializer())[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 767, in run run_metadata_ptr)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 965, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1015, in _do_run target_list, options, run_metadata)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1035, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[14525,14000] [[Node: rnn/basic_lstm_cell/weights/Initializer/random_uniform = Add[T=DT_FLOAT, _class=[""loc:@rnn/basic_lstm_cell/weights""], _device=""/job:localhost/replica:0/task:0/gpu:0""](rnn/basic_lstm_cell/weights/Initializer/random_uniform/mul, rnn/basic_lstm_cell/weights/Initializer/random_uniform/min)]]",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call return fn(*args)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1293, in _run_fn self._extend_graph()[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1354, in _extend_graph self._session, graph_def.SerializeToString(), status)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.UnavailableError: Trying to connect an http1.x server",0
"File <*>/pydevd.py, line 1599, in <module> globals = debugger.run(setup['file'], None, None, is_module)[SEP]File <*>/pydevd.py, line 1026, in run pydev_imports.execfile(file, globals, locals) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File worker.py, line 426, in <module> main()[SEP]File worker.py, line 418, in main run(args, server)[SEP]File worker.py, line 174, in run sess.run(trainer.sync)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.UnavailableError: Trying to connect an http1.x server",0
"File <*>/rock_detector.py, line 155, in <module> main()[SEP]File <*>/rock_detector.py, line 117, in main est_vgg16.train(input_fn=dataset_input_fn, steps=10)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 302, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 711, in _train_model features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 694, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py, line 145, in model_fn labels)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py, line 92, in _clone_and_build_model keras_model, features)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py, line 58, in _create_ordered_io for key in estimator_io_dict:[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 505, in __iter__ raise TypeError(""'Tensor' object is not iterable."")[SEP]TypeError: 'Tensor' object is not iterable.",0
"File <*>python3.5/dist-packages/Theano-1.0.0rc1-py3.5.egg/theano/gpuarray/__init__.py, line 220, in <module> use(config.device)[SEP]File <*>python3.5/dist-packages/Theano-1.0.0rc1-py3.5.egg/theano/gpuarray/__init__.py, line 207, in use init_dev(device, preallocate=preallocate)[SEP]File <*>python3.5/dist-packages/Theano-1.0.0rc1-py3.5.egg/theano/gpuarray/__init__.py, line 152, in init_dev pygpu.blas.gemm(0, tmp, tmp, 0, tmp, overwrite_c=True)[SEP]File <*>/blas.pyx, line 149, in pygpu.blas.gemm [CODE][SEP]File <*>/blas.pyx, line 47, in pygpu.blas.pygpu_blas_rgemm [CODE][SEP]pygpu.gpuarray.GpuArrayException: (b'cuLinkCreate: CUDA_ERROR_JIT_COMPILER_NOT_FOUND: PTX JIT compiler library not found', 3)",0
"File <ipython-input-6-b5da44e251a5>, line 1, in <module> from keras.layers import Input, Dense[SEP]ModuleNotFoundError: No module named 'keras'",0
"File SAMME_train_all.py, line 47, in <module> ce = K.categorical_crossentropy(label, label_pred)[SEP]File <*>/tensorflow_backend.py, line 2754, in categorical_c axis=len(output.get_shape()) - 1,[SEP]AttributeError: 'numpy.ndarray' object has no attribute 'get_shape'",0
"File modeltrain.py, line 180, in <module> model.fit_generator(next_batch(X_train_r, y_train_r, batch_size), steps_per_epoch=(X_train_r.shape[0]/batch_size), validation_data=(X_val_r, y_val_r), epochs=100, callbacks=[csv_logger, model_check])[SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 87, in wrapper return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1978, in fit_generator val_x, val_y, val_sample_weight)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1382, in _standardize_user_data exception_prefix='target')[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 111, in _standardize_input_data 'Found: array with shape ' + str(data.shape))[SEP]ValueError: The model expects 9 target arrays, but only received one array. Found: array with shape (70, 512, 512, 1)",0
"File test_python.py, line 1, in [FUNC] [CODE][SEP]ModuleNotFoundError: No module named 'numpy'",0
"File main.py, line 36, in <module> model.fit(X,Y, epochs=50, batch_size=100)[SEP]File <*>/site-packages/keras/models.py, line 960, in fit validation_steps=validation_steps)[SEP]File <*>/site-packages/keras/engine/training.py, line 1574, in fit batch_size=batch_size)[SEP]File <*>/site-packages/keras/engine/training.py, line 1407, in _standardize_user_data exception_prefix='input')[SEP]File <*>/site-packages/keras/engine/training.py, line 128, in _standardize_input_data arrays[i] = array[SEP]ValueError: could not broadcast input array from shape (14,1) into shape (14)",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call return fn(*args)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn status, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[500,80] [[Node: decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](decoder/while/BasicDecoderStep/basic_lstm_cell/concat, decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul/Enter)]] [[Node: gradients/Add/_282 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_457_gradients/Add"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](^_cloopdecoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y/_181)]]",0
"File <*>/main.py, line 89, in <module> _ = sess.run([update_step])[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[500,80] [[Node: decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](decoder/while/BasicDecoderStep/basic_lstm_cell/concat, decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul/Enter)]] [[Node: gradients/Add/_282 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_457_gradients/Add"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](^_cloopdecoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y/_181)]]",0
"File <stdin>, line 1, in <module> [CODE][SEP]RuntimeError: invalid argument 2: dimension 1 out of range of 1D tensor at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensor.c:24",0
"File <stdin>, line 1, in <module> [CODE][SEP]RuntimeError: t() expects a 2D tensor, but self is 1D",0
"File <stdin>, line 1, in <module> [CODE][SEP]RuntimeError: matrices expected, got 1D, 2D tensors at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensorMath.c:1288",0
"File <*>/LSTM-RNN.py, line 42, in <module> states_series, current_state = tf.contrib.rnn.static_rnn(cell, inputs_series, init_state)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/rnn.py, line 1181, in static_rnn input_shape = first_input.get_shape().with_rank_at_least(2)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/tensor_shape.py, line 670, in with_rank_at_least raise ValueError(""Shape %s must have rank at least %d"" % (self, rank))[SEP]ValueError: Shape () must have rank at least 2",0
"File <*>/site-packages/tensorflow/python/platform/self_check.py, line 75, in preload_check ctypes.WinDLL(build_info.cudart_dll_name)[SEP]File <*>/__init__.py, line 351, in __init__ self._handle = _dlopen(self._name, mode)[SEP]OSError: [WinError 126] This specified module could not be found",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import *[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 30, in <module> self_check.preload_check()[SEP]File <*>/site-packages/tensorflow/python/platform/self_check.py, line 82, in preload_check % (build_info.cudart_dll_name, build_info.cuda_version_number))[SEP]ImportError: Could not find 'cudart64_80.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 8.0 from this URL: https://developer.nvidia.com/cuda-toolkit",0
"File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 468, in make_tensor_proto str_values = [compat.as_bytes(x) for x in proto_values][SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 468, in <listcomp> str_values = [compat.as_bytes(x) for x in proto_values][SEP]File <*>/site-packages/tensorflow/python/util/compat.py, line 65, in as_bytes (bytes_or_text,))[SEP]TypeError: Expected binary or unicode string, got {'weights': <tf.Variable 'Variable:0' shape=(784, 600) dtype=float32_ref>, 'biases': <tf.Variable 'Variable_1:0' shape=(600,) dtype=float32_ref>}",0
"File <*>/neuralnetworktest.py, line 45, in <module> train(x)[SEP]File <*>/neuralnetworktest.py, line 29, in train prediction = neuralNetwork(inputdata)[SEP]File <*>/neuralnetworktest.py, line 22, in neuralNetwork FinalH2 = tf.add(tf.matmul(H1, H2[""weights""]), H2[""biases""])[SEP]File <*>/site-packages/tensorflow/python/ops/math_ops.py, line 1844, in matmul a = ops.convert_to_tensor(a, name=""a"")[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 836, in convert_to_tensor as_ref=False)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 926, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 229, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 208, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 472, in make_tensor_proto ""supported type."" % (type(values), values))[SEP]TypeError: Failed to convert object of type <class 'dict'> to Tensor.",0
"File <*>/site-packages/google/protobuf/internal/python_message.py, line 545, in _GetFieldByName return message_descriptor.fields_by_name[field_name][SEP]KeyError: 'layout_optimizer'",0
"File export_inference_graph.py, line 119, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough))[SEP]File export_inference_graph.py, line 115, in main FLAGS.output_directory, input_shape)[SEP]File <*>/site-packages/object_detection-0.1-py3.5.egg/object_detection/exporter.py, line 427, in export_inference_graph input_shape, optimize_graph, output_collection_name)[SEP]File <*>/site-packages/object_detection-0.1-py3.5.egg/object_detection/exporter.py, line 391, in _export_inference_graph initializer_nodes='')[SEP]File <*>/site-packages/object_detection-0.1-py3.5.egg/object_detection/exporter.py, line 72, in freeze_graph_with_def_protos layout_optimizer=rewriter_config_pb2.RewriterConfig.ON)[SEP]File <*>/site-packages/google/protobuf/internal/python_message.py, line 484, in init field = _GetFieldByName(message_descriptor, field_name)[SEP]File <*>/site-packages/google/protobuf/internal/python_message.py, line 548, in _GetFieldByName (message_descriptor.name, field_name))[SEP]ValueError: Protocol message RewriterConfig has no ""layout_optimizer"" field.",0
"File RF_2.py, line 312, in <module> main()[SEP]File RF_2.py, line 298, in main train_eval(x_train, y_train, x_validation, y_validation, x_test, y_test, num_tree)[SEP]File RF_2.py, line 221, in train_eval prob0 = results[0][eval_metrics.INFERENCE_PROB_NAME][SEP]KeyError: 'probabilities'",0
"File <ipython-input-7-e80e82960eb9>, line 1, in <module> cross = cross_val_score(estimator=classfier, X=Xtrain, y=Ytrain, cv=10 , n_jobs=-1)[SEP]File <*>/site-packages/sklearn/model_selection/_validation.py, line 342, in cross_val_score pre_dispatch=pre_dispatch)[SEP]File <*>/site-packages/sklearn/model_selection/_validation.py, line 206, in cross_validate for train, test in cv.split(X, y, groups))[SEP]File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 779, in __call__ while self.dispatch_one_batch(iterator):[SEP]File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 620, in dispatch_one_batch tasks = BatchedCalls(itertools.islice(iterator, batch_size))[SEP]File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 127, in __init__ self.items = list(iterator_slice)[SEP]File <*>/site-packages/sklearn/model_selection/_validation.py, line 206, in <genexpr> for train, test in cv.split(X, y, groups))[SEP]File <*>/site-packages/sklearn/base.py, line 62, in clone new_object_params[name] = clone(param, safe=False)[SEP]File <*>/site-packages/sklearn/base.py, line 53, in clone return copy.deepcopy(estimator)[SEP]File <*>/copy.py, line 180, in deepcopy y = _reconstruct(x, memo, *rv)[SEP]File <*>/copy.py, line 280, in _reconstruct state = deepcopy(state, memo)[SEP]File <*>/copy.py, line 150, in deepcopy y = copier(x, memo)[SEP]File <*>/copy.py, line 240, in _deepcopy_dict y[deepcopy(key, memo)] = deepcopy(value, memo)[SEP]File <*>/copy.py, line 215, in _deepcopy_list append(deepcopy(a, memo))[SEP]File <*>/copy.py, line 169, in deepcopy rv = reductor(4)[SEP]TypeError: can't pickle _thread.lock objects",0
"File generate_tfrecord.py, line 192, in <module> tf.app.run()[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough))[SEP]File generate_tfrecord.py, line 184, in main tf_example = create_tf_example(group, path)[SEP]File generate_tfrecord.py, line 173, in create_tf_example 'image/object/class/label': dataset_util.int64_list_feature(classes),[SEP]File <*>/dataset_util.py, line 26, in int64_list_feature return tf.train.Feature(int64_list=tf.train.Int64List(value=value))[SEP]TypeError: None has type NoneType, but expected one of: int, long",0
"File predict.py, line 34, in <module> preds = learn.predict_array(im[None])[SEP]File <*>/learner.py, line 266, in predict_array def predict_array(self, arr): return to_np(self.model(V(T(arr).cuda())))[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 325, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/container.py, line 67, in forward input = module(input)[SEP]File <*>python3.6/site-packages/torch/nn/modules/batchnorm.py, line 37, in forward self.training, self.momentum, self.eps)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1011, in batch_norm raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size))[SEP]ValueError: Expected more than 1 value per channel when training, got input size [1, 1024]",0
"File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call return fn(*args)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn status, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: cnn()conv2 : Tensor had Inf values [[Node: tower_7/conv2/CheckNumerics_3 = CheckNumerics[T=DT_FLOAT, message=""NaN: cnn()conv2"", _device=""/job:localhost/replica:0/task:0/device:GPU:7""](tower_7/conv2/conv2)]]",0
"File cnn_base.py, line 1703, in <module> training()[SEP]File cnn_base.py, line 1314, in training _, loss_value = sess.run([train_op, loss])[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: cnn()conv2 : Tensor had Inf values [[Node: tower_7/conv2/CheckNumerics_3 = CheckNumerics[T=DT_FLOAT, message=""NaN: cnn()conv2"", _device=""/job:localhost/replica:0/task:0/device:GPU:7""](tower_7/conv2/conv2)]]",0
"File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call return fn(*args)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn status, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: average_gradients(expanded_g) : Tensor had Inf and NaN values [[Node: CheckNumerics_30 = CheckNumerics[T=DT_FLOAT, message=""NaN: average_gradients(expanded_g)"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](ExpandDims_30)]] [[Node: tower_6/total_loss/_2216 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:6"", send_device_incarnation=1, tensor_name=""edge_4923_tower_6/total_loss"", _device=""/job:localhost/replica:0/task:0/device:GPU:6""](tower_6/total_loss)]]",0
"File cnn_base.py, line 1704, in <module> training()[SEP]File cnn_base.py, line 1312, in training nan_debug, _, loss_value = sess.run([check_op, train_op, loss])[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: average_gradients(expanded_g) : Tensor had Inf and NaN values [[Node: CheckNumerics_30 = CheckNumerics[T=DT_FLOAT, message=""NaN: average_gradients(expanded_g)"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](ExpandDims_30)]] [[Node: tower_6/total_loss/_2216 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:6"", send_device_incarnation=1, tensor_name=""edge_4923_tower_6/total_loss"", _device=""/job:localhost/replica:0/task:0/device:GPU:6""](tower_6/total_loss)]]",0
"File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.5/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.5/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory",0
"File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory",0
"File <*>/hackerearth_project.py, line 90, in <module> model(X_train, X_test, Y_train, Y_test)[SEP]File <*>/hackerearth_project.py, line 71, in model optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1, beta2=beta2).minimize(cost)[SEP]File <*>/site-packages/tensorflow/python/training/optimizer.py, line 343, in minimize grad_loss=grad_loss)[SEP]File <*>/site-packages/tensorflow/python/training/optimizer.py, line 394, in compute_gradients self._assert_valid_dtypes([loss])[SEP]File <*>/site-packages/tensorflow/python/training/optimizer.py, line 543, in _assert_valid_dtypes dtype = t.dtype.base_dtype[SEP]AttributeError: 'NoneType' object has no attribute 'dtype'",0
"File <*>/cli.py, line 797, in Execute resources = calliope_command.Run(cli=self, args=args)[SEP]File <*>/backend.py, line 757, in Run resources = command_instance.Run(args)[SEP]File <*>/predict.py, line 65, in Run args.text_instances)[SEP]File <*>/local_utils.py, line 89, in RunPredict raise LocalPredictRuntimeError(err)[SEP]LocalPredictRuntimeError: RuntimeError: Bad magic number in .pyc file ERROR: (gcloud.ml-engine.local.predict) RuntimeError: Bad magic number in .pyc file",0
"File <*>/site-packages/cx_Freeze/initscripts/__startup__.py, line 14, in run module.run()[SEP]File <*>/site-packages/cx_Freeze/initscripts/Console.py, line 26, in run exec(code, m.__dict__)[SEP]File app.py, line 2, in <module> [CODE][SEP]File <*>/retrain.py, line 16, in <module> import tensorflow as tf[SEP]File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import *[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 52, in <module> from tensorflow.core.framework.graph_pb2 import *[SEP]File <*>/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in <module> from google.protobuf import descriptor as _descriptor[SEP]ImportError: No module named 'google'",0
"File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1350, in _do_call return fn(*args)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1329, in _run_fn status, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,32,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[Node: FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Preprocessor/sub, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read)]]",0
"File eval.py, line 146, in <module> tf.app.run()[SEP]File <*>python3.5/dist-packages/tensorflow/python/platform/app.py, line 124, in run _sys.exit(main(argv))[SEP]File eval.py, line 142, in main FLAGS.checkpoint_dir, FLAGS.eval_dir)[SEP]File <*>/evaluator.py, line 240, in evaluate save_graph_dir=(eval_dir if eval_config.save_graph else ''))[SEP]File <*>/eval_util.py, line 407, in repeated_checkpoint_run save_graph_dir)[SEP]File <*>/eval_util.py, line 286, in _run_checkpoint_once result_dict = batch_processor(tensor_dict, sess, batch, counters)[SEP]File <*>/evaluator.py, line 183, in _process_batch result_dict = sess.run(tensor_dict)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 895, in run run_metadata_ptr)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1128, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1344, in _do_run options, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1363, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,32,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[Node: FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Preprocessor/sub, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read)]]",0
"File <*>python3.6/configparser.py, line 1138, in _unify_values sectiondict = self._sections[section][SEP]KeyError: 'blas'",0
"File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl input_tensors_as_shapes, status)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[1], expected a dimension of 1, got 3 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [100,3].",0
"File <*>/cnn_mnist.py, line 214, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 124, in run _sys.exit(main(argv))[SEP]File <*>/cnn_mnist.py, line 203, in main hooks=[logging_hook])[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 314, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 743, in _train_model features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 725, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs)[SEP]File <*>/cnn_mnist.py, line 67, in cnn_model_fn loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)[SEP]File <*>/site-packages/tensorflow/python/ops/losses/losses_impl.py, line 790, in sparse_softmax_cross_entropy labels, logits, weights, expected_rank_diff=1)[SEP]File <*>/site-packages/tensorflow/python/ops/losses/losses_impl.py, line 720, in _remove_squeezable_dimensions labels, predictions, expected_rank_diff=expected_rank_diff)[SEP]File <*>/site-packages/tensorflow/python/ops/confusion_matrix.py, line 76, in remove_squeezable_dimensions labels = array_ops.squeeze(labels, [-1])[SEP]File <*>/site-packages/tensorflow/python/ops/array_ops.py, line 2490, in squeeze return gen_array_ops._squeeze(input, axis, name)[SEP]File <*>/site-packages/tensorflow/python/ops/gen_array_ops.py, line 7049, in _squeeze ""Squeeze"", input=input, squeeze_dims=axis, name=name)[SEP]File <*>/site-packages/tensorflow/python/framework/op_def_library.py, line 787, in _apply_op_helper op_def=op_def)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 3162, in create_op compute_device=compute_device)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 3208, in _create_op_helper set_shapes_for_outputs(op)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 2427, in set_shapes_for_outputs return _set_shapes_for_outputs(op)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 2400, in _set_shapes_for_outputs shapes = shape_func(op)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 2330, in call_with_requiring return call_cpp_shape_fn(op, require_shape_fn=True)[SEP]File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 627, in call_cpp_shape_fn require_shape_fn)[SEP]File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 691, in _call_cpp_shape_fn_impl raise ValueError(err.message)[SEP]ValueError: Can not squeeze dim[1], expected a dimension of 1, got 3 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [100,3].",0
"File <*>python3.6/inspect.py, line 1119, in getfullargspec sigcls=Signature)[SEP]File <*>python3.6/inspect.py, line 2186, in _signature_from_callable raise TypeError('{!r} is not a callable object'.format(obj))[SEP]TypeError: (<tf.Tensor 'IteratorGetNext:0' shape=(?, 40, 40, ?) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=int32>) is not a callable object",0
"File <*>/task2_new.py, line 78, in <module> loss = compute_loss(h_fc2, margin)[SEP]File <*>/task2_new.py, line 37, in compute_loss Ltriplet = np.maximum(0, 1 - tf.square(diff_neg)/(tf.square(diff_pos) + margin))[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 614, in __bool__ raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""[SEP]TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",0
"File lec5.py, line 97, in <module> train(epoch)[SEP]File lec5.py, line 74, in train loss = criterion(y_pred, labels)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 357, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/loss.py, line 679, in forward self.ignore_index, self.reduce)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1161, in cross_entropy return nll_loss(log_softmax(input, 1), target, weight, size_average, ignore_index, reduce)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1052, in nll_loss return torch._C._nn.nll_loss(input, target, weight, size_average, ignore_index, reduce)[SEP]RuntimeError: multi-target not supported at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/THNN/generic/ClassNLLCriterion.c:22",0
"File <*>/main.py, line 6, in <module> watcher = Watcher('res/vid/planet_earth_s01e01/video.mp4', 'res/vid/planet_earth_s01e01/english.srt')[SEP]File <*>/watch.py, line 9, in __init__ self.detector = Detector()[SEP]File <*>/detect.py, line 6, in __init__ self.tfnet = TFNet(self.options)[SEP]File <*>python3.6/site-packages/darkflow/net/build.py, line 75, in __init__ self.build_forward()[SEP]File <*>python3.6/site-packages/darkflow/net/build.py, line 105, in build_forward self.inp = tf.placeholder(tf.float32, inp_size, 'input')[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/array_ops.py, line 1677, in placeholder raise RuntimeError(""tf.placeholder() is not compatible with ""[SEP]RuntimeError: tf.placeholder() is not compatible with eager execution.",0
"File <*>/lstm.py, line 131, in <module> main()[SEP]File <*>/lstm.py, line 111, in main model.fit_generator(generator=training_sequence)[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/models.py, line 1253, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>/site-packages/keras/engine/training.py, line 2244, in fit_generator class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1884, in train_on_batch class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1487, in _standardize_user_data exception_prefix='target')[SEP]File <*>/site-packages/keras/engine/training.py, line 113, in _standardize_input_data 'with shape ' + str(data_shape))[SEP]ValueError: Error when checking target: expected dense_1 to have 2 dimensions, but got array with shape (1, 1034, 9)",0
"File train.py, line 167, in <module> tf.app.run()[SEP]File <*>python3.5/app.py, line 126, in run _sys.exit(main(argv))[SEP]File train.py, line 163, in main worker_job_name, is_chief, FLAGS.train_dir)[SEP]File <*>python3.5/dist-packages/object_detection-0.1-py3.5.egg/object_detection/trainer.py, line 211, in train detection_model = create_model_fn()[SEP]File <*>python3.5/dist-packages/object_detection-0.1-py3.5.egg/object_detection/builders/model_builder.py, line 96, in build add_summaries)[SEP]File <*>python3.5/dist-packages/object_detection-0.1-py3.5.egg/object_detection/builders/model_builder.py, line 272, in _build_faster_rcnn_model frcnn_config.inplace_batchnorm_update)[SEP]AttributeError: 'FasterRcnn' object has no attribute 'inplace_batchnorm_update'",0
"File <*>/freeze_graph? line 11, in <module> sys.exit(main())[SEP]TypeError: main() missing 1 required positional argument: nused_args?
308,49760781,0,1,,,File [FILE]",0
"File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 579, in merge_with new_dims.append(dim.merge_with(other[i]))[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 138, in merge_with self.assert_is_compatible_with(other)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 111, in assert_is_compatible_with other))[SEP]ValueError: Dimensions 5 and 4 are not compatible",0
"File <*>python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py, line 602, in gradients in_grad.set_shape(t_in.get_shape())[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 407, in set_shape self._shape = self._shape.merge_with(shape)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 582, in merge_with raise ValueError(""Shapes %s and %s are not compatible"" % (self, other))[SEP]ValueError: Shapes (?, 5, 15, 1) and (?, 4, 15, 1) are not compatible",0
"File experiment.py, line 65, in <module> batches_per_lot=batches_per_lot, sigma=dp_sigma, dp=dp)[SEP]File <*>/model.py, line 247, in GAN_solvers G_solver = tf.train.AdamOptimizer().minimize(G_loss_mean_over_batch, var_list=generator_vars)[SEP]File <*>python3.5/dist-packages/tensorflow/python/training/optimizer.py, line 343, in minimize grad_loss=grad_loss)[SEP]File <*>python3.5/dist-packages/tensorflow/python/training/optimizer.py, line 414, in compute_gradients colocate_gradients_with_ops=colocate_gradients_with_ops)[SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py, line 609, in gradients % (op.name, i, t_in.shape, in_grad.shape))[SEP]ValueError: Incompatible shapes between op input and calculated input gradient. Forward operation: generator/conv2d_transpose_1. Input index: 2. Original input shape: (?, 4, 15, 1). Calculated input gradient shape: (?, 5, 15, 1)",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/k_means.py, line 10, in prepare_dataset dataset = tf.data.Dataset.from_tensor_slices(dm_data)[SEP]File <*>python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 222, in from_tensor_slices return TensorSliceDataset(tensors)[SEP]File <*>python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1017, in __init__ for i, t in enumerate(nest.flatten(tensors))[SEP]File <*>python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1017, in <listcomp> for i, t in enumerate(nest.flatten(tensors))[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 950, in convert_to_tensor as_ref=False)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1040, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 235, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 185, in constant t = convert_to_eager_tensor(value, ctx, dtype)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 131, in convert_to_eager_tensor return ops.EagerTensor(value, context=handle, device=device, dtype=dtype)[SEP]ValueError: Can't convert Python sequence with mixed types to Tensor.",0
"File processing_2a_1.py, line 96, in <module> model.add(Conv1D(60,32, strides=1, activation='relu',padding='causal',input_shape=(None,64,1)))[SEP]File <*>/models.py, line 442, in add [CODE][SEP]File <*>/topology.py, line 558, in __call__ [CODE][SEP]File <*>/topology.py, line 457, in assert_input_compatibility [CODE][SEP]ValueError: Input 0 is incompatible with layer conv1d_1: expected ndim=3, found ndim=4",0
"File processing_2a_1.py, line 125, in <module> history=model.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_val,Y_val), epochs=nr_of_epochs,verbose=2)[SEP]File <*>/models.py, line 871, in fit [CODE][SEP]File <*>/training.py, line 1524, in fit [CODE][SEP]File <*>/training.py, line 1382, in _standardize_user_data [CODE][SEP]File <*>/training.py, line 132, in _standardize_input_data [CODE][SEP]ValueError: Error when checking target: expected dense_2 to have 3 dimensions, but got array with shape (1496000, 1)",0
"File [FILE], line <*>, in [FUNC] [CODE][SEP]AttributeError: module 'tensorflow' has no attribute 'Session'",0
"File <*>/train.py, line 167, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File <*>/train.py, line 92, in main FLAGS.pipeline_config_path)[SEP]File <*>/config_util.py, line 93, in get_configs_from_pipeline_file text_format.Merge(proto_str, pipeline_config)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 533, in Merge descriptor_pool=descriptor_pool)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 587, in MergeLines return parser.MergeLines(lines, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 620, in MergeLines self._ParseOrMerge(lines, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 635, in _ParseOrMerge self._MergeField(tokenizer, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 735, in _MergeField merger(tokenizer, message, field)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 823, in _MergeMessageField self._MergeField(tokenizer, sub_message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 703, in _MergeField (message_descriptor.full_name, name))[SEP]google.protobuf.text_format.ParseError: 108:7 : Message type ""object_detection.protos.SsdFeatureExtractor"" has no field named ""batch_norm_trainable"".",0
"File train.py, line 167, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File train.py, line 92, in main FLAGS.pipeline_config_path)[SEP]File <*>/config_util.py, line 93, in get_configs_from_pipeline_file text_format.Merge(proto_str, pipeline_config)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 533, in Merge descriptor_pool=descriptor_pool)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 587, in MergeLines return parser.MergeLines(lines, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 620, in MergeLines self._ParseOrMerge(lines, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 635, in _ParseOrMerge self._MergeField(tokenizer, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 735, in _MergeField merger(tokenizer, message, field)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 823, in _MergeMessageField self._MergeField(tokenizer, sub_message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 703, in _MergeField (message_descriptor.full_name, name))[SEP]google.protobuf.text_format.ParseError: 108:7 : Message type ""object_detection.protos.SsdFeatureExtractor"" has no field named ""batch_norm_trainable"".",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1330, in _do_call return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1315, in _run_fn options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1423, in _call_tf_sessionrun status, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,25] vs. shape[1] = [30,100] [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](rnn/while/TensorArrayReadV3, rnn/while/Switch_4:1, rnn/while/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/Const)]]",0
"File <*>/dnn_gragh.py, line 198, in <module> model.train(5000, 0.0001, my_input_fn, training_examples, training_targets, sequenceLenth=trainSequenceL)[SEP]File <*>/dnn_gragh.py, line 124, in train state2, current_loss, nowAccuracy = sess.run([state, loss, accuracy])[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 908, in run run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1143, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1324, in _do_run run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1343, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,25] vs. shape[1] = [30,100] [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](rnn/while/TensorArrayReadV3, rnn/while/Switch_4:1, rnn/while/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/Const)]]",0
"File <*>/mnist_test.py, line 24, in <module> from official.mnist import mnist[SEP]ModuleNotFoundError: No module named 'official'",0
"File main.py, line 69, in <module> main();[SEP]File main.py, line 66, in main train_model(iris_dataset, model, optimizer);[SEP]File main.py, line 41, in train_model gradients = gradient_tune(features, label, model);[SEP]File main.py, line 27, in gradient_tune prediction_loss = prediction_loss_diff(features, targets, model);[SEP]File main.py, line 23, in prediction_loss_diff return tf.losses.sparse_softmax_cross_entropy(label, predicted_label);[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py, line 853, in sparse_softmax_cross_entropy name=""xentropy"")[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/nn_ops.py, line 2050, in sparse_softmax_cross_entropy_with_logits precise_logits, labels, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 7504, in sparse_softmax_cross_entropy_with_logits _six.raise_from(_core._status_to_exception(e.code, message), None)[SEP]File <string>, line 2, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.InternalError: Could not find valid device for node name: ""SparseSoftmaxCrossEntropyWithLogits""",0
"File pipe, line 320, in <module> tf.app.run()[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File pipe, line 316, in main train(FLAGS.num_training_iterations, FLAGS.report_interval, FLAGS.report_interval_verbose)[SEP]File pipe, line 120, in train print(sess.run(next_element))[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 905, in run run_metadata_ptr)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1140, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1321, in _do_run run_metadata)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1340, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.UnknownError: exceptions.AttributeError: 'numpy.dtype' object has no attribute 'as_numpy_dtype'",0
"File <string>, line 1, in <module> [CODE][SEP]File <*>/spawn.py, line 105, in spawn_main exitcode = _main(fd)[SEP]File <*>/spawn.py, line 114, in _main prepare(preparation_data)[SEP]File <*>/spawn.py, line 225, in prepare _fixup_main_from_path(data['init_main_from_path'])[SEP]File <*>/spawn.py, line 277, in _fixup_main_from_path run_name=""__mp_main__"")[SEP]File <*>/runpy.py, line 263, in run_path pkg_name=pkg_name, script_name=fname)[SEP]File <*>/runpy.py, line 96, in _run_module_code mod_name, mod_spec, pkg_name, script_name)[SEP]File <*>/runpy.py, line 85, in _run_code exec(code, run_globals)[SEP]File <*>/TutorialCIFAR10.py, line 36, in <module> dataiter = iter(trainloader)[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 451, in __iter__ return _DataLoaderIter(self)[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 239, in __init__ w.start()[SEP]File <*>/process.py, line 105, in start self._popen = self._Popen(self)[SEP]File <*>/context.py, line 223, in _Popen return _default_context.get_context().Process._Popen(process_obj)[SEP]File <*>/context.py, line 322, in _Popen return Popen(process_obj)[SEP]File <*>/popen_spawn_win32.py, line 33, in __init__ prep_data = spawn.get_preparation_data(process_obj._name)[SEP]File <*>/spawn.py, line 143, in get_preparation_data _check_not_importing_main()[SEP]File <*>/spawn.py, line 136, in _check_not_importing_main is not going to be frozen to produce an executable.)[SEP]RuntimeError: An attempt has been made to start a new process before the current process has finished its bootstrapping phase.",0
"File <*>/TutorialCIFAR10.py, line 36, in <module> dataiter = iter(trainloader)[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 451, in __iter__ return _DataLoaderIter(self)[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 239, in __init__ w.start()[SEP]File <*>/process.py, line 105, in start self._popen = self._Popen(self)[SEP]File <*>/context.py, line 223, in _Popen return _default_context.get_context().Process._Popen(process_obj)[SEP]File <*>/context.py, line 322, in _Popen return Popen(process_obj)[SEP]File <*>/popen_spawn_win32.py, line 65, in __init__ reduction.dump(process_obj, to_child)[SEP]File <*>/reduction.py, line 60, in dump ForkingPickler(file, protocol).dump(obj)[SEP]BrokenPipeError: [Errno 32] Broken pipe",0
"File test.py, line 7, in [FUNC] [CODE][SEP]TypeError: Parameter to MergeFrom() must be instance of same class: expected tensorflow.BytesList got tensorflow.Int64List.",0
"File <*>/label_map_util.py, line 135, in load_labelmap text_format.Merge(label_map_string, label_map)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 525, in Merge descriptor_pool=descriptor_pool)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 579, in MergeLines return parser.MergeLines(lines, message)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 612, in MergeLines self._ParseOrMerge(lines, message)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 627, in _ParseOrMerge self._MergeField(tokenizer, message)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 727, in _MergeField merger(tokenizer, message, field)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 815, in _MergeMessageField self._MergeField(tokenizer, sub_message)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 695, in _MergeField (message_descriptor.full_name, name))[SEP]google.protobuf.text_format.ParseError: 23:20 : Message type ""object_detection.protos.StringIntLabelMapItem"" has no field named ""s"".",0
"File <*>/site-packages/theano/gof/lazylinker_c.py, line 81, in <module> actual_version, force_compile, _need_reload))[SEP]ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True",0
"File <*>/site-packages/theano/gof/lazylinker_c.py, line 105, in <module> actual_version, force_compile, _need_reload))[SEP]ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True",0
"File <string>, line 1, in <module> [CODE][SEP]File <*>/setup.py, line 11, in <module> raise RuntimeError(README)[SEP]RuntimeError: PyTorch does not currently provide packages for PyPI (see status at https://github.com/pytorch/pytorch/issues/566).",0
"File <ipython-input-11-9a561e7b074b>, line 1, in <module> runfile('C:/Users/emile/Desktop/tensorflow.py', wdir='C:/Users/emile/Desktop')[SEP]File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 705, in runfile execfile(filename, namespace)[SEP]File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 102, in execfile exec(compile(f.read(), filename, 'exec'), namespace)[SEP]File <*>/tensorflow.py, line 6, in <module> import tensorflow as tf[SEP]File <*>/tensorflow.py, line 7, in <module> import tensorflow.contrib.eager as tfe[SEP]ModuleNotFoundError: No module named 'tensorflow.contrib'; 'tensorflow' is not a package",0
"File <ipython-input-17-412a606c772f>, line 1, in <module> dataset = tf.data.Dataset.from_tensor_slices((one_hot_dataset))[SEP]File <*>python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 235, in from_tensor_slices return TensorSliceDataset(tensors)[SEP]File <*>python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1030, in __init__ for i, t in enumerate(nest.flatten(tensors))[SEP]File <*>python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1030, in <listcomp> for i, t in enumerate(nest.flatten(tensors))[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 1014, in convert_to_tensor as_ref=False)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 1104, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/constant_op.py, line 235, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/constant_op.py, line 214, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/tensor_util.py, line 496, in make_tensor_proto [CODE][SEP]""Cannot create a tensor proto whose content is larger than 2GB."") ValueError: Cannot create a tensor proto whose content is larger than 2GB.",0
"File generate_tfrecord.py, line 17, in <module> import tensorflow as tf[SEP]File <*>/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 81, in <module> from tensorflow.python import keras[SEP]File <*>/site-packages/tensorflow/python/keras/__init__.py, line 24, in <module> from tensorflow.python.keras import activations[SEP]File <*>/site-packages/tensorflow/python/keras/activations/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.activations import elu[SEP]File <*>/site-packages/tensorflow/python/keras/_impl/keras/__init__.py, line 21, in <module> from tensorflow.python.keras._impl.keras import activations[SEP]File <*>/site-packages/tensorflow/python/keras/_impl/keras/activations.py, line 23, in <module> from tensorflow.python.keras._impl.keras import backend as K[SEP]File <*>/site-packages/tensorflow/python/keras/_impl/keras/backend.py, line 38, in <module> from tensorflow.python.layers import base as tf_base_layers[SEP]File <*>/site-packages/tensorflow/python/layers/base.py, line 25, in <module> from tensorflow.python.keras.engine import base_layer[SEP]File <*>/site-packages/tensorflow/python/keras/engine/__init__.py, line 21, in <module> from tensorflow.python.keras.engine.base_layer import InputSpec[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 33, in <module> from tensorflow.python.keras import backend[SEP]File <*>/site-packages/tensorflow/python/keras/backend/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.backend import abs[SEP]ImportError: cannot import name 'abs'",0
"File test.py, line 13, in <module> layers.Dense(64, activation='sigmoid')[SEP]NameError: name 'layers' is not defined",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.5/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>python3.5/site-packages/tensorflow/python/__init__.py, line 52, in <module> from tensorflow.core.framework.graph_pb2 import *[SEP]ImportError: No module named 'tensorflow.core'",0
"File <ipython-input-2-25b92e4d5dec>, line 2, in <module> hello = tf.constant('Hello, TensorFlow!')[SEP]AttributeError: module 'tensorflow' has no attribute 'constant'",0
"File model_builder_test.py, line 21, in <module> from object_detection.builders import model_builder[SEP]File <*>/model_builder.py, line 17, in <module> from object_detection.builders import anchor_generator_builder[SEP]File <*>/anchor_generator_builder.py, line 18, in <module> from object_detection.anchor_generators import grid_anchor_generator[SEP]File <*>/grid_anchor_generator.py, line 27, in <module> from object_detection.utils import ops[SEP]File <*>/ops.py, line 282, in <module> dtype=tf.float32):[SEP]AttributeError: module 'tensorflow' has no attribute 'float32'",0
"File main.py, line 109, in <module> train(loader_train, model, criterion, optimizer)[SEP]File main.py, line 54, in train optimizer.step()[SEP]File <*>python3.6/site-packages/torch/optim/sgd.py, line 93, in step d_p.add_(weight_decay, p.data)[SEP]RuntimeError: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/THC/generated/../generic/THCTensorMathPointwise.cu:265",0
"File deparser.py, line 402, in <module> d.train()[SEP]File deparser.py, line 331, in train total, correct, avgloss = self.train_util()[SEP]File deparser.py, line 362, in train_util loss = self.step(X_train, Y_train, correct, total)[SEP]File deparser.py, line 214, in step loss = nn.CrossEntropyLoss()(out.long(), y)[SEP]File <*>python3.5/site-packages/torch/nn/modules/module.py, line 477, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>python3.5/site-packages/torch/nn/modules/loss.py, line 862, in forward ignore_index=self.ignore_index, reduction=self.reduction)[SEP]File <*>python3.5/site-packages/torch/nn/functional.py, line 1550, in cross_entropy return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)[SEP]File <*>python3.5/site-packages/torch/nn/functional.py, line 975, in log_softmax return input.log_softmax(dim)[SEP]RuntimeError: ""host_softmax"" not implemented for 'torch.cuda.LongTensor'",0
"File pytorch.py, line 14, in <module> test_tensor = torch.tensor(test)[SEP]ValueError: could not determine the shape of object type 'DataFrame'",0
"File [FILE], line <*>, in [FUNC] [CODE][SEP]File <*>/setup.py, line 108, in [FUNC] [CODE][SEP]ImportError: No module named tools.setup_helpers.env",0
"File hello-world.py, line 1, in <module> from keras.models import Sequential[SEP]File <*>python3.6/site-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>python3.6/site-packages/keras/utils/__init__.py, line 2, in <module> from . import np_utils[SEP]File <*>python3.6/site-packages/keras/utils/np_utils.py, line 6, in <module> import numpy as np[SEP]File <*>python3.6/site-packages/numpy/__init__.py, line 142, in <module> from . import add_newdocs[SEP]File <*>python3.6/site-packages/numpy/add_newdocs.py, line 13, in <module> from numpy.lib import add_newdoc[SEP]File <*>python3.6/site-packages/numpy/lib/__init__.py, line 8, in <module> from .type_check import *[SEP]File <*>python3.6/site-packages/numpy/lib/type_check.py, line 11, in <module> import numpy.core.numeric as _nx[SEP]File <*>python3.6/site-packages/numpy/core/__init__.py, line 16, in <module> from . import multiarray[SEP]SystemError: initialization of multiarray raised unreported exception",0
"File <ipython-input-7-2ef5e6514df7>, line 33, in data_generator [CODE][SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1530, in __exit__ self._default_graph_context_manager.__exit__(exec_type, exec_value, exec_tb)[SEP]File <*>python3.6/contextlib.py, line 99, in __exit__ self.gen.throw(type, value, traceback)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 5025, in get_controller context.context().context_switches.pop()[SEP]File <*>python3.6/dist-packages/tensorflow/python/eager/context.py, line 136, in pop self.stack.pop()[SEP]IndexError: pop from empty list",0
"File <*>/predict.py, line 74, in <module> print(get_grad(x_cloned, x))[SEP]File <*>/predict.py, line 68, in get_grad A.backward()[SEP]File <*>python3.5/site-packages/torch/tensor.py, line 93, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>python3.5/site-packages/torch/autograd/__init__.py, line 90, in backward allow_unreachable=True) # allow_unreachable flag[SEP]RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn",0
"File <*>/playground.py, line 22, in <module> print(get_grad(x_cloned, x))[SEP]File <*>/playground.py, line 16, in get_grad A.backward()[SEP]File <*>python3.5/site-packages/torch/tensor.py, line 93, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>python3.5/site-packages/torch/autograd/__init__.py, line 84, in backward grad_tensors = _make_grads(tensors, grad_tensors)[SEP]File <*>python3.5/site-packages/torch/autograd/__init__.py, line 28, in _make_grads raise RuntimeError(""grad can be implicitly created only for scalar outputs"")[SEP]RuntimeError: grad can be implicitly created only for scalar outputs",0
"File <*>/all_good.py, line 15, in <module> import matplotlib.pyplot as plt[SEP]File <*>/site-packages/matplotlib/pyplot.py, line 115, in <module> _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()[SEP]File <*>/site-packages/matplotlib/backends/__init__.py, line 62, in pylab_setup [backend_name], 0)[SEP]File <*>/site-packages/matplotlib/backends/backend_qt5agg.py, line 15, in <module> from .backend_qt5 import ([SEP]File <*>/site-packages/matplotlib/backends/backend_qt5.py, line 19, in <module> import matplotlib.backends.qt_editor.figureoptions as figureoptions[SEP]File <*>/site-packages/matplotlib/backends/qt_editor/figureoptions.py, line 20, in <module> import matplotlib.backends.qt_editor.formlayout as formlayout[SEP]File <*>/site-packages/matplotlib/backends/qt_editor/formlayout.py, line 54, in <module> from matplotlib.backends.qt_compat import QtGui, QtWidgets, QtCore[SEP]File <*>/site-packages/matplotlib/backends/qt_compat.py, line 158, in <module> raise ImportError(""Failed to import any qt binding"")[SEP]ImportError: Failed to import any qt binding",0
"File <string>, line 1, in <module> [CODE][SEP]ImportError: No module named numpy",0
"File <*>/testing.py, line 10, in <module> model = Model(inputs=model_in, outputs=output)[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/engine/network.py, line 93, in __init__ self._init_graph_network(*args, **kwargs)[SEP]File <*>/site-packages/keras/engine/network.py, line 237, in _init_graph_network self.inputs, self.outputs)[SEP]File <*>/site-packages/keras/engine/network.py, line 1353, in _map_graph_network tensor_index=tensor_index)[SEP]File <*>/site-packages/keras/engine/network.py, line 1340, in build_map node_index, tensor_index)[SEP]File <*>/site-packages/keras/engine/network.py, line 1312, in build_map node = layer._inbound_nodes[node_index][SEP]AttributeError: 'NoneType' object has no attribute '_inbound_nodes'",0
"File lstm_test.py, line 152, in <module> model.fit(samples_train, labels_train, epochs=1, batch_size=1)[SEP]File <*>/site-packages/keras/models.py, line 1002, in fit validation_steps=validation_steps)[SEP]File <*>/site-packages/keras/engine/training.py, line 1630, in fit batch_size=batch_size)[SEP]File <*>/site-packages/keras/engine/training.py, line 1476, in _standardize_user_data exception_prefix='input')[SEP]File <*>/site-packages/keras/engine/training.py, line 113, in _standardize_input_data 'with shape ' + str(data_shape))[SEP]ValueError: Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (134, 1)",0
"File run.py, line 64, in <module> model.fit(images, labels, epochs=1, steps_per_epoch=2)[SEP]File <*>python2.7/site-packages/tensorflow/python/keras/engine/training.py, line 1363, in fit validation_steps=validation_steps)[SEP]File <*>python2.7/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 205, in fit_loop outs = f(ins)[SEP]File <*>python2.7/site-packages/tensorflow/python/keras/backend.py, line 2914, in __call__ fetched = self._callable_fn(*array_vals)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1382, in __call__ run_metadata_ptr)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/errors_impl.py, line 519, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Matrix size-incompatible: In[0]: [10000,1], In[1]: [3,1] [[Node: rgb_to_grayscale/Tensordot/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](rgb_to_grayscale/Tensordot/Reshape, rgb_to_grayscale/Tensordot/Reshape_1)]] [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,100,100,1], [?,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](OneShotIterator)]]",0
"File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2869, in _dep_map return self.__dep_map[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2663, in __getattr__ raise AttributeError(attr)[SEP]AttributeError: _DistInfoDistribution__dep_map",0
"File <*>python3.6/site-packages/pip/_vendor/packaging/requirements.py, line 93, in __init__ req = REQUIREMENT.parseString(requirement_string)[SEP]File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 1632, in parseString raise exc[SEP]File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 1622, in parseString loc, tokens = self._parse( instring, 0 )[SEP]File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 1379, in _parseNoCache loc,tokens = self.parseImpl( instring, preloc, doActions )[SEP]File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 3395, in parseImpl loc, exprtokens = e._parse( instring, loc, doActions )[SEP]File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 1383, in _parseNoCache loc,tokens = self.parseImpl( instring, preloc, doActions )[SEP]File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 3183, in parseImpl raise ParseException(instring, loc, self.errmsg, self)[SEP]pip._vendor.pyparsing.ParseException: Expected stringEnd (at char 33), (line:1, col:34)",0
"File <*>python3.6/site-packages/pip/_internal/basecommand.py, line 141, in main status = self.run(options, args)[SEP]File <*>python3.6/site-packages/pip/_internal/commands/install.py, line 330, in run self._warn_about_conflicts(to_install)[SEP]File <*>python3.6/site-packages/pip/_internal/commands/install.py, line 456, in _warn_about_conflicts package_set, _dep_info = check_install_conflicts(to_install)[SEP]File <*>python3.6/site-packages/pip/_internal/operations/check.py, line 98, in check_install_conflicts package_set = create_package_set_from_installed()[SEP]File <*>python3.6/site-packages/pip/_internal/operations/check.py, line 41, in create_package_set_from_installed package_set[name] = PackageDetails(dist.version, dist.requires())[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2607, in requires dm = self._dep_map[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2871, in _dep_map self.__dep_map = self._compute_dependencies()[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2881, in _compute_dependencies reqs.extend(parse_requirements(req))[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2942, in parse_requirements yield Requirement(line)[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2951, in __init__ raise RequirementParseError(str(e))[SEP]pip._vendor.pkg_resources.RequirementParseError: Invalid requirement, parse error at ""'; extra '""",0
"File noveou_train_netvlad.py, line 226, in <module> minu = keras.layers.Maximum()( [ minu, K.zeros(nN, nP) ] )[SEP]File <*>python2.7/dist-packages/keras/engine/base_layer.py, line 457, in __call__ output = self.call(inputs, **kwargs)[SEP]File <*>python2.7/dist-packages/keras/layers/merge.py, line 115, in call return self._merge_function(reshaped_inputs)[SEP]File <*>python2.7/dist-packages/keras/layers/merge.py, line 301, in _merge_function output = K.maximum(output, inputs[i])[SEP]File <*>python2.7/dist-packages/keras/backend/tensorflow_backend.py, line 1672, in maximum return tf.maximum(x, y)[SEP]File <*>python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 4707, in maximum ""Maximum"", x=x, y=y, name=name)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/op_def_library.py, line 546, in _apply_op_helper inferred_from[input_arg.type_attr]))[SEP]TypeError: Input 'y' of 'Maximum' Op has type string that does not match type float32 of argument 'x'.",0
"File <string>, line 1, in <module> [CODE][SEP]File <*>/setup.py, line 25, in <module> cythonize(ext_modules)[SEP]File <*>/site-packages/Cython/Build/Dependencies.py, line 956, in cythonize aliases=aliases)[SEP]File <*>/site-packages/Cython/Build/Dependencies.py, line 801, in create_extension_list for file in nonempty(sorted(extended_iglob(filepattern)), ""'%s' doesn't match any files"" % filepattern):[SEP]File <*>/site-packages/Cython/Build/Dependencies.py, line 111, in nonempty raise ValueError(error_msg)[SEP]ValueError: 'pycocotools/_mask.pyx' doesn't match any files",0
"File <*>/QuestionStackoverflow.py, line 26, in <module> q_vals_v = net(state_v.view(1, state_v.shape[0], state_v.shape[1]))[SEP]File <*>python3.5/site-packages/torch/nn/modules/module.py, line 477, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>/QuestionStackoverflow.py, line 15, in forward out = self.hidden2tag(out)[SEP]File <*>python3.5/site-packages/torch/nn/modules/, line 55, in forward return F.linear(input, self.weight, self.bias)[SEP]File <*>python3.5/site-packages/torch/nn/functional.py, line 1022, in linear if input.dim() == 2 and bias is not None:[SEP]AttributeError: 'tuple' object has no attribute 'dim'",0
"File <*>/tensor01.py, line 4, in <module> x = torch.Tensor([[.5, .3, 2.1]], requires_grad=False)[SEP]TypeError: new() received an invalid combination of arguments - got (list, requires_grad=bool), but expected one of: * (torch.device device) * (torch.Storage storage) * (Tensor other) * (tuple of ints size, torch.device device) didn't match because some of the keywords were incorrect: requires_grad * (object data, torch.device device) didn't match because some of the keywords were incorrect: requires_grad",0
"File convolutional_network_raw.py, line 137, in <module> writer.add_summary(summary=summary, global_step=step)[SEP]File <*>python3.6/site-packages/tensorflow/python/summary/writer/writer.py, line 126, in add_summary for value in summary.value:[SEP]AttributeError: 'numpy.float32' object has no attribute 'value'",0
"File binary_classification.py, line 59, in <module> history=model.fit(X, y,batch_size=10, epochs=25,validation_split=0.7)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1039, in fit validation_steps=validation_steps)[SEP]File <*>python3.6/site-packages/keras/engine/training_arrays.py, line 217, in fit_loop callbacks.on_epoch_end(epoch, epoch_logs)[SEP]File <*>python3.6/site-packages/keras/callbacks.py, line 79, in on_epoch_end callback.on_epoch_end(epoch, logs)[SEP]File <*>python3.6/site-packages/keras/callbacks.py, line 338, in on_epoch_end self.progbar.update(self.seen, self.log_values)[SEP]AttributeError: 'ProgbarLogger' object has no attribute 'log_values'",0
"File test_loocv.py, line 245, in <module> output = model_ft(test_data)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 477, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/resnet.py, line 139, in forward [CODE][SEP]File <*>python3.6/site-packages/torch/nn/modules/conv.py, line 301, in forward self.padding, self.dilation, self.groups)[SEP]RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[3, 1, 224, 224] to have 3 channels, but got 1 channels instead",0
"File <*>/lesson4-imdb2.py, line 27, in <module> pickle.dump(md, file)[SEP]TypeError: 'generator' object is not callable",0
"File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 204, in _convert_pb_to_mlmodel shape_list = shape.as_list()[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/tensor_shape.py, line 900, in as_list raise ValueError(""as_list() is not defined on an unknown TensorShape."")[SEP]ValueError: as_list() is not defined on an unknown TensorShape.",0
"File model.py, line 6, in <module> class_labels = 'conv_labels.txt'[SEP]File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 586, in convert custom_conversion_functions=custom_conversion_functions)[SEP]File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 206, in _convert_pb_to_mlmodel raise ValueError('Please provide the shape for the input {} through the argument \'input_name_shape_dict\''.format(input_name))[SEP]ValueError: Please provide the shape for the input wav_data:0 through the argument 'input_name_shape_dict'",0
"File model.py, line 7, in <module> class_labels = 'conv_labels.txt'[SEP]File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 586, in convert custom_conversion_functions=custom_conversion_functions)[SEP]File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 153, in _convert_pb_to_mlmodel tf.import_graph_def(gdef, name='')[SEP]File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 316, in new_func return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/importer.py, line 541, in import_graph_def raise ValueError('No op named %s in defined operations.' % node.op)[SEP]ValueError: No op named DecodeWav in defined operations.",0
"File <*>/tst1.py, line 110, in <module> classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)[SEP]File <*>/site-packages/keras/engine/training.py, line 950, in fit batch_size=batch_size)[SEP]File <*>/site-packages/keras/engine/training.py, line 787, in _standardize_user_data exception_prefix='target')[SEP]File <*>/site-packages/keras/engine/training_utils.py, line 137, in standardize_input_data str(data_shape))[SEP]ValueError: Error when checking target: expected dense_3 to have shape (1,) but got array with shape (6,)",0
"File <*>/site-packages/keras/engine/topology.py, line 442, in assert_input_compatibility K.is_keras_tensor(x)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 468, in is_keras_tensor raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '[SEP]ValueError: Unexpectedly found an instance of type `<class 'keras.layers.core.Masking'>`. Expected a symbolic tensor instance.",0
"File <*>/testcompile.py, line 46, in <module> model = network_structure(32, 44, 125)[SEP]File <*>/testcompile.py, line 12, in network_structure lstm_h1 = keras.layers.LSTM(lstm_neurons)(masking)[SEP]File <*>/site-packages/keras/layers/recurrent.py, line 499, in __call__ return super(RNN, self).__call__(inputs, **kwargs)[SEP]File <*>/site-packages/keras/engine/topology.py, line 575, in __call__ self.assert_input_compatibility(inputs)[SEP]File <*>/site-packages/keras/engine/topology.py, line 448, in assert_input_compatibility str(inputs) + '. All inputs to the layer '[SEP]ValueError: Layer lstm_1 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.core.Masking'>. Full input: [<keras.layers.core.Masking object at 0x000002224683A780>]. All inputs to the layer should be tensors.",0
"File <*>/auto_LSTM_try3.py, line 398, in <module> run_experiments(config, search_alg=algo, scheduler=hyperband)[SEP]File <*>python3.6/site-packages/ray/tune/tune.py, line 108, in run_experiments runner.step()[SEP]File <*>python3.6/site-packages/ray/tune/trial_runner.py, line 114, in step next_trial = self._get_next_trial()[SEP]File <*>python3.6/site-packages/ray/tune/trial_runner.py, line 254, in _get_next_trial self._update_trial_queue(blocking=wait_for_trial)[SEP]File <*>python3.6/site-packages/ray/tune/trial_runner.py, line 330, in _update_trial_queue trials = self._search_alg.next_trials()[SEP]File <*>python3.6/site-packages/ray/tune/suggest/suggestion.py, line 67, in next_trials for trial in self._trial_generator:[SEP]File <*>python3.6/site-packages/ray/tune/suggest/suggestion.py, line 88, in _generate_trials suggested_config = self._suggest(trial_id)[SEP]File <*>python3.6/site-packages/ray/tune/suggest/hyperopt.py, line 81, in _suggest self.rstate.randint(2**31 - 1))[SEP]File <*>python3.6/site-packages/hyperopt/tpe.py, line 835, in suggest = tpe_transform(domain, prior_weight, gamma)[SEP]File <*>python3.6/site-packages/hyperopt/tpe.py, line 816, in tpe_transform s_prior_weight[SEP]File <*>python3.6/site-packages/hyperopt/tpe.py, line 690, in build_posterior b_post = fn(*b_args, **dict(named_args))[SEP]TypeError: ap_uniform_sampler() missing 1 required positional argument: 'high'",0
"File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 3078, in get_loc return self._engine.get_loc(key)[SEP]File <*>/index.pyx, line 140, in pandas._libs.index.IndexEngine.get_loc [CODE][SEP]File <*>/index.pyx, line 162, in pandas._libs.index.IndexEngine.get_loc [CODE][SEP]File <*>/hashtable_class_helper.pxi, line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE][SEP]File <*>/hashtable_class_helper.pxi, line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE][SEP]KeyError: range(418, 419)",0
"File <*>/site-packages/flask/app.py, line 1813, in full_dispatch_request rv = self.dispatch_request()[SEP]File <*>/site-packages/flask/app.py, line 1799, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args)[SEP]File <*>/site-packages/flask_restful/__init__.py, line 458, in wrapper resp = resource(*args, **kwargs)[SEP]File <*>/site-packages/flask/views.py, line 88, in view return self.dispatch_request(*args, **kwargs)[SEP]File <*>/site-packages/flask_restful/__init__.py, line 573, in dispatch_request resp = meth(*args, **kwargs)[SEP]File app.py, line 41, in get print(ann.predict(x_test))[SEP]File <*>/site-packages/keras/engine/training.py, line 1164, in predict self._make_predict_function()[SEP]File <*>/site-packages/keras/engine/training.py, line 554, in _make_predict_function **kwargs)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2744, in function return Function(inputs, outputs, updates=updates, **kwargs)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2546, in __init__ with tf.control_dependencies(self.outputs):[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 5004, in control_dependencies return get_default_graph().control_dependencies(control_inputs)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 4543, in control_dependencies c = self.as_graph_element(c)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 3490, in as_graph_element return self._as_graph_element_locked(obj, allow_tensor, allow_operation)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 3569, in _as_graph_element_locked raise ValueError(""Tensor %s is not an element of this graph."" % obj)[SEP]ValueError: Tensor Tensor(""dense_3/Sigmoid:0"", shape=(?, 1), dtype=float32) is not an element of this graph.",0
"File <ipython-input-286-e49b6fac918b>, line 1, in <module> output=model(input_)[SEP]File <*>/site-packages/torch/nn/modules/module.py, line 489, in __call__ result = self.forward(*input, **kwargs)[SEP]TypeError: forward() missing 1 required positional argument: 'p'",0
"File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 138, in _worker_loop samples = collate_fn([dataset[i] for i in batch_indices])[SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 138, in <listcomp> samples = collate_fn([dataset[i] for i in batch_indices])[SEP]File <*>python3.6/site-packages/torch/utils/data/dataset.py, line 103, in __getitem__ return self.dataset[self.indices[idx]][SEP]File <ipython-input-27-107e03bc3c6a>, line 12, in __getitem__ x = torch.tensor(self.x_data.iloc[index].values, dtype=torch.float)[SEP]File <*>python3.6/site-packages/pandas/core/indexing.py, line 1478, in __getitem__ return self._getitem_axis(maybe_callable, axis=axis)[SEP]File <*>python3.6/site-packages/pandas/core/indexing.py, line 2091, in _getitem_axis return self._get_list_axis(key, axis=axis)[SEP]File <*>python3.6/site-packages/pandas/core/indexing.py, line 2070, in _get_list_axis return self.obj._take(key, axis=axis)[SEP]File <*>python3.6/site-packages/pandas/core/generic.py, line 2789, in _take verify=True)[SEP]File <*>python3.6/site-packages/pandas/core/internals.py, line 4537, in take new_labels = self.axes[axis].take(indexer)[SEP]File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 2195, in take return self._shallow_copy(taken)[SEP]File <*>python3.6/site-packages/pandas/core/indexes/range.py, line 267, in _shallow_copy return self._int64index._shallow_copy(values, **kwargs)[SEP]File <*>python3.6/site-packages/pandas/core/indexes/numeric.py, line 68, in _shallow_copy return self._shallow_copy_with_infer(values=values, **kwargs)[SEP]File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 538, in _shallow_copy_with_infer if not len(values) and 'dtype' not in kwargs:[SEP]TypeError: object of type 'numpy.int64' has no len()",0
"File <*>/tensorboard-script.py, line 6, in <module> from tensorboard.main import run_main[SEP]File <*>/site-packages/tensorboard/main.py, line 40, in <module> from tensorboard import default[SEP]File <*>/site-packages/tensorboard/default.py, line 38, in <module> from tensorboard.plugins.beholder import beholder_plugin[SEP]File <*>/site-packages/tensorboard/plugins/beholder/__init__.py, line 15, in <module> from tensorboard.plugins.beholder.beholder import Beholder[SEP]File <*>/site-packages/tensorboard/plugins/beholder/beholder.py, line 25, in <module> from tensorboard.plugins.beholder import im_util[SEP]File <*>/site-packages/tensorboard/plugins/beholder/im_util.py, line 89, in <module> class PNGDecoder(util.PersistentOpEvaluator):[SEP]AttributeError: module 'tensorboard.util' has no attribute 'PersistentOpEvaluator'",0
"File test.py, line 4, in <module> model = load_model(""test.h5"")[SEP]File <*>python3.7/site-packages/keras/engine/saving.py, line 419, in load_model model = _deserialize_model(f, custom_objects, compile)[SEP]File <*>python3.7/site-packages/keras/engine/saving.py, line 258, in _deserialize_model .format(len(layer_names), len(filtered_layers))[SEP]ValueError: You are trying to load a weight file containing 6 layers into a model with 0 layers",0
"File <*>/SVM_Stock.py, line 71, in <module> estimator.fit(x,y)[SEP]File <*>/site-packages/keras/wrappers/scikit_learn.py, line 210, in fit return super(KerasClassifier, self).fit(x, y, **kwargs)[SEP]File <*>/site-packages/keras/wrappers/scikit_learn.py, line 139, in fit **self.filter_sk_params(self.build_fn.__call__))[SEP]TypeError: __call__() missing 1 required positional argument: 'inputs'",0
"File test.py, line 141, in <module> max_queue_size=2)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 2177, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 147, in fit_generator generator_output = next(output_generator)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py, line 831, in get six.reraise(value.__class__, value, value.__traceback__)[SEP]File <*>python3.6/site-packages/six.py, line 693, in reraise raise value[SEP]TypeError: 'My_Generator' object is not an iterator",0
"File 6_reconstruct_alphabet_image.py, line 17, in <module> import caffe[SEP]File <*>python3/dist-packages/caffe/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer[SEP]File <*>python3/dist-packages/caffe/pycaffe.py, line 15, in <module> import caffe.io[SEP]File <*>python3/dist-packages/caffe/io.py, line 2, in <module> import skimage.io[SEP]File <*>python3/dist-packages/skimage/__init__.py, line 158, in <module> from .util.dtype import *[SEP]File <*>python3/dist-packages/skimage/util/__init__.py, line 7, in <module> from .arraycrop import crop[SEP]File <*>python3/dist-packages/skimage/util/arraycrop.py, line 8, in <module> from numpy.lib.arraypad import _validate_lengths[SEP]ImportError: cannot import name '_validate_lengths'",0
"File [FILE], line <*>, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow_<em>init</em>_.py, line 24, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow/python_<em>init</em>_.py, line 59, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in [FUNC] [CODE][SEP]File <*>/site-packages/google/protobuf/descriptor.py, line 47, in [FUNC] [CODE][SEP]ImportError: DLL load failed: The specified procedure could not be found.",0
"File <*>/WorkOut.py, line 416, in <module> main()[SEP]File <*>/WorkOut.py, line 412, in main train(args, model, device, train_loader, optimizer, epoch)[SEP]File <*>/WorkOut.py, line 324, in train loss = F.nll_loss(output, target)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1788, in nll_loss .format(input.size(0), target.size(0)))[SEP]ValueError: Expected input batch_size (4) to match target batch_size (64).",0
"File <*>python3.6/site-packages/theano/compile/function_module.py, line 884, in __call__ self.fn() if output_subset is None else\[SEP]ValueError: Input dimension mis-match. (input[0].shape[1] = 50, input[1].shape[1] = 100)",0
"File <*>/pydevd.py, line 1741, in <module> main()[SEP]File <*>/pydevd.py, line 1735, in main globals = debugger.run(setup['file'], None, None, is_module)[SEP]File <*>/pydevd.py, line 1135, in run pydev_imports.execfile(file, globals, locals) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/MnistTrainer.py, line 100, in <module> main()[SEP]File <*>/MnistTrainer.py, line 92, in main mnist_trainer.train(train_steps=100, log_interval=1, save_interval=1)[SEP]File <*>/MnistTrainer.py, line 56, in train self.save_models(output_folder_path, i + 1)[SEP]File <*>/MnistTrainer.py, line 69, in save_models os.path.join(output_folder_path, 'discriminator_model_{0}.h5'.format(iteration_no)))[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 1090, in save save_model(self, filepath, overwrite, include_optimizer)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 382, in save_model _serialize_model(model, f, include_optimizer)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 83, in _serialize_model model_config['config'] = model.get_config()[SEP]File <*>python3.6/site-packages/keras/engine/sequential.py, line 278, in get_config 'config': layer.get_config()[SEP]File <*>python3.6/site-packages/keras/layers/convolutional.py, line 493, in get_config config = super(Conv2D, self).get_config()[SEP]File <*>python3.6/site-packages/keras/layers/convolutional.py, line 226, in get_config 'activation': activations.serialize(self.activation),[SEP]File <*>python3.6/site-packages/keras/activations.py, line 176, in serialize return activation.__name__[SEP]AttributeError: 'LeakyReLU' object has no attribute '__name__'",0
"File <*>/train.py, line 107, in <module> callbacks=[Saver(save_every), Evaluation(evaluate_every)])[SEP]File <*>/site-packages/keras/engine/training.py, line 1039, in fit validation_steps=validation_steps)[SEP]File <*>/site-packages/keras/engine/training_arrays.py, line 204, in fit_loop callbacks.on_batch_end(batch_index, batch_logs)[SEP]File <*>/site-packages/keras/callbacks.py, line 115, in on_batch_end callback.on_batch_end(batch, logs)[SEP]File <*>/train.py, line 83, in on_batch_end self.model.save(name)[SEP]File <*>/site-packages/keras/engine/network.py, line 1090, in save save_model(self, filepath, overwrite, include_optimizer)[SEP]File <*>/site-packages/keras/engine/saving.py, line 382, in save_model _serialize_model(model, f, include_optimizer)[SEP]File <*>/site-packages/keras/engine/saving.py, line 83, in _serialize_model model_config['config'] = model.get_config()[SEP]File <*>/site-packages/keras/engine/network.py, line 931, in get_config return copy.deepcopy(config)[SEP]File <*>/copy.py, line 150, in deepcopy y = copier(x, memo)[SEP]File <*>/copy.py, line 240, in _deepcopy_dict y[deepcopy(key, memo)] = deepcopy(value, memo)[SEP]File <*>/copy.py, line 215, in _deepcopy_list append(deepcopy(a, memo))[SEP]File <*>/copy.py, line 220, in _deepcopy_tuple y = [deepcopy(a, memo) for a in x][SEP]File <*>/copy.py, line 220, in <listcomp> y = [deepcopy(a, memo) for a in x][SEP]File <*>/copy.py, line 180, in deepcopy y = _reconstruct(x, memo, *rv)[SEP]File <*>/copy.py, line 280, in _reconstruct state = deepcopy(state, memo)[SEP]File <*>/copy.py, line 169, in deepcopy rv = reductor(4)[SEP]TypeError: can't pickle _thread.RLock objects",0
"File <stdin>, line 1, in <module> [CODE][SEP]RuntimeError: Could not infer dtype of generator",0
"File <*>/min_working_example.py, line 37, in <module> model.fit(data_generator)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 873, in fit steps_name='steps_per_epoch')[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 352, in model_iteration batch_outs = f(ins_batch)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/backend.py, line 3217, in __call__ outputs = self._graph_fn(*converted_inputs)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 558, in __call__ return self._call_flat(args)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 627, in _call_flat outputs = self._inference_function.call(ctx, args)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 397, in call (len(args), len(list(self.signature.input_arg))))[SEP]ValueError: Arguments and signature arguments do not match: 21 23",0
"File <*>/min_working_example.py, line 37, in <module> model.fit_generator(data_generator)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 1515, in fit_generator steps_name='steps_per_epoch')[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py, line 140, in model_iteration shuffle=shuffle)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py, line 477, in convert_to_generator_like raise ValueError('You must specify `batch_size`')[SEP]ValueError: You must specify `batch_size`",0
"File <*>/testo.py, line 18, in <module> optim.minimize(loss, var_list=network.weights)[SEP]AttributeError: 'Adam' object has no attribute 'minimize'",0
"File pretrain_lm.py, line 7, in <module> import fastai[SEP]File <*>python3.7/site-packages/fastai/__init__.py, line 1, in <module> from .basic_train import *[SEP]File <*>python3.7/site-packages/fastai/basic_train.py, line 2, in <module> from .torch_core import *[SEP]File <*>python3.7/site-packages/fastai/torch_core.py, line 2, in <module> from .imports.torch import *[SEP]File <*>python3.7/site-packages/fastai/imports/__init__.py, line 2, in <module> from .torch import *[SEP]File <*>python3.7/site-packages/fastai/imports/torch.py, line 1, in <module> import torch, torch.nn.functional as F[SEP]File <*>python3.7/site-packages/torch/__init__.py, line 84, in <module> from torch._C import *[SEP]ImportError: libtorch_python.so: cannot open shared object file: No such file or directory",0
"File <*>/train.py, line 184, in <module> tf.app.run()[SEP]File <*>python3.6/site-packages/tensorflow/python/platform/app.py, line 125, in run _sys.exit(main(argv))[SEP]File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 324, in new_func return func(*args, **kwargs)[SEP]File <*>/train.py, line 180, in main graph_hook_fn=graph_rewriter_fn)[SEP]File <*>/trainer.py, line 416, in train saver=saver)[SEP]File <*>python3.6/site-packages/tensorflow/contrib/slim/python/slim/learning.py, line 785, in train ignore_live_threads=ignore_live_threads)[SEP]File <*>python3.6/site-packages/tensorflow/python/training/supervisor.py, line 832, in stop ignore_live_threads=ignore_live_threads)[SEP]File <*>python3.6/site-packages/tensorflow/python/training/coordinator.py, line 389, in join six.reraise(*self._exc_info_to_raise)[SEP]File <*>python3.6/site-packages/six.py, line 693, in reraise raise value[SEP]File <*>python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py, line 257, in _run enqueue_callable()[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1257, in _single_operation_run self._call_tf_sessionrun(None, {}, [], target_list, None)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1407, in _call_tf_sessionrun run_metadata)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[15,1,1755,2777,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [[{{node batch}}]]",0
"File <*>/vis.py, line 28, in <module> from deeplab import common[SEP]ModuleNotFoundError: No module named 'deeplab'",0
"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: module 'tensorflow' has no attribute 'estimator'",0
"File <*>python3.7/site-packages/conda/exceptions.py, line 819, in __call__ return func(*args, **kwargs)[SEP]File <*>python3.7/site-packages/conda/cli/main.py, line 78, in _main exit_code = do_call(args, p)[SEP]File <*>python3.7/site-packages/conda/cli/conda_argparse.py, line 77, in do_call exit_code = getattr(module, func_name)(args, parser)[SEP]File <*>python3.7/site-packages/conda/cli/main_update.py, line 14, in execute install(args, parser, 'update')[SEP]File <*>python3.7/site-packages/conda/cli/install.py, line 253, in install handle_txn(unlink_link_transaction, prefix, args, newenv)[SEP]File <*>python3.7/site-packages/conda/cli/install.py, line 282, in handle_txn unlink_link_transaction.execute()[SEP]File <*>python3.7/site-packages/conda/core/link.py, line 223, in execute self.verify()[SEP]File <*>python3.7/site-packages/conda/common/io.py, line 46, in decorated return f(*args, **kwds)[SEP]File <*>python3.7/site-packages/conda/core/link.py, line 200, in verify self.prepare()[SEP]File <*>python3.7/site-packages/conda/core/link.py, line 192, in prepare stp.remove_specs, stp.update_specs)[SEP]File <*>python3.7/site-packages/conda/core/link.py, line 282, in _prepare mkdir_p(transaction_context['temp_dir'])[SEP]File <*>python3.7/site-packages/conda/gateways/disk/__init__.py, line 60, in mkdir_p makedirs(path)[SEP]File <*>python3.7/os.py, line 221, in makedirs mkdir(name, mode)[SEP]PermissionError: [Errno 13] Permission denied: '/usr/share/anaconda3/.condatmp'",0
"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: cannot import name 'estimator' from 'tensorflow' (/home/cjs/.conda/envs/my-env/lib/python3.7/site-packages/tensorflow/__init__.py)",0
"File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.7/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.7/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: /usr/lib/libcublas.so.10.0: version `libcublas.so.10.0' not found (required by /home/techievin/.local/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)",0
"File <*>/extra_classes.py, line 31, in <module> model_out = MyLayer(2)(model_in)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 746, in __call__ self.build(input_shapes)[SEP]File <*>/extra_classes.py, line 20, in build trainable=True)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 609, in add_weight aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/training/checkpointable/base.py, line 639, in _add_variable_with_custom_getter **kwargs_for_getter)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1977, in make_variable aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 183, in __call__ return cls._variable_v1_call(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 146, in _variable_v1_call aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 125, in <lambda> previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variable_scope.py, line 2437, in default_variable_creator import_scope=import_scope)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 187, in __call__ return super(VariableMetaclass, cls).__call__(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 297, in __init__ constraint=constraint)[SEP]File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 409, in _init_from_args initial_value() if init_from_fn else initial_value,[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1959, in <lambda> shape, dtype=dtype, partition_info=partition_info)[SEP]File <*>/site-packages/tensorflow/python/ops/init_ops.py, line 255, in __call__ shape, self.minval, self.maxval, dtype, seed=self.seed)[SEP]File <*>/site-packages/tensorflow/python/ops/random_ops.py, line 235, in random_uniform shape = _ShapeTensor(shape)[SEP]File <*>/site-packages/tensorflow/python/ops/random_ops.py, line 44, in _ShapeTensor return ops.convert_to_tensor(shape, dtype=dtype, name=""shape"")[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 1050, in convert_to_tensor as_ref=False)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 1146, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 229, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 208, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 531, in make_tensor_proto ""supported type."" % (type(values), values))[SEP]TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (Dimension(4), 2). Consider casting elements to a supported type.",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.5/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>python3.5/site-packages/tensorflow/python/__init__.py, line 52, in <module> from tensorflow.core.framework.graph_pb2 import *[SEP]File <*>python3.5/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in <module> from google.protobuf import descriptor as _descriptor[SEP]File <*>python3.5/site-packages/google/protobuf/descriptor.py, line 47, in <module> from google.protobuf.pyext import _message[SEP]ImportError: /home/work/.conda/envs/tensorflow/lib/python3.5/site-packages/google/protobuf/pyext/_message.cpython-35m-x86_64-linux-gnu.so: undefined symbol: _ZNK6google8protobuf10TextFormat17FieldValuePrinter9PrintBoolEb",0
"File classifier_model.py, line 115, in <module> model.fit_generator(generator.flow(train_images, train_labels, batch_size=BATCH_SIZE), epochs=num_epochs)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1426, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 191, in model_iteration batch_outs = batch_function(*batch_data)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1191, in train_on_batch outputs = self._fit_function(ins) # pylint: disable=not-callable[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/backend.py, line 3076, in __call__ run_metadata=self.run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1439, in __call__ run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: logits and labels must have the same first dimension, got logits shape [1,7] and labels shape [7] [[{{node loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]",0
"File train.py, line 293, in <module> main()[SEP]File train.py, line 271, in main feed_dict={context: sample_batch()})[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 929, in run run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1152, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1328, in _do_run run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1348, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[51200,2304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[node model/h0/attn/c_attn/MatMul (defined at D:\Python and AI\Generative Chatbot\gpt-2\src\model.py:55) ]]",0
"File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.5/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.5/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: /usr/lib/aarch64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.22' not found (required by /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so)",0
"File <*>/mnist.py, line 69, in <module> train(epoch)[SEP]File <*>/mnist.py, line 60, in train loss = criterion(out, target)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 493, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/loss.py, line 942, in forward ignore_index=self.ignore_index, reduction=self.reduction)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 2056, in cross_entropy return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1869, in nll_loss .format(input.size(0), target.size(0)))[SEP]ValueError: Expected input batch_size (12) to match target batch_size (64).",0
"File <*>/pydevd.py, line 1758, in <module> main()[SEP]File <*>/pydevd.py, line 1752, in main globals = debugger.run(setup['file'], None, None, is_module)[SEP]File <*>/pydevd.py, line 1147, in run pydev_imports.execfile(file, globals, locals) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/deep_test_conv1d.py, line 231, in <module> main()[SEP]File <*>/deep_test_conv1d.py, line 149, in main for i, (images, labels) in enumerate(train_loader):[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 615, in __next__ batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 615, in <listcomp> batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>/deep_test_conv1d.py, line 102, in __getitem__ return self.transform(self.features[index]), self.transform(self.classes[index])[SEP]File <*>/site-packages/torchvision/transforms/transforms.py, line 60, in __call__ img = t(img)[SEP]File <*>/site-packages/torchvision/transforms/transforms.py, line 91, in __call__ return F.to_tensor(pic)[SEP]File <*>/site-packages/torchvision/transforms/functional.py, line 50, in to_tensor raise TypeError('pic should be PIL Image or ndarray. Got {}'.format(type(pic)))[SEP]TypeError: pic should be PIL Image or ndarray. Got <class 'numpy.ndarray'>",0
"File <*>/model.py, line 24, in <module> image = mnist_example[""image""][SEP]TypeError: 'DatasetV1Adapter' object is not subscriptable",0
"File train.py, line 194, in <module> _main()[SEP]File train.py, line 69, in _main callbacks=[logging, checkpoint])[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/engine/training.py, line 1418, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>/site-packages/keras/engine/training_generator.py, line 251, in fit_generator callbacks.on_epoch_end(epoch, epoch_logs)[SEP]File <*>/site-packages/keras/callbacks.py, line 79, in on_epoch_end callback.on_epoch_end(epoch, logs)[SEP]File <*>/site-packages/keras/callbacks.py, line 429, in on_epoch_end filepath = self.filepath.format(epoch=epoch + 1, **logs)[SEP]KeyError: 'val_loss'",0
"File <*>/train_fit.py, line 286, in <module> validation_steps=None) #devset_steps_per_epoch)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 780, in fit steps_name='steps_per_epoch')[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 374, in model_iteration callbacks._call_batch_hook(mode, 'end', batch_index, batch_logs)[SEP]File <*>/site-packages/tensorflow/python/keras/callbacks.py, line 248, in _call_batch_hook batch_hook(batch, logs)[SEP]File <*>/site-packages/tensorflow/python/keras/callbacks.py, line 531, in on_train_batch_end self.on_batch_end(batch, logs=logs)[SEP]File <*>/site-packages/tensorflow/python/keras/callbacks_v1.py, line 362, in on_batch_end profiler.save(self.log_dir, profiler.stop())[SEP]File <*>/site-packages/tensorflow/python/eager/profiler.py, line 144, in save gfile.MakeDirs(plugin_dir)[SEP]File <*>/site-packages/tensorflow/python/lib/io/file_io.py, line 438, in recursive_create_dir recursive_create_dir_v2(dirname)[SEP]File <*>/site-packages/tensorflow/python/lib/io/file_io.py, line 453, in recursive_create_dir_v2 pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(path))[SEP]tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: ./logs\plugins\profile\2019-07-02_13-04-26; No such file or directory",0
"File <*>python3.6/site-packages/tensorflow/python/framework/importer.py, line 427, in import_graph_def graph._c_graph, serialized, options) # pylint: disable=protected-access[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Input 1 of node StatefulPartitionedCall was passed float from conv2d/kernel:0 incompatible with expected resource.",0
"File <*>/tensorrt.py, line 23, in <module> converter.save(saved_model_dir_trt)[SEP]File <*>python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py, line 822, in save super(TrtGraphConverter, self).save(output_saved_model_dir)[SEP]File <*>python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py, line 432, in save importer.import_graph_def(self._converted_graph_def, name="""")[SEP]File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/importer.py, line 431, in import_graph_def raise ValueError(str(e))[SEP]ValueError: Input 1 of node StatefulPartitionedCall was passed float from conv2d/kernel:0 incompatible with expected resource.",0
"File <*>/debug_multiple_input_model.py, line 39, in <module> model.predict(zipped_input)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1054, in predict callbacks=callbacks)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training_generator.py, line 264, in model_iteration batch_outs = batch_function(*batch_data)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training_generator.py, line 536, in predict_on_batch return model.predict_on_batch(x)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1281, in predict_on_batch x, extract_tensors_from_dataset=True)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 2651, in _standardize_user_data exception_prefix='input')[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training_utils.py, line 346, in standardize_input_data str(len(data)) + ' arrays: ' + str(data)[:200] + '...')[SEP]ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [<tf.Tensor: id=71049, shape=(10, 100, 5), dtype=float64, numpy= array([[[0.54049765, 0.64218937, 0.31734092, 0.81307839, 0.75465237], [0.32371089, 0.85923477, 0.60619924, 0.68692891, 0.186234...",0
"File <*>/site-packages/tensorflow/python/platform/self_check.py, line 62, in preload_check ctypes.WinDLL(build_info.nvcuda_dll_name)[SEP]File <*>/__init__.py, line 356, in __init__ self._handle = _dlopen(self._name, mode)[SEP]OSError: [WinError 126] Das angegebene Modul wurde nicht gefunden",0
"File <*>python3.6/managers.py, line 228, in serve_client request = recv()[SEP]File <*>python3.6/connection.py, line 251, in recv return _ForkingPickler.loads(buf.getbuffer())[SEP]File <*>python3.6/site-packages/torch/multiprocessing/reductions.py, line 276, in rebuild_storage_fd fd = df.detach()[SEP]File <*>python3.6/resource_sharer.py, line 58, in detach return reduction.recv_handle(conn)[SEP]File <*>python3.6/reduction.py, line 182, in recv_handle return recvfds(s, 1)[0][SEP]File <*>python3.6/reduction.py, line 161, in recvfds len(ancdata))[SEP]RuntimeError: received 0 items of ancdata",0
"File <*>python3.6/dist-packages/pip/_internal/cli/base_command.py, line 178, in main status = self.run(options, args)[SEP]File <*>python3.6/dist-packages/pip/_internal/commands/install.py, line 326, in run self.name, wheel_cache[SEP]File <*>python3.6/dist-packages/pip/_internal/cli/base_command.py, line 268, in populate_requirement_set wheel_cache=wheel_cache[SEP]File <*>python3.6/dist-packages/pip/_internal/req/constructors.py, line 248, in install_req_from_line ""nor 'pyproject.toml' found."" % name[SEP]pip._internal.exceptions.InstallationError: Directory './' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.",0
"File <*>/bacteria_rcnn_train.py, line 53, in <module> import keras[SEP]File <*>python3.5/dist-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>python3.5/dist-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils[SEP]File <*>python3.5/dist-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K[SEP]File <*>python3.5/dist-packages/keras/backend/__init__.py, line 84, in <module> from .tensorflow_backend import *[SEP]File <*>python3.5/dist-packages/keras/backend/tensorflow_backend.py, line 5, in <module> import tensorflow as tf[SEP]File <*>python3.5/dist-packages/tensorflow/__init__.py, line 28, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>python3.5/dist-packages/tensorflow/python/__init__.py, line 83, in <module> from tensorflow.python import keras[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/__init__.py, line 26, in <module> from tensorflow.python.keras import activations[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/activations/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.activations import elu[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/_impl/keras/__init__.py, line 21, in <module> from tensorflow.python.keras._impl.keras import activations[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/_impl/keras/activations.py, line 23, in <module> from tensorflow.python.keras._impl.keras import backend as K[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py, line 38, in <module> from tensorflow.python.layers import base as tf_base_layers[SEP]File <*>python3.5/dist-packages/tensorflow/python/layers/base.py, line 25, in <module> from tensorflow.python.keras import backend[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/backend/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.backend import abs[SEP]ImportError: cannot import name 'abs'",0
"File <string>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/torch/cuda/__init__.py, line 163, in _lazy_init torch._C._cuda_init()[SEP]RuntimeError: cuda runtime error (38) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1556653099582/work/aten/src/THC/THCGeneral.cpp:51",0
"File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>python3.6/site-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils[SEP]File <*>python3.6/site-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K[SEP]File <*>python3.6/site-packages/keras/backend/__init__.py, line 1, in <module> from .load_backend import epsilon[SEP]File <*>python3.6/site-packages/keras/backend/load_backend.py, line 90, in <module> from .tensorflow_backend import *[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 13, in <module> from tensorflow.python.keras.utils import tf_utils[SEP]ImportError: cannot import name 'tf_utils'",0
"File file.py, line 2, in <module> from torch.utils.data import Dataset, DataLoader[SEP]ModuleNotFoundError: No module named 'torch'",0
"File <stdin>, line 1, in <module> [CODE][SEP]ModuleNotFoundError: No module named 'torch'",0
"File test_transform.py, line 87, in <module> for batch_idx, image, mask in enumerate(train_loader):[SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 314, in __next__ batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 314, in <listcomp> batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>python3.6/site-packages/torch/utils/data/dataset.py, line 103, in __getitem__ return self.dataset[self.indices[idx]][SEP]File <*>/data.py, line 164, in __getitem__ img, mask = self.transforms(img, mask)[SEP]File <*>/augmentations.py, line 17, in __call__ img, mask = a(img, mask)[SEP]TypeError: __call__() takes 2 positional arguments but 3 were given",0
"File classify_in_out_tf2.py, line 81, in [FUNC] [CODE][SEP]AttributeError: 'AutoTrackable' object has no attribute 'summary'",0
"File <ipython-input-12-f8636d3ba083>, line 26, in <module> predict(model, ""/home/x/?Deep_Learning/pytorch/MNIST/test/2/QQ?0191022093955.png"")[SEP]File <ipython-input-12-f8636d3ba083>, line 9, in predict test_image_tensor = transform(test_image)[SEP]File <*>python3.6/site-packages/torchvision/transforms/transforms.py, line 61, in __call__ img = t(img)[SEP]File <*>python3.6/site-packages/torchvision/transforms/transforms.py, line 166, in __call__ return F.normalize(tensor, self.mean, self.std, self.inplace)[SEP]File <*>python3.6/site-packages/torchvision/transforms/functional.py, line 217, in normalize tensor.sub_(mean[:, None, None]).div_(std[:, None, None])[SEP]RuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0",0
"File <*>/prova_bert.py, line 230, in <module> model = baseline_model(output_size, max_seq_len, visualize=True)[SEP]File <*>/prova_bert.py, line 165, in baseline_model )(bert_embeddings)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/wrappers.py, line 473, in __call__ return super(Bidirectional, self).__call__(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 746, in __call__ self.build(input_shapes)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/wrappers.py, line 612, in build self.forward_layer.build(input_shape)[SEP]File <*>/site-packages/tensorflow/python/keras/utils/tf_utils.py, line 149, in wrapper output_shape = fn(instance, input_shape)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/recurrent.py, line 552, in build self.cell.build(step_input_shape)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/recurrent.py, line 1934, in build constraint=self.kernel_constraint)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 609, in add_weight aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/training/checkpointable/base.py, line 639, in _add_variable_with_custom_getter **kwargs_for_getter)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1977, in make_variable aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 183, in __call__ return cls._variable_v1_call(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 146, in _variable_v1_call aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 125, in <lambda> previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variable_scope.py, line 2437, in default_variable_creator import_scope=import_scope)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 187, in __call__ return super(VariableMetaclass, cls).__call__(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 297, in __init__ constraint=constraint)[SEP]File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 409, in _init_from_args initial_value() if init_from_fn else initial_value,[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1959, in <lambda> shape, dtype=dtype, partition_info=partition_info)[SEP]File <*>/site-packages/tensorflow/python/ops/init_ops.py, line 473, in __call__ scale /= max(1., (fan_in + fan_out) / 2.)[SEP]TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'",0
"File <*>/Program.py, line 88, in FitModel model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 224, in fit distribution_strategy=strategy)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 547, in _process_training_inputs use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 606, in _process_inputs use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 479, in __init__ batch_size=batch_size, shuffle=shuffle, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 321, in __init__ dataset_ops.DatasetV2.from_tensors(inputs).repeat()[SEP]File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 414, in from_tensors return TensorDataset(tensors)[SEP]File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 2335, in __init__ element = structure.normalize_element(element)[SEP]File <*>/site-packages/tensorflow_core/python/data/util/structure.py, line 111, in normalize_element ops.convert_to_tensor(t, name=""component_%d"" % i))[SEP]File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1184, in convert_to_tensor return convert_to_tensor_v2(value, dtype, preferred_dtype, name)[SEP]File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1242, in convert_to_tensor_v2 as_ref=False)[SEP]File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1296, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py, line 52, in _default_conversion_function return constant_op.constant(value, dtype, name=name)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 227, in constant allow_broadcast=True)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 235, in _constant_impl t = convert_to_eager_tensor(value, ctx, dtype)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 96, in convert_to_eager_tensor return ops.EagerTensor(value, ctx.device_name, dtype)[SEP]ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float).",0
"File <input>, line 1, in <module> [CODE][SEP]AttributeError: module 'keras.applications' has no attribute 'resnet_v2'",0
"File <input>, line 1, in <module> [CODE][SEP]File <*>/pydev_umd.py, line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/train_model_so.py, line 108, in <module> print(""x shape is"" , x.shape())[SEP]TypeError: 'TensorShape' object is not callable",0
"File <*>/train_model.py, line 110, in <module> model.fit(train_dataset, epochs=5)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit 1/Unknown - 0s 13ms/step 1/Unknown - 0s 13ms/step use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 324, in fit total_epochs=epochs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 123, in run_one_epoch batch_outs = execution_function(iterator)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 86, in execution_function distributed_function(input_fn))[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__ result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call self._initialize(args, kwds, add_initializers_to=initializer_map)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize *args, **kwds))[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function capture_by_value=self._capture_by_value),[SEP]File <*>/site-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 66, in distributed_function model, input_iterator, mode)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 112, in _prepare_feed_values inputs, targets, sample_weights = _get_input_from_iterator(inputs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 149, in _get_input_from_iterator distribution_strategy_context.get_strategy(), x, y, sample_weights)[SEP]File <*>/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py, line 308, in validate_distributed_dataset_inputs x_values_list = validate_per_replica_inputs(distribution_strategy, x)[SEP]File <*>/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py, line 356, in validate_per_replica_inputs validate_all_tensor_shapes(x, x_values)[SEP]File <*>/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py, line 373, in validate_all_tensor_shapes x_shape = x_values[0].shape.as_list()[SEP]File <*>/site-packages/tensorflow_core/python/framework/tensor_shape.py, line 1171, in as_list raise ValueError(""as_list() is not defined on an unknown TensorShape."")[SEP]ValueError: as_list() is not defined on an unknown TensorShape.",0
"File <ipython-input-1-f9d072fc6a73>, line 19, in <module> onnx_model = keras2onnx.convert_keras(model)[SEP]File <*>/site-packages/keras2onnx/main.py, line 67, in convert_keras "" Please set environment variable TF_KERAS = 1."")[SEP]Exception: This is a tensorflow keras model, but keras standalone converter is used. Please set environment variable TF_KERAS = 1.",0
"File <*>python3.6/dist-packages/torch/utils/data/_utils/worker.py, line 178, in _worker_loop data = fetcher.fetch(index)[SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp> data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <ipython-input-180-0b00b175e18c>, line 72, in __getitem__ image = self.transform(image)[SEP]File <*>python3.6/dist-packages/torchvision/transforms/transforms.py, line 70, in __call__ img = t(img)[SEP]File <*>python3.6/dist-packages/torchvision/transforms/transforms.py, line 175, in __call__ return F.normalize(tensor, self.mean, self.std, self.inplace)[SEP]File <*>python3.6/dist-packages/torchvision/transforms/functional.py, line 217, in normalize tensor.sub_(mean[:, None, None]).div_(std[:, None, None])[SEP]RuntimeError: output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]",0
"File tf_1_day_scikit_dnn.py, line 12, in <module> from sklearn import decomposition[SEP]File <*>python3.6/site-packages/sklearn/decomposition/__init__.py, line 19, in <module> from ._online_lda import LatentDirichletAllocation[SEP]ImportError: cannot import name 'LatentDirichletAllocation'",0
"File <*>python37/runpy.py, line 193, in _run_module_as_main ""__main__"", mod_spec)[SEP]File <*>python37/runpy.py, line 85, in _run_code exec(code, run_globals)[SEP]File <*>/__main__.py, line 9, in <module> [CODE][SEP]File <*>/site-packages/flask/cli.py, line 966, in main cli.main(prog_name=""python -m flask"" if as_module else None)[SEP]File <*>/site-packages/flask/cli.py, line 586, in main return super(FlaskGroup, self).main(*args, **kwargs)[SEP]File <*>/site-packages/click/core.py, line 717, in main rv = self.invoke(ctx)[SEP]File <*>/site-packages/click/core.py, line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx))[SEP]File <*>/site-packages/click/core.py, line 956, in invoke return ctx.invoke(self.callback, **ctx.params)[SEP]File <*>/site-packages/click/core.py, line 555, in invoke return callback(*args, **kwargs)[SEP]File <*>/site-packages/click/decorators.py, line 64, in new_func return ctx.invoke(f, obj, *args, **kwargs)[SEP]File <*>/site-packages/flask/cli.py, line 860, in run_command extra_files=extra_files,[SEP]File <*>/site-packages/werkzeug/serving.py, line 1008, in run_simple run_with_reloader(inner, extra_files, reloader_interval, reloader_type)[SEP]File <*>/site-packages/werkzeug/_reloader.py, line 337, in run_with_reloader reloader.run()[SEP]File <*>/site-packages/werkzeug/_reloader.py, line 202, in run for filename in chain(_iter_module_files(), self.extra_files):[SEP]File <*>/site-packages/werkzeug/_reloader.py, line 24, in _iter_module_files filename = getattr(module, ""__file__"", None)[SEP]File <*>/site-packages/tensorflow/__init__.py, line 50, in __getattr__ module = self._load()[SEP]File <*>/site-packages/tensorflow/__init__.py, line 44, in _load module = _importlib.import_module(self.__name__)[SEP]File <*>python37/__init__.py, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <frozen importlib._bootstrap>, line 1006, in _gcd_import [CODE][SEP]File <frozen importlib._bootstrap>, line 983, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 965, in _find_and_load_unlocked [CODE][SEP]ModuleNotFoundError: No module named 'tensorflow_core.keras'",0
"File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 61, in quick_execute num_outputs)[SEP]TypeError: An op outside of the function building code is being passed",0
"File <*>/N09.py, line 363, in <module> main()[SEP]File <*>/N09.py, line 343, in main args.save_interval)[SEP]File <*>/N09.py, line 92, in train_model verbose=self.verbose)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 1297, in fit_generator steps_name='steps_per_epoch')[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py, line 265, in model_iteration batch_outs = batch_function(*batch_data)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 973, in train_on_batch class_weight=class_weight, reset_metrics=reset_metrics)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch output_loss_metrics=model._output_loss_metrics)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch output_loss_metrics=output_loss_metrics))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 268, in _process_single_batch grads = tape.gradient(scaled_total_loss, trainable_weights)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/backprop.py, line 1014, in gradient unconnected_gradients=unconnected_gradients)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py, line 76, in imperative_grad compat.as_str(unconnected_gradients.value))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 911, in _backward_function_wrapper processed_args, remapped_captures)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1224, in _call_flat ctx, args, cancellation_manager=cancellation_manager)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 511, in call ctx=ctx)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 75, in quick_execute ""tensors, but found {}"".format(keras_symbolic_tensors))[SEP]tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'StridedSliceGrad:0' shape=(16, 64, 64, 3) dtype=float32>]",0
"File <*>/data.py, line 4, in <module> import torchvision[SEP]ModuleNotFoundError: No module named 'torchvision'",0
"File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1455, in __del__ self._session._session, self._handle, status)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: No such callable handle: 94697914208640",0
"File <*>/cnn.py, line 70, in <module> validation_steps = 2000)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 1297, in fit_generator steps_name='steps_per_epoch')[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_generator.py, line 265, in model_iteration batch_outs = batch_function(*batch_data)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 973, in train_on_batch class_weight=class_weight, reset_metrics=reset_metrics)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch output_loss_metrics=model._output_loss_metrics)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch output_loss_metrics=output_loss_metrics))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 252, in _process_single_batch training=training))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 127, in _model_loss outs = model(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 891, in __call__ outputs = self.call(cast_inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/sequential.py, line 256, in call return super(Sequential, self).call(inputs, training=training, mask=mask)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 708, in call convert_kwargs_to_constants=base_layer_utils.call_context().saving)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 860, in _run_internal_graph output_tensors = layer(computed_tensors, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/layers/convolutional.py, line 197, in call outputs = self._convolution_op(inputs, self.kernel)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 1134, in __call__ return self.conv_op(inp, filter)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 639, in __call__ return self.call(inp, filter)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 238, in __call__ name=self.name)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 2010, in conv2d name=name)[SEP]File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1031, in conv2d data_format=data_format, dilations=dilations, name=name, ctx=_ctx)[SEP]File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1130, in conv2d_eager_fallback ctx=_ctx, name=name)[SEP]File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]",0
"File <*>/pydevd.py, line 1741, in <module> main()[SEP]File <*>/pydevd.py, line 1735, in main globals = debugger.run(setup['file'], None, None, is_module)[SEP]File <*>/pydevd.py, line 1135, in run pydev_imports.execfile(file, globals, locals) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/train_hopenet_with_validation_holdout.py, line 187, in <module> loss_reg_yaw = reg_criterion(yaw_predicted, label_yaw_cont)[SEP]File <*>/site-packages/torch/nn/modules/module.py, line 541, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>/site-packages/torch/nn/modules/loss.py, line 431, in forward return F.mse_loss(input, target, reduction=self.reduction)[SEP]File <*>/site-packages/torch/nn/functional.py, line 2204, in mse_loss ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))[SEP]RuntimeError: reduce failed to synchronize: cudaErrorAssert: device-side assert triggered",0
"File <*>/main.py, line 81, in <module> train(epoch)[SEP]File <*>/main.py, line 48, in train for iteration, batch in enumerate(training_data_loader, 1):[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 345, in __next__ data = self._next_data()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 841, in _next_data idx, data = self._get_data()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 808, in _get_data success, data = self._try_get_data()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 774, in _try_get_data raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str))[SEP]RuntimeError: DataLoader worker (pid(s) 16596, 9376, 12756, 9844) exited unexpectedly",0
"File <*>/Wrong.py, line 33, in <module> net.forward(dataset[0])[SEP]File <*>/Wrong.py, line 23, in forward x = F.relu(self.layer(x))[SEP]File <*>/site-packages/torch/nn/modules/module.py, line 532, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>/site-packages/torch/nn/modules/, line 87, in forward return F.linear(input, self.weight, self.bias)[SEP]File <*>/site-packages/torch/nn/functional.py, line 1372, in linear output = input.matmul(weight.t())[SEP]RuntimeError: Expected object of scalar type Double but got scalar type Float for argument #2 'mat2' in call to _th_mm",0
"File <*>/main.py, line 17, in <module> history = CNN.fit(TrainImages, TrainMasks, epochs = 3)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1239, in fit validation_freq=validation_freq)[SEP]File <*>python3.6/site-packages/keras/engine/training_arrays.py, line 196, in fit_loop outs = fit_function(ins_batch)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/keras/backend.py, line 3727, in __call__ outputs = self._graph_fn(*converted_inputs)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/eager/function.py, line 1551, in __call__ return self._call_impl(args, kwargs)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/eager/function.py, line 1591, in _call_impl return self._call_flat(args, self.captured_inputs, cancellation_manager)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>python3.6/site-packages/tensorflow_core/python/eager/function.py, line 545, in call ctx=ctx)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.**InvalidArgumentError: BiasGrad requires tensor size <= int32 max** [[node gradients/conv2d_22/BiasAdd_grad/BiasAddGrad (defined at /home/tomhalmos/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_5496]",0
"File <*>/test2.py, line 73, in <module> grads = gradients(model, x, y)[SEP]File <*>/test2.py, line 58, in gradients print(model.get_layer('minimalrnn').output)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 1553, in output raise AttributeError('Layer ' + self.name + ' has no inbound nodes.')[SEP]AttributeError: Layer minimalrnn has no inbound nodes.",0
"File <*>/unet_trainer.py, line 82, in <module> results = model.fit_generator(train_generator, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, validation_data=val_generator, validation_steps=VALIDATION_STEPS, callbacks=callbacks)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 1297, in fit_generator steps_name='steps_per_epoch')[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_generator.py, line 265, in model_iteration batch_outs = batch_function(*batch_data)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 973, in train_on_batch class_weight=class_weight, reset_metrics=reset_metrics)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch output_loss_metrics=model._output_loss_metrics)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch output_loss_metrics=output_loss_metrics))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 252, in _process_single_batch training=training))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 127, in _model_loss outs = model(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 891, in __call__ outputs = self.call(cast_inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 708, in call convert_kwargs_to_constants=base_layer_utils.call_context().saving)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 860, in _run_internal_graph output_tensors = layer(computed_tensors, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/layers/convolutional.py, line 197, in call outputs = self._convolution_op(inputs, self.kernel)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 1134, in __call__ return self.conv_op(inp, filter)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 639, in __call__ return self.call(inp, filter)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 238, in __call__ name=self.name)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 2010, in conv2d name=name)[SEP]File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1031, in conv2d data_format=data_format, dilations=dilations, name=name, ctx=_ctx)[SEP]File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1130, in conv2d_eager_fallback ctx=_ctx, name=name)[SEP]File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,16,1536,1536] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",0
"File TrainTest.py, line 71, in <module> model.save('test', save_format='tf')[SEP]File <*>/network.py, line 1008, in save signatures, options)[SEP]File <*>/save.py, line 115, in save_model signatures, options)[SEP]File <*>/save.py, line 78, in save save_lib.save(model, filepath, signatures, options)[SEP]File <*>/save.py, line 886, in save checkpoint_graph_view)[SEP]File <*>/signature_serialization.py, line 74, in find_function_to_export functions = saveable_view.list_functions(saveable_view.root)[SEP]File <*>/save.py, line 142, in list_functions self._serialization_cache)[SEP]File <*>/base_layer.py, line 2420, in _list_functions_for_serialization .list_functions_for_serialization(serialization_cache))[SEP]File <*>/base_serialization.py, line 91, in list_functions_for_serialization fns = self.functions_to_serialize(serialization_cache)[SEP]File <*>/layer_serialization.py, line 80, in functions_to_serialize serialization_cache).functions_to_serialize)[SEP]File <*>/layer_serialization.py, line 95, in _get_serialized_attributes serialization_cache)[SEP]File <*>/model_serialization.py, line 47, in _get_serialized_attributes_internal default_signature = save_impl.default_save_signature(self.obj)[SEP]File <*>/save_impl.py, line 212, in default_save_signature fn.get_concrete_function()[SEP]File <*>/def_function.py, line 909, in get_concrete_function self._initialize(args, kwargs, add_initializers_to=initializers)[SEP]File <*>/def_function.py, line 497, in _initialize *args, **kwds))[SEP]File <*>/function.py, line 2389, in _get_concrete_function_internal_garbage_collected graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/function.py, line 2703, in _maybe_define_function graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/function.py, line 2593, in _create_graph_function capture_by_value=self._capture_by_value),[SEP]File <*>/func_graph.py, line 978, in func_graph_from_py_func func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/def_function.py, line 439, in wrapped_fn return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/saving_utils.py, line 150, in _wrapped_model outputs_list = nest.flatten(model(inputs=inputs, training=False))[SEP]TypeError: __call__() missing 1 required positional argument: 'x'",0
"File <*>/mmconvert, line 8, in <module> sys.exit(_main())[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/_script/convert.py, line 102, in _main ret = convertToIR._convert(ir_args)[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/_script/convertToIR.py, line 62, in _convert from mmdnn.conversion.tensorflow.tensorflow_parser import TensorflowParser[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/tensorflow/tensorflow_parser.py, line 15, in <module> from tensorflow.tools.graph_transforms import TransformGraph[SEP]ImportError: No module named 'tensorflow.tools.graph_transforms'",0
"File <*>/mmconvert, line 8, in <module> sys.exit(_main())[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/_script/convert.py, line 102, in _main ret = convertToIR._convert(ir_args)[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/_script/convertToIR.py, line 46, in _convert parser = Keras2Parser(model)[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/keras/keras2_parser.py, line 126, in __init__ model = self._load_model(model[0], model[1])[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/keras/keras2_parser.py, line 78, in _load_model 'DepthwiseConv2D': layers.DepthwiseConv2D})[SEP]File <*>python3.5/dist-packages/keras/engine/saving.py, line 664, in model_from_json return deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.5/dist-packages/keras/layers/__init__.py, line 168, in deserialize printable_module_name='layer')[SEP]File <*>python3.5/dist-packages/keras/utils/generic_utils.py, line 147, in deserialize_keras_object list(custom_objects.items())))[SEP]File <*>python3.5/dist-packages/keras/engine/network.py, line 1056, in from_config process_layer(layer_data)[SEP]File <*>python3.5/dist-packages/keras/engine/network.py, line 1042, in process_layer custom_objects=custom_objects)[SEP]File <*>python3.5/dist-packages/keras/utils/generic_utils.py, line 149, in deserialize_keras_object return cls.from_config(config['config'])[SEP]File <*>python3.5/dist-packages/keras/engine/base_layer.py, line 1179, in from_config return cls(**config)[SEP]File <*>python3.5/dist-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>python3.5/dist-packages/keras/layers/convolutional.py, line 484, in __init__ **kwargs)[SEP]File <*>python3.5/dist-packages/keras/layers/convolutional.py, line 117, in __init__ self.kernel_initializer = initializers.get(kernel_initializer)[SEP]File <*>python3.5/dist-packages/keras/initializers.py, line 515, in get return deserialize(identifier)[SEP]File <*>python3.5/dist-packages/keras/initializers.py, line 510, in deserialize printable_module_name='initializer')[SEP]File <*>python3.5/dist-packages/keras/utils/generic_utils.py, line 140, in deserialize_keras_object ': ' + class_name)[SEP]ValueError: Unknown initializer: GlorotUniform",0
"File <*>python3.7/site-packages/IPython/core/interactiveshell.py, line 3331, in run_code exec(code_obj, self.user_global_ns, self.user_ns)[SEP]File <ipython-input-55-cc0dd3d9cbb7>, line 1, in <module> net(cc)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 532, in __call__ result = self.forward(*input, **kwargs)[SEP]File <ipython-input-2-19e11966d1cd>, line 181, in forward out = self.layer1(x)[SEP]File <*>python3.7/site-packages/torch/nn/modules/container.py, line 100, in forward input = module(input)[SEP]File <*>python3.7/site-packages/torch/nn/modules/conv.py, line 480, in forward self.padding, self.dilation, self.groups)[SEP]RuntimeError: Could not run 'aten::slow_conv3d_forward' with arguments from the 'CUDATensorId' backend. 'aten::slow_conv3d_forward' is only available for these backends: [CPUTensorId, VariableTensorId].",0
"File <*>/3D_tf_data_generator.py, line 181, in <module> evaluation_ad = model.evaluate(ad_test, ad_test_labels, verbose=0)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 930, in evaluate use_multiprocessing=use_multiprocessing)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 490, in evaluate use_multiprocessing=use_multiprocessing, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 426, in _model_iteration use_multiprocessing=use_multiprocessing)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 646, in _process_inputs x, y, sample_weight=sample_weights)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 2383, in _standardize_user_data batch_size=batch_size)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 2489, in _standardize_tensors y, self._feed_loss_fns, feed_output_shapes)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py, line 810, in check_loss_and_target_compatibility ' while using as loss `' + loss_name + '`. '[SEP]ValueError: A target array with shape (5, 2) was passed for an output of shape (None, 1) while using as loss `binary_crossentropy`. This loss expects targets to have the same shape as the output.",0
"File pytorch_test.py, line 21, in <module> a_copy.resize_(1, 1)[SEP]RuntimeError: cannot resize variables that require grad",0
"File <*>/train.py, line 74, in <module> model = nn.DataParallel(model, device_ids=[0, 1]).to(device)[SEP]File <*>/site-packages/torch/nn/parallel/data_parallel.py, line 133, in __init__ _check_balance(self.device_ids)[SEP]File <*>/site-packages/torch/nn/parallel/data_parallel.py, line 19, in _check_balance dev_props = [torch.cuda.get_device_properties(i) for i in device_ids][SEP]File <*>/site-packages/torch/nn/parallel/data_parallel.py, line 19, in <listcomp> dev_props = [torch.cuda.get_device_properties(i) for i in device_ids][SEP]File <*>/site-packages/torch/cuda/__init__.py, line 337, in get_device_properties raise AssertionError(""Invalid device id"")[SEP]AssertionError: Invalid device id",0
"File <*>/site-packages/IPython/core/interactiveshell.py, line 3296, in run_code exec(code_obj, self.user_global_ns, self.user_ns)[SEP]File <ipython-input-2-78553e2886de>, line 1, in <module> runfile('F:/experiment_code/U-net/train.py', wdir='F:/experiment_code/U-net')[SEP]File <*>/pydev_umd.py, line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/train.py, line 99, in <module> loss.backward()[SEP]File <*>/site-packages/torch/tensor.py, line 107, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>/site-packages/torch/autograd/__init__.py, line 93, in backward allow_unreachable=True) # allow_unreachable flag[SEP]RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [4, 2, 224, 224]], which is output 0 of SigmoidBackward, is at version 2; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",0
"File trial_mult-ips.py, line 240, in <module> predops=p.map(prediction,new_all_t)[SEP]File <*>python2.7/pool.py, line 253, in map return self.map_async(func, iterable, chunksize).get()[SEP]File <*>python2.7/pool.py, line 572, in get raise self._value[SEP]NotImplementedError: numpy() is only available when eager execution is enabled.",0
"File main.py, line 95, in <module> model.load_weights(checkpoint_dir)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 162, in load_weights return super(Model, self).load_weights(filepath, by_name)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/network.py, line 1398, in load_weights status.assert_nontrivial_match()[SEP]File <*>python3.7/site-packages/tensorflow/python/training/tracking/util.py, line 917, in assert_nontrivial_match return self.assert_consumed()[SEP]File <*>python3.7/site-packages/tensorflow/python/training/tracking/util.py, line 894, in assert_consumed (unused_attributes,))[SEP]AssertionError: Some objects had attributes which were not restored: {<tf.Variable 'embedding_1/embeddings:0' shape=(65, 256) dtype=float32, numpy= array([[-0.00044268, -0.02351714, -0.01139065, ..., -0.00327835, 0.00074228, -0.00383734], [-0.02313181, 0.04697707, -0.02350216, ..., 0.040385 , 0.03087702, 0.02765551], [ 0.0410727 , 0.00130001, 0.0051438 , ..., 0.02899202, 0.04258115, -0.03773504], ..., [-0.03134514, 0.01370119, 0.00993627, ..., -0.02257681, 0.02617678, 0.03761976], [-0.02954974, 0.02407967, 0.02768463, ..., -0.0056519 , -0.01507735, 0.04617763], [-0.04113789, -0.03544737, 0.01056757, ..., 0.01236727, -0.01791535, -0.01635399]], dtype=float32)>: ['embedding_1/embeddings'], <tf.Variable 'dense_1/kernel:0' shape=(1024, 65) dtype=float32, numpy= array([[-6.7811467e-02, -2.5536597e-02, 5.1763237e-02, ..., -6.9665730e-02, 3.9457709e-02, -5.3290475e-02], [ 1.5835620e-02, -3.0763537e-02, -7.4058644e-02, ..., 3.8087368e-05, -9.1508478e-03, 5.5485427e-02], [ 3.8143486e-02, 8.8131428e-04, -2.3478847e-02, ..., -1.5135627e-02, -5.2146181e-02, 7.1185097e-02], ..., [-6.6591002e-02, 4.7627889e-02, 5.7474524e-02, ..., 4.1528463e-02, 4.6467118e-02, -3.0670539e-02], [-5.0804108e-02, 5.4505378e-02, -1.5776977e-03, ..., 2.1875933e-02, -2.9637258e-02, 2.0201296e-02], [-4.7325939e-02, -8.0013275e-03, -3.6348965e-02, ..., -7.0560835e-02, -4.9752403e-02, 1.0509960e-02]], dtype=float32)>: ['dense_1/kernel'], <tf.Variable 'dense_1/bias:0' shape=(65,) dtype=float32, numpy= array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>: ['dense_1/bias'], <tf.Variable 'gru_1/kernel:0' shape=(256, 3072) dtype=float32, numpy= array([[ 0.00432818, 0.03131782, 0.00038544, ..., -0.00559966, 0.03458985, -0.03219106], [-0.00865119, 0.01648769, -0.00768028, ..., 0.01366192, -0.03043955, -0.01382086], [-0.01379537, 0.00547716, -0.00385967, ..., -0.00027269, -0.01285852, 0.0377048 ], ..., [-0.01940641, 0.01454895, 0.03349226, ..., -0.04234404, -0.02699661, 0.0376601 ], [ 0.00186675, -0.00547577, -0.02205843, ..., -0.01287581, -0.02314153, 0.04158166], [ 0.00954719, -0.02883693, -0.03259185, ..., -0.02587803, 0.02906795, -0.00559821]], dtype=float32)>: ['gru_1/kernel'], <tf.Variable 'gru_1/recurrent_kernel:0' shape=(1024, 3072) dtype=float32, numpy= array([[ 9.11542401e-03, 1.50135346e-02, 2.96630897e-02, ..., 2.25223936e-02, 2.31253020e-02, -2.96920985e-02], [-2.21075956e-02, -8.46013427e-06, -2.16848943e-02, ..., -1.26914177e-02, -3.49153839e-02, -3.01396102e-02], [-3.59148793e-02, 9.98445973e-03, 2.60963626e-02, ..., 3.15430500e-02, 1.28889643e-02, 3.37569825e-02], ..., [ 3.39106433e-02, 6.54980540e-03, -1.27352085e-02, ..., -4.14674729e-03, 3.53236459e-02, -1.36333425e-02], [-3.50691415e-02, -1.76392253e-02, 1.67468414e-02, ..., -2.06982102e-02, -1.06042419e-02, 2.26641595e-02], [-1.14825107e-02, -3.46554294e-02, -1.83847174e-03, ..., 2.25809850e-02, 2.45791934e-02, -2.70933360e-02]], dtype=float32)>: ['gru_1/recurrent_kernel'], <tf.Variable 'gru_1/bias:0' shape=(2, 3072) dtype=float32, numpy= array([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>: ['gru_1/bias']}",0
"File <*>/train.py, line 66, in <module> train(epochs=20, prefix='test_new_loss_fn')[SEP]File <*>/train.py, line 46, in train model = create_model((shape[0], shape[1], 3), backbone=backbone, loss_function=loss_fn, freeze_backbone=backbone_freeze, lr=learning_rate)[SEP]File <*>/__init__.py, line 48, in create_model loss=loss_function, metrics=[mean_relative_percentage_error, metrics.mean_absolute_error])[SEP]File <*>/site-packages/keras/engine/training.py, line 342, in compile sample_weight, mask)[SEP]File <*>/site-packages/keras/engine/training_utils.py, line 404, in weighted score_array = fn(y_true, y_pred)[SEP]File <*>/losses.py, line 8, in mean_relative_percentage_error diff = K.update_sub(ones, e)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 999, in update_sub return tf.assign_sub(x, decrement)[SEP]File <*>/site-packages/tensorflow/python/ops/state_ops.py, line 160, in assign_sub return ref.assign_sub(value)[SEP]AttributeError: 'Tensor' object has no attribute 'assign_sub'",0
"File <*>/train.py, line 66, in <module> train(epochs=20, prefix='test_new_loss_fn')[SEP]File <*>/train.py, line 46, in train model = create_model((shape[0], shape[1], 3), backbone=backbone, loss_function=loss_fn, freeze_backbone=backbone_freeze, lr=learning_rate)[SEP]File <*>/__init__.py, line 48, in create_model loss=loss_function, metrics=[mean_relative_percentage_error, metrics.mean_absolute_error])[SEP]File <*>/site-packages/keras/engine/training.py, line 342, in compile sample_weight, mask)[SEP]File <*>/site-packages/keras/engine/training_utils.py, line 404, in weighted score_array = fn(y_true, y_pred)[SEP]File <*>/losses.py, line 7, in mean_relative_percentage_error ones = K.variable(K.ones_like(err))[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 402, in variable v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 183, in __call__ return cls._variable_v1_call(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 146, in _variable_v1_call aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 125, in <lambda> previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variable_scope.py, line 2444, in default_variable_creator expected_shape=expected_shape, import_scope=import_scope)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 187, in __call__ return super(VariableMetaclass, cls).__call__(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 1329, in __init__ constraint=constraint)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 1472, in _init_from_args self._initial_value)[SEP]ValueError: initial_value must have a shape specified: Tensor(""loss/dense_3_loss/ones_like:0"", shape=(?, ?), dtype=float32)",0
"File test_dist_1.py, line 25, in <module> dist.broadcast(tensor=a, src=0)[SEP]File <*>python3.7/site-packages/torch/distributed/distributed_c10d.py, line 806, in broadcast work = _default_pg.broadcast([tensor], opts)[SEP]RuntimeError: NCCL error in: /tmp/pip-req-build-58y_cjjl/torch/lib/c10d/ProcessGroupNCCL.cpp:290, unhandled system error",0
"File <*>/rks.py, line 14, in <module> from tf.keras.preprocessing.image import ImageDataGenerator[SEP]ModuleNotFoundError: No module named 'tf'",0
"File <*>python3.6/dist-packages/torch/utils/data/_utils/worker.py, line 178, in _worker_loop data = fetcher.fetch(index)[SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp> data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <ipython-input-114-e0ccd94603fd>, line 31, in __getitem__ xs = label_data[:,0:8:2];[SEP]IndexError: too many indices for array",0
"File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1365, in _do_call return fn(*args)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1350, in _run_fn target_list, run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1443, in _call_tf_sessionrun run_metadata)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found. (0) Invalid argument: {{function_node __inference_Dataset_map_transform_and_pad_input_data_fn_3047}} assertion failed: [[0.748][0.758]] [[0.67][0.67]] [[{{node Assert/AssertGuard/else/_123/Assert}}]] [[IteratorGetNext]] (1) Invalid argument: {{function_node __inference_Dataset_map_transform_and_pad_input_data_fn_3047}} assertion failed: [[0.748][0.758]] [[0.67][0.67]] [[{{node Assert/AssertGuard/else/_123/Assert}}]] [[IteratorGetNext]] [[IteratorGetNext/_8451]] 0 successful operations. 0 derived errors ignored.",0
"File <*>/model_main.py, line 114, in <module> tf.app.run()[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)[SEP]File <*>python3.6/dist-packages/absl/app.py, line 299, in run _run_main(main, args)[SEP]File <*>python3.6/dist-packages/absl/app.py, line 250, in _run_main sys.exit(main(argv))[SEP]File <*>/model_main.py, line 110, in main tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py, line 473, in train_and_evaluate return executor.run()[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py, line 613, in run return self.run_local()[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py, line 714, in run_local saving_listeners=saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py, line 370, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py, line 1161, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py, line 1195, in _train_model_default saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py, line 1494, in _train_with_estimator_spec _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 754, in run run_metadata=run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1259, in run run_metadata=run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1360, in run raise six.reraise(*original_exc_info)[SEP]File <*>python3.6/dist-packages/six.py, line 693, in reraise raise value[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1345, in run return self._sess.run(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1418, in run run_metadata=run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1176, in run return self._sess.run(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 956, in run run_metadata_ptr)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1180, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1359, in _do_run run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1384, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found. (0) Invalid argument: assertion failed: [[0.748][0.758]] [[0.67][0.67]] [[{{node Assert/AssertGuard/else/_123/Assert}}]] [[IteratorGetNext]] (1) Invalid argument: assertion failed: [[0.748][0.758]] [[0.67][0.67]] [[{{node Assert/AssertGuard/else/_123/Assert}}]] [[IteratorGetNext]] [[IteratorGetNext/_8451]] 0 successful operations. 0 derived errors ignored.",0
"File <*>/tempCodeRunnerFile.python, line 1234, in <module> df_enc = tensorflow.one_hot(df, 2, on_value=None, off_value=None, axis=None, dtype=None, name=None)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/util/dispatch.py, line 180, in wrapper return target(*args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/ops/array_ops.py, line 3645, in one_hot name)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py, line 5549, in one_hot _ops.raise_from_not_ok_status(e, name)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/ops.py, line 6606, in raise_from_not_ok_status six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.NotFoundError: Could not find valid device for node.",0
"File <*>python3.6/dist-packages/optkeras/optkeras.py, line 230, in synch_with_optuna self.best_trial = self.study.best_trial[SEP]File <*>python3.6/dist-packages/optuna/study.py, line 97, in best_trial return copy.deepcopy(self._storage.get_best_trial(self._study_id))[SEP]File <*>python3.6/dist-packages/optuna/storages/in_memory.py, line 293, in get_best_trial raise ValueError(""No trials are completed yet."")[SEP]ValueError: No trials are completed yet.",0
"File <*>python3.6/dist-packages/optuna/study.py, line 734, in _run_trial result = func(trial)[SEP]File <*>python3.6/dist-packages/optkeras/optkeras.py, line 130, in fun_tf return fun(trial)[SEP]File <ipython-input-11-45495c9f2ae9>, line 65, in optima_run self.model.fit(self.train_images, self.train_labels, epochs=10, callbacks = self.ok.callbacks(trial), verbose = self.ok.keras_verbose)[SEP]File <*>python3.6/dist-packages/optkeras/optkeras.py, line 172, in callbacks self.synch_with_optuna()[SEP]File <*>python3.6/dist-packages/optkeras/optkeras.py, line 232, in synch_with_optuna self.best_trial = get_trial_default()[SEP]File <*>python3.6/dist-packages/optkeras/optkeras.py, line 367, in get_trial_default num_fields = optuna.structs.FrozenTrial._field_types.__len__()[SEP]AttributeError: type object 'FrozenTrial' has no attribute '_field_types'",0
"File <*>/train.py, line 17, in <module> from pegasus.data import infeed[SEP]ModuleNotFoundError: No module named 'pegasus'",0
"File <*>python3.6/site-packages/uvicorn/protocols/http/httptools_impl.py, line 385, in run_asgi result = await app(self.scope, self.receive, self.send)[SEP]File <*>python3.6/site-packages/uvicorn/middleware/proxy_headers.py, line 45, in __call__ return await self.app(scope, receive, send)[SEP]File <*>python3.6/site-packages/fastapi/applications.py, line 183, in __call__ await super().__call__(scope, receive, send) # pragma: no cover[SEP]File <*>python3.6/site-packages/starlette/applications.py, line 102, in __call__ await self.middleware_stack(scope, receive, send)[SEP]File <*>python3.6/site-packages/starlette/middleware/errors.py, line 181, in __call__ raise exc from None[SEP]File <*>python3.6/site-packages/starlette/middleware/errors.py, line 159, in __call__ await self.app(scope, receive, _send)[SEP]File <*>python3.6/site-packages/starlette/exceptions.py, line 82, in __call__ raise exc from None[SEP]File <*>python3.6/site-packages/starlette/exceptions.py, line 71, in __call__ await self.app(scope, receive, sender)[SEP]File <*>python3.6/site-packages/starlette/routing.py, line 550, in __call__ await route.handle(scope, receive, send)[SEP]File <*>python3.6/site-packages/starlette/routing.py, line 227, in handle await self.app(scope, receive, send)[SEP]File <*>python3.6/site-packages/starlette/routing.py, line 41, in app response = await func(request)[SEP]File <*>python3.6/site-packages/fastapi/routing.py, line 197, in app dependant=dependant, values=values, is_coroutine=is_coroutine[SEP]File <*>python3.6/site-packages/fastapi/routing.py, line 149, in run_endpoint_function return await run_in_threadpool(dependant.call, **values)[SEP]File <*>python3.6/site-packages/starlette/concurrency.py, line 34, in run_in_threadpool return await loop.run_in_executor(None, func, *args)[SEP]File <*>python3.6/thread.py, line 56, in run result = self.fn(*self.args, **self.kwargs)[SEP]File <*>/main.py, line 155, in API_call raise e[SEP]File <*>/main.py, line 129, in API_call model = pickle.load(open('models/' + current_model, 'rb'))[SEP]File <*>python3.6/site-packages/dill/_dill.py, line 270, in load return Unpickler(file, ignore=ignore, **kwds).load()[SEP]File <*>python3.6/site-packages/dill/_dill.py, line 473, in load obj = StockUnpickler.load(self)[SEP]File <*>python3.6/site-packages/dill/_dill.py, line 463, in find_class return StockUnpickler.find_class(self, module, name)[SEP]AttributeError: Can't get attribute 'Model_II_b' on <module '__mp_main__' from '/opt/apps/env/bin/uvicorn'>",0
"File <*>python3.6/pool.py, line 119, in worker result = (True, func(*args, **kwds))[SEP]File <*>python3.6/pool.py, line 44, in mapstar return list(map(*args))[SEP]File <ipython-input-35-6529ab6dac60>, line 11, in X_power_func X_power = X**j[SEP]RuntimeError: CUDA error: initialization error",0
"File <*>/site-packages/tensorflow/python/data/util/structure.py, line 93, in normalize_element spec = type_spec_from_value(t, use_fallback=False)[SEP]File <*>/site-packages/tensorflow/python/data/util/structure.py, line 466, in type_spec_from_value (element, type(element).__name__))[SEP]TypeError: Could not build a TypeSpec for 0 Tecmo Koei 1 Nippon Ichi Software 2 Ubisoft 3 Activision 4 Atari ... 6594 Kemco 6595 Infogrames 6596 Activision 6597 7G//AMES 6598 Wanadoo Name: Publisher, Length: 6599, dtype: object with type Series",0
"File <*>/main.py, line 45, in <module> linear_est.train(train_input_fn)[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 349, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1175, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners)[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1201, in _train_model_default self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1037, in _get_features_and_labels_from_input_fn self._call_input_fn(input_fn, mode))[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1130, in _call_input_fn return input_fn(**kwargs)[SEP]File <*>/main.py, line 34, in input_function ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 682, in from_tensor_slices return TensorSliceDataset(tensors)[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 3001, in __init__ element = structure.normalize_element(element)[SEP]File <*>/site-packages/tensorflow/python/data/util/structure.py, line 98, in normalize_element ops.convert_to_tensor(t, name=""component_%d"" % i))[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 1499, in convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 338, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 264, in constant allow_broadcast=True)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 282, in _constant_impl allow_broadcast=allow_broadcast))[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 563, in make_tensor_proto append_fn(tensor_proto, proto_values)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 155, in SlowAppendObjectArrayToTensorProto tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 155, in <listcomp> tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])[SEP]File <*>/site-packages/tensorflow/python/util/compat.py, line 87, in as_bytes (bytes_or_text,))[SEP]TypeError: Expected binary or unicode string, got nan",0
"File [FILE], line <*>, in [FUNC] [CODE][SEP]File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 349, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1182, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners)[SEP]File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1208, in _train_model_default self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))[SEP]File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1044, in _get_features_and_labels_from_input_fn self._call_input_fn(input_fn, mode))[SEP]File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1137, in _call_input_fn return input_fn(**kwargs)[SEP]File [FILE], line 1137, in [FUNC] [CODE][SEP]File <*>python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 406, in __iter__ raise RuntimeError(""__iter__() is only supported inside of tf.function ""[SEP]RuntimeError: __iter__() is only supported inside of tf.function or when eager execution is enabled.",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/torch_xla/core/xla_model.py, line 231, in xla_device devkind=devkind if devkind is not None else None)[SEP]File <*>python3.6/site-packages/torch_xla/core/xla_model.py, line 136, in get_xla_supported_devices xla_devices = _DEVICES.value[SEP]File <*>python3.6/site-packages/torch_xla/utils/utils.py, line 32, in value self._value = self._gen_fn()[SEP]File <*>python3.6/site-packages/torch_xla/core/xla_model.py, line 18, in <lambda> _DEVICES = xu.LazyProperty(lambda: torch_xla._XLAC._xla_get_devices())[SEP]RuntimeError: tensorflow/compiler/xla/xla_client/computation_client.cc:274 : Missing XLA configuration",0
"File <*>/site-packages/IPython/core/interactiveshell.py, line 3331, in run_code exec(code_obj, self.user_global_ns, self.user_ns)[SEP]File <ipython-input-2-d2317d03e1c1>, line 1, in <module> runfile('F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news/bitcoin.py', wdir='F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news')[SEP]File <*>/pydev_umd.py, line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/bitcoin.py, line 41, in <module> model.fit(x=x_train, y=y_train, batch_size=64, epochs=5, shuffle=True, validation_split=0.1)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 819, in fit use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 342, in fit total_epochs=epochs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch batch_outs = execution_function(iterator)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function distributed_function(input_fn))[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__ result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 632, in _call return self._stateless_fn(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2363, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call self.captured_inputs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 545, in call ctx=ctx)[SEP]File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Condition x == y did not hold element-wise:] [x (loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [64 1] [y (loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [64 14] [[node loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news/bitcoin.py:41) ]] [Op:__inference_distributed_function_2970]",0
"File <*>/site-packages/flask/app.py, line 2447, in wsgi_app response = self.full_dispatch_request()[SEP]File <*>/site-packages/flask/app.py, line 1952, in full_dispatch_request rv = self.handle_user_exception(e)[SEP]File <*>/site-packages/flask/app.py, line 1821, in handle_user_exception reraise(exc_type, exc_value, tb)[SEP]File <*>/site-packages/flask/_compat.py, line 39, in reraise raise value[SEP]File <*>/site-packages/flask/app.py, line 1950, in full_dispatch_request rv = self.dispatch_request()[SEP]File <*>/site-packages/flask/app.py, line 1936, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args)[SEP]File <*>/app.py, line 70, in predict out = model.predict(img)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 130, in _method_wrapper return method(self, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1562, in predict version_utils.disallow_legacy_graph('Model', 'predict')[SEP]File <*>/site-packages/tensorflow/python/keras/utils/version_utils.py, line 122, in disallow_legacy_graph raise ValueError(error_msg)[SEP]ValueError: Calling `Model.predict` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.predict` with eager mode enabled.",0
"File <*>/emotion.py, line 4, in <module> emotion_detector = EmotionRecognition(device='gpu', gpu_id=1)[SEP]File <*>python3.7/site-packages/facial_emotion_recognition/facial_emotion_recognition.py, line 25, in __init__ self.network = NetworkV2(in_c=1, nl=32, out_f=7).to(self.device)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 607, in to return self._apply(convert)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 354, in _apply module._apply(fn)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 376, in _apply param_applied = fn(param)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 605, in convert return t.to(device, dtype if t.is_floating_point() else None, non_blocking)[SEP]RuntimeError: CUDA error: invalid device ordinal",0
"File <*>/external_process.py, line 35, in <module> model.fit([SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper return method(self, *args, **kwargs)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/training.py, line 1098, in fit tmp_logs = train_function(iterator)[SEP]File <*>python3.8/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__ result = self._call(*args, **kwds)[SEP]File <*>python3.8/site-packages/tensorflow/python/eager/def_function.py, line 840, in _call return self._stateless_fn(*args, **kwds)[SEP]File <*>python3.8/site-packages/tensorflow/python/eager/function.py, line 2829, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>python3.8/site-packages/tensorflow/python/eager/function.py, line 1843, in _filtered_call return self._call_flat([SEP]File <*>python3.8/site-packages/tensorflow/python/eager/function.py, line 1923, in _call_flat return self._build_call_outputs(self._inference_function.call([SEP]File <*>python3.8/site-packages/tensorflow/python/eager/function.py, line 545, in call outputs = execute.execute([SEP]File <*>python3.8/site-packages/tensorflow/python/eager/execute.py, line 59, in quick_execute tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 1328 values, but the requested shape has 16 [[{{node TripletSemiHardLoss/PartitionedCall/Reshape}}]] [Op:__inference_train_function_13749]",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/tensorflow/__init__.py, line 101, in <module> from tensorflow_core import *[SEP]File <*>/site-packages/tensorflow_core/__init__.py, line 40, in <module> from tensorflow.python.tools import module_util as _module_util[SEP]File <frozen importlib._bootstrap>, line 983, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 959, in _find_and_load_unlocked [CODE][SEP]File <*>/site-packages/tensorflow/__init__.py, line 50, in __getattr__ module = self._load()[SEP]File <*>/site-packages/tensorflow/__init__.py, line 44, in _load module = _importlib.import_module(self.__name__)[SEP]File <*>/__init__.py, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <*>/site-packages/tensorflow_core/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py, line 15, in swig_import_helper import imp[SEP]ValueError: source code string cannot contain null bytes",0
"File foo_test.py, line 21, in test3 self.assertEqual(3,4)[SEP]AssertionError: 3 != 4",0
"File evaluate_spect.py, line 63, in <module> main()[SEP]File evaluate_spect.py, line 51, in main pred_audio = torchaudio.transforms.GriffinLim(n_fft=256)(inverse_mel_pred)[SEP]File <*>python3.8/site-packages/torch/nn/modules/module.py, line 727, in _call_impl result = self.forward(*input, **kwargs)[SEP]File <*>python3.8/site-packages/torchaudio/transforms.py, line 169, in forward return F.griffinlim(specgram, self.window, self.n_fft, self.hop_length, self.win_length, self.power,[SEP]File <*>python3.8/site-packages/torchaudio/functional.py, line 179, in griffinlim inverse = torch.istft(specgram * angles,[SEP]RuntimeError: The size of tensor a (256) must match the size of tensor b (129) at non-singleton dimension 1",0
"File model_main_tf2.py, line 113, in <module> tf.compat.v1.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)[SEP]File <*>/site-packages/absl/app.py, line 303, in run _run_main(main, args)[SEP]File <*>/site-packages/absl/app.py, line 251, in _run_main sys.exit(main(argv))[SEP]File model_main_tf2.py, line 104, in main model_lib_v2.train_loop([SEP]File <*>/site-packages/object_detection/model_lib_v2.py, line 639, in train_loop loss = _dist_train_step(train_input_iter)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__ result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 840, in _call return self._stateless_fn(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2829, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1843, in _filtered_call return self._call_flat([SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1923, in _call_flat return self._build_call_outputs(self._inference_function.call([SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 545, in call outputs = execute.execute([SEP]File <*>/site-packages/tensorflow/python/eager/execute.py, line 59, in quick_execute tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found. (0) Resource exhausted: OOM when allocating tensor with shape[64,256,17,17] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[node functional_3/conv2d_160/Conv2D (defined at \site-packages\object_detection\meta_architectures\faster_rcnn_meta_arch.py:1149) ]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. [[Identity_1/_432]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. (1) Resource exhausted: OOM when allocating tensor with shape[64,256,17,17] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[node functional_3/conv2d_160/Conv2D (defined at \site-packages\object_detection\meta_architectures\faster_rcnn_meta_arch.py:1149) ]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. 0 successful operations. 0 derived errors ignored. [Op:__inference__dist_train_step_79248]",0
"File <ipython-input-39-17211d5a107c>, line 8, in <module> train_loss, _ = modhelper.train(proc.train_dataloader)[SEP]File <*>/model.py, line 71, in train preds = self.model(sent_id, mask)[SEP]File <*>/site-packages/torch/nn/modules/module.py, line 727, in _call_impl result = self.forward(*input, **kwargs)[SEP]File <*>/model.py, line 181, in forward #pass the inputs to the model[SEP]File <*>/site-packages/transformers/modeling_bert.py, line 837, in forward embedding_output = self.embeddings([SEP]File <*>/site-packages/transformers/modeling_bert.py, line 201, in forward embeddings = inputs_embeds + position_embeddings + token_type_embeddings[SEP]RuntimeError: The size of tensor a (4000) must match the size of tensor b (512) at non-singleton dimension 1",0
"File <*>/site-packages/pytorch_lightning/trainer/trainer.py, line 521, in train self.train_loop.run_training_epoch()[SEP]File <*>/site-packages/pytorch_lightning/trainer/training_loop.py, line 588, in run_training_epoch self.trainer.run_evaluation(test_mode=False)[SEP]File <*>/site-packages/pytorch_lightning/trainer/trainer.py, line 613, in run_evaluation self.evaluation_loop.log_evaluation_step_metrics(output, batch_idx)[SEP]File <*>/site-packages/pytorch_lightning/trainer/evaluation_loop.py, line 346, in log_evaluation_step_metrics self.__log_result_step_metrics(step_log_metrics, step_pbar_metrics, batch_idx)[SEP]File <*>/site-packages/pytorch_lightning/trainer/evaluation_loop.py, line 350, in __log_result_step_metrics cached_batch_pbar_metrics, cached_batch_log_metrics = cached_results.update_logger_connector()[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 378, in update_logger_connector batch_log_metrics = self.get_latest_batch_log_metrics()[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 418, in get_latest_batch_log_metrics batch_log_metrics = self.run_batch_from_func_name(""get_batch_log_metrics"")[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 414, in run_batch_from_func_name results = [func(include_forked_originals=False) for func in results][SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 414, in <listcomp> results = [func(include_forked_originals=False) for func in results][SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 122, in get_batch_log_metrics return self.run_latest_batch_metrics_with_func_name(""get_batch_log_metrics"", *args, **kwargs)[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 115, in run_latest_batch_metrics_with_func_name for dl_idx in range(self.num_dataloaders)[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 115, in <listcomp> for dl_idx in range(self.num_dataloaders)[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 100, in get_latest_from_func_name results.update(func(*args, add_dataloader_idx=add_dataloader_idx, **kwargs))[SEP]File <*>/site-packages/pytorch_lightning/core/step_result.py, line 298, in get_batch_log_metrics result[dl_key] = self[k]._forward_cache.detach()[SEP]AttributeError: 'NoneType' object has no attribute 'detach'",0
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 64, in <module> from tensorflow.python._pywrap_tensorflow_internal import *[SEP]ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.",0
"File <stdin>, line 24, in <module> [CODE][SEP]TypeError: expected CPU (got CUDA)",0
"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/smdistributed/dataparallel/__init__.py, line 16, in <module> import smddpcommon as hc[SEP]ImportError: libc10.so: cannot open shared object file: No such file or directory",0
"File <*>python3.4/site-packages/theano/gof/op.py, line 517, in __call__(self, *inputs, **kwargs) storage_map[ins] = [self._get_test_value(ins)][SEP]File <*>python3.4/site-packages/theano/gof/op.py, line 479, in _get_test_value(cls, v) raise AttributeError('%s has no test value' % v)[SEP]AttributeError: x has no test value",0
"File [FILE], line 5, in <module>() z = x + y[SEP]File <*>python3.4/site-packages/theano/tensor/var.py, line 128, in __add__(self, other) return theano.tensor.basic.add(self, other)[SEP]File <*>python3.4/site-packages/theano/gof/op.py, line 525, in __call__(self, *inputs, **kwargs) raise ValueError('Cannot compute test value: input %i (%s) of Op %s missing default value' % (i, ins, node))[SEP]ValueError: Cannot compute test value: input 0 (x) of Op Elemwise{add,no_inplace}(x, y) missing default value",0
"File [FILE], line 16, in <module>() caffe.Net(net_param, caffe.TEST)[SEP]ArgumentError: Python argument types in Net.__init__(Net, NetParameter, int) did not match C++ signature: __init__(boost::python::api::object, std::string, std::string, int) __init__(boost::python::api::object, std::string, int)",0
"File [FILE], line 19, in <module>() rotate_x_axis_theano = theano.function([angle_var],rotate_x_axis_expr(angle_var))[SEP]File [FILE], line 14, in rotate_x_axis_expr(angle) R[1][1] = cosa; R[1][2] = -sina[SEP]TypeError: 'TensorVariable' object does not support item assignment",0
"File [FILE], line 2, in <module>() y_pred = model.predict(X_nn)[SEP]File <*>/site-packages/keras/models.pyc, line 493, in predict(self, X, batch_size, verbose) return self._predict_loop(self._predict, X, batch_size, verbose)[0][SEP]AttributeError: 'Sequential' object has no attribute '_predict'",0
"File [FILE], line 1, in <module>() import input_data[SEP]ImportError: No module named input_data",0
"File [FILE], line 9, in <module>() example, label = sess.run([features, col1])[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.pyc, line 345, in run(self, fetches, feed_dict) results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.pyc, line 419, in _do_run(self, target_list, fetch_list, feed_dict) e.code)[SEP]InvalidArgumentError: Field 1 in record 0 is not a valid int32: 0.766126609",0
"File [FILE], line 1, in <module>() saver.restore(sess, ""params.ckpt"")[SEP]File <*>python3.5/site-packages/tensorflow/python/training/saver.py, line 891, in restore(self, sess, save_path) sess.run([self._restore_op_name], {self._filename_tensor_name: save_path})[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 368, in run(self, fetches, feed_dict) results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 428, in _do_run(self, target_list, fetch_list, feed_dict) target_list)[SEP]SystemError: <built-in function delete_Status> returned a result with an error set",0
"File [FILE], line 1, in <module>() T.grad(cost=cost, wrt=reg.weights)[SEP]File <*>python2.7/site-packages/theano/gradient.pyc, line 432, in grad(c ost, wrt, consider_constant, disconnected_inputs, add_names, known_grads, return_disconnected ) raise TypeError(""cost must be a scalar."")[SEP]TypeError: cost must be a scalar.",0
"File [FILE], line 3, in <module>() batch_size=16)[SEP]File <*>python2.7/site-packages/keras/models.pyc, line 402, in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs) sample_weight=sample_weight)[SEP]File <*>python2.7/site-packages/keras/engine/training.pyc, line 971, in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight) batch_size=batch_size)[SEP]File <*>python2.7/site-packages/keras/engine/training.pyc, line 911, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size) check_loss_and_target_compatibility(y, self.loss_functions, self.internal_output_shapes)[SEP]File <*>python2.7/site-packages/keras/engine/training.pyc, line 184, in check_loss_and_target_compatibility(targets, losses, output_shapes) ' while using as loss `categorical_crossentropy`. '[SEP]Exception: You are passing a target array of shape (10105, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via: ``` from keras.utils.np_utils import to_categorical y_binary = to_categorical(y_int) ``` Alternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",0
"File [FILE], line 30, in <module>() sess.run(optimizer, feed_dict={X: x, y: y})[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.pyc, line 340, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.pyc, line 542, in _run(self, handle, fetches, feed_dict, options, run_metadata) + e.args[0])[SEP]TypeError: Cannot interpret feed_dict key as Tensor: Can not convert a float64 into a Tensor.",0
"File [FILE], line 2, in <module>() sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 340, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 564, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_string, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 637, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) target_list, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 659, in _do_call(self, fn, *args) e.code)[SEP]InternalError: Blas SGEMM launch failed : a.shape=(100, 784), b.shape=(784, 10), m=100, n=10, k=784 [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_Placeholder_0/_4, Variable/read)]]",0
"File [FILE], line 1, in <module>() biases = tf.get_variable('biases', [64], tf.constant_initializer(0.0))[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 732, in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape) partitioner=partitioner, validate_shape=validate_shape)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 596, in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape) partitioner=partitioner, validate_shape=validate_shape)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 161, in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape) caching_device=caching_device, validate_shape=validate_shape)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 425, in _get_single_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, validate_shape) dtype = dtypes.as_dtype(dtype)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/dtypes.pyc, line 536, in as_dtype(type_value) if key == type_value:[SEP]TypeError: data type not understood",0
"File [FILE], line 7, in <module>() input_map={'import/pool5':out_pool})[SEP]File <*>python3.4/dist-packages/tensorflow/python/framework/importer.py, line 335, in import_graph_def(graph_def, input_map, return_elements, name, op_dict) ops.set_shapes_for_outputs(op)[SEP]File <*>python3.4/dist-packages/tensorflow/python/framework/ops.py, line 1612, in set_shapes_for_outputs(op) shapes = shape_func(op)[SEP]File <*>/roi_pooling_op_grad.py, line 15, in _roi_pool_shape(op) dims_rois = op.inputs[1].get_shape().as_list()[SEP]File <*>python3.4/dist-packages/tensorflow/python/framework/tensor_shape.py, line 747, in as_list(self) return [dim.value for dim in self._dims][SEP]TypeError: 'NoneType' object is not iterable",0
"File [FILE], line 13, in <module>() m.fit(input_fn=train_input_fn, steps=200)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 240, in fit(self, x, y, input_fn, steps, batch_size, monitors, max_steps) max_steps=max_steps)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 550, in _train_model(self, input_fn, steps, feed_fn, init_op, init_feed_fn, init_fn, device_fn, monitors, log_every_steps, fail_on_nan_loss, max_steps) train_op, loss_op = self._get_train_ops(features, targets)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.pyc, line 336, in _get_train_ops(self, features, targets) return super(LinearRegressor, self)._get_train_ops(features, targets)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.pyc, line 182, in _get_train_ops(self, features, targets) logits = self._logits(features, is_training=True)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.pyc, line 271, in _logits(self, features, is_training) logits = self._linear_logits(features, is_training)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.pyc, line 233, in _linear_logits(self, features, is_training) features, self._linear_feature_columns, is_training)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/composable_model.pyc, line 177, in build_model(self, features, feature_columns, is_training) scope=scope)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/feature_column_ops.pyc, line 178, in weighted_sum_from_feature_columns(columns_to_tensors, feature_columns, num_outputs, weight_collections, trainable, scope) transformed_tensor = transformer.transform(column)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/feature_column_ops.pyc, line 384, in transform(self, feature_column) feature_column.insert_transformed_feature(self._columns_to_tensors)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/feature_column.pyc, line 364, in insert_transformed_feature(self, columns_to_tensors) name=self.name + ""_lookup"")[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/gen_string_ops.pyc, line 185, in string_to_hash_bucket_fast(input, num_buckets, name) num_buckets=num_buckets, name=name)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc, line 463, in apply_op(self, op_type_name, name, **keywords) (prefix, dtypes.as_dtype(input_arg.type).name))[SEP]TypeError: Input 'input' of 'StringToHashBucketFast' Op has type int64 that does not match expected type of string.",0
"File [FILE], line 1, in <module>() audiocnn(input)[SEP]File <*>python2.7/site-packages/torch/nn/modules/module.pyc, line 224, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File [FILE], line 17, in forward(self, x) _, (_, _) = self.lstm(x,(h_0,c_0)) # x dim : 2 x 1 x 256[SEP]File <*>python2.7/site-packages/torch/nn/modules/rnn.pyc, line 162, in forward(self, input, hx) output, hidden = func(input, self.all_weights, hx)[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 351, in forward(input, *fargs, **fkwargs) return func(input, *fargs, **fkwargs)[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 244, in forward(input, weight, hidden) nexth, output = func(input, hidden, weight)[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 84, in forward(input, hidden, weight) hy, output = inner(input, hidden[l], weight[l])[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 113, in forward(input, hidden, weight) hidden = inner(input[i], hidden, *weight)[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 31, in LSTMCell(input, hidden, w_ih, w_hh, b_ih, b_hh) gates = F.linear(input, w_ih, b_ih) + F.linear(hx, w_hh, b_hh)[SEP]File <*>python2.7/site-packages/torch/nn/functional.pyc, line 553, in linear(input, weight, bias) return torch.addmm(bias, input, weight.t())[SEP]File <*>python2.7/site-packages/torch/autograd/variable.pyc, line 924, in addmm(cls, *args) return cls._blas(Addmm, args, False)[SEP]File <*>python2.7/site-packages/torch/autograd/variable.pyc, line 920, in _blas(cls, args, inplace) return cls.apply(*(tensors + (alpha, beta, inplace)))[SEP]RuntimeError: save_for_backward can only save input or output tensors, but argument 0 doesn't satisfy this condition",0
"File [FILE], line 10, in <module>() left.save('left.h5') # creates a HDF5 file 'my_model.h5'[SEP]File <*>python3.4/dist-packages/keras/engine/topology.py, line 2506, in save(self, filepath, overwrite, include_optimizer) save_model(self, filepath, overwrite, include_optimizer)[SEP]File <*>python3.4/dist-packages/keras/models.py, line 55, in save_model(model, filepath, overwrite, include_optimizer) raise ImportError('`save_model` requires h5py.')[SEP]ImportError: `save_model` requires h5py.",0
"File [FILE], line 1, in <module>() from imagenet_utils import preprocess_input, decode_predictions[SEP]ImportError: No module named 'imagenet_utils'",0
"File [FILE], line 18, in <module>() curr_loss = train(train_loader, model, criterion, epoch, num_epochs)[SEP]File [FILE], line 18, in train(train_loader, model, criterion, epoch, num_epochs) loss = criterion(outputs, labels)[SEP]File <*>python3.5/dist-packages/torch/nn/modules/module.py, line 325, in _ _call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File [FILE], line 11, in forward(self, logits, targets) return self.crossEntropy_loss(probs_flat, targets_flat)[SEP]File <*>python3.5/dist-packages/torch/nn/modules/module.py, line 325, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.5/dist-packages/torch/nn/modules/loss.py, line 601, in f orward(self, input, target) self.ignore_index, self.reduce)[SEP]File <*>python3.5/dist-packages/torch/nn/functional.py, line 1140, in cross_entropy(input, target, weight, size_average, ignore_index, reduce) return nll_loss(log_softmax(input, 1), target, weight, size_average, ignore_index, reduce)[SEP]File <*>python3.5/dist-packages/torch/nn/functional.py, line 786, in log_softmax(input, dim, _stacklevel) return torch._C._nn.log_softmax(input, dim)[SEP]RuntimeError: dimension out of range (expected to be in range of [-1, 0], but got 1)",0
"File [FILE], line 2, in <module>() loaded_model = load_model('my_model_vgg16.h5')[SEP]File <*>/site-packages/keras/models.py, line 246, in load_model(filepath, custom_objects, compile) topology.load_weights_from_hdf5_group(f['model_weights'], model.layers)[SEP]File <*>/site-packages/keras/engine/topology.py, line 3166, in load_weights_from_hdf5_group(f, layers) K.batch_set_value(weight_value_tuples)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2365, in batch_set_value(tuples) assign_op = x.assign(assign_placeholder)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 573, in assign(self, value, use_locking) return state_ops.assign(self._variable, value, use_locking=use_locking)[SEP]File <*>/site-packages/tensorflow/python/ops/state_ops.py, line 276, in assign(ref, value, validate_shape, use_locking, name) validate_shape=validate_shape)[SEP]File <*>/site-packages/tensorflow/python/ops/gen_state_ops.py, line 56, in assign(ref, value, validate_shape, use_locking, name) use_locking=use_locking, name=name)[SEP]File <*>/site-packages/tensorflow/python/framework/op_def_library.py, line 787, in _apply_op_helper(self, op_type_name, name, **keywords) op_def=op_def)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 2958, in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device) set_shapes_for_outputs(ret)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 2209, in set_shapes_for_outputs(op) shapes = shape_func(op)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 2159, in call_with_requiring(op) return call_cpp_shape_fn(op, require_shape_fn=True)[SEP]File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 627, in call_cpp_shape_fn(op, require_shape_fn) require_shape_fn)[SEP]File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 691, in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn) raise ValueError(err.message)[SEP]ValueError: Dimension 0 in both shapes must be equal, but are 4096 and 1000 for 'Assign_30' (op: 'Assign') with input shapes: [4096,3], [1000,3].",0
"File <*>python3.6/dist-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn) input_tensors_as_shapes, status)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]InvalidArgumentError: Negative dimension size caused by subtracting 3 from 1 for 'conv1d_26/convolution/Conv2D' (op: 'Conv2D') with input shapes: [?,1,1,256], [1,3,256,256].",0
"File <*>python3.5/site-packages/keras/utils/vis_utils.py, line 27, in _check_pydot() raise ImportError('Failed to import pydot. You must install pydot'[SEP]AttributeError: 'NoneType' object has no attribute 'Dot'",0
"File [FILE], line 1, in <module>() import tensorflow as tf[SEP]ModuleNotFoundError: No module named 'tensorflow'",0
"File [FILE], line 4, in <module>() (x_train, y_train), (x_test, y_test) = mnist.load_data()[SEP]File <*>python3.6/site-packages/keras/datasets/mnist.py, line 23, in load_data(path) file_hash='8a61469f7ea1b51cbae51d4f78837e45')[SEP]File <*>python3.6/site-packages/keras/utils/data_utils.py, line 224, in get_file(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir) raise Exception(error_msg.format(origin, e.errno, e.reason))[SEP]Exception: URL fetch failure on https://s3.amazonaws.com/img-datasets/mnist.npz: None -- [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)",0
"File <*>/train.py, line 167, in <module>() tf.app.run()[SEP]File <*>python3.6/dist-packages/tensorflow/python/platform/app.py, line 126, in run(main, argv) _sys.exit(main(argv))[SEP]File <*>/train.py, line 107, in main(_) overwrite=True)[SEP]File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 392, in copy(oldpath, newpath, overwrite) compat.as_bytes(oldpath), compat.as_bytes(newpath), overwrite, status)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]NotFoundError: ; No such file or directory",0
"File [FILE], line 35, in <module>() mean , variance = tf.nn.moments(X_train, axes = 1, keep_dims = True)[SEP]File <*>python2.7/nn_impl.pyc, line 666, in moments(x, axes, shift, name, keep_dims) y = math_ops.cast(x, dtypes.float32) if x.dtype == dtypes.float16 else x[SEP]TypeError: data type not understood",0
"File [FILE], line [NUM], in () [CODE][SEP]File [FILE], line [NUM], in [FUNC] [CODE][SEP]File <*>python3.6/site-packages/torch/autograd/variable.py, line [NUM], in setitem(self, key, value) [CODE][SEP]RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1327, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1306, in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata) status, run_metadata)[SEP]File <*>/contextlib.py, line 89, in __exit__(self, type, value, traceback) next(self.gen)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 466, in raise_exception_on_not_ok_status() pywrap_tensorflow.TF_GetCode(status))[SEP]InvalidArgumentError: You must feed a value for placeholder tensor 'dense_84_target' with dtype float and shape [?,?] [[Node: dense_84_target = Placeholder[dtype=DT_FLOAT, shape=[?,?], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]",0
"File <*>/model_finegrained.py, line 1, in <module>() tf.Variable(2, name='a:b')[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/variables.py, line 213, in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint) constraint=constraint)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/variables.py, line 289, in _init_from_args(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint) [initial_value]) as name:[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 4932, in __enter__(self) return self._name_scope.__enter__()[SEP]File <*>python3.6/contextlib.py, line 81, in __enter__(self) return next(self.gen)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3514, in name_scope(self, name) raise ValueError(""'%s' is not a valid scope name"" % name)[SEP]ValueError: 'a:b' is not a valid scope name",0
"File [FILE], line 1, in <module>() for batch_idx, (data, target) in enumerate(train_loader):[SEP]File <*>python2.7/dist-packages/torch/utils/data/dataloader.pyc, line 259, in __next__(self) batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>python2.7/dist-packages/torch/utils/data/dataloader.pyc, line 135, in default_collate(batch) return [default_collate(samples) for samples in transposed][SEP]File <*>python2.7/dist-packages/torch/utils/data/dataloader.pyc, line 112, in default_collate(batch) return torch.stack(batch, 0, out=out)[SEP]File <*>python2.7/dist-packages/torch/functional.pyc, line 64, in stack(sequence, dim, out) return torch.cat(inputs, dim)[SEP]RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 400 and 487 in dimension 2 at /pytorch/torch/lib/TH/generic/THTensorMath.c:2897",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 282, in __init__(self, fetches, contraction_fn) fetch, allow_tensor=True, allow_operation=True))[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3590, in as_graph_element(self, obj, allow_tensor, allow_operation) return self._as_graph_element_locked(obj, allow_tensor, allow_operation)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3679, in _as_graph_element_locked(self, obj, allow_tensor, allow_operation) types_str))[SEP]TypeError: Can not convert a Iterator into a Tensor or Operation.",0
"File [FILE], line 49, in <module>() sess.run(train_iter)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 900, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1120, in _run(self, handle, fetches, feed_dict, options, run_metadata) self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 427, in __init__(self, graph, fetches, feeds, feed_handles) self._fetch_mapper = _FetchMapper.for_fetch(fetches)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 253, in for_fetch(fetch) return _ElementFetchMapper(fetches, contraction_fn)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 286, in __init__(self, fetches, contraction_fn) (fetch, type(fetch), str(e)))[SEP]TypeError: Fetch argument <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x7fa2c0697c88> has invalid type <class 'tensorflow.python.data.ops.iterator_ops.Iterator'>, must be a string or Tensor. (Can not convert a Iterator into a Tensor or Operation.)",0
"File [FILE], line 16, in <module>() grads = grad(model, x, y)[SEP]File [FILE], line 8, in grad(model, inputs, targets) return tape.gradient(loss_value, model.variables)[SEP]File <*>/site-packages/tensorflow/python/eager/backprop.py, line 767, in gradient(self, target, sources, output_gradients) output_gradients=output_gradients)[SEP]File <*>/site-packages/tensorflow/python/eager/imperative_grad.py, line 63, in imperative_grad(vspace, tape, target, sources, output_gradients) tape._tape, vspace, target, sources, output_gradients) # pylint: disable=protected-access[SEP]RuntimeError: Trying to call tape.gradient on a non-persistent tape while it is still active.",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata) status, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]InvalidArgumentError: You must feed a value for placeholder tensor 'time_distributed_2_target' with dtype float and shape [?,?,?] [[Node: time_distributed_2_target = Placeholder[dtype=DT_FLOAT, shape=[?,?,?], _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1322, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1307, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1409, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata)[SEP]InvalidArgumentError: slice index 0 of dimension 0 out of bounds. [[Node: lstm_25/strided_slice_13 = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](lstm_25/transpose, loss_11/dense_58_loss/Const_2, lstm_25/strided_slice_9/stack_2, lstm_25/strided_slice_9/stack_2)]]",0
"File [FILE], line 57, in <module>() feed_dict=feed_dict)[SEP]TypeError: 'NoneType' object is not iterable",0
"File [FILE], line 2, in <module>() steps_per_epoch=1, epochs=15, verbose=2)[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/engine/training.py, line 2230, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1877, in train_on_batch(self, x, y, sample_weight, class_weight) class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1480, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size) exception_prefix='target')[SEP]File <*>/site-packages/keras/engine/training.py, line 76, in _standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data][SEP]File <*>/site-packages/keras/engine/training.py, line 76, in <listcomp>(.0) data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data][SEP]AttributeError: 'Tensor' object has no attribute 'ndim'",0
"File [FILE], line 7, in <module>() X = AttentionLayer()(X)[SEP]File <*>python3.6/site-packages/keras/engine/topology.py, line 619, in __call__(self, inputs, **kwargs) output = self.call(inputs, **kwargs)[SEP]File <*>/attention.py, line 51, in call(self, x) flatten_g = hw_flatten(g)[SEP]File <*>/attention.py, line 41, in hw_flatten(x) return K.reshape(x, shape=[x.shape[0], x.shape[1]*x.shape[2], x.shape[-1]])[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 1898, in reshape(x, shape) return tf.reshape(x, shape)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py, line 6113, in reshape(tensor, shape, name) ""Reshape"", tensor=tensor, shape=shape, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 513, in _apply_op_helper(self, op_type_name, name, **keywords) raise err[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 510, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1104, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 235, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 214, in constant(value, dtype, shape, name, verify_shape) value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 521, in make_tensor_proto(values, dtype, shape, verify_shape) ""supported type."" % (type(values), values))[SEP]TypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [Dimension(None), Dimension(64), Dimension(8)]. Consider casting elements to a supported type.",0
"File [FILE], line 3, in <module>() plt.imshow(grid)[SEP]File <*>python3.6/site-packages/matplotlib/pyplot.py, line 3205, in imshow(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs) **kwargs)[SEP]File <*>python3.6/site-packages/matplotlib/__init__.py, line 1855, in inner(ax, *args, **kwargs) return func(ax, *args, **kwargs)[SEP]File <*>python3.6/site-packages/matplotlib/axes/_axes.py, line 5487, in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs) im.set_data(X)[SEP]File <*>python3.6/site-packages/matplotlib/image.py, line 653, in set_data(self, A) raise TypeError(""Invalid dimensions for image data"")[SEP]TypeError: Invalid dimensions for image data",0
"File [FILE], line 2, in <module>() grid = torchvision.utils.make_grid(w.permute(0,2,3,1), nrow=5)[SEP]File <*>python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/utils.py, line 85, in make_grid(tensor, nrow, padding, normalize, range, scale_each, pad_value) .copy_(tensor[k])[SEP]RuntimeError: The expanded size of the tensor (3) must match the existing size (640) at non-singleton dimension 0",0
"File [FILE], line 1, in <module>() df = pd.DataFrame((dataset))[SEP]File <*>python3.6/site-packages/pandas/core/frame.py, line 404, in __init__(self, data, index, columns, dtype, copy) raise ValueError('DataFrame constructor not properly called!')[SEP]ValueError: DataFrame constructor not properly called!",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1330, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1315, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1423, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) status, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]FailedPreconditionError: Attempting to use uninitialized value W_4 [[Node: W_4/read = Identity[T=DT_FLOAT, _class=[""loc:@W_4""], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](W_4)]]",0
"File [FILE], line 116, in <module>() print('Test_accuracy : ',sess.run(accuracy, feed_dict={input: x, output: y,keep_prob:1.0}))[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 908, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1143, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1324, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1343, in _do_call(self, fn, *args) raise type(e)(node_def, op, message)[SEP]FailedPreconditionError: Attempting to use uninitialized value W_4 [[Node: W_4/read = Identity[T=DT_FLOAT, _class=[""loc:@W_4""], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](W_4)]]",0
"File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 510, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1144, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 981, in _TensorTensorConversionFunction(t, dtype, name, as_ref) (dtype.name, t.dtype.name, str(t)))[SEP]ValueError: Tensor conversion requested dtype float16 for Tensor with dtype float32: 'Tensor(""sampled_softmax_loss/Log:0"", shape=(64, 1), dtype=float32)'",0
"File [FILE], line 48, in <module>() labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1349, in sampled_softmax_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name, seed) seed=seed)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1128, in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed) true_logits -= math_ops.log(true_expected_count)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/math_ops.py, line 862, in binary_op_wrapper(x, y) return func(x, y, name=name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 8318, in sub(x, y, name) ""Sub"", x=x, y=y, name=name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 546, in _apply_op_helper(self, op_type_name, name, **keywords) inferred_from[input_arg.type_attr]))[SEP]TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type float16 of argument 'x'.",0
"File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1334, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1319, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1407, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata)[SEP]UnimplementedError: File system scheme '[local]' not implemented (file: 'checkpointsBook2Vec5Inputs') [[{{node save/SaveV2}} = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, embeddings, embeddings/Shampoo, embeddings/Shampoo_1, embeddings/Shampoo_2, epochCount, softmax_biases, softmax_weights, softmax_weights/Shampoo, softmax_weights/Shampoo_1, softmax_weights/Shampoo_2)]]",0
"File [FILE], line 50, in <module>() save_path = saver.save(session, ""checkpointsBook2Vec5Inputs/Research2VecCS4.ckpt"") #Save checkpoint[SEP]File <*>python3.6/dist-packages/tensorflow/python/training/saver.py, line 1441, in save(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs) {self.saver_def.filename_tensor_name: checkpoint_file})[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 929, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1152, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1328, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1348, in _do_call(self, fn, *args) raise type(e)(node_def, op, message)[SEP]UnimplementedError: File system scheme '[local]' not implemented (file: 'checkpointsBook2Vec5Inputs') [[node save/SaveV2 (defined at <ipython-input-15-c14caac2081d>:45) = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, embeddings, embeddings/Shampoo, embeddings/Shampoo_1, embeddings/Shampoo_2, epochCount, softmax_biases, softmax_weights, softmax_weights/Shampoo, softmax_weights/Shampoo_1, softmax_weights/Shampoo_2)]]",0
"File [FILE], line 3, in <module>() steps=10)[SEP]File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 354, in train(self, input_fn, hooks, steps, max_steps, saving_listeners) loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1207, in _train_model(self, input_fn, hooks, saving_listeners) return self._train_model_default(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1237, in _train_model_default(self, input_fn, hooks, saving_listeners) features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)[SEP]File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1195, in _call_model_fn(self, features, labels, mode, config) model_fn_results = self._model_fn(features=features, **kwargs)[SEP]File [FILE], line 35, in my_model(features, labels, mode, params) num_classes=vocabulary_size))[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1248, in nce_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name) name=name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1031, in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed) if labels.dtype != dtypes.int64:[SEP]TypeError: data type not understood",0
"File [FILE], line 8, in <module>() concat = tf.keras.layers.Concatenate()((features['a'], features['b']))[SEP]File <*>/base_layer.py, line 753, in __call__(self, inputs, *args, **kwargs) self.build(input_shapes)[SEP]File <*>/tf_utils.py, line 150, in wrapper(instance, input_shape) input_shape = tuple(tensor_shape.TensorShape(input_shape).as_list())[SEP]File <*>/tensor_shape.py, line 690, in __init__(self, dims) self._dims = [as_dimension(d) for d in dims_iter][SEP]File <*>/tensor_shape.py, line 632, in as_dimension(value) return Dimension(value)[SEP]File <*>/tensor_shape.py, line 185, in __init__(self, value) self._value = int(value)[SEP]TypeError: int() argument must be a string or a number, not 'TensorShapeV1'",0
"File [FILE], line 5, in <module>() for i, data in enumerate(trainloader, 0):[SEP]File <*>python3.7/site-packages/torch/utils/data/dataloader.py, line 313, in __next__(self) indices = next(self.sample_iter) # may raise StopIteration[SEP]File <*>python3.7/site-packages/torch/utils/data/sampler.py, line 138, in __iter__(self) for idx in self.sampler:[SEP]File <*>python3.7/site-packages/torch/utils/data/sampler.py, line 34, in __iter__(self) return iter(range(len(self.data_source)))[SEP]TypeError: 'torch.Size' object cannot be interpreted as an integer",0
"File [FILE], line 3, in <module>() epochs = range(epochs)[SEP]NameError: name 'epochs' is not defined",0
"File [FILE], line 16, in <module>() dataset = dataset.padded_batch(2, padded_shapes=([None],[None]), padding_values=-1)[SEP]File <*>python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py, line 945, in padded_batch(self, batch_size, padded_shapes, padding_values, drop_remainder) drop_remainder)[SEP]File <*>python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py, line 2528, in __init__(self, input_dataset, batch_size, padded_shapes, padding_values, drop_remainder) input_dataset.output_types)[SEP]File <*>python3.6/dist-packages/tensorflow/python/data/util/nest.py, line 467, in map_structure_up_to(shallow_tree, func, *inputs) assert_shallow_structure(shallow_tree, input_tree)[SEP]File <*>python3.6/dist-packages/tensorflow/python/data/util/nest.py, line 301, in assert_shallow_structure(shallow_tree, input_tree, check_types) ""Input has type: %s."" % type(input_tree))[SEP]TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'int'>.",0
"File [FILE], line 4, in <module>() module_spec=""https://tfhub.dev/google/nnlm-en-dim128/1"")[SEP]File <*>python3.6/site-packages/tensorflow_hub/feature_column.py, line 74, in text_embedding_column(key, module_spec, trainable) module_spec = module.as_module_spec(module_spec)[SEP]File <*>python3.6/site-packages/tensorflow_hub/module.py, line 33, in as_module_spec(spec) return load_module_spec(spec)[SEP]File <*>python3.6/site-packages/tensorflow_hub/module.py, line 58, in load_module_spec(path) return registry.loader(path)[SEP]File <*>python3.6/site-packages/tensorflow_hub/registry.py, line 45, in __call__(self, *args, **kwargs) self._name, args, kwargs))[SEP]RuntimeError: Missing implementation that supports: loader(*('/var/folders/pc/h0fr0z2x1pjbmdb63mhn84_w0000gn/T/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997',), **{})",0
"File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 511, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1175, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 304, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 245, in constant(value, dtype, shape, name) allow_broadcast=True)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast))[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/tensor_util.py, line 454, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) raise ValueError(""None values not supported."")[SEP]ValueError: None values not supported.",0
"File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 525, in _apply_op_helper(self, op_type_name, name, **keywords) values, as_ref=input_arg.is_ref).dtype.name[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1175, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 304, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 245, in constant(value, dtype, shape, name) allow_broadcast=True)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast))[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/tensor_util.py, line 454, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) raise ValueError(""None values not supported."")[SEP]ValueError: None values not supported.",0
"File [FILE], line 5, in <module> hessian = tf.hessians(f, xy)[SEP]File <*>python3.7/site-packages/tensorflow/python/ops/gradients_impl.py, line 1407, in hessians(ys, xs, name, colocate_gradients_with_ops, gate_gradients, aggregation_method) gradient = array_ops.reshape(gradient, [-1])[SEP]File <*>python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py, line 7180, in reshape(tensor, shape, name) ""Reshape"", tensor=tensor, shape=shape, name=name)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 529, in _apply_op_helper(self, op_type_name, name, **keywords) (input_name, err))[SEP]ValueError: Tried to convert 'tensor' to a tensor and failed. Error: None values not supported.",0
"File [FILE], line 1, in () output = model(data)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line [NUM], in call(self, *input, **kwargs) [CODE][SEP]File <*>python3.6/dist-packages/torch/nn/functional.py, line 1354, in linear(input, weight, bias) output = input.matmul(weight.t())[SEP]RuntimeError: size mismatch, m1: [3584 x 28], m2: [784 x 128] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:940",0
"File [FILE], line 14, in <module>() random_search.fit(X_train, y_train)[SEP]File <*>python3.6/site-packages/sklearn/model_selection/_search.py, line 677, in fit(self, X, y, groups, **fit_params) base_estimator = clone(self.estimator)[SEP]File <*>python3.6/site-packages/sklearn/base.py, line 58, in clone(estimator, safe) % (repr(estimator), type(estimator)))[SEP]TypeError: Cannot clone object '<keras.engine.sequential.Sequential object at 0x7fc268d8abe0>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods.",0
"File [FILE], line 1, in <module> modl(x)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 477, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File [FILE], line 223, in forward(self, x) de2 = torch.cat([en6add,de2_],1)[SEP]RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 5 and 4 in dimension 2 at /opt/conda/conda-bld/pytorch_1535491974311/work/aten/src/TH/generic/THTensorMath.cpp:3616",0
"File [FILE], line 1, in <module>() tf.enable_eager_execution()[SEP]AttributeError: module 'tensorflow' has no attribute 'enable_eager_execution'",0
"File [FILE], line 1, in <module>() create_record()[SEP]File [FILE], line 17, in create_record() ""mfcc"":tf.train.Feature(float_list=tf.train.FloatList(value=mfcc.tolist()))[SEP]TypeError: [-389.381029172618, -393.08814551655723, -404.7248725876356, -407.1006984237564, -409.22695909850626 has type list, but expected one of: int, long, float",0
"File [FILE], line 6, in <module>() print(char_OneHotEncoding(torch.tensor(x_train, dtype=torch.long).cuda()).shape)[SEP]File [FILE], line 4, in char_OneHotEncoding(x) coded[:,i] = scatter(x[:,i])[SEP]File [FILE], line 9, in scatter(x) return torch.zeros(x.shape[0], 101).scatter_(1, x.view(-1,1), 1)[SEP]RuntimeError: Expected object of backend CPU but got backend CUDA for argument #3 'index'",0
"File [FILE], line 1, in <module> tflite_quantized_model = converter.convert()[SEP]File <*>python3.5/site-packages/tensorflow/contrib/lite/python/lite.py, line 453, in convert(self) **converter_kwargs)[SEP]File <*>python3.5/site-packages/tensorflow/contrib/lite/python/convert.py, line 342, in toco_convert_impl(input_data, input_tensors, output_tensors, *args, **kwargs) input_data.SerializeToString())[SEP]File <*>python3.5/site-packages/tensorflow/contrib/lite/python/convert.py, line 135, in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str) (stdout, stderr))[SEP]RuntimeError: TOCO failed see console for info.",0
"File [FILE], line 34, in <module>() train_op.minimize(cost, var_list=[w])[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py, line 296, in minimize(self, loss, var_list, grad_loss, name) loss, var_list=var_list, grad_loss=grad_loss)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py, line 328, in _compute_gradients(self, loss, var_list, grad_loss) loss_value = loss()[SEP]TypeError: 'tensorflow.python.framework.ops.EagerTensor' object is not callable",0
"File [FILE], line 51, in <module> model.fit([x_img_train, x_transform_train], y_train, batch_size=8)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1039, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs) validation_steps=validation_steps)[SEP]File <*>python3.6/site-packages/keras/engine/training_arrays.py, line 199, in fit_loop(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps) outs = f(ins_batch)[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 2715, in __call__(self, inputs) return self._call(inputs)[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 2675, in _call(self, inputs) fetched = self._callable_fn(*array_vals)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1439, in __call__(self, *args, **kwargs) run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]InvalidArgumentError: Incompatible shapes: [8,28,28,32] vs. [8,32] [[{{node training_5/Adam/gradients/affine_transform_18/mul_grad/BroadcastGradientArgs}} = BroadcastGradientArgs[T=DT_INT32, _class=[""loc:@training_5/Adam/gradients/batch_normalization_22/cond/Merge_grad/cond_grad""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](training_5/Adam/gradients/affine_transform_18/mul_grad/Shape, training_5/Adam/gradients/affine_transform_18/mul_grad/Shape_1)]]",0
"File [FILE], line 4, in <module>() validation_steps=10, verbose=1, callbacks=[lr_reduction])[SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1418, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/keras/engine/training_generator.py, line 181, in fit_generator(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) generator_output = next(output_generator)[SEP]File <*>python3.6/site-packages/keras/utils/data_utils.py, line 601, in get(self) six.reraise(*sys.exc_info())[SEP]File <*>python3.6/site-packages/six.py, line 693, in reraise(tp, value, tb) raise value[SEP]File <*>python3.6/site-packages/keras/utils/data_utils.py, line 595, in get(self) inputs = self.queue.get(block=True).get()[SEP]File <*>python3.6/pool.py, line 644, in get(self, timeout) raise self._value[SEP]File <*>python3.6/pool.py, line 119, in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception) result = (True, func(*args, **kwds))[SEP]File <*>python3.6/site-packages/keras/utils/data_utils.py, line 401, in get_index(uid, i) return _SHARED_SEQUENCES[uid][i][SEP]File <*>python3.6/site-packages/keras_preprocessing/image/iterator.py, line 65, in __getitem__(self, idx) return self._get_batches_of_transformed_samples(index_array)[SEP]File <*>python3.6/site-packages/keras_preprocessing/image/iterator.py, line 235, in _get_batches_of_transformed_samples(self, index_array) x = self.image_data_generator.standardize(x)[SEP]File <*>python3.6/site-packages/keras_preprocessing/image/image_data_generator.py, line 697, in standardize(self, x) x = self.preprocessing_function(x)[SEP]File [FILE], line 2, in preprocess(im) im = cv2.imread(im, 1)[SEP]TypeError: bad argument type for built-in operation",0
"File [FILE], line 1, in <module> model.fit(dataset, epochs=10, steps_per_epoch=10)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 791, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1515, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch')[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 257, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) batch_outs = batch_function(*batch_data)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1238, in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics) extract_tensors_from_dataset=True)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 2596, in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset) exception_prefix='input')[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 349, in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) str(data_shape))[SEP]ValueError: Error when checking input: expected input_1 to have shape (32,) but got array with shape (1,)",0
"File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1659, in _create_c_op(graph, node_def, inputs, control_inputs) c_op = c_api.TF_FinishOperation(op_desc)[SEP]InvalidArgumentError: Shapes must be equal rank, but are 2 and 3 for 'ScatterUpdate' (op: 'ScatterUpdate') with input shapes: [?,10], [?,2], [?,2].",0
"File [FILE], line 29, in <module>() output_data = top_n_filter_layer(input_layer)[SEP]File [FILE], line 20, in top_n_filter_layer(input_data, n, tf_dtype) output = tf.scatter_update(zeros_variable, indices_to_keep, values_to_keep)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/state_ops.py, line 299, in scatter_update(ref, indices, updates, use_locking, name) use_locking=use_locking, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py, line 1275, in scatter_update(ref, indices, updates, use_locking, name) use_locking=use_locking, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 788, in _apply_op_helper(self, op_type_name, name, **keywords) op_def=op_def)[SEP]File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3300, in create_op(***failed resolving arguments***) op_def=op_def)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1823, in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def) control_input_ops)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1662, in _create_c_op(graph, node_def, inputs, control_inputs) raise ValueError(str(e))[SEP]ValueError: Shapes must be equal rank, but are 2 and 3 for 'ScatterUpdate' (op: 'ScatterUpdate') with input shapes: [?,10], [?,2], [?,2].",0
"File [FILE], line 32, in <module> loss = loss_func(output, b_y)[SEP]File <*>python3.5/site-packages/torch/nn/modules/module.py, line 489, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.5/site-packages/torch/nn/modules/loss.py, line 504, in forward(self, input, target) return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)[SEP]File <*>python3.5/site-packages/torch/nn/functional.py, line 2027, in binary_cross_entropy(input, target, weight, size_average, reduce, reduction) input, target, weight, reduction_enum)[SEP]RuntimeError: Expected object of scalar type Float but got scalar type Long for argument #2 'target'",0
"File [FILE], line 23, in <module>() print(model(torch.tensor(X)).size)[SEP]File [FILE], line 14, in forward(self, x) x = self.layer1(x)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 489, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/conv.py, line 187, in forward(self, input) self.padding, self.dilation, self.groups)[SEP]RuntimeError: Expected 3-dimensional input for 3-dimensional weight [20, 7, 5], but got 2-dimensional input of size [10, 7] instead",0
"File <*>python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py, line 612, in __call__(self, inputs, *args, **kwargs) outputs = self.call(inputs, *args, **kwargs)[SEP]File [FILE], line 8, in call(self, data_input) model = self.input_layer(data_input)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/input_layer.py, line 233, in Input(shape, batch_size, name, dtype, sparse, tensor, **kwargs) input_tensor=tensor)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/input_layer.py, line 94, in __init__(self, input_shape, batch_size, dtype, input_tensor, sparse, name, **kwargs) batch_input_shape = (batch_size,) + tuple(input_shape)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 449, in __iter__(self) ""Tensor objects are only iterable when eager execution is ""[SEP]TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.",0
"File [FILE], line 5, in <module>() train_step(x_sample=x_point, y_sample=y_point)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 418, in __call__(self, *args, **kwds) results = self._stateful_fn(*args, **kwds)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1287, in __call__(self, *args, **kwargs) graph_function, args, kwargs = self._maybe_define_function(args, kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1611, in _maybe_define_function(self, args, kwargs) args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1512, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/func_graph.py, line 694, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 317, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/func_graph.py, line 686, in wrapper(*args, **kwargs) ), args, kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/autograph/impl/api.py, line 392, in converted_call(f, owner, options, args, kwargs) result = converted_f(*effective_args, **kwargs)[SEP]File <*>/tmpluzodr7d.py, line 4, in tf__train_step(x_sample, y_sample) predictions = ag__.converted_call(nn_regressor, None, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (x_sample,), {})[SEP]File <*>python3.6/site-packages/tensorflow/python/autograph/impl/api.py, line 267, in converted_call(f, owner, options, args, kwargs) return _call_unconverted(f, args, kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/autograph/impl/api.py, line 188, in _call_unconverted(f, args, kwargs) return f(*args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py, line 625, in __call__(self, inputs, *args, **kwargs) exception_str + '\n""""""')[SEP]TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.",0
"File [FILE], line 72, in <module>() validate=True, resume=False, flow=True, use_cuda=cuda)[SEP]File <*>/train_helper.py, line 109, in train(model, num_epochs, train_set, dev_set, lr, batch_size, start_epoch, log, checkpoint_path, validate, resume, flow, use_cuda) loss = criterion(outputs, labels)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 489, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/loss.py, line 904, in forward(self, input, target) ignore_index=self.ignore_index, reduction=self.reduction)[SEP]File <*>python3.6/dist-packages/torch/nn/functional.py, line 1970, in cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction) return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)[SEP]File <*>python3.6/dist-packages/torch/nn/functional.py, line 1790, in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction) ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)[SEP]RuntimeError: Expected object of scalar type Long but got scalar type Byte for argument #2 'target'",0
"File [FILE], line 3, in <module> act([a,b])[SEP]File <*>python36/site-packages/keras/engine/base_layer.py, line 431, in __call__(self, inputs, **kwargs) self.build(unpack_singleton(input_shapes))[SEP]TypeError: build() takes 1 positional argument but 2 were given",0
"File [FILE], line 17, in <module>() d1, d2 = sess.run((d_fx1, d_fx2))[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 929, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1137, in _run(self, handle, fetches, feed_dict, options, run_metadata) self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 471, in __init__(self, graph, fetches, feeds, feed_handles) self._fetch_mapper = _FetchMapper.for_fetch(fetches)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 261, in for_fetch(fetch) return _ListFetchMapper(fetch)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 370, in __init__(self, fetches) self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches][SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 370, in <listcomp>(.0) self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches][SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 258, in for_fetch(fetch) type(fetch)))[SEP]TypeError: Fetch argument None has invalid type <class 'NoneType'>",0
"File [FILE], line 27, in <module>() grads = sess.run(d_fx)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 929, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1137, in _run(self, handle, fetches, feed_dict, options, run_metadata) self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 471, in __init__(self, graph, fetches, feeds, feed_handles) self._fetch_mapper = _FetchMapper.for_fetch(fetches)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 258, in for_fetch(fetch) type(fetch)))[SEP]TypeError: Fetch argument None has invalid type <class 'NoneType'>",0
"File [FILE], line 70, in <module>() filtered_output = keras.layers.merge.Multiply()([output, actions_input])[SEP]File <*>python3.6/dist-packages/keras/layers/merge.py, line 61, in _compute_elemwise_op_output_shape(self, shape1, shape2) str(shape1) + ' ' + str(shape2))[SEP]ValueError: Operands could not be broadcast together with shapes (2592,) (4,)",0
"File [FILE], line 9, in <module>() for i in train_iter:[SEP]File <*>python3.6/site-packages/torchtext/data/iterator.py, line 157, in __iter__(self) yield Batch(minibatch, self.dataset, self.device)[SEP]File <*>python3.6/site-packages/torchtext/data/batch.py, line 34, in __init__(self, data, dataset, device) setattr(self, name, field.process(batch, device=device))[SEP]File <*>python3.6/site-packages/torchtext/data/field.py, line 201, in process(self, batch, device) tensor = self.numericalize(padded, device=device)[SEP]File <*>python3.6/site-packages/torchtext/data/field.py, line 302, in numericalize(self, arr, device) arr = [self.vocab.stoi[x] for x in arr][SEP]File <*>python3.6/site-packages/torchtext/data/field.py, line 302, in <listcomp>(.0) arr = [self.vocab.stoi[x] for x in arr][SEP]AttributeError: 'Field' object has no attribute 'vocab'",0
"File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1659, in _create_c_op(graph, node_def, inputs, control_inputs) c_op = c_api.TF_FinishOperation(op_desc)[SEP]InvalidArgumentError: Dimensions must be equal, but are 1 and 64 for 'loss_1/zero_padding2d_5_loss/MatMul' (op: 'BatchMatMul') with input shapes: [?,64,64,1], [1,64,64,?].",0
"File [FILE], line 42, in <module> autoencoder.compile(optimizer='adadelta', loss=[custom_loss1,custom_loss2])[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 342, in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs) sample_weight, mask)[SEP]File <*>python3.6/site-packages/keras/engine/training_utils.py, line 404, in weighted(y_true, y_pred, weights, mask) score_array = fn(y_true, y_pred)[SEP]File [FILE], line 4, in custom_loss1(y_true, y_pred) dcor = -1*distance_correlation(y_true,encoded_layer)[SEP]File [FILE], line 4, in distance_correlation(y_true, y_pred) pred_d = pred_r - 2*tf.matmul(y_pred,tf.transpose(y_pred))+tf.transpose(pred_r)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/math_ops.py, line 2417, in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name) a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py, line 1423, in batch_mat_mul(x, y, adj_x, adj_y, name) ""BatchMatMul"", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 788, in _apply_op_helper(self, op_type_name, name, **keywords) op_def=op_def)[SEP]File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3300, in create_op(***failed resolving arguments***) op_def=op_def)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1823, in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def) control_input_ops)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1662, in _create_c_op(graph, node_def, inputs, control_inputs) raise ValueError(str(e))[SEP]ValueError: Dimensions must be equal, but are 1 and 64 for 'loss_1/zero_padding2d_5_loss/MatMul' (op: 'BatchMatMul') with input shapes: [?,64,64,1], [1,64,64,?].",0
"File [FILE], line 4, in <module> steps=20)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1185, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors) raise RuntimeError(""Attempting to capture an EagerTensor without ""[SEP]RuntimeError: Attempting to capture an EagerTensor without building a function.",0
"File [FILE], line 3, in <module> train(n_epochs,net,loaders,optimizer,criterion,'saved_model/dog_model.pt')[SEP]File [FILE], line 24, in train(n_epochs, model, loader, optimizer, criterion, save_path) loss = criterion(outputs,target)[SEP]RuntimeError: The size of tensor a (133) must match the size of tensor b (10) at non-singleton dimension 1.",0
"File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 1969, in __setattr__(self, name, value) super(tracking.AutoTrackable, self).__setattr__(name, value)[SEP]AttributeError: can't set attribute",0
"File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 1974, in __setattr__(self, name, value) 'different name.').format(name))[SEP]AttributeError: Can't set the attribute ""name"", likely because it conflicts with an existing read-only @property of the object. Please choose a different name.",0
"File [FILE], line 1, in <module> import tensorflow_probability as tfp[SEP]ModuleNotFoundError: No module named 'tensorflow_probability'.",0
"File [FILE], line 35, in <module>() output = model(data)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/conv.py, line 338, in forward(self, input) self.padding, self.dilation, self.groups)[SEP]RuntimeError: Expected 4-dimensional input for 4-dimensional weight 32 3 3, but got 3-dimensional input of size [3, 224, 224] instead",0
"File [FILE], line 1, in <module>() process_image('IMG_PATH')[SEP]File [FILE], line 5, in process_image(img_path) pImg = MobileNetV2.preprocess_input(img_array)[SEP]AttributeError: 'function' object has no attribute 'preprocess_input'",0
"File [FILE], line 23, in <module> optimizer = nlp.resume_training()[SEP]TypeError: Model() got multiple values for argument 'nr_class'",0
"File [FILE], line 22, in <module> dydx = tape.gradient(y, YIELDS)[SEP]File <*>/site-packages/tensorflow/python/eager/backprop.py, line 1002, in gradient(self, target, sources, output_gradients, unconnected_gradients) unconnected_gradients=unconnected_gradients)[SEP]File <*>/site-packages/tensorflow/python/eager/imperative_grad.py, line 76, in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients) compat.as_str(unconnected_gradients.value))[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 906, in backward_function(*args) list(args) + side_outputs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 612, in _call_flat(self, args) ""but got CompositeTensor: %r"" % args)[SEP]AssertionError: Expected all args to be Tensors or Variables; but got CompositeTensor: [<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x00000203013C2128>, <tf.Tensor: id=1024, shape=(), dtype=float32, numpy=-1.0>, <tf.Tensor: id=1025, shape=(10,), dtype=float32, numpy= array([0.04153733, 0.0851776 , 0.13988876, 0.27034396, 0.40101147, dtype=float32)>, <tf.Tensor: id=1026, shape=(10,), dtype=float32, numpy=array([ 1., 2., 3., 5., 7., 10., 12., 15., 20., 25.], dtype=float32)>, <tf.Tensor: id=1027, shape=(10,), dtype=float32, numpy= array([0.04153733, 0.0425888 , 0.04662959, 0.05406879, 0.05728735, dtype=float32)>]",0
"File [FILE], line 29, in <module> global_loss_list = global_training(lstm2)[SEP]File [FILE], line 5, in global_training(optimizee) _, global_loss_1 = learn2(LSTM_Optimizee, training_steps, retain_graph_flag=True, reset_theta=True)[SEP]File [FILE], line 45, in learn2(optimizee, unroll_train_steps, retain_graph_flag, reset_theta) loss.backward(retain_graph = retain_graph_flag) #The default is False, when the optimized LSTM is set to True[SEP]File <*>python3.7/site-packages/torch/tensor.py, line 118, in backward(self, gradient, retain_graph, create_graph) torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>python3.7/site-packages/torch/autograd/__init__.py, line 93, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables) allow_unreachable=True) # allow_unreachable flag[SEP]RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 10]] is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",0
"File [FILE], line 2, in <module> x.forward(torch.tensor([0,2,5,8]), higgs_bosson=2)[SEP]TypeError: forward() got an unexpected keyword argument 'higgs_bosson'",0
"File [FILE], line [NUM], in <module> [CODE][SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 458, in load_wrapper(*args, **kwargs) return load_function(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 550, in load_model(filepath, custom_objects, compile) model = _deserialize_model(h5dict, custom_objects, compile)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 292, in _deserialize_model(h5dict, custom_objects, compile) reshape=False)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 811, in convert_nested_model(weights) original_backend=original_backend))[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 823, in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape) weights = convert_nested_model(weights)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 799, in convert_nested_model(weights) original_backend=original_backend))[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 942, in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape) weights[0] = np.transpose(weights[0], (3, 2, 0, 1))[SEP]File <*>python3.6/site-packages/numpy/core/fromnumeric.py, line 639, in transpose(a, axes) return _wrapfunc(a, 'transpose', axes)[SEP]File <*>python3.6/site-packages/numpy/core/fromnumeric.py, line 56, in _wrapfunc(obj, method, *args, **kwds) return getattr(obj, method)(*args, **kwds)[SEP]ValueError: axes don't match array",0
"File <*>python3.6/site-packages/keras/engine/topology.py, line 425, in assert_input_compatibility(self, inputs) K.is_keras_tensor(x)[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 400, in is_keras_tensor(x) raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '[SEP]ValueError: Unexpectedly found an instance of type `<class 'keras.layers.normalization.BatchNormalization'>`. Expected a symbolic tensor instance.",0
"File [FILE], line 16, in <module> print(stock_prediction())[SEP]File [FILE], line 25, in stock_prediction() model.fit(trainX, trainY, batch_size=1, epochs=200, verbose=2)[SEP]File <*>/site-packages/keras/engine/training.py, line 1178, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) validation_freq=validation_freq)[SEP]File <*>/site-packages/keras/engine/training_arrays.py, line 213, in fit_loop(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq) if batch_index == len(batches) - 1: # Last batch.[SEP]UnboundLocalError: local variable 'batch_index' referenced before assignment",0
"File [FILE], line 8, in <module> train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](root='./.data', ngrams=NGRAMS, vocab=None)[SEP]File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 170, in AG_NEWS(*args, **kwargs) return _setup_datasets(*((""AG_NEWS"",) + args), **kwargs)[SEP]File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 128, in _setup_datasets(dataset_name, root, ngrams, vocab, include_unk) vocab = build_vocab_from_iterator(_csv_iterator(train_csv_path, ngrams))[SEP]File <*>python36/site-packages/torchtext/vocab.py, line 557, in build_vocab_from_iterator(iterator) for tokens in iterator:[SEP]File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 35, in _csv_iterator(data_path, ngrams, yield_cls) for row in reader:[SEP]File <*>python36/site-packages/torchtext/utils.py, line 130, in unicode_csv_reader(unicode_csv_data, **kwargs) csv.field_size_limit(sys.maxsize)[SEP]OverflowError: Python int too large to convert to C long",0
"File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1356, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1339, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) self._extend_graph()[SEP]File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1374, in _extend_graph(self) tf_session.ExtendSession(self._session)[SEP]InvalidArgumentError: Cannot assign a device for operation MatMul: {{node MatMul}}was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.",0
"File [FILE], line 8, in <module> print (sess.run(c))[SEP]File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 950, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1173, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1350, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata)[SEP]File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1370, in _do_call(self, fn, *args) raise type(e)(node_def, op, message)[SEP]InvalidArgumentError: Cannot assign a device for operation MatMul: node MatMul (defined at <ipython-input-9-b145a02709f7>:5) was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.",0
"File <*>python3.6/dist-packages/pandas/core/indexes/base.py, line 2657, in get_loc(self, key, method, tolerance) return self._engine.get_loc(key)[SEP]File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE][SEP]File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE][SEP]KeyError: 'filename'",0
"File [FILE], line 20, in <module> subset='training')[SEP]File <*>python3.6/dist-packages/keras/preprocessing/image.py, line 594, in flow_from_dataframe(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs) **kwargs[SEP]File <*>python3.6/dist-packages/keras/preprocessing/image.py, line 235, in __init__(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames) validate_filenames=validate_filenames)[SEP]File <*>python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py, line 129, in __init__(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames) self._check_params(df, x_col, y_col, weight_col, classes)[SEP]File <*>python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py, line 181, in _check_params(self, df, x_col, y_col, weight_col, classes) if not all(df[x_col].apply(lambda x: isinstance(x, str))):[SEP]File <*>python3.6/dist-packages/pandas/core/frame.py, line 2927, in __getitem__(self, key) indexer = self.columns.get_loc(key)[SEP]File <*>python3.6/dist-packages/pandas/core/indexes/base.py, line 2659, in get_loc(self, key, method, tolerance) return self._engine.get_loc(self._maybe_cast_indexer(key))[SEP]File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE][SEP]File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE][SEP]KeyError: 'filename'",0
"File [FILE], line 4, in <module>() feature_extractor = hub.KerasLayer(_URL, input_shape=(_TARGET_SIZE, _TARGET_SIZE,3))[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py, line 167, in _variable_handle_from_shape_and_dtype(shape, dtype, shared_name, name, graph_mode, initial_value) handle_data.shape_and_type.append([SEP]AttributeError: 'google.protobuf.pyext._message.RepeatedCompositeCo' object has no attribute 'append'",0
"File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 2897, in get_loc(self, key, method, tolerance) return self._engine.get_loc(key)[SEP]File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE][SEP]File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE][SEP]KeyError: 40592",0
"File [FILE], line 1, in <module> loaded_model.summary()[SEP]AttributeError: 'NoneType' object has no attribute 'summary'",0
"File [FILE], line 24, in <module> loaded_regressor.load_weights(latest_checkpoint(checkpoint_path))[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 162, in load_weights(self, filepath, by_name) return super(Model, self).load_weights(filepath, by_name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/network.py, line 1377, in load_weights(self, filepath, by_name) if _is_hdf5_filepath(filepath):[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/network.py, line 1672, in _is_hdf5_filepath(filepath) return (filepath.endswith('.h5') or filepath.endswith('.keras') or[SEP]AttributeError: 'NoneType' object has no attribute 'endswith'",0
"File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 2, in [FUNC] from tensorboard.summary.writer.record_writer import RecordWriter # noqa F401[SEP]ModuleNotFoundError: No module named 'tensorboard.summary'; 'tensorboard' is not a package",0
"File [FILE], line 4, in <module>() pred = model(x)[SEP]File <*>python3.6/sequential.py, line 256, in call(self, inputs, training, mask) return super(Sequential, self).call(inputs, training=training, mask=mask)[SEP]File <*>python3.6/network.py, line 708, in call(self, inputs, training, mask) convert_kwargs_to_constants=base_layer_utils.call_context().saving)[SEP]File <*>python3.6/network.py, line 860, in _run_internal_graph(self, inputs, training, mask, convert_kwargs_to_constants) output_tensors = layer(computed_tensors, **kwargs)[SEP]File <*>python3.6/wrappers.py, line 528, in __call__(self, inputs, initial_state, constants, **kwargs) return super(Bidirectional, self).__call__(inputs, **kwargs)[SEP]File <*>python3.6/base_layer.py, line 891, in __call__(self, inputs, *args, **kwargs) outputs = self.call(cast_inputs, *args, **kwargs)[SEP]File <*>python3.6/wrappers.py, line 642, in call(self, inputs, training, mask, initial_state, constants) initial_state=forward_state, **kwargs)[SEP]File <*>python3.6/recurrent.py, line 623, in __call__(self, inputs, initial_state, constants, **kwargs) return super(RNN, self).__call__(inputs, **kwargs)[SEP]File <*>python3.6/recurrent_v2.py, line 961, in call(self, inputs, mask, training, initial_state) **cudnn_lstm_kwargs)[SEP]File <*>python3.6/recurrent_v2.py, line 1174, in cudnn_lstm(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards) rnn_mode='lstm')[SEP]File <*>python3.6/gen_cudnn_rnn_ops.py, line 109, in cudnn_rnn(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name) ctx=_ctx)[SEP]File <*>python3.6/gen_cudnn_rnn_ops.py, line 198, in cudnn_rnn_eager_fallback(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx) attrs=_attrs, ctx=_ctx, name=name)[SEP]File <*>python3.6/execute.py, line 67, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <*>python3.6/dist-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE][SEP]InvalidArgumentError: Invalid input_h shape: [1,64,1024] [1,54,1024] [Op:CudnnRNN]",0
"File [FILE], line 9, in <module>() train(test_net, train_loader, 10, batch_size, optimiser, clip, criterion)[SEP]File [FILE], line 59, in train(SNN, dataloader, epochs, batch_size, optimiser, clip, criterion) loss = criterion(output1, output2, labels)[SEP]File [FILE], line 51, in forward(self, output1, output2, labels) pred, loss = estimate_loss(self.d)[SEP]File [FILE], line 45, in estimate_loss(forward) distance = dimensional_reduction(self.d)[SEP]File [FILE], line 38, in dimensional_reduction(forward) self.d = self.linear(self.d)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/linear.py, line 87, in forward(self, input) return F.linear(input, self.weight, self.bias)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1370, in linear(input, weight, bias) ret = torch.addmm(bias, input, weight.t())[SEP]RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_addmm",0
"File [FILE], line 1001, in <module>() train_step(group, inp, tar, label)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializer_map)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize(self, args, kwds, add_initializers_to) *args, **kwds))[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py, line 905, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]ValueError: in converted code: <ipython-input-1-81054f0385cb>:856 train_step * optimizer.apply_gradients(zip(gradients, transformer.trainable_variables)) /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:427 apply_gradients grads_and_vars = _filter_grads(grads_and_vars) /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:1025 _filter_grads ([v.name for _, v in grads_and_vars],)) ValueError: No gradients provided for any variable: ['transformer_1/encoder_1/embedding_2/embeddings:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_98/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_98/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_99/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_99/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_100/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_100/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_101/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_101/bias:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_102/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_102/bias:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_103/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_103/bias:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_30/gamma:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_30/beta:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_31/gamma:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_31/beta:0', 'transformer_1/encoder_1/encoder_layer_7/multi_head_attention_19/dense_104/kernel:0', 'transformer_1/encoder_1/encoder...",0
"File [FILE], line 10, in <module>() scan_object = ta.Scan(x_train, y_train, params=p, model=iris_model, experiment_name='test', x_val=x_val, y_val=y_val, fraction_limit=0.1)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 2309, in _distribution_standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, validation_split, shuffle, epochs, allow_partial_batch) if dataset_size % batch_size == 0:[SEP]TypeError: unsupported operand type(s) for %: 'int' and 'NoneType'",0
"File [FILE], line 48, in <module> prediction = model(X)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 493, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/parallel/data_parallel.py, line 146, in forward(self, *inputs, **kwargs) ""them on device: {}"".format(self.src_device_obj, t.device))[SEP]RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:2",0
"File [FILE], line 2, in <module> model = make_feed_forward_model()[SEP]File [FILE], line 20, in make_feed_forward_model() dense_layer_1 = tf.keras.layers.Dense(HPARAMS.num_fc_units, activation='relu')(inputs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 616, in __call__(self, inputs, *args, **kwargs) self._maybe_build(inputs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1966, in _maybe_build(self, inputs) self.build(input_shapes)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/core.py, line 1005, in build(self, input_shape) raise ValueError('The last dimension of the inputs to `Dense` '[SEP]ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.",0
"File [FILE], line 1, in <module>() learn.lr_find()[SEP]File <*>python3.6/dist-packages/fastai/train.py, line 41, in lr_find(learn, start_lr, end_lr, num_it, stop_div, wd) learn.fit(epochs, start_lr, callbacks=[cb], wd=wd)[SEP]File <*>python3.6/dist-packages/fastai/basic_train.py, line 200, in fit(self, epochs, lr, wd, callbacks) fit(epochs, self, metrics=self.metrics, callbacks=self.callbacks+callbacks)[SEP]File <*>python3.6/dist-packages/fastai/basic_train.py, line 101, in fit(epochs, learn, callbacks, metrics) loss = loss_batch(learn.model, xb, yb, learn.loss_func, learn.opt, cb_handler)[SEP]File <*>python3.6/dist-packages/fastai/basic_train.py, line 30, in loss_batch(model, xb, yb, loss_func, opt, cb_handler) loss = loss_func(out, *yb)[SEP]File <*>python3.6/dist-packages/fastai/layers.py, line 243, in __call__(self, input, target, **kwargs) return self.func.__call__(input, target.view(-1), **kwargs)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/loss.py, line 916, in forward(self, input, target) ignore_index=self.ignore_index, reduction=self.reduction)[SEP]File <*>python3.6/dist-packages/torch/nn/functional.py, line 2009, in cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction) return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)[SEP]File <*>python3.6/dist-packages/torch/nn/functional.py, line 1838, in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction) ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)[SEP]RuntimeError: Assertion `cur_target >= 0 &amp;&amp; cur_target < n_classes' failed. at /pytorch/aten/src/THNN/generic/ClassNLLCriterion.c:97",0
"File [FILE], line 1, in <module> foo[0][SEP]TypeError: 'TakeDataset' object does not support indexing",0
"File [FILE], line 2, in <module> (X_train_full, y_train_full), (X_test, y_test) = (fashion_mnist)[SEP]TypeError: cannot unpack non-iterable module object",0
"File [FILE], line 7, in <module>() loss_log = train(net, train_set, EPOCHS, LEARNING_RATE, BATCH_SIZE)[SEP]File [FILE], line 15, in train(net, training_set, EPOCHS, LEARNING_RATE, BATCH_SIZE) output, sm = net(x_batch)[SEP]File [FILE], line 43, in forward(self, x) x = self.convs(x)[SEP]File [FILE], line 33, in convs(self, x) x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=(2, 2))[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/conv.py, line 345, in forward(self, input) return self.conv2d_forward(input, self.weight)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/conv.py, line 342, in conv2d_forward(self, input, weight) self.padding, self.dilation, self.groups)[SEP]RuntimeError: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same",0
"File [FILE], line 4, in <module> model.fit(train_encoded, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(test_encoded,test_labels))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 324, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs) total_epochs=epochs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 123, in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs) batch_outs = execution_function(iterator)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 86, in execution_function(input_fn) distributed_function(input_fn))[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializer_map)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize(self, args, kwds, add_initializers_to) *args, **kwds))[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>/site-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 73, in distributed_function(input_iterator) per_replica_function, args=(model, x, y, sample_weights))[SEP]File <*>/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 760, in experimental_run_v2(self, fn, args, kwargs) return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 1787, in call_for_each_replica(self, fn, args, kwargs) return self._call_for_each_replica(fn, args, kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 2132, in _call_for_each_replica(self, fn, args, kwargs) return fn(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/autograph/impl/api.py, line 292, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics) output_loss_metrics=model._output_loss_metrics)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics) output_loss_metrics=output_loss_metrics))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 252, in _process_single_batch(model, inputs, targets, output_loss_metrics, sample_weights, training) training=training))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 127, in _model_loss(model, inputs, targets, output_loss_metrics, sample_weights, training) outs = model(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 847, in __call__(self, inputs, *args, **kwargs) outputs = call_fn(cast_inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/sequential.py, line 270, in call(self, inputs, training, mask) outputs = layer(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 812, in __call__(self, inputs, *args, **kwargs) self.name)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/input_spec.py, line 213, in assert_input_compatibility(input_spec, inputs, layer_name) ' but received input with shape ' + str(shape))[SEP]ValueError: Input 0 of layer dense_3 is incompatible with the layer: expected axis -1 of input shape to have value 6022 but received input with shape [None, 512]",0
"File <*>/site-packages/tensorflow_datasets/core/download/extractor.py, line 89, in _sync_extract(self, from_path, method, to_path) for path, handle in iter_archive(from_path, method):[SEP]File <*>/site-packages/tensorflow_datasets/core/download/extractor.py, line 177, in iter_zip(arch_f) z = zipfile.ZipFile(fobj)[SEP]File <*>/zipfile.py, line 1131, in __init__(self, file, mode, compression, allowZip64) self._RealGetContents()[SEP]File <*>/zipfile.py, line 1194, in _RealGetContents(self) endrec = _EndRecData(fp)[SEP]File <*>/zipfile.py, line 264, in _EndRecData(fpin) fpin.seek(0, 2)[SEP]File <*>/site-packages/tensorflow_core/python/util/deprecation.py, line 507, in new_func(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/lib/io/file_io.py, line 167, in seek(self, offset, whence, position) offset += self.size()[SEP]File <*>/site-packages/tensorflow_core/python/lib/io/file_io.py, line 102, in size(self) return stat(self.__name).length[SEP]File <*>/site-packages/tensorflow_core/python/lib/io/file_io.py, line 727, in stat(filename) return stat_v2(filename)[SEP]File <*>/site-packages/tensorflow_core/python/lib/io/file_io.py, line 744, in stat_v2(path) pywrap_tensorflow.Stat(compat.as_bytes(path), file_statistics)[SEP]OutOfRangeError: C:\Users\%user%\tensorflow_datasets\downloads\images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip; Unknown error",0
"File [FILE], line 19, in <module> transformed_dataset, transform_fn = (raw_dataset | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))[SEP]File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 863, in expand(self, dataset) dataset | 'AnalyzeDataset' >> AnalyzeDataset(self._preprocessing_fn))[SEP]File <*>python3.7/site-packages/apache_beam/transforms/ptransform.py, line 989, in __ror__(self, pvalueish, _unused) return self.transform.__ror__(pvalueish, self.label)[SEP]File <*>python3.7/site-packages/apache_beam/transforms/ptransform.py, line 549, in __ror__(self, left, label) result = p.apply(self, pvalueish, label)[SEP]File <*>python3.7/site-packages/apache_beam/pipeline.py, line 536, in apply(self, transform, pvalueish, label) return self.apply(transform, pvalueish)[SEP]File <*>python3.7/site-packages/apache_beam/pipeline.py, line 577, in apply(self, transform, pvalueish, label) pvalueish_result = self.runner.apply(transform, pvalueish, self._options)[SEP]File <*>python3.7/site-packages/apache_beam/runners/runner.py, line 195, in apply(self, transform, input, options) return m(transform, input, options)[SEP]File <*>python3.7/site-packages/apache_beam/runners/runner.py, line 225, in apply_PTransform(self, transform, input, options) return transform.expand(input)[SEP]File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 810, in expand(self, dataset) None, input_metadata))[SEP]File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 683, in expand(self, dataset) output_signature = self._preprocessing_fn(copied_inputs)[SEP]File [FILE], line 11, in preprocessing_fn(inputs) tf.constant(value, shape=outputs[key].shape),[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/constant_op.py, line 258, in constant(value, dtype, shape, name) allow_broadcast=True)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/constant_op.py, line 296, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py, line 448, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) if shape is not None and np.prod(shape, dtype=np.int64) == 0:[SEP]File [FILE], line [NUM], in prod(*args, **kwargs) [CODE][SEP]File <*>python3.7/site-packages/numpy/core/fromnumeric.py, line 2962, in prod(a, axis, dtype, out, keepdims, initial, where) keepdims=keepdims, initial=initial, where=where)[SEP]File <*>python3.7/site-packages/numpy/core/fromnumeric.py, line 90, in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs) return ufunc.reduce(obj, axis, dtype, out, **passkwargs)[SEP]TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'",0
"File [FILE], line 3, in <module> pooling='avg')[SEP]File <*>python3.6/site-packages/keras/applications/__init__.py, line 20, in wrapper(*args, **kwargs) return base_fun(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/applications/resnet.py, line 14, in ResNet50(*args, **kwargs) return resnet.ResNet50(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 435, in ResNet50(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs) **kwargs)[SEP]File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 413, in ResNet(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs) model.load_weights(weights)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 492, in load_wrapper(*args, **kwargs) return load_function(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 1230, in load_weights(self, filepath, by_name, skip_mismatch, reshape) f, self.layers, reshape=reshape)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 1237, in load_weights_from_hdf5_group(f, layers, reshape) K.batch_set_value(weight_value_tuples)[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 2960, in batch_set_value(tuples) tf_keras_backend.batch_set_value(tuples)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/keras/backend.py, line 3323, in batch_set_value(tuples) x.assign(np.asarray(value, dtype=dtype(x)))[SEP]File <*>python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py, line 819, in assign(self, value, use_locking, name, read_value) self._shape.assert_is_compatible_with(value_tensor.shape)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/framework/tensor_shape.py, line 1110, in assert_is_compatible_with(self, other) raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))[SEP]ValueError: Shapes (1, 1, 256, 512) and (512, 128, 1, 1) are incompatible",0
"File [FILE], line 26, in <module>() images, labels = next(iter(train_loader))[SEP]File <*>python3.6/dist-packages/torch/utils/data/dataloader.py, line 345, in __next__(self) data = self._next_data()[SEP]File <*>python3.6/dist-packages/torch/utils/data/dataloader.py, line 385, in _next_data(self) data = self._dataset_fetcher.fetch(index) # may raise StopIteration[SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch(self, possibly_batched_index) data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp>(.0) data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <*>python3.6/dist-packages/torchvision/datasets/mnist.py, line 97, in __getitem__(self, index) img = self.transform(img)[SEP]File <*>python3.6/dist-packages/torchvision/transforms/transforms.py, line 70, in __call__(self, img) img = t(img)[SEP]File <*>python3.6/dist-packages/torchvision/transforms/transforms.py, line 1003, in __call__(self, img) return F.rotate(img, angle, self.resample, self.expand, self.center, self.fill)[SEP]File <*>python3.6/dist-packages/torchvision/transforms/functional.py, line 729, in rotate(img, angle, resample, expand, center, fill) return img.rotate(angle, resample, expand, center, fillcolor=fill)[SEP]File <*>python3.6/dist-packages/PIL/Image.py, line 2005, in rotate(self, angle, resample, expand, center, translate, fillcolor) return self.transform((w, h), AFFINE, matrix, resample, fillcolor=fillcolor)[SEP]File <*>python3.6/dist-packages/PIL/Image.py, line 2299, in transform(self, size, method, data, resample, fill, fillcolor) im = new(self.mode, size, fillcolor)[SEP]File <*>python3.6/dist-packages/PIL/Image.py, line 2505, in new(mode, size, color) return im._new(core.fill(mode, size, color))[SEP]TypeError: function takes exactly 1 argument (3 given)",0
"File [FILE], line 6, in <module> num_epochs=25)[SEP]File [FILE], line 33, in train_model(model, criterion, optimizer, scheduler, num_epochs) _, preds = torch.max(outputs, 1)[SEP]TypeError: max() received an invalid combination of arguments - got (Linear, int), but expected one of: * (Tensor input) * (Tensor input, name dim, bool keepdim, tuple of Tensors out) * (Tensor input, Tensor other, Tensor out) * (Tensor input, int dim, bool keepdim, tuple of Tensors out)",0
"File [FILE], line 13, in <module> loss = criterion(output, labels)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 532, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/loss.py, line 204, in forward(self, input, target) return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1838, in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction) ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)[SEP]RuntimeError: expected scalar type Long but found Float",0
"File [FILE], line 7, in <module>() print(x[tensor(0)])[SEP]KeyError: tensor(0)",0
"File [FILE], line 11, in <module>() print(x[0])[SEP]KeyError: 0",0
"File [FILE], line 8, in <module> layers['flatten'] = nn.Flatten()[SEP]AttributeError: module 'torch.nn' has no attribute 'Flatten'",0
"File [FILE], line 8, in <module>() callbacks=[ccall, esd3][SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 813, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) callbacks.on_epoch_end(epoch, epoch_logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 365, in on_epoch_end(self, epoch, logs) callback.on_epoch_end(epoch, logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 1485, in on_epoch_end(self, epoch, logs) self.model.set_weights(self.best_weights)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 1519, in set_weights(self, weights) if expected_num_weights != len(weights):[SEP]TypeError: object of type 'NoneType' has no len()",0
"File [FILE], line 9, in <module> train_loss, train_acc = train(model, train_iterator, optimizer, criterion)[SEP]File [FILE], line 8, in train(model, iterator, optimizer, criterion) for batch in iterator:[SEP]File <*>python3.7/site-packages/torchtext/data/iterator.py, line 142, in __iter__(self) for idx, minibatch in enumerate(self.batches):[SEP]File <*>python3.7/site-packages/torchtext/data/iterator.py, line 286, in pool(data, batch_size, key, batch_size_fn, random_shuffler, shuffle, sort_within_batch) if sort_within_batch \[SEP]TypeError: '<' not supported between instances of 'Example' and 'Example'",0
"File [FILE], line 70, in <module>() loss = torch.nn.MSELoss(out, target)[SEP]File <*>python3.6/dist-packages/torch/nn/_reduction.py, line 36, in legacy_get_string(size_average, reduce, emit_warning) if size_average and reduce:[SEP]RuntimeError: bool value of Tensor with more than one value is ambiguous",0
"File [FILE], line 13, in <module>() validation_steps = validation_steps,[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]ValueError: in user code: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function * outputs = self.distribute_strategy.run( /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run ** return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica return fn(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step ** y, y_pred, sample_weight, regularization_losses=self.losses) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__ loss_value = loss_obj(y_t, y_p, sample_weight=sw) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:143 __call__ losses = self.call(y_true, y_pred) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:246 call return self.fn(y_true, y_pred, **self._fn_kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1527 categorical_crossentropy return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4561 categorical_crossentropy target.shape.assert_is_compatible_with(output.shape) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1117 assert_is_compatible_with raise ValueError(""Shapes %s and %s are incompatible"" % (self, other)) ValueError: Shapes (None, 1) and (None, 2) are incompatible",0
"File [FILE], line 6, in <module> from tensorflow.keras.models import Sequential[SEP]File <*>/site-packages/tensorflow/keras/__init__.py, line 14, in <module> from . import activations[SEP]File <*>/site-packages/tensorflow/keras/activations/__init__.py, line 23, in <module> from tensorflow.python.keras.activations import swish[SEP]ImportError: cannot import name 'swish' from 'tensorflow.python.keras.activations' (C:\Users\FlamePrinz\Anaconda3\lib\site-packages\tensorflow\python\keras\activations.py)",0
"File [FILE], line 16, in <module> model.fit(X_train, y_train, epochs=3)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 819, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 342, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) total_epochs=epochs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs) batch_outs = execution_function(iterator)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function(input_fn) distributed_function(input_fn))[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 632, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2363, in __call__(self, *args, **kwargs) return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call(self, args, kwargs) self.captured_inputs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat(self, args, captured_inputs, cancellation_manager) ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 545, in call(self, ctx, args, cancellation_manager) ctx=ctx)[SEP]File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <*>/site-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE][SEP]UnimplementedError: Cast string to int64 is not supported [[node loss/output_1_loss/Cast (defined at <ipython-input-111-1a89f1d94518>:16) ]] [Op:__inference_distributed_function_544280]",0
"File [FILE], line 14, in <module> Y = torch.masked_select(X, (mask == 1))[SEP]RuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2",0
"File [FILE], line 5, in <module> verbose = 1)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 872, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) return_dict=True)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1081, in evaluate(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict) tmp_logs = test_function(iterator)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 618, in _call(self, *args, **kwds) results = self._stateful_fn(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2419, in __call__(self, *args, **kwargs) graph_function, args, kwargs = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2774, in _maybe_define_function(self, args, kwargs) return self._define_function_with_shape_relaxation(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2706, in _define_function_with_shape_relaxation(self, args, kwargs) args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2667, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 981, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 441, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]AssertionError: in user code: c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\training.py:941 test_function * outputs = self.distribute_strategy.run( c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:951 run ** return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2290 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2649 _call_for_each_replica return fn(*args, **kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\training.py:909 test_step ** y_pred = self(x, training=False) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:927 __call__ outputs = call_fn(cast_inputs, *args, **kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\ etwork.py:719 call convert_kwargs_to_constants=base_layer_utils.call_context().saving) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\ etwork.py:899 _run_internal_graph assert str(id(x)) in tensor_dict, 'Could not compute output ' + str(x) AssertionError: Could not compute output Tensor(""O1_6/Identity:0"", shape=(None, 2), dtype=float32)",0
"File [FILE], line 58, in <module>() optimizer.step()[SEP]File <*>python3.6/dist-packages/torch/autograd/grad_mode.py, line 15, in decorate_context(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/torch/optim/adam.py, line 99, in step(self, closure) exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)[SEP]RuntimeError: expected device cpu but got device cuda:0",0
"File [FILE], line 4, in <module>() model = encoder_model(k)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1113, in op(self) ""Tensor.op is meaningless when eager execution is enabled."")[SEP]AttributeError: Tensor.op is meaningless when eager execution is enabled.",0
"File [FILE], line 9, in <module>() model.save(outdir+'model.h5')[SEP]File <*>python3.6/dist-packages/h5py/_hl/group.py, line 373, in __setitem__(self, name, obj) h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl)[SEP]File <*>/_objects.pyx, line [NUM], in h5py._objects.with_phil.wrapper() [CODE][SEP]File <*>/h5o.pyx, line [NUM], in h5py.h5o.link() [CODE][SEP]RuntimeError: Unable to create link (name already exists)",0
"File <*>/site-packages/tensorflow_core/python/client/session.py, line 1365, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1350, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) target_list, run_metadata)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1443, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata)[SEP]InvalidArgumentError: indices[24,0] = 335 is not in [0, 304) [[{{node user-embedding-mlp_1/GatherV2}}]]",0
"File [FILE], line 1, in <module> history = model.fit([train.id, train.user_id], train.user_like, nb_epoch=3)[SEP]File <*>/site-packages/keras/engine/training.py, line 1657, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs) validation_steps=validation_steps)[SEP]File <*>/site-packages/keras/engine/training.py, line 1213, in _fit_loop(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps) outs = f(ins_batch)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2357, in __call__(self, inputs) **self.session_kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 956, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1180, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1359, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1384, in _do_call(self, fn, *args) session_config.graph_options.rewrite_options.' raise type(e)(node_def, op, message)[SEP]InvalidArgumentError: indices[24,0] = 335 is not in [0, 304) [[node user-embedding-mlp_1/GatherV2 (defined at E:\My\Ananconda\envs\tensor\lib\site-packages\tensorflow_core\python\framework\ops.py:1748) ]]",0
"File [FILE], line 4, in <module> history = comp_lstm.fit(train,[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/training.py, line 848, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) tmp_logs = train_function(iterator)[SEP]File <*>python3.8/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>python3.8/site-packages/tensorflow/python/eager/def_function.py, line 611, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) # pylint: disable=not-callable[SEP]TypeError: 'NoneType' object is not callable",0
"File [FILE], line 1, in <module>() model.fit(train_dataset, epochs=15)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]TypeError: in user code: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function * outputs = self.distribute_strategy.run( /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run ** return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica return fn(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step ** y, y_pred, sample_weight, regularization_losses=self.losses) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__ loss_value = loss_obj(y_t, y_p, sample_weight=sw) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:145 __call__ losses, sample_weight, reduction=self._get_reduction()) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:104 compute_weighted_loss losses = ops.convert_to_tensor_v2(losses) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1283 convert_to_tensor_v2 as_ref=False) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1341 convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:321 _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:262 constant allow_broadcast=True) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:300 _constant_impl allow_broadcast=allow_broadcast)) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py:547 make_tensor_proto ""supported type."" % (type(values), values)) TypeError: Failed to convert object of type <class 'tensorflow.python.keras.losses.BinaryCrossentropy'> to Tensor. Contents: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f76215279b0>. Consider casting elements to a supported type.",0
"File [FILE], line 29, in <module> interpreter.allocate_tensors()[SEP]File <*>/interpreter.py, line 242, in allocate_tensors(self) return self._interpreter.AllocateTensors()[SEP]File <*>/tensorflow_wrap_interpreter_wrapper.py, line 110, in AllocateTensors(self) return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)[SEP]RuntimeError: tensorflow/lite/kernels/reshape.cc:66 num_input_elements != num_output_elements (1536 != 768)Node number 3 (RESHAPE) failed to prepare.",0
"File [FILE], line 1, in <module> output = encoder(src, src_mask)[SEP]File <*>python3.7/site-packages/torch/nn/modules/transformer.py, line 167, in forward(self, src, mask, src_key_padding_mask) src_key_padding_mask=src_key_padding_mask)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 547, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.7/site-packages/torch/nn/modules/transformer.py, line 266, in forward(self, src, src_mask, src_key_padding_mask) key_padding_mask=src_key_padding_mask)[0][SEP]File <*>python3.7/site-packages/torch/nn/modules/activation.py, line 783, in forward(self, query, key, value, key_padding_mask, need_weights, attn_mask) attn_mask=attn_mask)[SEP]File <*>python3.7/site-packages/torch/nn/functional.py, line 3252, in multi_head_attention_forward(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v) attn_output_weights += attn_mask[SEP]RuntimeError: The size of tensor a (20) must match the size of tensor b (95) at non-singleton dimension 2",0
"File [FILE], line 8, in <module>() h = model.fit(x_train, y_train, epochs=10, batch_size=256)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]ValueError: in user code: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function * outputs = self.distribute_strategy.run( /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run ** return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica return fn(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step ** y, y_pred, sample_weight, regularization_losses=self.losses) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__ loss_value = loss_obj(y_t, y_p, sample_weight=sw) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:143 __call__ losses = self.call(y_true, y_pred) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:246 call return self.fn(y_true, y_pred, **self._fn_kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1527 categorical_crossentropy return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4561 categorical_crossentropy target.shape.assert_is_compatible_with(output.shape) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1117 assert_is_compatible_with raise ValueError(""Shapes %s and %s are incompatible"" % (self, other)) ValueError: Shapes (None, 1) and (None, 10) are incompatible",0
"File [FILE], line 3, in <module> validation_data=validation_batches)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 848, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) tmp_logs = train_function(iterator)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 611, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) # pylint: disable=not-callable[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2420, in __call__(self, *args, **kwargs) return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1665, in _filtered_call(self, args, kwargs) self.captured_inputs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1746, in _call_flat(self, args, captured_inputs, cancellation_manager) ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 598, in call(self, ctx, args, cancellation_manager) ctx=ctx)[SEP]File <*>/site-packages/tensorflow/python/eager/execute.py, line 60, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) inputs, attrs, num_outputs)[SEP]InvalidArgumentError: 2 root error(s) found. (0) Invalid argument: Invalid JPEG data or crop window, data size 34228 [[{{node DecodeJpeg}}]] [[IteratorGetNext]] (1) Invalid argument: Invalid JPEG data or crop window, data size 34228 [[{{node DecodeJpeg}}]] [[IteratorGetNext]] [[IteratorGetNext/_4]]",0
"File [FILE], line 21, in <module>() history = m.fit([X, y, W], y, epochs=10)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 819, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 235, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 593, in _process_training_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing) use_multiprocessing=use_multiprocessing)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 646, in _process_inputs(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing) x, y, sample_weight=sample_weights)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 2383, in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset) batch_size=batch_size)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 2469, in _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size) exception_prefix='target')[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_utils.pyc, line 496, in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) 'expected no data, but got:', data)[SEP]ValueError: ('Error when checking model target: expected no data, but got:', array([3.39102071e-01, 1.23122638e-01, 7.54209531e-01, 8.10110230e-01,",0
"File [FILE], line 4, in <module>() y_true = np.argmax(testdata, axis=1)[SEP]File [FILE], line [NUM], in argmax(*args, **kwargs) [CODE][SEP]File <*>python3.6/dist-packages/numpy/core/fromnumeric.py, line 47, in _wrapit(obj, method, *args, **kwds) result = getattr(asarray(obj), method)(*args, **kwds)[SEP]AxisError: axis 1 is out of bounds for array of dimension 1",0
"File [FILE], line 2, in <module> model.save(""network.h5"")[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 1008, in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options) signatures, options)[SEP]File <*>/site-packages/tensorflow_core/python/keras/saving/save.py, line 99, in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options) (h5py is not None and isinstance(filepath, h5py.File)) or[SEP]AttributeError: module 'h5py' has no attribute 'File'",0
"File [FILE], line 22, in [FUNC] train_iter.next()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 345, in __next__(self) data = self._next_data()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 385, in _next_data(self) data = self._dataset_fetcher.fetch(index) # may raise StopIteration[SEP]File <*>/site-packages/torch/utils/data/_utils/fetch.py, line 47, in fetch(self, possibly_batched_index) return self.collate_fn(data)[SEP]File <*>/site-packages/torch/utils/data/_utils/collate.py, line 79, in default_collate(batch) return [default_collate(samples) for samples in transposed][SEP]File <*>/site-packages/torch/utils/data/_utils/collate.py, line 79, in (.0) return [default_collate(samples) for samples in transposed][SEP]File <*>/site-packages/torch/utils/data/_utils/collate.py, line 81, in default_collate(batch) raise TypeError(default_collate_err_msg_format.format(elem_type))[SEP]TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found",0
"File [FILE], line 27, in <module> loss = criterion(pred, y)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 550, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.7/site-packages/torch/nn/modules/loss.py, line 432, in forward(self, input, target) return F.mse_loss(input, target, reduction=self.reduction)[SEP]File <*>python3.7/site-packages/torch/nn/functional.py, line 2530, in mse_loss(input, target, size_average, reduce, reduction) if not (target.size() == input.size()):[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 594, in __getattr__(self, name) type(self).__name__, name))[SEP]AttributeError: 'UNet3D' object has no attribute 'size'",0
"File [FILE], line 5, in <module>() loaded_model = load_model('save_at_47.h5')[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/saving/save.py, line 184, in load_model(filepath, custom_objects, compile) return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py, line 178, in load_model_from_hdf5(filepath, custom_objects, compile) custom_objects=custom_objects)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/saving/model_config.py, line 55, in model_from_config(config, custom_objects) return deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py, line 109, in deserialize(config, custom_objects) printable_module_name='layer')[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py, line 362, in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name) config, module_objects, custom_objects, printable_module_name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py, line 321, in class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name) raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)[SEP]ValueError: Unknown layer: Functional",0
"File [FILE], line 1, in <module> from transformers import AutoModelWithLMHead, AutoTokenizer[SEP]ImportError: cannot import name 'AutoModelWithLMHead' from 'transformers' (c:\python38\lib\site-packages\transformers\__init__.py)",0
"File [FILE], line 30, in <module>() attn_out, attn_states = tf.keras.layers.Attention()([encoder_output, decoder_output])[SEP]File <*>python3.6/site-packages/tensorflow_core/python/framework/ops.py, line 548, in __iter__(self) ""Cannot iterate over a tensor with unknown first dimension."")[SEP]TypeError: Cannot iterate over a tensor with unknown first dimension.",0
"File [FILE], line 1, in <module> writer.add_graph(net, images)[SEP]File <*>/site-packages/tensorboardX/writer.py, line 793, in add_graph(self, model, input_to_model, verbose) from torch.utils.tensorboard._pytorch_graph import graph[SEP]File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 4, in <module> raise ImportError('TensorBoard logging requires TensorBoard version 1.15 or above')[SEP]ImportError: TensorBoard logging requires TensorBoard version 1.15 or above",0
"File [FILE], line 16, in <module>() abc = model.predict(img)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py, line 971, in select_data_adapter(x, y) _type_name(x), _type_name(y)))[SEP]ValueError: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>",0
"File [FILE], line 8, in <module> from keras.models import Sequential[SEP]File <*>/site-packages/keras/__init__.py, line 6, in <module> 'Keras requires TensorFlow 2.2 or higher. '[SEP]ImportError: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow",0
"File [FILE], line 5, in <module>() out = vae.generate(model, mean, var)[SEP]File <*>/vae.py, line 92, in generate(model, mean, var) out = model.decode(z)[SEP]File <*>/vae.py, line 58, in decode(self, z) out = self.z_develop(z)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 722, in _call_impl(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/linear.py, line 91, in forward(self, input) return F.linear(input, self.weight, self.bias)[SEP]File <*>python3.6/dist-packages/torch/nn/functional.py, line 1676, in linear(input, weight, bias) output = input.matmul(weight.t())[SEP]RuntimeError: mat1 dim 1 must match mat2 dim 0",0
"File [FILE], line 3, in <module>() loss = keras.losses.categorical_crossentropy()[SEP]File <*>python3.6/dist-packages/tensorflow/python/util/dispatch.py, line 201, in wrapper(*args, **kwargs) return target(*args, **kwargs)[SEP]TypeError: categorical_crossentropy() missing 2 required positional arguments: 'y_true' and 'y_pred'",0
"File [FILE], line 29, in <module>() model.add(Bidirectional(LSTM(150, return_sequences=True)))[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py, line 180, in assert_input_compatibility(input_spec, inputs, layer_name) str(x.shape.as_list()))[SEP]ValueError: Input 0 of layer bidirectional is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, 1, 1, 80]",0
"File [FILE], line 4, in <module>() validation_data = validation_dataset)[SEP]File <*>python3.6/dist-packages/tensorflow/python/eager/def_function.py, line 807, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) # pylint: disable=not-callable[SEP]TypeError: 'NoneType' object is not callable",0
"File [FILE], line 1, in <module> import deeplabcut as dlc[SEP]File <*>python3.7/site-packages/deeplabcut/__init__.py, line 38, in <module> from deeplabcut import generate_training_dataset[SEP]File <*>python3.7/site-packages/deeplabcut/generate_training_dataset/__init__.py, line 18, in <module> from deeplabcut.generate_training_dataset.labeling_toolbox import *[SEP]File <*>python3.7/site-packages/deeplabcut/generate_training_dataset/labeling_toolbox.py, line 33, in <module> from deeplabcut.utils import auxiliaryfunctions[SEP]File <*>python3.7/site-packages/deeplabcut/utils/__init__.py, line 6, in <module> from deeplabcut.utils.make_labeled_video import *[SEP]File <*>python3.7/site-packages/deeplabcut/utils/make_labeled_video.py, line 28, in <module> from matplotlib.animation import FFMpegWriter[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 737, in <module> class ImageMagickWriter(ImageMagickBase, MovieWriter):[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 120, in wrapper(writerClass) if writerClass.isAvailable():[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 730, in isAvailable(cls) return super().isAvailable()[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 427, in isAvailable(cls) return shutil.which(cls.bin_path()) is not None[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 724, in bin_path(cls) binpath = mpl._get_executable_info('magick').executable[SEP]File <*>python3.7/site-packages/matplotlib/__init__.py, line 385, in _get_executable_info(name) return impl([path, ""--version""], r""^Version: ImageMagick (\S*)"")[SEP]File <*>python3.7/site-packages/matplotlib/__init__.py, line 330, in impl(args, regex, min_ver, ignore_exit_code) raise _cpe[SEP]File <*>python3.7/site-packages/matplotlib/__init__.py, line 325, in impl(args, regex, min_ver, ignore_exit_code) universal_newlines=True, errors=""replace"")[SEP]File <*>python3.7/subprocess.py, line 411, in check_output(timeout, *popenargs, **kwargs) **kwargs).stdout[SEP]File <*>python3.7/subprocess.py, line 512, in run(input, capture_output, timeout, check, *popenargs, **kwargs) output=stdout, stderr=stderr)[SEP]CalledProcessError: Command '['convert', '--version']' returned non-zero exit status 1.",0
"File [FILE], line 1, in <module>() model.fit([images, negatives], positives, epochs=10, batch_size=8, verbose=2)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 1098, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) tmp_logs = train_function(iterator)[SEP]File <*>python3.6/dist-packages/tensorflow/python/eager/def_function.py, line 780, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>python3.6/dist-packages/tensorflow/python/eager/def_function.py, line 807, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) # pylint: disable=not-callable[SEP]TypeError: 'NoneType' object is not callable",0
"File [FILE], line 3, in <module> torch.load(cachefile)[SEP]File <*>python3.8/site-packages/torch/serialization.py, line 584, in load(f, map_location, pickle_module, **pickle_load_args) return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)[SEP]File <*>python3.8/site-packages/torch/serialization.py, line 839, in _load(zip_file, map_location, pickle_module, **pickle_load_args) data_file = io.BytesIO(zip_file.get_record('data.pkl'))[SEP]RuntimeError: [enforce fail at inline_container.cc:209] . file not found: archive/data.pkl",0
"File [FILE], line 15, in <module> outi.backward(torch.tensor([0.,1.]))[SEP]File <*>python3.8/site-packages/torch/tensor.py, line 185, in backward(self, gradient, retain_graph, create_graph) torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>python3.8/site-packages/torch/autograd/__init__.py, line 125, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables) Variable._execution_engine.run_backward([SEP]RuntimeError: leaf variable has been moved into the graph interior",0
"File [FILE], line 1, in <module>() model = tf.keras.models.load_model('/content/saved_models/model_best.h5',custom_objects={'TemporalReshape':TemporalReshape})[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/saving/save.py, line 182, in load_model(filepath, custom_objects, compile, options) return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py, line 178, in load_model_from_hdf5(filepath, custom_objects, compile) custom_objects=custom_objects)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/saving/model_config.py, line 55, in model_from_config(config, custom_objects) return deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py, line 358, in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name) list(custom_objects.items())))[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/functional.py, line 617, in from_config(cls, config, custom_objects) config, custom_objects)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/functional.py, line 1204, in reconstruct_from_config(config, custom_objects, created_layers) process_layer(layer_data)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/functional.py, line 1186, in process_layer(layer_data) layer = deserialize_layer(layer_data, custom_objects=custom_objects)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py, line 175, in deserialize(config, custom_objects) printable_module_name='layer')[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py, line 360, in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name) return cls.from_config(cls_config)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 697, in from_config(cls, config) return cls(**config)[SEP]TypeError: __init__() got an unexpected keyword argument 'name'",0
"File [FILE], line 3, in <module> shap_values = explainer.shap_values(X_train)[SEP]File <*>/site-packages/shap/explainers/deep/__init__.py, line 119, in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity) return self.explainer.shap_values(X, ranked_outputs, output_rank_order, check_additivity=check_additivity)[SEP]File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 304, in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity) sample_phis = self.run(self.phi_symbolic(feature_ind), self.model_inputs, joint_input)[SEP]File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 361, in run(self, out, model_inputs, X) return self.execute_with_overridden_gradients(anon)[SEP]File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 397, in execute_with_overridden_gradients(self, f) out = f()[SEP]File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 357, in anon() final_out = out(inputs)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 823, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializers)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 696, in _initialize(self, args, kwds, add_initializers_to) self._stateful_fn._get_concrete_function_internal_garbage_collected( # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2855, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 3213, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 3065, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) func_graph_module.func_graph_from_py_func([SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 986, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 600, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 973, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]StagingError: in user code: C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\shap\explainers\deep\deep_tf.py:244 grad_graph * x_grad = tape.gradient(out, shap_rAnD) C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\backprop.py:1067 gradient ** flat_grad = imperative_grad.imperative_grad( C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\imperative_grad.py:71 imperative_grad return pywrap_tfe.TFE_Py_TapeGradient( C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\backprop.py:151 _gradient_function grad_fn = ops._gradient_registry.lookup(op_name) # pylint: disable=protected-access C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\framework\registry.py:96 lookup raise LookupError( LookupError: gradient registry has no entry for: shap_TensorListStack",0
"File [FILE], line 1, in <module>() x = build_img_encod()[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py, line 166, in assert_input_compatibility(input_spec, inputs, layer_name) if x.shape.ndims is None:[SEP]AttributeError: 'Functional' object has no attribute 'shape'",0
"File [FILE], line 6, in <module>() validation_data=(x_test, y_test),[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 973, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]ValueError: in user code: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function * return step_function(self, iterator) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function ** outputs = model.distribute_strategy.run(run_step, args=(data,)) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica return fn(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step ** outputs = model.train_step(data) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step y_pred = self(x, training=True) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__ outputs = call_fn(inputs, *args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call inputs, training=training, mask=mask) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph outputs = node.layer(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__ outputs = call_fn(inputs, *args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py:183 call return self._merge_function(inputs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py:522 _merge_function return K.concatenate(inputs, axis=self.axis) /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper return target(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:2881 concatenate return array_ops.concat([to_dense(x) for x in tensors], axis) /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper return target(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1654 concat return gen_array_ops.concat_v2(values=values, axis=axis, name=name) /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:1222 concat_v2 ""ConcatV2"", values=values, axis=axis, name=name) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper attrs=attr_protos, op_def=op_def) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal compute_device) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3485 _create_op_internal op_def=op_def) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1975 __init__ control_input_ops, op_def) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1815 _create_c_op raise ValueError(str(e)) ValueError: Dimension 2 in both shapes must be equal, but are 512 and 511. Shapes are [?,384,512] and [?,384,511]. for '{{node functional_3/decoder_stage3_concat/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](functional_3/decoder_stage3_upsampling/resize/ResizeNearestNeighbor, functional_3/relu0/Relu, functional_3/decoder_stage3_concat/concat/axis)' with input shapes: [?,384,512,64], [?,384,511,64], [] and with computed input tensors: input[2] = <3>.",0
"File <*>python3.6/dist-packages/tensorflow/python/util/nest.py, line 402, in assert_same_structure(nest1, nest2, check_types, expand_composites) % (str(e), str1, str2))[SEP]ValueError: The two structures don't have the same nested structure.",0
"File [FILE], line 7, in <module>() gen.load_state_dict(torch.load(os.path.join(workspace_dir, 'dcgan_g.pth')))[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 1052, in load_state_dict(self, state_dict, strict) self.__class__.__name__, ""\n\t"".join(error_msgs)))[SEP]***RuntimeError: Error(s) in loading state_dict for Generator: Missing key(s) in state_dict***: ""gen.0.0.weight"", ""gen.0.1.weight"", ""gen.0.1.bias"", ""gen.0.1.running_mean"", ""gen.0.1.running_var"", ""gen.1.0.weight"", ""gen.1.1.weight"", ""gen.1.1.bias"", ""gen.1.1.running_mean"", ""gen.1.1.running_var"", ""gen.2.0.weight"", ""gen.2.1.weight"", ""gen.2.1.bias"", ""gen.2.1.running_mean"", ""gen.2.1.running_var"", ""gen.3.0.weight"", ""gen.3.1.weight"", ""gen.3.1.bias"", ""gen.3.1.running_mean"", ""gen.3.1.running_var"", ""gen.4.weight"", ""gen.4.bias"". Unexpected key(s) in state_dict: ""disc.0.weight"", ""disc.0.bias"", ""disc.2.0.weight"", ""disc.2.1.weight"", ""disc.2.1.bias"", ""disc.2.1.running_mean"", ""disc.2.1.running_var"", ""disc.2.1.num_batches_tracked"", ""disc.3.0.weight"", ""disc.3.1.weight"", ""disc.3.1.bias"", ""disc.3.1.running_mean"", ""disc.3.1.running_var"", ""disc.3.1.num_batches_tracked"", ""disc.4.0.weight"", ""disc.4.1.weight"", ""disc.4.1.bias"", ""disc.4.1.running_mean"", ""disc.4.1.running_var"", ""disc.4.1.num_batches_tracked"", ""disc.5.weight"", ""disc.5.bias"".",0
"File [FILE], line 8, in <module> optimization.train(x_train, y_train, x_val, y_val,[SEP]File [FILE], line 70, in train(self, x_train, y_train, x_val, y_val, batch_size, n_epochs, dropout, do_teacher_forcing) y_pred = self._predict(x_batch, y_batch, seq_len, do_teacher_forcing)[SEP]File [FILE], line 95, in _predict(self, x_batch, y_batch, seq_len, do_teacher_forcing) y_pred = self.model(x_batch)[SEP]File [FILE], line 19, in forward(self, input, future, y) h_t, c_t = self.lstm(input_t, (h_t, c_t))[SEP]File <*>/site-packages/torch/nn/modules/module.py, line 727, in _call_impl(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>/site-packages/torch/nn/modules/rnn.py, line 965, in forward(self, input, hx) self.check_forward_input(input)[SEP]File <*>/site-packages/torch/nn/modules/rnn.py, line 791, in check_forward_input(self, input) raise RuntimeError([SEP]RuntimeError: input has inconsistent input_size: got 1, expected 3",0
"File [FILE], line 8, in <module> model.save(""temp_model"")[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1979, in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options) signatures, options)[SEP]File <*>/site-packages/tensorflow/python/keras/saving/save.py, line 134, in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options) signatures, options)[SEP]File <*>/site-packages/tensorflow/python/keras/saving/saved_model/save.py, line 80, in save(model, filepath, overwrite, include_optimizer, signatures, options) save_lib.save(model, filepath, signatures, options)[SEP]File <*>/site-packages/tensorflow/python/saved_model/save.py, line 976, in save(obj, export_dir, signatures, options) obj, export_dir, signatures, options, meta_graph_def)[SEP]File <*>/site-packages/tensorflow/python/saved_model/save.py, line 1061, in _build_meta_graph(obj, export_dir, signatures, options, meta_graph_def) _ = _SaveableView(checkpoint_graph_view)[SEP]File <*>/site-packages/tensorflow/python/saved_model/save.py, line 178, in __init__(self, checkpoint_view, wrapped_functions) self.checkpoint_view.objects_ids_and_slot_variables())[SEP]File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 426, in objects_ids_and_slot_variables(self) object_names[obj] = _object_prefix_from_path(path)[SEP]File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 64, in _object_prefix_from_path(path_to_root) for trackable in path_to_root))[SEP]File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 64, in <genexpr>(.0) for trackable in path_to_root))[SEP]File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 57, in _escape_local_name(name) return (name.replace(_ESCAPE_CHAR, _ESCAPE_CHAR + _ESCAPE_CHAR)[SEP]AttributeError: 'NoneType' object has no attribute 'replace'",0
"File <*>python3.6/dist-packages/optkeras/optkeras.py, line 230, in synch_with_optuna(self) self.best_trial = self.study.best_trial[SEP]ValueError: No trials are completed yet.",0
"File <*>python3.6/dist-packages/optkeras/optkeras.py, line 367, in get_trial_default() num_fields = optuna.structs.FrozenTrial._field_types.__len__()[SEP]AttributeError: type object 'FrozenTrial' has no attribute '_field_types'",0
"File [FILE], line 16, in <module>() results = p.map(X_power_func, range(8))[SEP]File <*>python3.6/pool.py, line 644, in get(self, timeout) raise self._value[SEP]RuntimeError: CUDA error: initialization error",0
"File [FILE], line 7, in <module>() validation_steps = valid_step , callbacks = [metrics], verbose=2)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 673, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 1433, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch')[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py, line 331, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) callbacks.on_epoch_end(epoch, epoch_logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 311, in on_epoch_end(self, epoch, logs) callback.on_epoch_end(epoch, logs)[SEP]File [FILE], line 16, in on_epoch_end(self, batch, logs) X_val, y_val = self.validation_data[0], self.validation_data[1][SEP]TypeError: 'NoneType' object is not subscriptable",0
"File [FILE], line 7, in <module>() validation_steps = valid_step , callbacks = [metrics], verbose=2)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 673, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 1433, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch')[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py, line 260, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) callbacks._call_batch_hook(mode, 'begin', step, batch_logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 247, in _call_batch_hook(self, mode, hook, batch, logs) batch_hook = getattr(callback, hook_name)[SEP]AttributeError: 'Metrics' object has no attribute 'on_train_batch_begin'",0
"File [FILE], line 11, in <module> foo_test.main()[SEP]File <*>/foo_test.py, line 25, in main() tf.test.main()[SEP]File <*>/site-packages/tensorflow/python/platform/test.py, line 58, in main(argv) return _googletest.main(argv)[SEP]File <*>/site-packages/tensorflow/python/platform/googletest.py, line 66, in main(argv) benchmark.benchmarks_main(true_main=main_wrapper)[SEP]File <*>/site-packages/tensorflow/python/platform/benchmark.py, line 486, in benchmarks_main(true_main, argv) true_main()[SEP]File <*>/site-packages/tensorflow/python/platform/googletest.py, line 65, in main_wrapper() return app.run(main=g_main, argv=args)[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 40, in run(main, argv) _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)[SEP]File <*>/site-packages/absl/app.py, line 303, in run(main, argv, flags_parser) _run_main(main, args)[SEP]File <*>/site-packages/absl/app.py, line 251, in _run_main(main, argv) sys.exit(main(argv))[SEP]File <*>/site-packages/tensorflow/python/platform/googletest.py, line 56, in g_main(argv) absltest_main(argv=argv)[SEP]File <*>/site-packages/absl/testing/absltest.py, line 2002, in main(*args, **kwargs) _run_in_app(run_tests, args, kwargs)[SEP]File <*>/site-packages/absl/testing/absltest.py, line 2105, in _run_in_app(function, args, kwargs) argv = FLAGS(sys.argv)[SEP]File <*>/site-packages/absl/flags/_flagvalues.py, line 654, in __call__(self, argv, known_only) raise _exceptions.UnrecognizedFlagError([SEP]UnrecognizedFlagError: Unknown command line flag 'f'",0
"File [FILE], line 49, in <module>() for images, labels in myTrain_dataloader:[SEP]File <*>python3.6/dist-packages/torch/utils/data/dataloader.py, line 819, in __next__(self) return self._process_data(data)[SEP]File <*>python3.6/dist-packages/torch/utils/data/dataloader.py, line 846, in _process_data(self, data) data.reraise()[SEP]File <*>python3.6/dist-packages/torch/_utils.py, line 385, in reraise(self) raise self.exc_type(msg)[SEP]RuntimeError: Caught RuntimeError in DataLoader worker process 0.",0
