Templates,label
"File <pyshell#146>, line 1, in <module> that[~(that>=5).nonzero()].max().eval() AttributeError: 'TensorVariable' object has no attribute 'nonzero'",1
"File <stdin>, line 1, in <module> [CODE] File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import * File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow import contrib File <*>python2.7/site-packages/tensorflow/contrib/__init__.py, line 23, in <module> from tensorflow.contrib import layers File <*>python2.7/site-packages/tensorflow/contrib/layers/__init__.py, line 68, in <module> from tensorflow.contrib.layers.python.layers import * File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/__init__.py, line 22, in <module> from tensorflow.contrib.layers.python.layers.initializers import * File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/initializers.py, line 24, in <module> from tensorflow.python.ops import random_ops File <*>python2.7/site-packages/tensorflow/python/ops/random_ops.py, line 23, in <module> from tensorflow.python.framework import ops File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 39, in <module> from tensorflow.python.framework import versions File <*>python2.7/site-packages/tensorflow/python/framework/versions.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper() File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description) ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory",1
"File <*>/test3.py, line 5, in [FUNC] [CODE] AttributeError: module 'tensorflow.contrib.learn' has no attribute 'TensorFlowDNNClassifier'",1
"File DA_test_pred.py, line 24, in <module> logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False) File <*>/inception_v1.py, line 290, in inception_v1 net, end_points = inception_v1_base(inputs, scope=scope) File <*>/inception_v1.py, line 96, in inception_v1_base net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3]) File <*>python2.7/dist-packages/tensorflow/python/ops/array_ops.py, line 1053, in concat dtype=dtypes.int32).get_shape( File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 651, in convert_to_tensor as_ref=False) File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 716, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python2.7/dist-packages/tensorflow/python/framework/constant_op.py, line 176, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name) File <*>python2.7/dist-packages/tensorflow/python/framework/constant_op.py, line 165, in constant tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape)) File <*>python2.7/dist-packages/tensorflow/python/framework/tensor_util.py, line 367, in make_tensor_proto _AssertCompatible(values, dtype) File <*>python2.7/dist-packages/tensorflow/python/framework/tensor_util.py, line 302, in _AssertCompatible (dtype.name, repr(mismatch), type(mismatch).__name__)) TypeError: Expected int32, got list containing Tensors of type '_Message' instead.",1
"File ptb_word_lm.py, line 374, in <module> tf.app.run() File <*>python3.6/site-packages/tensorflow/python/platform/app.py, line 43, in run sys.exit(main(sys.argv[:1] + flags_passthrough)) File ptb_word_lm.py, line 334, in main train_input = PTBInput(config=config, data=train_data, name=""TrainInput"") File ptb_word_lm.py, line 94, in __init__ data, batch_size, num_steps, name=name) File <*>/reader.py, line 117, in ptb_producer [batch_size, (i + 1) * num_steps]) TypeError: strided_slice() missing 1 required positional argument: 'strides'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper() return importlib.import_module(mname) File <*>/importlib__init__.py, line 126, in import_module(name, package) return _bootstrap._gcd_import(name[level:], package, level) File <*>/importlib_bootstrap.py, line [NUM], in _gcd_import(name, package, level) [CODE] File <*>/importlib_bootstrap.py, line [NUM], in _find_and_load(name, import_) [CODE] File <*>/importlib_bootstrap.py, line [NUM], in _find_and_load_unlocked(name, import_) [CODE] File <*>/importlib_bootstrap.py, line [NUM], in _load_unlocked(spec) [CODE] File <*>/importlib_bootstrap.py, line [NUM], in module_from_spec(spec ) [CODE] File <*>/importlib_bootstrap_external.py, line [NUM], in create_module(self, spec) [CODE] File <*>/importlib_bootstrap.py, line [NUM], in _call_with_frames_removed(f, *args, **kwds) [CODE] ImportError: DLL load failed: The specified module could not be found.",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper return importlib.import_module(mname) File <*>/importlib__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File [FILE], line 126, in [FUNC] [CODE] ImportError: DLL load failed: The specified module could not be found.",1
"File <*>python3.5/site-packages/tensorflow/python/framework/op_def_library.py, line 491, in apply_op(self, op_type_name, name, **keywords) preferred_dtype=default_dtype) File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 704, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 577, in _TensorTensorConversionFunction(t, dtype, name, as_ref) % (dtype.name, t.dtype.name, str(t))) ValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(""nce_loss/Reshape_1:0"", shape=(?, 1, ?), dtype=float32)'",1
"File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in _pywrap_tensorflow_internal = swig_import_helper() File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File <*>python3.6/imp.py, line 242, in load_module return load_dynamic(name, filename, file) File <*>python3.6/imp.py, line 342, in load_dynamic return _load(spec) ImportError: dlopen(/Users/joson/tensorflow/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 10): Library not loaded: @rpath/libcublas.8.0.dylib",1
"File <string>, line 1, in <module> [CODE] File <*>python3.4/site-packages/pandas/__init__.py, line 35, in <module> ""the C extensions first."".format(module)) ImportError: C extension: numpy.core.multiarray failed to import not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.",1
"File <stdin>, line 1, in <module> [CODE] File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer File <*>/pycaffe.py, line 15, in <module> import caffe.io File <*>/io.py, line 2, in <module> import skimage.io File <*>python3.6/site-packages/skimage/io/__init__.py, line 15, in <module> reset_plugins() File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 93, in reset_plugins _load_preferred_plugins() File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 73, in _load_preferred_plugins _set_plugin(p_type, preferred_plugins['all']) File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 85, in _set_plugin use_plugin(plugin, kind=plugin_type) File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 255, in use_plugin _load(name) File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 299, in _load fromlist=[modname]) File <*>python3.6/site-packages/skimage/io/_plugins/matplotlib_plugin.py, line 3, in <module> import matplotlib.pyplot as plt File <*>python3.6/site-packages/matplotlib/pyplot.py, line 40, in <module> from matplotlib.figure import Figure, figaspect File <*>python3.6/site-packages/matplotlib/figure.py, line 39, in <module> from matplotlib.axes import Axes, SubplotBase, subplot_class_factory File <*>python3.6/site-packages/matplotlib/axes/__init__.py, line 4, in <module> from ._subplots import * File <*>python3.6/site-packages/matplotlib/axes/_subplots.py, line 10, in <module> from matplotlib.axes._axes import Axes File <*>python3.6/site-packages/matplotlib/axes/_axes.py, line 23, in <module> import matplotlib.dates as _ # <-registers a date unit converter File <*>python3.6/site-packages/matplotlib/dates.py, line 148, in <module> from dateutil.rrule import (rrule, MO, TU, WE, TH, FR, SA, SU, YEARLY, File <*>python3.6/site-packages/dateutil/rrule.py, line 55, in [FUNC] [CODE] SyntaxError: invalid syntax",1
"File [FILE], line 9, in <module>() features, label = iter(train_dataset).next() TypeError: 'BatchDataset' object is not iterable",1
"File kerasbottleneck.py, line 104, in <module> train_top_model() File kerasbottleneck.py, line 82, in train_top_model train_data = np.load(open('bottleneck_features_train.npy')) File <*>python3.6/site-packages/numpy/lib/npyio.py, line 404, in load magic = fid.read(N) File <*>python3.6/codecs.py, line 321, in decode (result, consumed) = self._buffer_decode(data, self.errors, final) UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte",1
"File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File <*>python3.6/imp.py, line 243, in load_module return load_dynamic(name, filename, file) File <*>python3.6/imp.py, line 343, in load_dynamic return _load(spec) ImportError: dlopen(/Users/me/tensorflow/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation",1
"File tSNE-images.py, line 95, in <module> run_tsne(images_path, output_path, tsne_dimensions, tsne_perplexity, tsne_learning_rate) File tSNE-images.py, line 75, in run_tsne images, pca_features = analyze_images(images_path) File tSNE-images.py, line 50, in analyze_images feat_extractor = Model(inputs=model.input, outputs=model.get_layer(""fc2"").output) File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/network.py, line 91, in __init__ self._init_graph_network(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/network.py, line 251, in _init_graph_network input_shapes=[x._keras_shape for x in self.inputs], File <*>python3.6/site-packages/keras/engine/network.py, line 251, in <listcomp> input_shapes=[x._keras_shape for x in self.inputs], AttributeError: 'Tensor' object has no attribute '_keras_shape'",1
"File [FILE], line 2, in <module>() from keras.utils import model_to_dot ImportError: cannot import name 'model_to_dot'",1
"File tuto.py, line 85, in <module> estimator.train(input_fn=get_input_fn(num_epochs=None,n_batch = 128,shuffle=True),steps=1000) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 354, in train loss = self._train_model(input_fn, hooks, saving_listeners) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 1207, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 1237, in _train_model_default features, labels, model_fn_lib.ModeKeys.TRAIN, self.config) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 1195, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/, line 537, in _model_fn sparse_combiner=sparse_combiner) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/, line 215, in _linear_model_fn logits=logits) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 239, in create_estimator_spec regularization_losses)) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 1482, in _create_tpu_estimator_spec features=features, mode=mode, logits=logits, labels=labels) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 1381, in create_loss expected_labels_dimension=self._logits_dimension) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 305, in _check_dense_labels_match_logits_and_reshape labels = sparse_tensor.convert_to_tensor_or_sparse_tensor(labels) File <*>python3.6/site-packages/tensorflow/python/framework/sparse_tensor.py, line 279, in convert_to_tensor_or_sparse_tensor value, dtype=dtype, name=name) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1146, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 229, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name) File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 208, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape)) File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 531, in make_tensor_proto ""supported type."" % (type(values), values)) TypeError: Failed to convert object of type <class 'dict'> to Tensor. Contents: {'DispositionSoldAmount': <tf.Tensor 'random_shuffle_queue_DequeueMany:4' shape=(128,) dtype=float64>}. Consider casting elements to a supported type.",1
"File <*>/train.py, line 326, in <module> batch_size=params.batch_size, is_binary=params.is_b_binary) File <*>/models.py, line 378, in g_unet i = Input(shape=(in_ch, 512, 512)) File <*>/site-packages/keras/engine/input_layer.py, line 178, in Input input_tensor=tensor) File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) File <*>/site-packages/keras/engine/input_layer.py, line 39, in __init__ name = prefix + '_' + str(K.get_uid(prefix)) File <*>/site-packages/keras/backend/tensorflow_backend.py, line 74, in get_uid graph = tf.get_default_graph() AttributeError: module 'tensorflow' has no attribute 'get_default_graph'",1
"File [FILE], line 4, in <module>() model =load_model('Leavesnet Model.h5') File <*>python3.6/dist-packages/keras/backend/tensorflow_backend.py, line 541, in placeholder(shape, ndim, dtype, sparse, name) x = tf.placeholder(dtype, shape=shape, name=name) AttributeError: module 'tensorflow' has no attribute 'placeholder'",1
"File <*>python3.6/dist-packages/numpy/core/function_base.py, line 117, in linspace num = operator.index(num) TypeError: 'numpy.float64' object cannot be interpreted as an integer",1
"File <*>/train.py, line 165, in <module> main() File <*>/train.py, line 65, in main tf.set_random_seed(args.random_seed) AttributeError: 'module' object has no attribute 'set_random_seed'",1
"File <stdin>, line 1, in <module> [CODE] AttributeError: module 'tensorflow' has no attribute 'random_normal'",1
"File <stdin>, line 1, in <module> [CODE] File <*>python3.7/site-packages/torch/__init__.py, line 81, in <module> from torch._C import * ImportError: /lib/arm-linux-gnueabihf/libc.so.6: version `GLIBC_2.28' not found (required by /usr/local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)",1
"File <stdin>, line 1, in <module> [CODE] File <*>/site-packages/tensorflow/__init__.py, line 101, in <module> from tensorflow_core import * File <*>/site-packages/tensorflow_core/__init__.py, line 46, in <module> from . _api.v2 import compat File <*>/site-packages/tensorflow_core/_api/v2/compat/__init__.py, line 39, in <module> from . import v1 File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/__init__.py, line 32, in <module> from . import compat File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/compat/__init__.py, line 39, in <module> from . import v1 File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/compat/v1/__init__.py, line 29, in <module> from tensorflow._api.v2.compat.v1 import app File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/compat/v1/__init__.py, line 667, in <module> from tensorflow_estimator.python.estimator.api._v1 import estimator File <*>/site-packages/tensorflow_estimator/__init__.py, line 10, in <module> from tensorflow_estimator._api.v1 import estimator File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py, line 10, in <module> from tensorflow_estimator._api.v1.estimator import experimental File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py, line 10, in <module> from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder File <*>/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py, line 33, in <module> from tensorflow_estimator.python.estimator import estimator File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 53, in <module> from tensorflow_estimator.python.estimator import util as estimator_util File <*>/site-packages/tensorflow_estimator/python/estimator/util.py, line 75, in <module> class _DatasetInitializerHook(tf.compat.v1.train.SessionRunHook): AttributeError: module 'tensorflow' has no attribute 'compat'",1
"File <*>/site-packages/keras/models.py, line 1211, in from_config if 'class_name' not in config[0] or config[0]['class_name'] == 'Merge': KeyError: 0",1
"File <*>/coco.py, line 456, in <module> model_dir=args.logs) File <*>/site-packages/mrcnn/model.py, line 1832, in __init__ self.keras_model = self.build(mode=mode, config=config) File <*>/site-packages/mrcnn/model.py, line 1871, in build x, K.shape(input_image)[1:3]))(input_gt_boxes) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 952, in __call__ input_list) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1091, in _functional_construction_call inputs, input_masks, args, kwargs) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 822, in _keras_tensor_symbolic_call return self._infer_output_signature(inputs, args, kwargs, input_masks) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 869, in _infer_output_signature keras_tensor.keras_tensor_from_tensor, outputs) File <*>/site-packages/tensorflow/python/util/nest.py, line 659, in map_structure structure[0], [func(*x) for x in entries], File <*>/site-packages/tensorflow/python/util/nest.py, line 659, in <listcomp> structure[0], [func(*x) for x in entries], File <*>/site-packages/tensorflow/python/keras/engine/keras_tensor.py, line 606, in keras_tensor_from_tensor out = keras_tensor_cls.from_tensor(tensor) File <*>/site-packages/tensorflow/python/keras/engine/keras_tensor.py, line 205, in from_tensor type_spec = type_spec_module.type_spec_from_value(tensor) File <*>/site-packages/tensorflow/python/framework/type_spec.py, line 554, in type_spec_from_value (value, type(value).__name__)) TypeError: Could not build a TypeSpec for <KerasTensor: shape=(None, None, 4) dtype=float32 (created by layer 'tf.math.truediv')> with type KerasTensor",1
"File <*>/script.py, line 654, in <module> prediction_result, (r, t) = cf.to(model_runner.predict(processed_feature_dict, random_seed=seed), ""cpu"") File <*>python3.7/site-packages/alphafold/model/model.py, line 134, in predict result, recycles = self.apply(self.params, jax.random.PRNGKey(random_seed), feat) File <*>python3.7/site-packages/jax/interpreters/xla.py, line 373, in backend_compile return backend.compile(built_c, compile_options=options) RuntimeError: Resource exhausted: Out of memory while trying to allocate 4649385984 bytes.",1
"File <*>/site-packages/theano/configparser.py, line 168, in fetch_val_for_key return theano_cfg.get(section, option) File <*>/configparser.py, line 781, in get d = self._unify_values(section, vars) File <*>/configparser.py, line 1149, in _unify_values raise NoSectionError(section) from None configparser.NoSectionError: No section: 'blas'",1
"File <stdin>, line 1, in <module> [CODE] File <*>/site-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 540, in runfile execfile(filename, namespace) File <*>/untitled4.py, line 603, in <module> params = test_mlp() File <*>/untitled4.py, line 553, in test_mlp minibatch_avg_cost = train_model(minibatch_index) File <*>/site-packages/theano-0.6.0-py2.7.egg/theano/compile/function_module.py, line 588, in __call__ self.fn.thunks[self.fn.position_of_error]) File <*>/site-packages/theano-0.6.0-py2.7.egg/theano/compile/function_module.py, line 579, in __call__ outputs = self.fn() ValueError: y_i value out of bounds Apply node that caused the error: CrossentropySoftmaxArgmax1HotWithBias(Dot22.0, b, Elemwise{Cast{int32}}.0) Inputs shapes: [(10L, 1L), (1L,), (10L,)] Inputs strides: [(8L, 8L), (8L,), (4L,)] Inputs types: [TensorType(float64, matrix), TensorType(float64, vector), TensorType(int32, vector)] Use the Theano flag 'exception_verbosity=high' for a debugprint of this apply node.",0
"File <string>, line 1, in <module> [CODE] ImportError: No module named caffe",0
"File ae.py, line 330, in <module> main() File ae.py, line 305, in main ae.train(n_epochs=n_epochs, mini_batch_size=100, learning_rate=0.002, train_data= train_sentence_embeddings, test_data= test_sentence_embeddings) File ae.py, line 87, in train givens={x:self.X[index:index+mini_batch_size,:]}) File <*>python2.7/dist-packages/theano/compile/function.py, line 266, in function profile=profile) File <*>python2.7/dist-packages/theano/compile/pfunc.py, line 489, in pfunc no_default_updates=no_default_updates) File <*>python2.7/dist-packages/theano/compile/pfunc.py, line 194, in rebuild_collect_shared store_into) TypeError: ('update target must be a SharedVariable', Subtensor{::, int64}.0)",0
"File tensor_restore.py, line 14, in <module> saver.restore(sess, ""/tmp/model.ckpt"") File <*>python2.7/site-packages/tensorflow/python/training/saver.py, line 891, in restore sess.run([self._restore_op_name], {self._filename_tensor_name: save_path}) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 368, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 444, in _do_run e.code) tensorflow.python.framework.errors.NotFoundError: Tensor name ""v2"" not found in checkpoint files /tmp/model.ckpt [[Node: save/restore_slice_1 = RestoreSlice[dt=DT_INT32, preferred_shard=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_1/tensor_name, save/restore_slice_1/shape_and_slice)]]",0
"File kaggle_otto_nn.py, line 28, in <module> from keras.models import Sequential File <*>/models.py, line 15, in <module> [CODE] File <*>/__init__.py, line 46, in <module> [CODE] File <*>/theano_backend.py, line 1, in <module> [CODE] File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/__init__.py, line 111, in <module> theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1() File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/sandbox/cuda/tests/test_driver.py, line 38, in test_nvidia_driver1 if not numpy.allclose(f(), a.sum()): File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.py, line 871, in __call__ storage_map=getattr(self.fn, 'storage_map', None)) File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/link.py, line 314, in raise_with_op reraise(exc_type, exc_value, exc_trace) File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.py, line 859, in __call__ outputs = self.fn() RuntimeError: Cuda error: kernel_reduce_ccontig_node_97496c4d3cf9a06dc4082cc141f918d2_0: out of memory. (grid: 1 x 1; block: 256 x 1 x 1)",0
"File <stdin>, line 1, in <module> [CODE] File <*>/site-packages/theano/__init__.py, line 111, in <module> theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1() File <*>/site-packages/theano/sandbox/cuda/tests/test_driver.py, line 31, in test_nvidia_driver1 profile=False) File <*>/site-packages/theano/compile/function.py, line 320, in function output_keys=output_keys) File <*>/site-packages/theano/compile/pfunc.py, line 479, in pfunc output_keys=output_keys) File <*>/site-packages/theano/compile/function_module.py, line 1776, in orig_function output_keys=output_keys).create( File <*>/site-packages/theano/compile/function_module.py, line 1456, in __init__ optimizer_profile = optimizer(fgraph) File <*>/site-packages/theano/gof/opt.py, line 101, in __call__ return self.optimize(fgraph) File <*>/site-packages/theano/gof/opt.py, line 89, in optimize ret = self.apply(fgraph, *args, **kwargs) File <*>/site-packages/theano/gof/opt.py, line 230, in apply sub_prof = optimizer.optimize(fgraph) File <*>/site-packages/theano/sandbox/cuda/dnn.py, line 2508, in apply dnn_available.msg) AssertionError: cuDNN optimization was enabled, but Theano was not able to use it. We got this error: Theano can not compile with cuDNN.",0
"File detectGoNo.py, line 95, in <module> sess.run(train_step, feed_dict={x: image_batch, y_: label_batch}) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 340, in run run_metadata_ptr) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 545, in _run raise TypeError('The value of a feed cannot be a tf.Tensor object. ' TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, or numpy ndarrays.",0
"File <*>/pool.py, line 119, in worker result = (True, func(*args, **kwds)) TypeError: func1() got multiple values for argument 'func'",0
"File <stdin>, line 1, in <module> [CODE] File caffepb.py, line 28, in <module> type=None), File <*>python2.7/site-packages/google/protobuf/descriptor.py, line 652, in __new__ _message.Message._CheckCalledFromGeneratedFile() TypeError: Descriptors should not be created directly, but only retrieved from their parent.",0
"File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 715, in _do_call return fn(*args) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 697, in _run_fn status, run_metadata) File <*>python3.5/contextlib.py, line 66, in __exit__ next(self.gen) File <*>python3.5/dist-packages/tensorflow/python/framework/errors.py, line 450, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value auc/false_positives [[Node: auc/false_positives/read = Identity[T=DT_FLOAT, _class=[""loc:@auc/false_positives""], _device=""/job:localhost/replica:0/task:0/cpu:0""](auc/false_positives)]]",0
"File test.py, line 45, in <module> (x_train, _), (x_test, _) = data ValueError: too many values to unpack (expected 2)",0
"File mnist_tensorflow.py, line 60, in <module> x: batch[0], y_: batch[1], keep_prob1: 1.0, keep_prob2: 1.0}) File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 559, in eval return _eval_using_default_session(self, feed_dict, self.graph, session) File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 3761, in _eval_using_default_session return session.run(tensors, feed_dict) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 717, in run run_metadata_ptr) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 915, in _run feed_dict_string, options, run_metadata) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 965, in _do_run target_list, options, run_metadata) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 985, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors.InvalidArgumentError: Input to reshape is a tensor with 313600 values, but the requested shape requires a multiple of 4608 [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](dropout/mul, Reshape_1/shape)]]",0
"File <*>/test_counter.py, line 61, in <module> saver = tf.train.Saver({'w':temp}) File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 1043, in __init__ self.build() File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 1073, in build restore_sequentially=self._restore_sequentially) File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 649, in build saveables = self._ValidateAndSliceInputs(names_to_saveables) File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 578, in _ValidateAndSliceInputs variable) TypeError: names_to_saveables must be a dict mapping string names to Tensors/Variables. Not a variable: Tensor(""TransformFeatureToIndex:0"", shape=(100,), dtype=string)",0
"File <stdin>, line 1, in <module> [CODE] File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import * File <*>/site-packages/tensorflow/python/__init__.py, line 63, in <module> from tensorflow.core.framework.graph_pb2 import * File <*>/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in <module> from google.protobuf import descriptor as _descriptor ImportError: No module named 'google'",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 10, in [FUNC] [CODE] File <*>/contextlib.py, line 66, in __exit__ next(self.gen) File <*>/contextlib.py, line 66, in [FUNC] [CODE] n_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [10000,10] vs. [10000] [[Node: sub = Sub[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](Add, _recv_Placeholder_1_0/_7)]]",0
"File test1.py, line 43, in <module> c = sess.run(cost, feed_dict={X: train_X, Y: train_Y}) File <*>/site-packages/tensorflow/python/client/session.py, line 76, in [FUNC] [CODE] File <*>/site-packages/tensorflow/python/client/session.py, line 96, in [FUNC] [CODE] File <*>/site-packages/tensorflow/python/client/session.py, line 10, in [FUNC] [CODE] tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [10000,10] vs. [10000] [[Node: sub = Sub[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](Add, _recv_Placeholder_1_0/_7)]]",0
"File Netzwerk_v0.5.1_gamma.py, line 171, in <module> session.run(tf.global_variables_initializer()) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 767, in run run_metadata_ptr) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 965, in _run feed_dict_string, options, run_metadata) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1015, in _do_run target_list, options, run_metadata) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1035, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[14525,14000] [[Node: rnn/basic_lstm_cell/weights/Initializer/random_uniform = Add[T=DT_FLOAT, _class=[""loc:@rnn/basic_lstm_cell/weights""], _device=""/job:localhost/replica:0/task:0/gpu:0""](rnn/basic_lstm_cell/weights/Initializer/random_uniform/mul, rnn/basic_lstm_cell/weights/Initializer/random_uniform/min)]]",0
"File test_python.py, line 1, in [FUNC] [CODE] ModuleNotFoundError: No module named 'numpy'",0
"File <stdin>, line 1, in <module> [CODE] RuntimeError: invalid argument 2: dimension 1 out of range of 1D tensor at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensor.c:24",0
"File <*>/site-packages/google/protobuf/internal/python_message.py, line 545, in _GetFieldByName return message_descriptor.fields_by_name[field_name] KeyError: 'layout_optimizer'",0
"File predict.py, line 34, in <module> preds = learn.predict_array(im[None]) File <*>/learner.py, line 266, in predict_array def predict_array(self, arr): return to_np(self.model(V(T(arr).cuda()))) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 325, in __call__ result = self.forward(*input, **kwargs) File <*>python3.6/site-packages/torch/nn/modules/container.py, line 67, in forward input = module(input) File <*>python3.6/site-packages/torch/nn/modules/batchnorm.py, line 37, in forward self.training, self.momentum, self.eps) File <*>python3.6/site-packages/torch/nn/functional.py, line 1011, in batch_norm raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size)) ValueError: Expected more than 1 value per channel when training, got input size [1, 1024]",0
"File cnn_base.py, line 1703, in <module> training() File cnn_base.py, line 1314, in training _, loss_value = sess.run([train_op, loss]) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: cnn()conv2 : Tensor had Inf values [[Node: tower_7/conv2/CheckNumerics_3 = CheckNumerics[T=DT_FLOAT, message=""NaN: cnn()conv2"", _device=""/job:localhost/replica:0/task:0/device:GPU:7""](tower_7/conv2/conv2)]]",0
"File cnn_base.py, line 1704, in <module> training() File cnn_base.py, line 1312, in training nan_debug, _, loss_value = sess.run([check_op, train_op, loss]) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: average_gradients(expanded_g) : Tensor had Inf and NaN values [[Node: CheckNumerics_30 = CheckNumerics[T=DT_FLOAT, message=""NaN: average_gradients(expanded_g)"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](ExpandDims_30)]] [[Node: tower_6/total_loss/_2216 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:6"", send_device_incarnation=1, tensor_name=""edge_4923_tower_6/total_loss"", _device=""/job:localhost/replica:0/task:0/device:GPU:6""](tower_6/total_loss)]]",0
"File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1350, in _do_call return fn(*args) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1329, in _run_fn status, run_metadata) File <*>python3.5/dist-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,32,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[Node: FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Preprocessor/sub, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read)]]",0
"File eval.py, line 146, in <module> tf.app.run() File <*>python3.5/dist-packages/tensorflow/python/platform/app.py, line 124, in run _sys.exit(main(argv)) File eval.py, line 142, in main FLAGS.checkpoint_dir, FLAGS.eval_dir) File <*>/evaluator.py, line 240, in evaluate save_graph_dir=(eval_dir if eval_config.save_graph else '')) File <*>/eval_util.py, line 407, in repeated_checkpoint_run save_graph_dir) File <*>/eval_util.py, line 286, in _run_checkpoint_once result_dict = batch_processor(tensor_dict, sess, batch, counters) File <*>/evaluator.py, line 183, in _process_batch result_dict = sess.run(tensor_dict) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 895, in run run_metadata_ptr) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1128, in _run feed_dict_tensor, options, run_metadata) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1344, in _do_run options, run_metadata) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1363, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,32,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[Node: FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Preprocessor/sub, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read)]]",0
"File <*>python3.6/configparser.py, line 1138, in _unify_values sectiondict = self._sections[section] KeyError: 'blas'",0
"File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl input_tensors_as_shapes, status) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[1], expected a dimension of 1, got 3 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [100,3].",0
"File <*>/main.py, line 6, in <module> watcher = Watcher('res/vid/planet_earth_s01e01/video.mp4', 'res/vid/planet_earth_s01e01/english.srt') File <*>/watch.py, line 9, in __init__ self.detector = Detector() File <*>/detect.py, line 6, in __init__ self.tfnet = TFNet(self.options) File <*>python3.6/site-packages/darkflow/net/build.py, line 75, in __init__ self.build_forward() File <*>python3.6/site-packages/darkflow/net/build.py, line 105, in build_forward self.inp = tf.placeholder(tf.float32, inp_size, 'input') File <*>python3.6/site-packages/tensorflow/python/ops/array_ops.py, line 1677, in placeholder raise RuntimeError(""tf.placeholder() is not compatible with "" RuntimeError: tf.placeholder() is not compatible with eager execution.",0
"File <*>/lstm.py, line 128, in <module> main() File <*>/lstm.py, line 108, in main model.fit_generator(generator=training_sequence) File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) File <*>/site-packages/keras/models.py, line 1253, in fit_generator initial_epoch=initial_epoch) File <*>/site-packages/keras/engine/training.py, line 2244, in fit_generator class_weight=class_weight) File <*>/site-packages/keras/engine/training.py, line 1884, in train_on_batch class_weight=class_weight) File <*>/site-packages/keras/engine/training.py, line 1487, in _standardize_user_data exception_prefix='target') File <*>/site-packages/keras/engine/training.py, line 113, in _standardize_input_data 'with shape ' + str(data_shape)) ValueError: Error when checking target: expected dense_1 to have 5 dimensions, but got array with shape (1, 1939, 9)",0
"File train.py, line 167, in <module> tf.app.run() File <*>python3.5/app.py, line 126, in run _sys.exit(main(argv)) File train.py, line 163, in main worker_job_name, is_chief, FLAGS.train_dir) File <*>python3.5/dist-packages/object_detection-0.1-py3.5.egg/object_detection/trainer.py, line 211, in train detection_model = create_model_fn() File <*>python3.5/dist-packages/object_detection-0.1-py3.5.egg/object_detection/builders/model_builder.py, line 96, in build add_summaries) File <*>python3.5/dist-packages/object_detection-0.1-py3.5.egg/object_detection/builders/model_builder.py, line 272, in _build_faster_rcnn_model frcnn_config.inplace_batchnorm_update) AttributeError: 'FasterRcnn' object has no attribute 'inplace_batchnorm_update'",0
"File experiment.py, line 65, in <module> batches_per_lot=batches_per_lot, sigma=dp_sigma, dp=dp) File <*>/model.py, line 247, in GAN_solvers G_solver = tf.train.AdamOptimizer().minimize(G_loss_mean_over_batch, var_list=generator_vars) File <*>python3.5/dist-packages/tensorflow/python/training/optimizer.py, line 343, in minimize grad_loss=grad_loss) File <*>python3.5/dist-packages/tensorflow/python/training/optimizer.py, line 414, in compute_gradients colocate_gradients_with_ops=colocate_gradients_with_ops) File <*>python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py, line 609, in gradients % (op.name, i, t_in.shape, in_grad.shape)) ValueError: Incompatible shapes between op input and calculated input gradient. Forward operation: generator/conv2d_transpose_1. Input index: 2. Original input shape: (?, 4, 15, 1). Calculated input gradient shape: (?, 5, 15, 1)",0
"File processing_2a_1.py, line 96, in <module> model.add(Conv1D(60,32, strides=1, activation='relu',padding='causal',input_shape=(None,64,1))) File <*>/models.py, line 442, in add [CODE] File <*>/topology.py, line 558, in __call__ [CODE] File <*>/topology.py, line 457, in assert_input_compatibility [CODE] ValueError: Input 0 is incompatible with layer conv1d_1: expected ndim=3, found ndim=4",0
"File train.py, line 167, in <module> tf.app.run() File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv)) File train.py, line 92, in main FLAGS.pipeline_config_path) File <*>/config_util.py, line 93, in get_configs_from_pipeline_file text_format.Merge(proto_str, pipeline_config) File <*>/site-packages/google/protobuf/text_format.py, line 533, in Merge descriptor_pool=descriptor_pool) File <*>/site-packages/google/protobuf/text_format.py, line 587, in MergeLines return parser.MergeLines(lines, message) File <*>/site-packages/google/protobuf/text_format.py, line 620, in MergeLines self._ParseOrMerge(lines, message) File <*>/site-packages/google/protobuf/text_format.py, line 635, in _ParseOrMerge self._MergeField(tokenizer, message) File <*>/site-packages/google/protobuf/text_format.py, line 735, in _MergeField merger(tokenizer, message, field) File <*>/site-packages/google/protobuf/text_format.py, line 823, in _MergeMessageField self._MergeField(tokenizer, sub_message) File <*>/site-packages/google/protobuf/text_format.py, line 703, in _MergeField (message_descriptor.full_name, name)) google.protobuf.text_format.ParseError: 108:7 : Message type ""object_detection.protos.SsdFeatureExtractor"" has no field named ""batch_norm_trainable"".",0
"File train.py, line 167, in <module> tf.app.run() File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv)) File train.py, line 163, in main worker_job_name, is_chief, FLAGS.train_dir) File <*>/trainer.py, line 275, in train clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue]) File <*>/model_deploy.py, line 193, in create_clones outputs = model_fn(*args, **kwargs) File <*>/trainer.py, line 198, in _create_losses prediction_dict = detection_model.predict(images, true_image_shapes) File <*>/ssd_meta_arch.py, line 384, in predict preprocessed_inputs) File <*>/ssd_mobilenet_v2_feature_extractor.py, line 123, in extract_features scope=scope) File <*>/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py, line 183, in func_with_args return func(*args, **current_args) File <*>/mobilenet_v2.py, line 162, in mobilenet_base base_only=True, **kwargs) File <*>/mobilenet_v2.py, line 154, in mobilenet **kwargs) File <*>/mobilenet.py, line 325, in mobilenet net, end_points = mobilenet_base(inputs, scope=scope, **mobilenet_args) File <*>/mobilenet.py, line 244, in mobilenet_base net = opdef.op(net, **params) File <*>/site-packages/tensorflow/contrib/layers/python/layers/layers.py, line 1058, in convolution outputs = normalizer_fn(outputs, **normalizer_params) File <*>/site-packages/tensorflow/contrib/layers/python/layers/layers.py, line 650, in batch_norm outputs = layer.apply(inputs, training=is_training) File <*>/site-packages/tensorflow/python/layers/base.py, line 825, in apply return self.__call__(inputs, *args, **kwargs) File <*>/site-packages/tensorflow/python/layers/base.py, line 714, in __call__ outputs = self.call(inputs, *args, **kwargs) File <*>/site-packages/tensorflow/python/layers/normalization.py, line 549, in call training_value = utils.constant_value(training) File <*>/site-packages/tensorflow/python/layers/utils.py, line 232, in constant_value return smart_module.smart_constant_value(pred) File <*>/site-packages/tensorflow/python/framework/smart_cond.py, line 93, in smart_constant_value ""Found instead: %s"" % pred) TypeError: `pred` must be a Tensor, or a Python bool, or 1 or 0. Found instead: None",0
"File <*>/scratch_4.py, line 11, in <module> assert type(elem) == tf.python.framework.ops.EagerTensor AttributeError: module 'tensorflow' has no attribute 'python'",0
"File <*>python2.7/site-packages/tensorflow/python/ops/script_ops.py, line 147, in __call__ ret = func(*args) File <*>python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 378, in generator_py_func nest.flatten_up_to(output_types, values), flattened_types) AttributeError: 'numpy.dtype' object has no attribute 'as_numpy_dtype'",0
"File pipe, line 320, in <module> tf.app.run() File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv)) File pipe, line 316, in main train(FLAGS.num_training_iterations, FLAGS.report_interval, FLAGS.report_interval_verbose) File pipe, line 120, in train print(sess.run(next_element)) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 905, in run run_metadata_ptr) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1140, in _run feed_dict_tensor, options, run_metadata) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1321, in _do_run run_metadata) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1340, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.UnknownError: exceptions.AttributeError: 'numpy.dtype' object has no attribute 'as_numpy_dtype'",0
"File <*>/label_map_util.py, line 135, in load_labelmap text_format.Merge(label_map_string, label_map) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 525, in Merge descriptor_pool=descriptor_pool) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 579, in MergeLines return parser.MergeLines(lines, message) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 612, in MergeLines self._ParseOrMerge(lines, message) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 627, in _ParseOrMerge self._MergeField(tokenizer, message) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 727, in _MergeField merger(tokenizer, message, field) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 815, in _MergeMessageField self._MergeField(tokenizer, sub_message) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 695, in _MergeField (message_descriptor.full_name, name)) google.protobuf.text_format.ParseError: 23:20 : Message type ""object_detection.protos.StringIntLabelMapItem"" has no field named ""s"".",0
"File train.py, line 184, in <module> tf.app.run() File <*>python3.6/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv)) File train.py, line 180, in main graph_hook_fn=graph_rewriter_fn) File <*>/trainer.py, line 264, in train train_config.prefetch_queue_capacity, data_augmentation_options) File <*>/trainer.py, line 59, in create_input_queue tensor_dict = create_tensor_dict_fn() File train.py, line 121, in get_next dataset_builder.build(config)).get_next() File <*>/dataset_builder.py, line 155, in build label_map_proto_file=label_map_proto_file) File <*>/tf_example_decoder.py, line 245, in init use_display_name) File <*>/label_map_util.py, line 152, in get_label_map_dict label_map = load_labelmap(label_map_path) File <*>/label_map_util.py, line 137, in load_labelmap label_map.ParseFromString(label_map_string) TypeError: a bytes-like object is required, not 'str'",0
"File <ipython-input-11-9a561e7b074b>, line 1, in <module> runfile('C:/Users/emile/Desktop/tensorflow.py', wdir='C:/Users/emile/Desktop') File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 705, in runfile execfile(filename, namespace) File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 102, in execfile exec(compile(f.read(), filename, 'exec'), namespace) File <*>/tensorflow.py, line 6, in <module> import tensorflow as tf File <*>/tensorflow.py, line 7, in <module> import tensorflow.contrib.eager as tfe ModuleNotFoundError: No module named 'tensorflow.contrib'; 'tensorflow' is not a package",0
"File model.py, line 91, in <module> model = Model(inputs=[x1, x2], outputs=[out]) File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/network.py, line 91, in __init__ self._init_graph_network(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/network.py, line 183, in _init_graph_network 'The tensor that caused the issue was: ' + AttributeError: 'Model' object has no attribute 'name'",0
"File main.py, line 109, in <module> train(loader_train, model, criterion, optimizer) File main.py, line 54, in train optimizer.step() File <*>python3.6/site-packages/torch/optim/sgd.py, line 93, in step d_p.add_(weight_decay, p.data) RuntimeError: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/THC/generated/../generic/THCTensorMathPointwise.cu:265",0
"File convolutional_network_raw.py, line 137, in <module> writer.add_summary(summary=summary, global_step=step) File <*>python3.6/site-packages/tensorflow/python/summary/writer/writer.py, line 126, in add_summary for value in summary.value: AttributeError: 'numpy.float32' object has no attribute 'value'",0
"File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 204, in _convert_pb_to_mlmodel shape_list = shape.as_list() File <*>python3.6/site-packages/tensorflow/python/framework/tensor_shape.py, line 900, in as_list raise ValueError(""as_list() is not defined on an unknown TensorShape."") ValueError: as_list() is not defined on an unknown TensorShape.",0
"File <*>/site-packages/flask/app.py, line 1813, in full_dispatch_request rv = self.dispatch_request() File <*>/site-packages/flask/app.py, line 1799, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args) File <*>/site-packages/flask_restful/__init__.py, line 458, in wrapper resp = resource(*args, **kwargs) File <*>/site-packages/flask/views.py, line 88, in view return self.dispatch_request(*args, **kwargs) File <*>/site-packages/flask_restful/__init__.py, line 573, in dispatch_request resp = meth(*args, **kwargs) File app.py, line 41, in get print(ann.predict(x_test)) File <*>/site-packages/keras/engine/training.py, line 1164, in predict self._make_predict_function() File <*>/site-packages/keras/engine/training.py, line 554, in _make_predict_function **kwargs) File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2744, in function return Function(inputs, outputs, updates=updates, **kwargs) File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2546, in __init__ with tf.control_dependencies(self.outputs): File <*>/site-packages/tensorflow/python/framework/ops.py, line 5004, in control_dependencies return get_default_graph().control_dependencies(control_inputs) File <*>/site-packages/tensorflow/python/framework/ops.py, line 4543, in control_dependencies c = self.as_graph_element(c) File <*>/site-packages/tensorflow/python/framework/ops.py, line 3490, in as_graph_element return self._as_graph_element_locked(obj, allow_tensor, allow_operation) File <*>/site-packages/tensorflow/python/framework/ops.py, line 3569, in _as_graph_element_locked raise ValueError(""Tensor %s is not an element of this graph."" % obj) ValueError: Tensor Tensor(""dense_3/Sigmoid:0"", shape=(?, 1), dtype=float32) is not an element of this graph.",0
"File 6_reconstruct_alphabet_image.py, line 17, in <module> import caffe File <*>python3/dist-packages/caffe/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer File <*>python3/dist-packages/caffe/pycaffe.py, line 15, in <module> import caffe.io File <*>python3/dist-packages/caffe/io.py, line 2, in <module> import skimage.io File <*>python3/dist-packages/skimage/__init__.py, line 158, in <module> from .util.dtype import * File <*>python3/dist-packages/skimage/util/__init__.py, line 7, in <module> from .arraycrop import crop File <*>python3/dist-packages/skimage/util/arraycrop.py, line 8, in <module> from numpy.lib.arraypad import _validate_lengths ImportError: cannot import name '_validate_lengths'",0
"File <frozen importlib._bootstrap>, line 980, in _find_and_load [CODE] SystemError: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set ImportError: numpy.core._multiarray_umath failed to import ImportError: numpy.core.umath failed to import",0
"File [FILE], line <*>, in [FUNC] [CODE] File <*>/site-packages/tensorflow_<em>init</em>_.py, line 24, in [FUNC] [CODE] File <*>/site-packages/tensorflow/python_<em>init</em>_.py, line 59, in [FUNC] [CODE] File <*>/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in [FUNC] [CODE] File <*>/site-packages/google/protobuf/descriptor.py, line 47, in [FUNC] [CODE] ImportError: DLL load failed: The specified procedure could not be found.",0
"File <*>python3.6/site-packages/theano/compile/function_module.py, line 884, in __call__ self.fn() if output_subset is None else\ ValueError: Input dimension mis-match. (input[0].shape[1] = 50, input[1].shape[1] = 100)",0
"File <*>/pydevd.py, line 1741, in <module> main() File <*>/pydevd.py, line 1735, in main globals = debugger.run(setup['file'], None, None, is_module) File <*>/pydevd.py, line 1135, in run pydev_imports.execfile(file, globals, locals) # execute the script File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc) File <*>/MnistTrainer.py, line 100, in <module> main() File <*>/MnistTrainer.py, line 92, in main mnist_trainer.train(train_steps=100, log_interval=1, save_interval=1) File <*>/MnistTrainer.py, line 56, in train self.save_models(output_folder_path, i + 1) File <*>/MnistTrainer.py, line 69, in save_models os.path.join(output_folder_path, 'discriminator_model_{0}.h5'.format(iteration_no))) File <*>python3.6/site-packages/keras/engine/network.py, line 1090, in save save_model(self, filepath, overwrite, include_optimizer) File <*>python3.6/site-packages/keras/engine/saving.py, line 382, in save_model _serialize_model(model, f, include_optimizer) File <*>python3.6/site-packages/keras/engine/saving.py, line 83, in _serialize_model model_config['config'] = model.get_config() File <*>python3.6/site-packages/keras/engine/sequential.py, line 278, in get_config 'config': layer.get_config() File <*>python3.6/site-packages/keras/layers/convolutional.py, line 493, in get_config config = super(Conv2D, self).get_config() File <*>python3.6/site-packages/keras/layers/convolutional.py, line 226, in get_config 'activation': activations.serialize(self.activation), File <*>python3.6/site-packages/keras/activations.py, line 176, in serialize return activation.__name__ AttributeError: 'LeakyReLU' object has no attribute '__name__'",0
"File <*>/train.py, line 107, in <module> callbacks=[Saver(save_every), Evaluation(evaluate_every)]) File <*>/site-packages/keras/engine/training.py, line 1039, in fit validation_steps=validation_steps) File <*>/site-packages/keras/engine/training_arrays.py, line 204, in fit_loop callbacks.on_batch_end(batch_index, batch_logs) File <*>/site-packages/keras/callbacks.py, line 115, in on_batch_end callback.on_batch_end(batch, logs) File <*>/train.py, line 83, in on_batch_end self.model.save(name) File <*>/site-packages/keras/engine/network.py, line 1090, in save save_model(self, filepath, overwrite, include_optimizer) File <*>/site-packages/keras/engine/saving.py, line 382, in save_model _serialize_model(model, f, include_optimizer) File <*>/site-packages/keras/engine/saving.py, line 83, in _serialize_model model_config['config'] = model.get_config() File <*>/site-packages/keras/engine/network.py, line 931, in get_config return copy.deepcopy(config) File <*>/copy.py, line 150, in deepcopy y = copier(x, memo) File <*>/copy.py, line 240, in _deepcopy_dict y[deepcopy(key, memo)] = deepcopy(value, memo) File <*>/copy.py, line 215, in _deepcopy_list append(deepcopy(a, memo)) File <*>/copy.py, line 220, in _deepcopy_tuple y = [deepcopy(a, memo) for a in x] File <*>/copy.py, line 220, in <listcomp> y = [deepcopy(a, memo) for a in x] File <*>/copy.py, line 180, in deepcopy y = _reconstruct(x, memo, *rv) File <*>/copy.py, line 280, in _reconstruct state = deepcopy(state, memo) File <*>/copy.py, line 169, in deepcopy rv = reductor(4) TypeError: can't pickle _thread.RLock objects",0
"File <stdin>, line 1, in <module> [CODE] RuntimeError: Could not infer dtype of generator",0
"File <*>/min_working_example.py, line 37, in <module> model.fit(data_generator) File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 873, in fit steps_name='steps_per_epoch') File <*>python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 352, in model_iteration batch_outs = f(ins_batch) File <*>python3.7/site-packages/tensorflow/python/keras/backend.py, line 3217, in __call__ outputs = self._graph_fn(*converted_inputs) File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 558, in __call__ return self._call_flat(args) File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 627, in _call_flat outputs = self._inference_function.call(ctx, args) File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 397, in call (len(args), len(list(self.signature.input_arg)))) ValueError: Arguments and signature arguments do not match: 21 23",0
"File <*>/min_working_example.py, line 37, in <module> model.fit_generator(data_generator) File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 1515, in fit_generator steps_name='steps_per_epoch') File <*>python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py, line 140, in model_iteration shuffle=shuffle) File <*>python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py, line 477, in convert_to_generator_like raise ValueError('You must specify `batch_size`') ValueError: You must specify `batch_size`",0
"File <*>/main.py, line 182, in <module> batch_size=128, epochs=1) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 880, in fit validation_steps=validation_steps) File <*>/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 329, in model_iteration batch_outs = f(ins_batch) File <*>/site-packages/tensorflow/python/keras/backend.py, line 3076, in __call__ run_metadata=self.run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1439, in __call__ run_metadata_ptr) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [10,2] vs. [10] [[{{node metrics/acc/Equal}}]] [[{{node loss/mul}}]]",0
"File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File <*>python3.7/imp.py, line 242, in load_module return load_dynamic(name, filename, file) File <*>python3.7/imp.py, line 342, in load_dynamic return _load(spec) ImportError: /usr/lib/libcublas.so.10.0: version `libcublas.so.10.0' not found (required by /home/techievin/.local/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)",0
"File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in make_tensor_proto str_values = [compat.as_bytes(x) for x in proto_values] File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in <listcomp> str_values = [compat.as_bytes(x) for x in proto_values] File <*>/site-packages/tensorflow/python/util/compat.py, line 61, in as_bytes (bytes_or_text,)) TypeError: Expected binary or unicode string, got Dimension(4)",0
"File TestServe.py, line 62, in <module> ts.train() File TestServe.py, line 56, in train epochs=2, verbose=1, callbacks=callbacks, steps_per_epoch=20) #The steps_per_epoch is typically samples_per_epoch / batch_size File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 880, in fit validation_steps=validation_steps) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 364, in model_iteration validation_in_fit=True) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 202, in model_iteration steps_per_epoch) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 76, in _get_num_samples_or_steps 'steps_per_epoch') File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 230, in check_num_samples if check_steps_argument(ins, steps, steps_name): File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 960, in check_steps_argument input_type=input_type_str, steps_name=steps_name)) ValueError: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument.",0
"File <*>/toco, line 11, in <module> sys.exit(main()) File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 503, in main app.run(main=run_main, argv=sys.argv[:1]) File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef) File <*>python2.7/site-packages/absl/app.py, line 300, in run _run_main(main, args) File <*>python2.7/site-packages/absl/app.py, line 251, in _run_main sys.exit(main(argv)) File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 499, in run_main _convert_tf1_model(tflite_flags) File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 124, in _convert_tf1_model converter = _get_toco_converter(flags) File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 111, in _get_toco_converter return converter_fn(**converter_kwargs) File <*>python2.7/site-packages/tensorflow/lite/python/lite.py, line 628, in from_frozen_graph _import_graph_def(graph_def, name="""") File <*>python2.7/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func return func(*args, **kwargs) File <*>python2.7/site-packages/tensorflow/python/framework/importer.py, line 431, in import_graph_def raise ValueError(str(e)) ValueError: Input 0 of node dense_1/weights_quant/AssignMinLast was passed float from dense_1/weights_quant/min:0 incompatible with expected float_ref.",0
"File test_model.py, line 5, in <module> import tensorflow as tf File <*>/site-packages/tensorflow/__init__.py, line 28, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import File <*>/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 30, in <module> self_check.preload_check() File <*>/site-packages/tensorflow/python/platform/self_check.py, line 70, in preload_check % build_info.nvcuda_dll_name) ImportError: Could not find 'nvcuda.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Typically it is installed in 'C:\Windows\System32'. If it is not present, ensure that you have a CUDA-capable GPU with the correct driver installed.",0
"File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1473, in __del__ self._session._session, self._handle) tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')",0
"File <*>/main.py, line 41, in <module> predics = nmodel.predict([x_test]) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 821, in predict use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 705, in predict x, check_steps=True, steps_name='steps', steps=steps) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 2335, in _standardize_user_data self._set_inputs(cast_inputs) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 2553, in _set_inputs outputs = self(inputs, **kwargs) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 662, in __call__ outputs = call_fn(inputs, *args, **kwargs) File <*>/site-packages/tensorflow/python/keras/engine/sequential.py, line 262, in call outputs = layer(inputs, **kwargs) File <*>/site-packages/tensorflow/python/keras/layers/core.py, line 580, in call inputs, (tensor_shape.dimension_value(inputs.shape[0]) or AttributeError: 'list' object has no attribute 'shape'",0
"File <*>/pathtoproject, line 75, in predict cm_prediction = self.model.predict([face, reye, leye, fg])[0] File <*>/pathtoproject, line 1462, in predict callbacks=callbacks) File <*>/site-packages/keras/engine/training_arrays.py, line 276, in predict_loop callbacks.model.stop_training = False File <*>/site-packages/keras/engine/network.py, line 323, in __setattr__ super(Network, self).__setattr__(name, value) File <*>/site-packages/keras/engine/base_layer.py, line 1215, in __setattr__ if not _DISABLE_TRACKING.value: AttributeError: '_thread._local' object has no attribute 'value'",0
"File train.py, line 6, in <module> import keras.backend as K File <*>/site-packages/keras/__init__.py, line 3, in <module> from . import utils File <*>/site-packages/keras/utils/__init__.py, line 27, in <module> from .multi_gpu_utils import multi_gpu_model File <*>/site-packages/keras/utils/multi_gpu_utils.py, line 7, in <module> from ..layers.merge import concatenate File <*>/site-packages/keras/layers/__init__.py, line 4, in <module> from ..engine.base_layer import Layer File <*>/site-packages/keras/engine/__init__.py, line 8, in <module> from .training import Model File <*>/site-packages/keras/engine/training.py, line 21, in <module> from . import training_arrays File <*>/site-packages/keras/engine/training_arrays.py, line 14, in <module> from .. import callbacks as cbks File <*>/site-packages/keras/callbacks/__init__.py, line 19, in <module> if K.backend() == 'tensorflow' and not K.tensorflow_backend._is_tf_1(): AttributeError: module 'keras.backend.tensorflow_backend' has no attribute '_is_tf_1'",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 738, in __del__ [CODE] TypeError: 'NoneType' object is not callable",0
"File <input>, line 1, in <module> [CODE] File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 495, in ResNet50V2 **kwargs) File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 348, in ResNet data_format=backend.image_data_format(), AttributeError: 'NoneType' object has no attribute 'image_data_format'",0
"File main.py, line 69, in <module> pickle.dump(history, f) TypeError: can't pickle _thread._local objects",0
"File model_main.py, line 109, in [FUNC] [CODE] File <*>/site-packages/tensorflow/python/platform/app.py, line 125, in run _sys.exit(main(argv)) File model_main.py, line 105, in main tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0]) File <*>/site-packages/tensorflow/python/estimator/training.py, line 471, in train_and_evaluate return executor.run() File <*>/site-packages/tensorflow/python/estimator/training.py, line 610, in run return self.run_local() File <*>/site-packages/tensorflow/python/estimator/training.py, line 711, in run_local saving_listeners=saving_listeners) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 354, in train loss = self._train_model(input_fn, hooks, saving_listeners) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 1207, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 1241, in _train_model_default saving_listeners) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 1471, in _train_with_estimator_spec _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss]) File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 783, in exit self._close_internal(exception_type) File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 816, in _close_internal h.end(self._coordinated_creator.tf_sess) File <*>/site-packages/tensorflow/python/training/basic_session_run_hooks.py, line 590, in end l.end(session, last_step) File <*>/site-packages/tensorflow/python/estimator/training.py, line 531, in end self._evaluate(global_step_value) File <*>/site-packages/tensorflow/python/estimator/training.py, line 537, in _evaluate self._evaluator.evaluate_and_export()) File <*>/site-packages/tensorflow/python/estimator/training.py, line 924, in evaluate_and_export is_the_final_export) File <*>/site-packages/tensorflow/python/estimator/training.py, line 957, in _export_eval_result is_the_final_export=is_the_final_export)) File <*>/site-packages/tensorflow/python/estimator/exporter.py, line 418, in export is_the_final_export) File <*>/site-packages/tensorflow/python/estimator/exporter.py, line 126, in export strip_default_attrs=self._strip_default_attrs) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 663, in export_savedmodel mode=model_fn_lib.ModeKeys.PREDICT) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 789, in _export_saved_model_for_mode strip_default_attrs=strip_default_attrs) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 883, in _export_all_saved_models builder = saved_model_builder.SavedModelBuilder(temp_export_dir) File <*>/site-packages/tensorflow/python/saved_model/builder_impl.py, line 97, in init file_io.recursive_create_dir(self._export_dir) File <*>/site-packages/tensorflow/python/lib/io/file_io.py, line 379, in recursive_create_dir pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in exit c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: training/export\Servo\temp-b'1576742954'; No such file or directory",0
"File <*>/maxmem.py, line 11, in <module> dic[x]=tf.random.normal((nn,dd)) File <*>python3.7/site-packages/tensorflow_core/python/ops/random_ops.py, line 76, in random_normal value = math_ops.add(mul, mean_tensor, name=name) File <*>python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py, line 391, in add _six.raise_from(_core._status_to_exception(e.code, message), None) File <string>, line 3, in raise_from [CODE] tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1000,250000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add] name: random_normal/",0
"File DL_Ensemble.py, line 145, in <module> fused = concatenate([graph, graph_1], axis= 1 ) File <*>python3.8/site-packages/tensorflow_core/python/keras/layers/merge.py, line 705, in concatenate return Concatenate(axis=axis, **kwargs)(inputs) File <*>python3.8/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 887, in __call__ self._maybe_build(inputs) File <*>python3.8/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 2141, in _maybe_build self.build(input_shapes) File <*>python3.8/site-packages/tensorflow_core/python/keras/utils/tf_utils.py, line 306, in wrapper output_shape = fn(instance, input_shape) File <*>python3.8/site-packages/tensorflow_core/python/keras/layers/merge.py, line 378, in build raise ValueError('A `Concatenate` layer should be called ' ValueError: A `Concatenate` layer should be called on a list of at least 2 inputs",0
"File tf2_main.py, line 50, in <module> model = CycleGAN(args) File <*>/tf2_model.py, line 55, in __init__ self._build_model(args) File <*>/tf2_model.py, line 63, in _build_model name='Generator_A2B') File <*>/tf2_module.py, line 154, in build_generator name='IN_1')(x) File <*>python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 773, in __call__ outputs = call_fn(cast_inputs, *args, **kwargs) File <*>python3.6/site-packages/tensorflow_core/python/keras/layers/core.py, line 847, in call self._check_variables(created_variables, tape.watched_variables()) File <*>python3.6/site-packages/tensorflow_core/python/keras/layers/core.py, line 873, in _check_variables raise ValueError(error_str) ValueError: The following Variables were created within a Lambda layer (IN_1) but are not tracked by said layer: <tf.Variable 'IN_1/SCALE:0' shape=(64,) dtype=float32> <tf.Variable 'IN_1/OFFSET:0' shape=(64,) dtype=float32> The layer cannot safely ensure proper Variable reuse across multiple calls, and consquently this behavior is disallowed for safety. Lambda layers are not well suited to stateful computation; instead, writing a subclassed Layer is the recommend way to define layers with Variables.",0
"File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 61, in quick_execute num_outputs) TypeError: An op outside of the function building code is being passed a ""Graph"" tensor. It is possible to have Graph tensors leak out of the function building context by including a tf.init_scope in your function building code.",0
"File <stdin>, line 1, in <module> [CODE] File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 1013, in predict use_multiprocessing=use_multiprocessing) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 498, in predict workers=workers, use_multiprocessing=use_multiprocessing, **kwargs) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 475, in _model_iteration total_epochs=1) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch batch_outs = execution_function(iterator) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function distributed_function(input_fn)) File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__ result = self._call(*args, **kwds) File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 638, in _call return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds) # pylint: disable=protected-access File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call self.captured_inputs) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat ctx, args, cancellation_manager=cancellation_manager)) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 545, in call ctx=ctx) File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 75, in quick_execute ""tensors, but found {}"".format(keras_symbolic_tensors)) tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'conv_name_base_1/Identity:0' shape=(None, 160, 160, 64) dtype=float32>]",0
"File pytorch_test.py, line 14, in <module> a_copy.resize_(1, 1) RuntimeError: set_sizes_contiguous is not allowed on a Tensor created from .data or .detach().",0
"File <*>python2.7/process.py, line 267, in _bootstrap self.run() File <*>python2.7/process.py, line 114, in run self._target(*self._args, **self._kwargs) File <*>python2.7/pool.py, line 102, in worker task = get() File <*>python2.7/queues.py, line 376, in get return recv() AttributeError: 'module' object has no attribute 'prediction'",0
"File stackoverflow.py, line 47, in <module> with multiprocessing.Pool() as p: AttributeError: __exit__",0
"File the_other_end-mp.py, line 216, in <module> predops=p.map(prediction,modelon) File <*>python2.7/pool.py, line 253, in map return self.map_async(func, iterable, chunksize).get() File <*>python2.7/pool.py, line 572, in get raise self._value ValueError: Resource handles are not convertible to numpy.",0
"File <*>/site-packages/torch/_utils_internal.py, line 46, in get_source_lines_and_file [CODE] File inspect.py, line 967, in getsourcelines [CODE] File inspect.py, line 798, in findsource [CODE] OSError: could not get source code",0
"File extractor.py, line 3, in <module> import torch File <frozen importlib._bootstrap>, line 991, in _find_and_load [CODE] File <frozen importlib._bootstrap>, line 975, in _find_and_load_unlocked [CODE] File <frozen importlib._bootstrap>, line 671, in _load_unlocked [CODE] File <*>/site-packages/PyInstaller/loader/pyimod03_importers.py, line 623, in exec_module exec(bytecode, module.__dict__) File <*>/site-packages/torch/__init__.py, line 367, in <module> [CODE] File <*>/site-packages/torch/distributions/__init__.py, line 112, in <module> [CODE] File <*>/site-packages/torch/distributions/von_mises.py, line 55, in <module> [CODE] File <*>/site-packages/torch/jit/__init__.py, line 1287, in script [CODE] File <*>/site-packages/torch/jit/frontend.py, line 164, in get_jit_def [CODE] File <*>/site-packages/torch/_utils_internal.py, line 53, in get_source_lines_and_file [CODE] OSError: Can't get source for <function _rejection_sample at 0x0000000006892F70>. TorchScript requires source access in order to carry out compilation, make sure original .py files are available.",0
"File plot_parametric_pytorch_cifar100.py, line 130, in <module> loss_fn = F.nll_loss(ops, tgts) File <*>python3.7/site-packages/torch/nn/functional.py, line 2115, in nll_loss ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index) IndexError: Target 42 is out of bounds.",0
"File trainer.py, line 629, in <module> clear_outputs=True File <*>/utils.py, line 62, in wrapper result = func(*args, **kwargs) File trainer.py, line 490, in train validation_data=valid_dataset, File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper return method(self, *args, **kwargs) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1090, in fit tmp_logs = train_function(iterator) File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 766, in __call__ result = self._call(*args, **kwds) File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 826, in _call return self._stateless_fn(*args, **kwds) File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 2811, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1838, in _filtered_call cancellation_manager=cancellation_manager) File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1914, in _call_flat ctx, args, cancellation_manager=cancellation_manager)) File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 549, in call ctx=ctx) File <*>python3.6/site-packages/tensorflow/python/eager/execute.py, line 60, in quick_execute inputs, attrs, num_outputs) tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [4,76,76,3,1] vs. [4,19,19,3,1] [[node yolo_loss/logistic_loss/mul (defined at ../Helpers/utils.py:260) ]] [Op:__inference_train_function_38735]",0
"File <*>/trainer.py, line 693, in <module> clear_outputs=True, File <*>/utils.py, line 62, in wrapper result = func(*args, **kwargs) File <*>/trainer.py, line 526, in train validation_data=valid_dataset, File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper return method(self, *args, **kwargs) File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 848, in fit tmp_logs = train_function(iterator) File <*>python3.7/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__ result = self._call(*args, **kwds) File <*>python3.7/site-packages/tensorflow/python/eager/def_function.py, line 644, in _call return self._stateless_fn(*args, **kwds) File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 2420, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 1665, in _filtered_call self.captured_inputs) File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 1746, in _call_flat ctx, args, cancellation_manager=cancellation_manager)) File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 598, in call ctx=ctx) File <*>python3.7/site-packages/tensorflow/python/eager/execute.py, line 60, in quick_execute inputs, attrs, num_outputs) tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [8,13,13,3,2] vs. [8,52,52,3,2] [[node gradient_tape/yolo_loss/sub_5/BroadcastGradientArgs (defined at Users/emadboctor/Desktop/Code/yolov3-keras-tf2/Main/trainer.py:526) ]] [Op:__inference_train_function_42744]",0
"File imdb_classification.py, line 65, in <module> history = model.fit(x_train,y_train,epochs=50,batch_size=32,verbose=1) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 819, in fit use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 235, in fit use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 593, in _process_training_inputs use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 706, in _process_inputs use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 357, in __init__ dataset = self.slice_inputs(indices_dataset, inputs) File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 383, in slice_inputs dataset_ops.DatasetV2.from_tensors(inputs).repeat() File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 566, in from_tensors return TensorDataset(tensors) File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 2765, in __init__ element = structure.normalize_element(element) File <*>/site-packages/tensorflow_core/python/data/util/structure.py, line 113, in normalize_element ops.convert_to_tensor(t, name=""component_%d"" % i)) File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1314, in convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py, line 52, in _default_conversion_function return constant_op.constant(value, dtype, name=name) File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 258, in constant allow_broadcast=True) File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 266, in _constant_impl t = convert_to_eager_tensor(value, ctx, dtype) File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 96, in convert_to_eager_tensor return ops.EagerTensor(value, ctx.device_name, dtype) ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list)",0
"File <*>/convert.py, line 13, in <module> tflite_model = converter.convert() File <*>/site-packages/tensorflow/lite/python/lite.py, line 1076, in convert return super(TFLiteConverterV2, self).convert() File <*>/site-packages/tensorflow/lite/python/lite.py, line 899, in convert return super(TFLiteFrozenGraphConverterV2, File <*>/site-packages/tensorflow/lite/python/lite.py, line 629, in convert result = _toco_convert_impl( File <*>/site-packages/tensorflow/lite/python/convert.py, line 569, in toco_convert_impl data = toco_convert_protos( File <*>/site-packages/tensorflow/lite/python/convert.py, line 202, in toco_convert_protos raise ConverterError(str(e)) tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types <unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x?x?x3x!tf.quint8>) -> tensor<1x?x?x3xui8>",0
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 64, in <module> from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.",0
"File <*>/model_main_tf2.py, line 113, in <module> tf.compat.v1.app.run() File <*>python3.6/dist-packages/tensorflow/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef) File <*>python3.6/dist-packages/absl/app.py, line 300, in run _run_main(main, args) File <*>python3.6/dist-packages/absl/app.py, line 251, in _run_main sys.exit(main(argv)) File <*>/model_main_tf2.py, line 110, in main record_summaries=FLAGS.record_summaries) File <*>python3.6/dist-packages/object_detection/model_lib_v2.py, line 630, in train_loop manager.save() File <*>python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py, line 819, in save self._record_state() File <*>python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py, line 728, in _record_state save_relative_paths=True) File <*>python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py, line 248, in update_checkpoint_state_internal text_format.MessageToString(ckpt)) File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 570, in atomic_write_string_to_file rename(temp_pathname, filename, overwrite) File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 529, in rename rename_v2(oldname, newname, overwrite) File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 546, in rename_v2 compat.as_bytes(src), compat.as_bytes(dst), overwrite) tensorflow.python.framework.errors_impl.FailedPreconditionError: /content/drive/My Drive/Tensorflow/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint.tmp91048f3bf67645619be6603094546de1; Is a directory",0
"File ml_model.py, line 1, in <module> import torch File <*>/site-packages/torch/__init__.py, line 117, in <module> import torch File <*>/site-packages/torch/__init__.py, line 117, in <module> raise err OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading ""C:\Users\user\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\lib\cudnn_cnn_infer64_8.dll"" or one of its dependencies. raise err",0
"File [FILE], line 14, in <module>() p.fit(x=df_train, y=df_train, steps=10, batch_size=100) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 173, in fit(self, x, y, input_fn, steps, batch_size, monitors) input_fn, feed_fn = _get_input_fn(x, y, batch_size) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 67, in _get_input_fn(x, y, batch_size) x, y, n_classes=None, batch_size=batch_size) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.pyc, line 99, in setup_train_data_feeder(X, y, n_classes, batch_size, shuffle, epochs) X, y = _data_type_filter(X, y) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.pyc, line 67, in _data_type_filter(X, y) X = extract_pandas_data(X) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/pandas_io.pyc, line 53, in extract_pandas_data(data) raise ValueError('Data types for data must be int, float, or bool.') ValueError: Data types for data must be int, float, or bool.",0
"File [FILE], line 7, in <module>() hidden1 = tf.nn.relu(tf.matmul(images_placeholder, weights) + biases) File <*>python3.4/site-packages/tensorflow/python/ops/math_ops.py, line 1325, in matmul(a, b, transpose_a, transpose_b, a_is_sparse, b_is_sparse, name) with ops.op_scope([a, b], name, ""MatMul"") as name: File <*>python3.4/contextlib.py, line 59, in __enter__(self) return next(self.gen) File <*>python3.4/site-packages/tensorflow/python/framework/ops.py, line 4016, in op_scope(values, name, default_name) g = _get_graph_from_inputs(values) File <*>python3.4/site-packages/tensorflow/python/framework/ops.py, line 3814, in _get_graph_from_inputs(op_input_list, graph) _assert_same_graph(original_graph_element, graph_element) File <*>python3.4/site-packages/tensorflow/python/framework/ops.py, line 3759, in _assert_same_graph(original_item, item) ""%s must be from the same graph as %s."" % (item, original_item)) ValueError: Tensor(""weights:0"", shape=(1024, 200), dtype=float32_ref) must be from the same graph as Tensor(""Placeholder:0"", shape=(100, 1024), dtype=float32).`",0
"File [FILE], line 27, in () train = model.train(images, labels) File [FILE], line 62, in train(self, images, labels) logits = model._create_model(images) File [FILE], line 41, in _create_model(self, inputs) inputs = self._create_dense_layer(name, inputs, n_in, n_out) File [FILE], line 27, in _create_dense_layer(self, name, inputs, n_in, n_out, activation) weights = self._weights([n_in, n_out]) File <*>python3.5/site-packages/tensorflow/python/ops/template.py, line 267, in __call__(self, *args, **kwargs) return self._call_func(args, kwargs, check_for_new_variables=False) File <*>python3.5/site-packages/tensorflow/python/ops/template.py, line 208, in _call_func(self, args, kwargs, check_for_new_variables) result = self._func(*args, **kwargs) TypeError: _real_weights() missing 1 required positional argument: 'shape'",0
"File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn) input_tensors_as_shapes, status) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status)) InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 4096 and 1000 for 'Assign_30' (op: 'Assign') with input shapes: [4096,3], [1000,3].",0
"File <*>/train.py, line 58, in <module>() flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.') File <*>python3.6/dist-packages/tensorflow/python/platform/flags.py, line 58, in wrapper(*args, **kwargs) return original_function(*args, **kwargs) File <*>python3.6/dist-packages/absl/flags/_defines.py, line 241, in DEFINE_string(name, default, help, flag_values, **args) DEFINE(parser, name, default, help, flag_values, serializer, **args) File <*>python3.6/dist-packages/absl/flags/_defines.py, line 82, in DEFINE(parser, name, default, help, flag_values, serializer, module_name, **args) flag_values, module_name) File <*>python3.6/dist-packages/absl/flags/_defines.py, line 104, in DEFINE_flag(flag, flag_values, module_name) fv[flag.name] = flag File <*>python3.6/dist-packages/absl/flags/_flagvalues.py, line 427, in __setitem__(self, name, flag) raise _exceptions.DuplicateFlagError.from_flag(name, self) DuplicateFlagError: The flag 'master' is defined twice. First from object_detection/train.py, Second from object_detection/train.py. Description from first occurrence: Name of the TensorFlow master to use.",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1322, in _do_call(self, fn, *args) return fn(*args) File <*>/site-packages/tensorflow/python/client/session.py, line 1307, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1409, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata) InvalidArgumentError: Matrix size-incompatible: In[0]: [1,16384], In[1]: [1024,10] [[Node: dense_251/MatMul = MatMul[T=DT_FLOAT, _class=[""loc:@training_22/RMSprop/gradients/dense_251/MatMul_grad/MatMul""], transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](flatten_153/Reshape, dense_251/kernel/read)]] [[Node: loss_26/mul/_579 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1108_loss_26/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]",0
"File [FILE], line 87, in <module>() initial_epoch=initial_epoch) File <*>python36/site-packages/keras/legacy/interfaces.py, line 87, in wrapper(*args, **kwargs) return func(*args, **kwargs) File <*>python36/site-packages/keras/engine/training.py, line 2042, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) class_weight=class_weight) File <*>python36/site-packages/keras/engine/training.py, line 1756, in train_on_batch(self, x, y, sample_weight, class_weight) check_batch_axis=True) File <*>python36/site-packages/keras/engine/training.py, line 1378, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size) exception_prefix='input') File <*>python36/site-packages/keras/engine/training.py, line 58, in _standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) 'expected no data, but got:', data) ValueError: ('Error when checking model input: expected no data, but got:', [array([[[[1.62046947e+01, 0.00000000e+00, 0.00000000e+00, ...",0
"File [FILE], line 4, in <module>() model = torch.load('checkpoint.pth') File <*>python3.6/site-packages/torch/serialization.py, line 303, in load(f, map_location, pickle_module) return _load(f, map_location, pickle_module) File <*>python3.6/site-packages/torch/serialization.py, line 469, in _load(f, map_location, pickle_module) result = unpickler.load() AttributeError: Can't get attribute 'Network' on <module '__main__'>",0
"File [FILE], line [NUM], in <module> [CODE] File <*>python3.7/site-packages/keras/engine/training.py, line 952, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs) batch_size=batch_size) File <*>python3.7/site-packages/keras/engine/training.py, line 677, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size) self._set_inputs(x) File <*>python3.7/site-packages/keras/engine/training.py, line 589, in _set_inputs(self, inputs, outputs, training) self.build(input_shape=(None,) + inputs.shape[1:]) File <*>python3.7/site-packages/keras/engine/sequential.py, line 221, in build(self, input_shape) x = layer(x) File <*>python3.7/site-packages/keras/engine/base_layer.py, line 457, in __call__(self, inputs, **kwargs) output = self.call(inputs, **kwargs) File <*>python3.7/site-packages/keras/layers/core.py, line 126, in call(self, inputs, training) training=training) File <*>python3.7/site-packages/keras/backend/tensorflow_backend.py, line 3105, in in_train_phase(x, alt, training) training = learning_phase() File <*>python3.7/site-packages/keras/backend/tensorflow_backend.py, line 135, in learning_phase() name='keras_learning_phase') File <*>python3.7/site-packages/tensorflow/python/ops/array_ops.py, line 2093, in placeholder_with_default(input, shape, name) return gen_array_ops.placeholder_with_default(input, shape, name) File <*>python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py, line 5925, in placeholder_with_default(input, shape, name) ""PlaceholderWithDefault"", input=input, shape=shape, name=name) File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 511, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype) File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1175, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 304, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 245, in constant(value, dtype, shape, name) allow_broadcast=True) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast)) File <*>python3.7/site-packages/tensorflow/python/framework/tensor_util.py, line 573, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) append_fn(tensor_proto, proto_values) File <*>/fast_tensor_util.pyxintensorflow.python, line [NUM], in tensorflow.python.framework.fast_tensor_util.AppendBoolArrayToTensorProto() [CODE] File <*>python3.7/site-packages/numpy/lib/type_check.py, line 547, in asscalar(***failed resolving arguments***) return a.item() UnboundLocalError: local variable 'a' referenced before assignment",0
"File [FILE], line 11, in <module>() model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc']) File <*>python3.6/dist-packages/tensorflow/python/training/checkpointable/base.py, line 442, in _method_wrapper(self, *args, **kwargs) method(self, *args, **kwargs) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 449, in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs) output_loss = weighted_loss(y_true, y_pred, sample_weight, mask) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py, line 676, in weighted(y_true, y_pred, weights, mask) score_array = math_ops.div_no_nan(score_array, weights) File <*>python3.6/dist-packages/tensorflow/python/util/dispatch.py, line 180, in wrapper(*args, **kwargs) return target(*args, **kwargs) File <*>python3.6/dist-packages/tensorflow/python/ops/math_ops.py, line 1027, in div_no_nan(x, y, name) return gen_math_ops.div_no_nan(x, y, name=name) File <*>python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 3022, in div_no_nan(x, y, name) ""DivNoNan"", x=x, y=y, name=name) File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 610, in _apply_op_helper(self, op_type_name, name, **keywords) param_name=input_name) File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 60, in _SatisfiesTypeConstraint(dtype, attr_def, param_name) "", "".join(dtypes.as_dtype(x).name for x in allowed_list))) TypeError: Value passed to parameter 'x' has DataType float16 not in list of allowed values: float32, float64",0
"File [FILE], line 1, in <module> train_image_ds = train_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE) File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1146, in map(self, map_func, num_parallel_calls) self, map_func, num_parallel_calls, preserve_cardinality=True) File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 3264, in __init__(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function) use_legacy_function=use_legacy_function) File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 2591, in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs) self._function = wrapper_fn._get_concrete_function_internal() File <*>/site-packages/tensorflow/python/eager/function.py, line 1366, in _get_concrete_function_internal(self, *args, **kwargs) *args, **kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 1360, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 1648, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 1541, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value), File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 716, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs) File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 2585, in wrapper_fn(*args) ret = _wrapper_helper(*args) File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 2530, in _wrapper_helper(*args) ret = func(*nested_args) File [FILE], line 3, in load_and_preprocess_image(path) return preprocess_image(image) File [FILE], line 13, in preprocess_image(image) image = tf.image.central_crop(image, hor_scale_factor) File <*>/site-packages/tensorflow/python/ops/image_ops_impl.py, line 643, in central_crop(image, central_fraction) if central_fraction <= 0.0 or central_fraction > 1.0: File <*>/site-packages/tensorflow/python/framework/ops.py, line 698, in __bool__(self) raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. "" TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",0
"File [FILE], line 17, in <module>() opt.minimize(lambda: loss_function(intercept,slope,price_batch,size_batch),var_list=[intercept,slope]) File <*>python3.6/dist-packages/tensorflow/python/eager/tape.py, line 59, in watch(tape, tensor) pywrap_tensorflow.TFE_Py_TapeWatch(tape._tape, tensor) # pylint: disable=protected-access SystemError: <built-in function TFE_Py_TapeWatch> returned a result with an error set",0
"File [FILE], line 7, in <module>() A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a') File [FILE], line 45, in identity_block(X, f, filters, stage, block) X = Add()([X_shortcut,X]) File <*>python3.6/site-packages/keras/engine/topology.py, line 558, in __call__(self, inputs, **kwargs) self.assert_input_compatibility(inputs) File <*>python3.6/site-packages/keras/engine/topology.py, line 431, in assert_input_compatibility(self, inputs) str(inputs) + '. All inputs to the layer ' ValueError: Layer add_1 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.normalization.BatchNormalization'>. Full input: [<tf.Tensor 'Placeholder:0' shape=(3, 4, 4, 6) dtype=float32>, <keras.layers.normalization.BatchNormalization object at 0x7f169c6d9668>]. All inputs to the layer should be tensors.",0
"File [FILE], line 1, in <module> import acgan File <*>/acgan.py, line 3, in <module> from keras.datasets import mnist File <*>python3.6/site-packages/keras/__init__.py, line 3, in <module> from . import utils File <*>python3.6/site-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils File <*>python3.6/site-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K File <*>python3.6/site-packages/keras/backend/__init__.py, line 1, in <module> from .load_backend import epsilon File <*>python3.6/site-packages/keras/backend/load_backend.py, line 90, in <module> from .tensorflow_backend import * File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 54, in <module> get_graph = tf_keras_backend.get_graph File [FILE], line [NUM], in [FUNC] [CODE] AttributeError: module 'tensorflow.python.keras.backend' has no attribute 'get_graph'",0
"File [FILE], line 28, in <module> loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) TypeError: forward() got an unexpected keyword argument 'labels'",0
"File [FILE], line 1, in <module> for batch_idx, (data, _) in enumerate(trainDL): File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 346, in __next__(self) data = self._dataset_fetcher.fetch(index) # may raise StopIteration File <*>python3.6/site-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch(self, possibly_batched_index) data = [self.dataset[idx] for idx in possibly_batched_index] File <*>python3.6/site-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp>(.0) data = [self.dataset[idx] for idx in possibly_batched_index] File <*>python3.6/site-packages/pandas/core/frame.py, line 2995, in __getitem__(self, key) indexer = self.columns.get_loc(key) File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 2899, in get_loc(self, key, method, tolerance) return self._engine.get_loc(self._maybe_cast_indexer(key)) File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE] File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE] KeyError: 40592",0
"File <*>/tensorboard.py, line 1, in [FUNC] from torch.utils.tensorboard import SummaryWriter File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 4, in [FUNC] raise ImportError('TensorBoard logging requires TensorBoard with Python summary writer installed. ' ImportError: TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above.",0
"File [FILE], line 10, in <module>() scan_object = ta.Scan(x_train, y_train, params=p, model=iris_model, experiment_name='test', x_val=x_val, y_val=y_val, fraction_limit=0.1) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 1815, in _validate_or_infer_batch_size(self, batch_size, steps, x) x, batch_size)) ValueError: The `batch_size` argument must not be specified for the given input type. Received input: <DatasetV1Adapter shapes: ((512, 4), (512, 3)), types: (tf.float32, tf.float32)>, batch_size: 512",0
"File [FILE], line 3, in <module> epochs=10) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 324, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs) total_epochs=epochs) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 123, in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs) batch_outs = execution_function(iterator) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 86, in execution_function(input_fn) distributed_function(input_fn)) File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializer_map) File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize(self, args, kwds, add_initializers_to) *args, **kwds)) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value), File <*>python3.7/site-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs) File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 73, in distributed_function(input_iterator) per_replica_function, args=(model, x, y, sample_weights)) File <*>python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 760, in experimental_run_v2(self, fn, args, kwargs) return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) File <*>python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 1787, in call_for_each_replica(self, fn, args, kwargs) return self._call_for_each_replica(fn, args, kwargs) File <*>python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 2132, in _call_for_each_replica(self, fn, args, kwargs) return fn(*args, **kwargs) File <*>python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py, line 292, in wrapper(*args, **kwargs) return func(*args, **kwargs) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics) output_loss_metrics=model._output_loss_metrics) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 315, in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics) model, outs, targets, sample_weights=sample_weights, masks=masks) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 74, in _eager_metrics_fn(model, outputs, targets, sample_weights, masks) skip_target_masks=model._prepare_skip_target_masks()) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 2063, in _handle_metrics(self, outputs, targets, skip_target_masks, sample_weights, masks, return_weighted_metrics, return_weighted_and_unweighted_metrics) target, output, output_mask)) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 2014, in _handle_per_output_metrics(self, metrics_dict, y_true, y_pred, mask, weights) metric_fn, y_true, y_pred, weights=weights, mask=mask) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py, line 1067, in call_metric_function(metric_fn, y_true, y_pred, weights, mask) return metric_fn(y_true, y_pred, sample_weight=weights) File <*>python3.7/site-packages/tensorflow_core/python/keras/metrics.py, line 193, in __call__(self, *args, **kwargs) replica_local_fn, *args, **kwargs) File <*>python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py, line 1135, in call_replica_local_fn(fn, *args, **kwargs) return fn(*args, **kwargs) File <*>python3.7/site-packages/tensorflow_core/python/keras/metrics.py, line 176, in replica_local_fn(*args, **kwargs) update_op = self.update_state(*args, **kwargs) # pylint: disable=not-callable File <*>python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py, line 75, in decorated(metric_obj, *args, **kwargs) update_op = update_state_fn(*args, **kwargs) File <*>python3.7/site-packages/tensorflow_core/python/keras/metrics.py, line 883, in update_state(self, y_true, y_pred, sample_weight) sample_weight=sample_weight) File <*>python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py, line 278, in update_confusion_matrix_variables(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight) y_pred.shape.assert_is_compatible_with(y_true.shape) File <*>python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py, line 1115, in assert_is_compatible_with(self, other) raise ValueError(""Shapes %s and %s are incompatible"" % (self, other)) ValueError: Shapes (None, 4) and (None, 1) are incompatible",0
"File [FILE], line 8, in <module> es.tell(X, eval_all(X, NPARAMS)) File [FILE], line 16, in _evaluate2(self, X, *args) return [job.get() for job in jobs] File [FILE], line 16, in <listcomp>(.0) return [job.get() for job in jobs] File <*>python3.7/pool.py, line 657, in get(self, timeout) raise self._value File <*>python3.7/pool.py, line 431, in _handle_tasks(taskqueue, put, outqueue, pool, cache) put(task) File <*>python3.7/connection.py, line 206, in send(self, obj) self._send_bytes(_ForkingPickler.dumps(obj)) File <*>python3.7/reduction.py, line 51, in dumps(cls, obj, protocol) cls(buf, protocol).dump(obj) TypeError: can't pickle _thread.lock objects",0
"File [FILE], line 3, in <module> cocoBuilder.download_and_prepare() File <*>/site-packages/tensorflow_datasets/core/api_utils.py, line 52, in disallow_positional_args_dec(fn, instance, args, kwargs) return fn(*args, **kwargs) File <*>/site-packages/tensorflow_datasets/core/dataset_builder.py, line 287, in download_and_prepare(self, download_dir, download_config) download_config=download_config) File <*>/site-packages/tensorflow_datasets/core/dataset_builder.py, line 948, in _download_and_prepare(self, dl_manager, download_config) max_examples_per_split=download_config.max_examples_per_split, File <*>/site-packages/tensorflow_datasets/core/dataset_builder.py, line 804, in _download_and_prepare(self, dl_manager, **prepare_split_kwargs) for split_generator in self._split_generators(dl_manager): File <*>/site-packages/tensorflow_datasets/image/coco.py, line 239, in _split_generators(self, dl_manager) key: root_url + url for key, url in urls.items() File <*>/site-packages/tensorflow_datasets/core/download/download_manager.py, line 359, in download_and_extract(self, url_or_urls) return _map_promise(self._download_extract, url_or_urls) File <*>/site-packages/tensorflow_datasets/core/download/download_manager.py, line 395, in _map_promise(map_fn, all_inputs) res = utils.map_nested(_wait_on_promise, all_promises) File <*>/site-packages/tensorflow_datasets/core/utils/py_utils.py, line 129, in map_nested(function, data_struct, dict_only, map_tuple) for k, v in data_struct.items() File <*>/site-packages/tensorflow_datasets/core/utils/py_utils.py, line 129, in <dictcomp>(.0) for k, v in data_struct.items() File <*>/site-packages/tensorflow_datasets/core/utils/py_utils.py, line 143, in map_nested(function, data_struct, dict_only, map_tuple) return function(data_struct) File <*>/site-packages/tensorflow_datasets/core/download/download_manager.py, line 379, in _wait_on_promise(p) return p.get() File <*>/site-packages/promise/promise.py, line 510, in get(self, timeout) return self._target_settled_value(_raise=True) File <*>/site-packages/promise/promise.py, line 514, in _target_settled_value(self, _raise) return self._target()._settled_value(_raise) File <*>/site-packages/promise/promise.py, line 224, in _settled_value(self, _raise) reraise(type(raise_val), raise_val, self._traceback) File <*>/site-packages/six.py, line 696, in reraise(tp, value, tb) raise value File <*>/site-packages/promise/promise.py, line 842, in handle_future_result(future) resolve(future.result()) File <*>/_base.py, line 425, in result(self, timeout) return self.__get_result() File <*>/_base.py, line 384, in __get_result(self) raise self._exception File <*>/thread.py, line 56, in run(self) result = self.fn(*self.args, **self.kwargs) File <*>/site-packages/tensorflow_datasets/core/download/extractor.py, line 94, in _sync_extract(self, from_path, method, to_path) raise ExtractError(msg) ExtractError: Error while extracting C:\Users\%user%\tensorflow_datasets\downloads\images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip to C:\Users\%user%\tensorflow_datasets\downloads\extracted\ZIP.images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip : C:\Users\%user%\tensorflow_datasets\downloads\images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip; Unknown error",0
"File [FILE], line 1, in <module>() addn = tf.add(mul, div) File <*>python3.5/site-packages/tensorflow_core/python/ops/gen_math_ops.py, line 343, in add(x, y, name) _ops.raise_from_not_ok_status(e, name) File <*>python3.5/site-packages/tensorflow_core/python/framework/ops.py, line 6606, in raise_from_not_ok_status(e, name) six.raise_from(core._status_to_exception(e.code, message), None) File <*>python3.5/site-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE] InvalidArgumentError: cannot compute Add as input #1(zero-based) was expected to be a int32 tensor but is a double tensor [Op:Add]",0
"File [FILE], line 13, in <module> model = FullyConnectedLayer (512, dist, 0.99, 0.5 ) # 4 LAYERS File [FILE], line 58, in FullyConnectedLayer(denseUnits, seluDistribution, batchMomentum, alphaDropRate) model.add(Activation(gelu(x=seluDistribution))) File <*>/site-packages/tensorflow_core/python/keras/layers/core.py, line 378, in __init__(self, activation, **kwargs) self.activation = activations.get(activation) File <*>/site-packages/tensorflow_core/python/keras/activations.py, line 454, in get(identifier) repr(identifier))) TypeError: Could not interpret activation function identifier: <tf.Tensor: shape=(5, 5, 1, 32), dtype=float32, numpy= array([[[[-1.26586094e-01, -1.02963023e-01, 3.14652212e-02, -1.39087364e-01, 1.13992631e-01, 1.52557418e-01, -1.09972686e-01, -5.12595251e-02, -1.58538278e-02, -1.29528284e-01, 1.63152684e-02, 1.01518132e-01, -4.35875840e-02, 1.46785110e-01, -2.23108958e-02, -2.09968127e-02, -8.54036435e-02, 9.01642349e-03, -4.25574742e-02, 4.80710454e-02]], [[ 9.34263412e-03, 1.06001608e-01, -7.65870064e-02, -8.02185014e-02, 6.67698979e-02, -8.98385793e-02, -6.12295903e-02, 7.36039877e-02, -1.33156419e-01, [[-1.38585389e-01, 1.03538044e-01, 1.76681668e-01, -6.94317510e-03, 6.14152141e-02, -3.92788239e-02, -5.83523549e-02, 6.68111816e-02, 5.49897328e-02, -5.77139147e-02, -7.64194950e-02, -7.55715296e-02, -4.95074578e-02, 7.71198049e-02, 5.40203564e-02, -9.74030495e-02, -1.00650810e-01, 1.23783059e-01, -8.46874043e-02, -1.04908131e-01, -2.63819955e-02, -1.31487399e-01, 1.30674899e-01]], [[ 6.60606772e-02, 1.46065757e-01, 1.59279909e-02, -1.20391339e-01, -7.02986643e-02, -2.74278801e-02, -1.29030854e-01, -7.62277395e-02, -1.19075023e-01, -9.22646299e-02, 7.98776373e-02, 6.54103830e-02, -6.72401339e-02, -4.81364317e-02, -6.03620708e-02, -2.84200851e-02, -9.10447016e-02]], [[-1.23140588e-01, 1.10491589e-01, -9.61843282e-02, -8.91052186e-02, 4.01075035e-01, 1.94666237e-02, -2.61222124e-02, -1.56512097e-01, 9.74281505e-02, -3.66279632e-02, 6.65708026e-03, 9.61058680e-03, -1.21156186e-01, -2.98077669e-02, 1.66137442e-02, -3.38280275e-02, -9.28360224e-02, -7.76154548e-02, -7.96113610e-02, -2.57881228e-02, -1.58247918e-01, [[[-1.13160208e-01, -1.98329911e-02, 1.20878376e-01, -1.13716172e-02, -5.21509871e-02, 7.25255907e-02, -1.12730011e-01, -7.29970336e-02, 6.37045652e-02, -8.64603445e-02, -2.22087242e-02, -2.47925967e-02, -6.44451613e-03, -1.73095725e-02, -6.07393086e-02, -4.96991165e-02, -3.15147117e-02, 2.43039820e-02, -7.35211000e-02, -6.92363605e-02]], [[ 3.96580771e-02, 1.26118317e-01, 1.16271339e-01, -5.80145419e-02, -2.15136074e-03, -9.12490934e-02, -1.27457187e-01, 3.60154063e-02, 9.91806835e-02, -4.64559309e-02, -2.11531147e-02, 4.10205543e-01, -4.43787202e-02, 4.39099297e-02, 3.06370091e-02, -9.87873599e-02, -5.10304309e-02]], [[ 2.13202462e-02, 1.41525701e-01, -4.84775938e-02, -1.43082231e-01, 4.21900637e-02, -1.17563821e-01, -3.71489525e-02, -1.45584494e-01, -1.12884097e-01, -7.87854716e-02, -2.01713406e-02, -3.49416770e-02, -6.53499886e-02, -2.09143162e-02, 2.94101406e-02, -5.27165644e-02, 1.19348057e-02, -4.39126566e-02, -6.26288429e-02, 4.20925207e-02]], [[-8.23830441e-02, 2.23106906e-01, 8.56178179e-02, -5.99831380e-02, -1.71386788e-03, -3.62357125e-02, -1.59021363e-01, -2.17766548e-03, 2.16864720e-01, -5.73305860e-02, -1.80698894e-02, 1.36940643e-01, -1.97473206e-02, 8.14313069e-02, 1.96376622e-01, -6.43103570e-02, -3.85615453e-02]], [[-3.53560485e-02, 4.35038935e-03, -7.06349090e-02, -2.80691660e-03, -6.92954510e-02, 1.11481667e-01, -4.58219610e-02, -2.38394644e-02, -7.87800774e-02, -1.67009607e-02, 6.01479635e-02, 1.56740978e-01, -9.78638828e-02, -4.29860055e-02, 1.38192121e-02, -1.36006713e-01, -1.05418041e-01, -2.51792613e-02, -1.22639257e-02, -1.21888302e-01, -5.46660051e-02, -7.12147309e-03, -6.58531636e-02, -7.14808479e-02, [[[ 6.32937178e-02, 2.72242278e-01, -3.74731459e-02, -2.62564681e-02, -1.54855132e-01, 7.81283434e-03, -8.01301673e-02, 7.47360140e-02, -5.00108190e-02, -7.64894933e-02, 8.45131949e-02, -3.27355303e-02, -3.79370786e-02, -6.93783676e-03, -4.87477183e-02, [[-7.98909813e-02, 2.59152979e-01, 1.75541520e-01, -8.12215135e-02, -9.54297185e-02, 1.99518725e-03, -3.72358635e-02, -1.39946237e-01, -5.76626435e-02, -7.13582858e-02, 5.86171262e-02, -1.39267772e-01, -1.00216493e-01, 2.68728107e-01, 1.63495377e-01, -2.24205833e-02, 1.44553408e-01, -9.67240557e-02, -1.24277532e-01, -1.40620157e-01]], [[-5.69531657e-02, 1.71630532e-01, 2.86230773e-01, -5.93378842e-02, -1.71954520e-02, -3.26295868e-02, -3.98173966e-02, 7.21049905e-02, -6.91456124e-02, -1.23138815e-01, 1.33402884e-01, -1.02245316e-01, -4.69203852e-02, -1.75676849e-02, 1.40360445e-01, -3.40559036e-02, 3.35928686e-02, -1.04908220e-01, [[-7.85556585e-02, -1.18466914e-01, 1.53003752e-01, -4.67218924e-03, -1.16112582e-01, 5.51390201e-02, -1.52055770e-02, 3.54320277e-03, 3.42624858e-02, -1.05386212e-01, 1.98949352e-02, 2.73315758e-02, -7.58572146e-02, 1.03625186e-01, 2.05493998e-03, -1.01805991e-02, 2.19766423e-02]], [[-1.00509115e-02, 2.22494956e-02, -9.08879191e-02, -8.11229870e-02, 9.98405516e-02, -5.72074987e-02, -1.33951874e-02, 3.92576605e-02, 1.16789080e-01, -1.89318452e-02, -1.59033425e-02, 9.48152542e-02, -2.66773477e-02, 1.37753570e-02, 1.79445334e-02, -6.62883669e-02, -9.37851295e-02, 1.94142580e-01, -1.28269400e-02, 1.25869989e-01, 1.50878415e-01, -2.11219154e-02, -1.05045862e-01, -2.73662023e-02, [[[ 1.83003962e-01, -4.02955636e-02, 7.92874582e-03, -1.04859909e-02, 1.41754048e-02, -1.52763631e-02, -9.11424682e-02, 3.24082047e-01, 1.05546042e-02, -1.30687788e-01, -3.98224816e-02, 1.38061410e-02, [[ 2.33758405e-01, -9.26907063e-02, 1.65917858e-01, -1.22203723e-01, -2.83196904e-02, 1.02213569e-01, -5.63387433e-03, -3.08787469e-02, 1.96257643e-02, -7.37890229e-02, -1.93086471e-02, 1.30984381e-01, [[-5.09779751e-02, 6.08728305e-02, -8.07061568e-02, -1.26804784e-01, -1.43676013e-01, -3.28507088e-02, -1.66144117e-03, -7.41888210e-03, 1.42028257e-01, -4.99214791e-02, -1.86899900e-02, -1.09298825e-02, -8.03249031e-02, -1.00237548e-01]], [[-7.80191123e-02, 4.05082256e-02, 7.47731477e-02, -8.76973122e-02, -2.91744564e-02, 1.23694569e-01, -1.49070352e-01, 2.42730626e-03, 3.52480598e-02, -5.62792830e-03, -2.28355639e-02, -1.27415329e-01, -8.48858505e-02, -3.52028869e-02, -7.95315206e-02, -3.92727107e-02, -4.16678861e-02, 2.39140958e-01, -1.44019471e-02, -8.69576260e-03]], [[-1.67441964e-02, -1.43177100e-02, -9.23768803e-02, -2.72830930e-02, 7.51334131e-02, -2.28366554e-02, -5.57800010e-02, -1.31770581e-01, 9.31192283e-03, -1.38517320e-02, -1.41043484e-01, -6.42404705e-02, -4.86476049e-02, -1.12639852e-01, 7.89660513e-02, -1.09081008e-01, -3.03610712e-02]]], [[[-1.40361011e-01, 1.21919084e-02, 4.36685272e-02, -3.61564793e-02, -1.11773185e-01, 2.25092173e-02, -1.02469876e-01, 1.76996499e-01, 4.30173017e-02, -2.26258971e-02, 2.11037025e-01, 9.66922417e-02, -4.83587980e-02, 4.68245940e-04, -1.47096828e-01, -2.91392524e-02, 8.22411999e-02, 2.07852814e-02, -4.12134677e-02, 5.33621386e-02, 9.24792588e-02, [[ 1.66879535e-01, 6.54919222e-02, -3.27483788e-02, -1.43241754e-03, -1.14416316e-01, -2.12962832e-02, -4.46583293e-02, 2.71647628e-02, -5.61558232e-02, -1.24854170e-01, 1.25476092e-01, -7.09585026e-02, -4.40548174e-02, 7.21732453e-02, 7.45785460e-02, -1.17296316e-01, -1.46051958e-01, 1.88378561e-02, [[ 2.60874778e-01, -1.45940065e-01, -9.79427770e-02, -8.68195742e-02, 2.04389215e-01, -2.24198923e-02, -8.38927086e-03, -4.99465019e-02, 4.69646640e-02, -7.15569034e-02, -1.78242605e-02, -8.51068646e-03, -3.08227092e-02, -4.82530929e-02, 8.31630453e-02, -4.16018628e-02, -7.55471215e-02]], [[ 2.24076852e-01, -1.39667824e-01, 7.93220941e-03, -1.78845283e-02, -5.64770252e-02, -7.84719810e-02, -1.81565285e-02, 1.24106847e-01, -6.28474308e-03, -1.72791779e-02, -3.47166769e-02, -4.92920280e-02, -9.12440866e-02, 6.42236844e-02, -1.16013244e-01, -7.96606317e-02, 1.50838092e-01, -4.71229590e-02, -4.02066261e-02, 1.17019311e-01]], [[-3.95799540e-02, -4.35096361e-02, -9.93420109e-02, -6.20126911e-02, 1.93700612e-01, 5.02851121e-02, -9.00325775e-02, 1.32245719e-01, 2.68575907e-01, -8.08344856e-02, -4.56905663e-02, 1.26069590e-01, -6.64912462e-02, 9.61613879e-02, -1.48803489e-02, "", 'Error', 'Error', '', '')",0
"File [FILE], line 8, in <module>() ds = ds.filter(filter_fn) File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e) OperatorNotAllowedInGraphError: in user code: <ipython-input-52-52131b5369b6>:5 filter_fn * return features['department'] in ['FERRAMENTAS', 'MERCEARIA', 'MOVEIS'] /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:778 __bool__ self._disallow_bool_casting() /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:545 _disallow_bool_casting ""using a `tf.Tensor` as a Python `bool`"") /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:532 _disallow_when_autograph_enabled "" decorating it directly with @tf.function."".format(task)) OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.",0
"File [FILE], line 11, in <module> validation_steps=nb_val_steps) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1063, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) steps_per_execution=self._steps_per_execution) File <*>/site-packages/tensorflow/python/keras/engine/data_adapter.py, line 1110, in __init__(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution) model=model) File <*>/site-packages/tensorflow/python/keras/engine/data_adapter.py, line 798, in __init__(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs) output_shapes = nest.map_structure(_get_dynamic_shape, peek) File <*>/site-packages/tensorflow/python/util/est.py, line 635, in map_structure(func, *structure, **kwargs) structure[0], [func(*x) for x in entries], File <*>/site-packages/tensorflow/python/util/est.py, line 635, in <listcomp>(.0) structure[0], [func(*x) for x in entries], File <*>/site-packages/tensorflow/python/keras/engine/data_adapter.py, line 794, in _get_dynamic_shape(t) if shape.rank is None: AttributeError: 'tuple' object has no attribute 'rank'",0
"File [FILE], line 1, in <module>() load_image('/content/train2017/000000000009.jpg') File [FILE], line 4, in load_image(image_path) img = tf.image.resize(img, (299, 299)) File <*>python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py, line 1517, in resize_images_v2(images, size, method, preserve_aspect_ratio, antialias, name) skip_resize_if_same=False) File <*>python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py, line 1185, in _resize_images_common(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same) if images.get_shape().ndims is None: File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1073, in get_shape(self) return self.shape File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1067, in shape(self) six.raise_from(core._status_to_exception(e.code, e.message), None) File <*>python3.6/dist-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE] UnimplementedError: File system scheme '[local]' not implemented (file: '/content/train2017/000000000009.jpg')",0
"File [FILE], line 1, in <module>() X_prime_class_split = np.array_split(X_prime_class.numpy(), TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",0
"File [FILE], line 6, in <module> train_step(image_x, image_y) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 823, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializers) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 696, in _initialize(self, args, kwds, add_initializers_to) self._stateful_fn._get_concrete_function_internal_garbage_collected( # pylint: disable=protected-access File <*>/site-packages/tensorflow/python/eager/function.py, line 2855, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 3213, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 3065, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) func_graph_module.func_graph_from_py_func( File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 986, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 600, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds) File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 973, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e) OperatorNotAllowedInGraphError: in user code: <ipython-input-160-538af916a6fd>:28 train_step * total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_losss(real_y, cycled_y) <ipython-input-151-74a790ebcddf>:2 calc_cycle_loss * loss1 = tf.reduce_mean(tf.abs(real_image, cycled_image)) C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\util\dispatch.py:201 wrapper ** return target(*args, **kwargs) C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\ops\math_ops.py:388 abs with ops.name_scope(name, ""Abs"", [x]) as name: C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:6492 __enter__ return self._name_scope.__enter__() c:\users\astro\appdata\local\programs\python\python38\lib\contextlib.py:113 __enter__ return next(self.gen) C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:4176 name_scope if name: C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:877 __bool__ self._disallow_bool_casting() C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:486 _disallow_bool_casting self._disallow_when_autograph_enabled( C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:472 _disallow_when_autograph_enabled raise errors.OperatorNotAllowedInGraphError( OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.",0
"File [FILE], line [NUM], in apache_beam.runners.common.DoFnRunner.process() [CODE] File [FILE], line [NUM], in apache_beam.runners.common.PerWindowInvoker.invoke_process() [CODE] File [FILE], line [NUM], in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window() [CODE] File [FILE], line [NUM], in apache_beam.runners.common._OutputProcessor.process_outputs() [CODE] File [FILE], line [NUM], in apache_beam.runners.worker.operations.SingletonConsumerSet.receive() [CODE] File [FILE], line [NUM], in apache_beam.runners.worker.operations.PGBKCVOperation.process() [CODE] File <*>python3.7/site-packages/tensorflow_model_analysis/evaluators/metrics_and_plots_evaluator_v2.py, line 356, in add_input(self, accumulator, element) result = c.add_input(a, get_combiner_input(elements[0], i)) File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/calibration_histogram.py, line 142, in add_input(self, accumulator, element) class_weights=self._class_weights)): File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py, line 284, in to_label_prediction_example_weight(inputs, eval_config, model_name, output_name, sub_key, class_weights, flatten, squeeze, allow_none) label, prediction = select_top_k(sub_key.top_k, label, prediction) File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py, line 622, in select_top_k(top_k, labels, predictions, scores) labels = one_hot(labels, predictions) File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py, line 672, in one_hot(tensor, target) tensor = np.delete(np.eye(target.shape[-1] + 1)[tensor], -1, axis=-1) IndexError: arrays used as indices must be of integer (or boolean) type",0
"File <*>/site-packages/keras/__init__.py, line 3, in <module> from tensorflow.keras.layers.experimental.preprocessing import RandomRotation ModuleNotFoundError: No module named 'tensorflow.keras.layers.experimental.preprocessing'",0
"File [FILE], line 1, in <module> batch_first[:,1:].view(-1, embedding) # slicing out the first time step RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",0
"File [FILE], line 49, in <module> logps = model(images) #log probabilities File <*>python3.8/site-packages/torch/nn/modules/container.py, line 117, in forward(self, input) input = module(input) File <*>python3.8/site-packages/torch/nn/modules/module.py, line 727, in _call_impl(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.8/site-packages/torch/nn/modules/linear.py, line 93, in forward(self, input) return F.linear(input, self.weight, self.bias) File <*>python3.8/site-packages/torch/nn/functional.py, line 1690, in linear(input, weight, bias) ret = torch.addmm(bias, input, weight.t()) RuntimeError: expected scalar type Float but found Byte",0
