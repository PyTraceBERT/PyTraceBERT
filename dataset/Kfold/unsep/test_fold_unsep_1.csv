Templates,label
"File [FILE], line 1, in <module>() import tensorflow File <*>python2.7/site-packages/tensorflow/__init__.py, line 4, in <module>() from tensorflow.python import * File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 13, in <module>() from tensorflow.core.framework.graph_pb2 import * File <*>python2.7/site-packages/tensorflow/core/framework/graph_pb2.py, line 8, in <module>() from google.protobuf import reflection as _reflection File <*>python2.7/site-packages/google/protobuf/reflection.py, line 58, in <module>() from google.protobuf.internal import python_message as message_impl File <*>python2.7/site-packages/google/protobuf/internal/python_message.py, line 59, in <module>() import six.moves.copyreg as copyreg ImportError: No module named copyreg",1
"File multiply.py, line 2, in <module> import tensorflow as tf File <*>python2.7.10/site-packages/tensorflow/__init__.py, line 4, in <module> from tensorflow.python import * File <*>python2.7.10/site-packages/tensorflow/python/__init__.py, line 22, in <module> from tensorflow.python.client.client_lib import * File <*>python2.7.10/site-packages/tensorflow/python/client/client_lib.py, line 35, in <module> from tensorflow.python.client.session import InteractiveSession File <*>python2.7.10/site-packages/tensorflow/python/client/session.py, line 11, in <module> from tensorflow.python import pywrap_tensorflow as tf_session File <*>python2.7.10/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper() File <*>python2.7.10/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description) ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory",1
"File <stdin>, line 1, in <module> [CODE] File <*>python2.7/dist-packages/theano/__init__.py, line 74, in <module> from theano.printing import pprint, pp File <*>python2.7/dist-packages/theano/printing.py, line 35, in <module> if pd.find_graphviz(): AttributeError: 'module' object has no attribute 'find_graphviz'",1
"File fully_connected_feed.py, line 229, in <module> tf.app.run() File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 44, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough)) File fully_connected_feed.py, line 225, in main run_training() File fully_connected_feed.py, line 154, in run_training summary_op = tf.merge_all_summaries() AttributeError: 'module' object has no attribute 'merge_all_summaries'",1
"File convnet.py, line 6, in <module> model.add(Conv2D(32, (3, 3), input_shape=(3, 150, 150))) TypeError: __init__() missing 1 required positional argument: 'nb_col'",1
"File <*>/CNNTest-one.py, line 7, in <module> import lasagne File <*>/site-packages/lasagne/__init__.py, line 19, in <module> from . import layers File <*>/site-packages/lasagne/layers/__init__.py, line 7, in <module> from .pool import * File <*>/site-packages/lasagne/layers/pool.py, line 6, in <module> from theano.tensor.signal import downsample ImportError: cannot import name 'downsample'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal') File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) ImportError: No module named '_pywrap_tensorflow_internal'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper return importlib.import_module(mname) File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File <frozen importlib._bootstrap>, line 986, in _gcd_import [CODE] File <frozen importlib._bootstrap>, line 969, in _find_and_load [CODE] File <frozen importlib._bootstrap>, line 958, in _find_and_load_unlocked [CODE] File <frozen importlib._bootstrap>, line 666, in _load_unlocked [CODE] File <frozen importlib._bootstrap>, line 577, in module_from_spec [CODE] File <frozen importlib._bootstrap_external>, line 919, in create_module [CODE] File <frozen importlib._bootstrap>, line 222, in _call_with_frames_removed [CODE] ImportError: DLL load failed: The specified module could not be found.",1
"File <*>/site-packages/tensorflow/python/platform/self_check.py, line 75, in preload_check ctypes.WinDLL(build_info.cudart_dll_name) File <*>/__init__.py, line 347, in __init__ self._handle = _dlopen(self._name, mode) OSError: [WinError 126] The specified module could not be found",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal') File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 17, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 16, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal') File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'",1
"File kerasbottleneck.py, line 103, in <module> save_bottlebeck_features() File kerasbottleneck.py, line 69, in save_bottlebeck_features np.save(open('bottleneck_features_train.npy', 'w'),bottleneck_features_train) File <*>python3.6/site-packages/numpy/lib/npyio.py, line 511, in save pickle_kwargs=pickle_kwargs) File <*>python3.6/site-packages/numpy/lib/format.py, line 565, in write_array version) File <*>python3.6/site-packages/numpy/lib/format.py, line 335, in _write_array_header fp.write(header_prefix) TypeError: write() argument must be str, not bytes",1
"File <*>/train_network.py, line 109, in <module> model = LeNet.build(width=100, height=100, depth=3, classes=5) File <*>/lenet.py, line 39, in build output = model(pretrainedOutput) File <*>python3.6/dist-packages/keras/engine/base_layer.py, line 443, in __call__ previous_mask = _collect_previous_mask(inputs) File <*>python3.6/dist-packages/keras/engine/base_layer.py, line 1311, in _collect_previous_mask mask = node.output_masks[tensor_index] AttributeError: 'Node' object has no attribute 'output_masks'",1
"File serialize_model.py, line 60, in <module> traced_script_module.save(""model.pt"") AttributeError: 'function' object has no attribute 'save'",1
"File <*>python3.6/threading.py, line 916, in _bootstrap_inner self.run() File <*>python3.6/threading.py, line 864, in run self._target(*self._args, **self._kwargs) File <*>python3.6/site-packages/keras/utils/data_utils.py, line 671, in _run executor.apply_async(next_sample, (self.uid,)), block=True) File <*>python3.6/queue.py, line 127, in put if self.maxsize > 0: TypeError: '>' not supported between instances of 'list' and 'int'",1
"File [FILE], line 19, in <module>() history = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=0, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_split=0.25) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 880, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs) validation_steps=validation_steps) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py, line 325, in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs) callbacks._call_batch_hook(mode, 'begin', batch_index, batch_logs) File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 196, in _call_batch_hook(self, mode, hook, batch, logs) batch_hook = getattr(callback, hook_name) AttributeError: 'EarlyStopping' object has no attribute 'on_train_batch_begin'",1
"File <stdin>, line 1, in <module> [CODE] AttributeError: module 'tensorflow' has no attribute 'Session'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File <*>/imp.py, line 242, in load_module return load_dynamic(name, filename, file) File <*>/imp.py, line 342, in load_dynamic return _load(spec) ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.",1
"File <*>/script.py, line 150, in <module> callbacks=[cb_checkpointer, cb_early_stopper] File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/training.py, line 1418, in fit_generator initial_epoch=initial_epoch) File <*>python3.6/site-packages/keras/engine/training_generator.py, line 264, in fit_generator callbacks.on_train_end() File <*>python3.6/site-packages/keras/callbacks.py, line 142, in on_train_end callback.on_train_end(logs) File <*>python3.6/site-packages/tensorflow/python/keras/callbacks.py, line 940, in on_train_end if self.model._ckpt_saved_epoch is not None: AttributeError: 'Sequential' object has no attribute '_ckpt_saved_epoch'",1
"File <*>/keras-script.py, line 18, in <module> model = load_model(MODEL_PATH) File <*>python3.7/dist-packages/keras/engine/saving.py, line 492, in load_wrapper return load_function(*args, **kwargs) File <*>python3.7/dist-packages/keras/engine/saving.py, line 584, in load_model model = _deserialize_model(h5dict, custom_objects, compile) File <*>python3.7/dist-packages/keras/engine/saving.py, line 274, in _deserialize_model model = model_from_config(model_config, custom_objects=custom_objects) File <*>python3.7/dist-packages/keras/engine/saving.py, line 627, in model_from_config return deserialize(config, custom_objects=custom_objects) File <*>python3.7/dist-packages/keras/layers/__init__.py, line 168, in deserialize printable_module_name='layer') File <*>python3.7/dist-packages/keras/utils/generic_utils.py, line 147, in deserialize_keras_object list(custom_objects.items()))) File <*>python3.7/dist-packages/keras/engine/sequential.py, line 301, in from_config custom_objects=custom_objects) File <*>python3.7/dist-packages/keras/engine/network.py, line 1056, in from_config process_layer(layer_data) File <*>python3.7/dist-packages/keras/engine/network.py, line 1042, in process_layer custom_objects=custom_objects) File <*>python3.7/dist-packages/keras/utils/generic_utils.py, line 149, in deserialize_keras_object return cls.from_config(config['config']) File <*>python3.7/dist-packages/keras/engine/base_layer.py, line 1179, in from_config return cls(**config) File <*>python3.7/dist-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) TypeError: __init__() got an unexpected keyword argument 'ragged'",1
"File <ipython-input-3-0715decb6662>, line 1, in <module> runfile('G:/Traffic Violation Detection/object_detection.py', wdir='G:/Traffic Violation Detection') File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 710, in runfile execfile(filename, namespace) File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 101, in execfile exec(compile(f.read(), filename, 'exec'), namespace) File <*>/object_detection.py, line 6, in <module> from keras.layers.merge import add, concatenate File <*>/site-packages/keras/__init__.py, line 3, in <module> from . import utils File <*>/site-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils File <*>/site-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K File <*>/site-packages/keras/backend/__init__.py, line 1, in <module> from .load_backend import epsilon File <*>/site-packages/keras/backend/load_backend.py, line 90, in <module> from .tensorflow_backend import * File <*>/site-packages/keras/backend/tensorflow_backend.py, line 54, in <module> get_graph = tf_keras_backend.get_graph AttributeError: module 'tensorflow.python.keras.backend' has no attribute 'get_graph'",1
"File <stdin>, line 1, in <module> [CODE] ModuleNotFoundError: No module named 'tensorflow'",1
"File <*>/NN_Training.py, line 128, in <module> history = model.fit(X, Y, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[tensorboard]) # Feed in the trainset for X and y and run the model!!! File <*>/site-packages/keras/engine/training.py, line 1239, in fit validation_freq=validation_freq) File <*>/site-packages/keras/engine/training_arrays.py, line 119, in fit_loop callbacks.set_model(callback_model) File <*>/site-packages/keras/callbacks/callbacks.py, line 68, in set_model callback.set_model(model) File <*>/site-packages/keras/callbacks/tensorboard_v2.py, line 116, in set_model super(TensorBoard, self).set_model(model) File <*>/site-packages/tensorflow_core/python/keras/callbacks.py, line 1532, in set_model self.log_dir, self.model._get_distribution_strategy()) # pylint: disable=protected-access AttributeError: 'Sequential' object has no attribute '_get_distribution_strategy'",1
"File [FILE], line 2, in () from bert import run_classifier_with_tfhub # run_classifier File <*>python3.6/dist-packages/bert/optimization.py, line [NUM], in [FUNC] [CODE] File [FILE], line 87, in () class AdamWeightDecayOptimizer(tf.train.Optimizer): AttributeError: module 'tensorflow._api.v2.train' has no attribute 'Optimizer'",1
"File PATH, line 1, in <module> import tensorflow_probability File PATH, line 75, in <module> from tensorflow_probability.python import * # pylint: disable=wildcard-import File PATH, line 24, in <module> from tensorflow_probability.python import edward2 File PATH, line 32, in <module> from tensorflow_probability.python.experimental.edward2.generated_random_variables import * File PATH, line 34, in <module> from tensorflow_probability.python.experimental import auto_batching File PATH, line 24, in <module> from tensorflow_probability.python.experimental.auto_batching import frontend File PATH, line 46, in <module> from tensorflow.python.autograph.pyct import compiler ImportError: cannot import name 'compiler' from 'tensorflow.python.autograph.pyct' (PATH)",1
"File object_detection_test.py, line 15, in <module> from utils import label_map_util File <*>/label_map_util.py, line 27, in <module> import tensorflow.compat.v1 as tf ModuleNotFoundError: No module named 'tensorflow.compat.v1'",1
"File file.py, line 537, in <Module> params,tuner = search_model(X_train,y_train,trials=t,executions=e) File file.py, line 503, in search_model verbose = 0 File <*>python3.6/dist-packages/kerastuner/engine/base_tuner.py, line 131, in search self.run_trial(trial, *fit_args, **fit_kwargs) File file.py, line 476, in run_trial super(MyTuner, self).run_trial(trial, *args, **kwargs) File <*>python3.6/dist-packages/kerastuner/engine/multi_execution_tuner.py, line 78, in [FUNC] [CODE] File <*>python3.6/dist-packages/kerastuner/engine/tuner.py, line 317, in _get_checkp if (isinstance(self.distribution_strategy, tf.distribute.TPUStrategy) and AttributeError: module 'tensorflow._api.v2.distribute' has no attribute 'TPUStrategy'",1
"File <*>/main.py, line 217, in Processing y_predict = model(x) # [batch size, fc3 output] File <*>/site-packages/torch/nn/modules/module.py, line 722, in _call_impl result = self.forward(*input, **kwargs) File <*>/cnn.py, line 104, in forward x = self.fc1(x) File <*>/site-packages/torch/nn/modules/, line 91, in forward return F.linear(input, self.weight, self.bias) File <*>/site-packages/torch/nn/functional.py, line 1674, in linear ret = torch.addmm(bias, input, weight.t()) RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",1
"File <stdin>, line 1, in <module> [CODE] File <*>/__init__.py, line 55, in <module> from theano.compile import \ File <*>/__init__.py, line 6, in <module> from theano.compile.function_module import * File <*>/function_module.py, line 18, in <module> import theano.compile.mode File <*>/mode.py, line 11, in <module> import theano.gof.vm File <*>/vm.py, line 516, in <module> import lazylinker_c File <*>/lazylinker_c.py, line 86, in <module> preargs=args) File <*>/cmodule.py, line 1975, in compile_str (status, compile_stderr.replace('\n', '. '))) Exception: Compilation failed (return status=1): /usr/bin/ld: /home/minh.lengoc/.local/lib/libpython2.7.a(abstract.o): relocation R_X86_64_32 against `.rodata.str1.8' can not be used when making a shared object; recompile with -fPIC. /home/minh.lengoc/.local/lib/libpython2.7.a: could not read symbols: Bad value. collect2: ld returned 1 exit status.",0
"File <*>python2.7/dist-packages/apport_python_hook.py, line 66, in apport_excepthook from apport.fileutils import likely_packaged, get_recent_crashes File <*>python2.7/dist-packages/apport/__init__.py, line 1, in <module> from apport.report import Report File <*>python2.7/dist-packages/apport/report.py, line 18, in <module> import problem_report File <*>python2.7/dist-packages/problem_report.py, line 14, in <module> import zlib, base64, time, sys, gzip, struct, os File <*>python2.7/gzip.py, line 10, in <module> import io File <*>/io.py, line 2, in <module> import skimage.io File <*>python2.7/dist-packages/skimage/io/__init__.py, line 11, in <module> from ._io import * File <*>python2.7/dist-packages/skimage/io/_io.py, line 1, in <module> from io import BytesIO ImportError: cannot import name BytesIO",0
"File cnn_age_gender_demo.py, line 25, in [FUNC] [CODE] File <*>/classifier.py, line 34, in init self.transformer.set_mean(in_, mean) File <*>/io.py, line 255, in set_mean raise ValueError('Mean shape incompatible with input shape.') ValueError: Mean shape incompatible with input shape.",0
"File <stdin>, line 1, in <module> [CODE] File <*>python2.7/site-packages/tensorflow/__init__.py, line 8, in <module> from tensorflow.python import * File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 34, in <module> from tensorflow.python.client.client_lib import * File <*>python2.7/site-packages/tensorflow/python/client/client_lib.py, line 39, in <module> from tensorflow.python.client.session import InteractiveSession File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 16, in <module> from tensorflow.python import pywrap_tensorflow as tf_session File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 26, in <module> _pywrap_tensorflow = swig_import_helper() File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 22, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description) ImportError: /home/zjuese/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: clock_gettime",0
"File <stdin>, line 1, in <module> [CODE] File <*>/models.py, line 602, in compile [CODE] File <*>/advanced_activations.py, line 149, in get_output [CODE] File <*>/core.py, line 117, in get_input [CODE] File <*>/core.py, line 1334, in get_output [CODE] File <*>/core.py, line 1282, in get_output_sum [CODE] File <*>/core.py, line 1266, in get_output_at [CODE] File <*>/core.py, line 730, in get_output [CODE] File <*>/core.py, line 1340, in get_output [CODE] File <*>/core.py, line 1312, in get_output_dot [CODE] File <*>python2.7/site-packages/theano/tensor/var.py, line 360, in dimshuffle pattern) File <*>python2.7/site-packages/theano/tensor/elemwise.py, line 164, in __init__ (input_broadcastable, new_order)) ValueError: ('You cannot drop a non-broadcastable dimension.', ((False, False, False, False), (0, 'x')))",0
"File mnist_mlp.py, line 13, in <module> from keras.models import Sequential File <*>python3.5/site-packages/Keras-0.3.1-py3.5.egg/keras/models.py, line 15, in <module> [CODE] File <*>python3.5/site-packages/Keras-0.3.1-py3.5.egg/keras/backend/__init__.py, line 46, in <module> [CODE] File <*>python3.5/site-packages/Keras-0.3.1-py3.5.egg/keras/backend/theano_backend.py, line 4, in <module> [CODE] File <*>python3.5/site-packages/Theano-0.8.0.dev0-py3.5.egg/theano/tensor/signal/downsample.py, line 2, in <module> import pool ImportError: No module named 'pool'",0
"File <stdin>, line 1, in <module> [CODE] ImportError: No module named sklearn.linear_model",0
"File <ipython-input-1-65016ddab3cd>, line 1, in <module> from keras.utils.visualize_util import plot File <*>/site-packages/keras/utils/visualize_util.py, line 8, in <module> raise RuntimeError('Failed to import pydot. You must install pydot' RuntimeError: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",0
"File <*>python2.7/dist-packages/pip/basecommand.py, line 122, in main status = self.run(options, args) File <*>python2.7/dist-packages/pip/commands/install.py, line 278, in run requirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle) File <*>python2.7/dist-packages/pip/req.py, line 1091, in prepare_files req_to_install.check_if_exists() File <*>python2.7/dist-packages/pip/req.py, line 811, in check_if_exists self.satisfied_by = pkg_resources.get_distribution(self.req) File <*>python2.7/dist-packages/pkg_resources/__init__.py, line 535, in get_distribution dist = get_provider(dist) File <*>python2.7/dist-packages/pkg_resources/__init__.py, line 415, in get_provider return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0] IndexError: list index out of range",0
"File <*>/audiornn.py, line 56, in <module> tf.with_dependencies([expected_output], input_tensor) AttributeError: module 'tensorflow' has no attribute 'with_dependencies'",0
"File main.py, line 6, in <module> connection.start_socket(8089, callback=handler.message_processor) File <*>/python_socket_server.py, line 13, in start_socket process_message(connection, callback=callback) File <*>/python_socket_server.py, line 38, in process_message result = callback(general_proto) File <*>/proto_handler.py, line 39, in message_processor return train_shape(general_proto.template) File <*>/proto_handler.py, line 23, in train_shape rec.add_training_data(recognition_template.interpretation.label, recognition_template.shape) File <*>/recognition_manager.py, line 98, in add_training_data self.recognizers[label].train(label, points) File <*>/recognizer.py, line 78, in train self.classifier.fit(x=reshaped_tensor, y=target, steps=1) File <*>python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py, line 173, in fit input_fn, feed_fn = _get_input_fn(x, y, batch_size) File <*>python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py, line 67, in _get_input_fn x, y, n_classes=None, batch_size=batch_size) File <*>python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py, line 117, in setup_train_data_feeder X, y, n_classes, batch_size, shuffle=shuffle, epochs=epochs) File <*>python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py, line 239, in __init__ self.X.shape, None if self.y is None else self.y.shape, n_classes, AttributeError: 'Tensor' object has no attribute 'shape'",0
"File <*>/theano_multiprocess_debug.py, line 36, in <module> Y = MPjob(xlist) File <*>/theano_multiprocess_debug.py, line 29, in MPjob for y in Results: File <*>/pool.py, line 695, in next raise value TypeError: func1() got multiple values for argument 'func'",0
"File <stdin>, line 1, in <module> [CODE] ImportError: cannot import name Nadam",0
"File <*>python3.5/dist-packages/tensorflow/python/framework/common_shapes.py, line 594, in call_cpp_shape_fn status) File <*>python3.5/contextlib.py, line 66, in exit next(self.gen) File <*>python3.5/dist-packages/tensorflow/python/framework/errors.py, line 463, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors.InvalidArgumentError: Shape must be rank 0 but is rank 1",0
"File <string>, line 1, in <module> [CODE] File <*>/setup.py, line 339, in <module> cmdclass=cmdclass, File <*>python3.5/core.py, line 148, in setup dist.run_commands() File <*>python3.5/dist.py, line 955, in run_commands self.run_command(cmd) File <*>python3.5/dist.py, line 974, in run_command cmd_obj.run() File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/egg_info.py, line 279, in run [CODE] File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/egg_info.py, line 306, in find_sources [CODE] File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/egg_info.py, line 533, in run [CODE] File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/egg_info.py, line 562, in add_defaults [CODE] File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/py36compat.py, line 36, in add_defaults [CODE] File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/py36compat.py, line 119, in _add_defaults_ext [CODE] File <*>python3.5/cmd.py, line 299, in get_finalized_command cmd_obj.ensure_finalized() File <*>python3.5/cmd.py, line 107, in ensure_finalized self.finalize_options() File <*>python3.5/site-packages/Cython/Distutils/build_ext.py, line 19, in finalize_options self.distribution.ext_modules) File <*>python3.5/site-packages/Cython/Build/Dependencies.py, line 809, in cythonize aliases=aliases) File <*>python3.5/site-packages/Cython/Build/Dependencies.py, line 752, in create_extension_list **kwds)) TypeError: __init__() missing 3 required positional arguments: 'feature_name', 'feature_description', and 'feature_check'",0
"File <*>python35/site-packages/tensorflow/python/client/session.py, line 972, in _do_call return fn(*args) File <*>python35/site-packages/tensorflow/python/client/session.py, line 954, in _run_fn status, run_metadata) File <*>python35/contextlib.py, line 66, in __exit__ next(self.gen) File <*>python35/site-packages/tensorflow/python/framework/errors.py, line 463, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype float [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]",0
"File neural_network.py, line 48, in <module> print(sess.run(loss), feed_dict={xs:x_data, ys:y_data}) File <*>python35/site-packages/tensorflow/python/client/session.py, line 717, in run run_metadata_ptr) File <*>python35/site-packages/tensorflow/python/client/session.py, line 915, in _run feed_dict_string, options, run_metadata) File <*>python35/site-packages/tensorflow/python/client/session.py, line 965, in _do_run target_list, options, run_metadata) File <*>python35/site-packages/tensorflow/python/client/session.py, line 985, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype float [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]",0
"File <*>/testing.py, line 31, in [FUNC] [CODE] File <*>python3.5/site-packages/tensorflow/python/ops/functional_ops.py, line 390, in map_fn swap_memory=swap_memory) File <*>python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py, line 2636, in while_loop result = context.BuildLoop(cond, body, loop_vars, shape_invariants) File <*>python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py, line 2469, in BuildLoop pred, body, original_loop_vars, loop_vars, shape_invariants) File <*>python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py, line 2419, in _BuildLoop body_result = body(*packed_vars_for_body) File <*>python3.5/site-packages/tensorflow/python/ops/functional_ops.py, line 380, in compute packed_fn_values = fn(packed_values) TypeError: () missing 1 required positional argument: 'crop'",0
"File <*>/test_placeholder.py, line 5, in <module> input = tf.placeholder(tf.int32, [batchSize, 5]) File <*>/site-packages/tensorflow/python/ops/array_ops.py, line 1579, in placeholder shape = tensor_shape.as_shape(shape) File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 821, in as_shape return TensorShape(shape) File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 457, in __init__ self._dims = [as_dimension(d) for d in dims_iter] File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 457, in <listcomp> self._dims = [as_dimension(d) for d in dims_iter] File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 378, in as_dimension return Dimension(value) File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 33, in __init__ self._value = int(value) TypeError: int() argument must be a string, a bytes-like object or a number, not 'Tensor'",0
"File mnist.py, line 154, in <module> input_shape=(1, img_rows, img_cols))) File <*>python2.7/dist-packages/keras/models.py, line 276, in add layer.create_input_layer(batch_input_shape, input_dtype) File <*>python2.7/dist-packages/keras/engine/topology.py, line 370, in create_input_layer self(x) File <*>python2.7/dist-packages/keras/engine/topology.py, line 514, in __call__ self.add_inbound_node(inbound_layers, node_indices, tensor_indices) File <*>python2.7/dist-packages/keras/engine/topology.py, line 572, in add_inbound_node Node.create_node(self, inbound_layers, node_indices, tensor_indices) File <*>python2.7/dist-packages/keras/engine/topology.py, line 149, in create_node output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0])) File <*>python2.7/dist-packages/keras/layers/convolutional.py, line 466, in call filter_shape=self.W_shape) File <*>python2.7/dist-packages/keras/backend/tensorflow_backend.py, line 1579, in conv2d x = tf.nn.conv2d(x, kernel, strides, padding=padding) File <*>python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py, line 396, in conv2d data_format=data_format, name=name) File <*>python2.7/dist-packages/tensorflow/python/framework/op_def_library.py, line 759, in apply_op op_def=op_def) File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 2242, in create_op set_shapes_for_outputs(ret) File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 1617, in set_shapes_for_outputs shapes = shape_func(op) File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 1568, in call_with_requiring return call_cpp_shape_fn(op, require_shape_fn=True) File <*>python2.7/dist-packages/tensorflow/python/framework/common_shapes.py, line 610, in call_cpp_shape_fn debug_python_shape_fn, require_shape_fn) File <*>python2.7/dist-packages/tensorflow/python/framework/common_shapes.py, line 675, in _call_cpp_shape_fn_impl raise ValueError(err.message) ValueError: Negative dimension size caused by subtracting 3 from 1 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,1,28,28], [3,3,28,32].",0
"File <*>/fine-tune-v3-new-classes.py, line 75, in <module> nb_val_samples=nb_validation_samples) #1020 File <*>python2.7/site-packages/keras/engine/training.py, line 1508, in fit_generator class_weight=class_weight) File <*>python2.7/site-packages/keras/engine/training.py, line 1261, in train_on_batch check_batch_dim=True) File <*>python2.7/site-packages/keras/engine/training.py, line 985, in _standardize_user_data exception_prefix='model target') File <*>python2.7/site-packages/keras/engine/training.py, line 113, in standardize_input_data str(array.shape)) ValueError: Error when checking model target: expected dense_2 to have shape (None, 200) but got array with shape (16, 2)",0
"File <*>python2.7/dist-packages/tensorflow/python/__init__.py, line 61, in <module> from tensorflow.python import pywrap_tensorflow File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper() File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description) ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory Failed to load the native TensorFlow runtime.",0
"File train.py, line 6, in <module> vgg19.fit(nb_epoch=1) File <*>/vgg19.py, line 84, in fit nb_val_samples=8 File <*>python2.7/dist-packages/keras/models.py, line 907, in fit_generator pickle_safe=pickle_safe) File <*>python2.7/dist-packages/keras/engine/training.py, line 1378, in fit_generator callbacks._set_model(callback_model) File <*>python2.7/dist-packages/keras/callbacks.py, line 32, in _set_model callback._set_model(model) File <*>python2.7/dist-packages/keras/callbacks.py, line 493, in _set_model self.sess = KTF.get_session() File <*>python2.7/dist-packages/keras/backend/tensorflow_backend.py, line 111, in get_session _initialize_variables() File <*>python2.7/dist-packages/keras/backend/tensorflow_backend.py, line 200, in _initialize_variables sess.run(tf.variables_initializer(uninitialized_variables)) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 766, in run run_metadata_ptr) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 964, in _run feed_dict_string, options, run_metadata) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 1014, in _do_run target_list, options, run_metadata) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 1034, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[4096] [[Node: Variable_43/Assign = Assign[T=DT_FLOAT, _class=[""loc:@Variable_43""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Variable_43, Const_59)]]",0
"File <*>python2.7/threading.py, line 801, in __bootstrap_inner self.run() File <*>python2.7/threading.py, line 754, in run self.__target(*self.__args, **self.__kwargs) File <*>python2.7/dist-packages/keras/engine/training.py, line 409, in data_generator_task generator_output = next(generator) File <*>/load_gluc_data.py, line 198, in generate yield self.next_batch() File <*>/load_gluc_data.py, line 192, in next_batch X, y, l = self.process_image(json_im, X, y, l) File <*>/load_gluc_data.py, line 131, in process_image im.augment_with_tf(self.tf_sess) File <*>/load_gluc_data.py, line 85, in augment_with_tf self.im = sess.run(saturation, {im_placeholder: np.asarray(self.im)}) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 766, in run run_metadata_ptr) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 921, in _run + e.args[0]) TypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(""Placeholder:0"", shape=(96, 96, 3), dtype=float32) is not an element of this graph.",0
"File <*>/tfclass.py, line 36, in <module> summary_writer = tf.summary.FileWriter('/home/sergo/work/logs',graph_def = sess.graph_def) File <*>python3.6/site-packages/tensorflow/python/summary/writer/writer.py, line 308, in __init__ event_writer = EventFileWriter(logdir, max_queue, flush_secs) File <*>python3.6/site-packages/tensorflow/python/summary/writer/event_file_writer.py, line 69, in __init__ gfile.MakeDirs(self._logdir) File <*>python3.6/site-packages/tensorflow/python/lib/io/file_io.py, line 301, in recursive_create_dir pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status) File <*>python3.6/contextlib.py, line 89, in __exit__ next(self.gen) File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 469, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors_impl.UnimplementedError: /home/sergo",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call return fn(*args) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn status, run_metadata) File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[500,80] [[Node: decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](decoder/while/BasicDecoderStep/basic_lstm_cell/concat, decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul/Enter)]] [[Node: gradients/Add/_282 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_457_gradients/Add"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](^_cloopdecoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y/_181)]]",0
"File <stdin>, line 1, in <module> [CODE] RuntimeError: t() expects a 2D tensor, but self is 1D",0
"File <*>/LSTM-RNN.py, line 42, in <module> states_series, current_state = tf.contrib.rnn.static_rnn(cell, inputs_series, init_state) File <*>python3.6/site-packages/tensorflow/python/ops/rnn.py, line 1181, in static_rnn input_shape = first_input.get_shape().with_rank_at_least(2) File <*>python3.6/site-packages/tensorflow/python/framework/tensor_shape.py, line 670, in with_rank_at_least raise ValueError(""Shape %s must have rank at least %d"" % (self, rank)) ValueError: Shape () must have rank at least 2",0
"File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 468, in make_tensor_proto str_values = [compat.as_bytes(x) for x in proto_values] File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 468, in <listcomp> str_values = [compat.as_bytes(x) for x in proto_values] File <*>/site-packages/tensorflow/python/util/compat.py, line 65, in as_bytes (bytes_or_text,)) TypeError: Expected binary or unicode string, got {'weights': <tf.Variable 'Variable:0' shape=(784, 600) dtype=float32_ref>, 'biases': <tf.Variable 'Variable_1:0' shape=(600,) dtype=float32_ref>}",0
"File <*>/neuralnetworktest.py, line 45, in <module> train(x) File <*>/neuralnetworktest.py, line 29, in train prediction = neuralNetwork(inputdata) File <*>/neuralnetworktest.py, line 22, in neuralNetwork FinalH2 = tf.add(tf.matmul(H1, H2[""weights""]), H2[""biases""]) File <*>/site-packages/tensorflow/python/ops/math_ops.py, line 1844, in matmul a = ops.convert_to_tensor(a, name=""a"") File <*>/site-packages/tensorflow/python/framework/ops.py, line 836, in convert_to_tensor as_ref=False) File <*>/site-packages/tensorflow/python/framework/ops.py, line 926, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 229, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name) File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 208, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape)) File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 472, in make_tensor_proto ""supported type."" % (type(values), values)) TypeError: Failed to convert object of type <class 'dict'> to Tensor.",0
"File RF_2.py, line 312, in <module> main() File RF_2.py, line 298, in main train_eval(x_train, y_train, x_validation, y_validation, x_test, y_test, num_tree) File RF_2.py, line 221, in train_eval prob0 = results[0][eval_metrics.INFERENCE_PROB_NAME] KeyError: 'probabilities'",0
"File generate_tfrecord.py, line 192, in <module> tf.app.run() File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough)) File generate_tfrecord.py, line 184, in main tf_example = create_tf_example(group, path) File generate_tfrecord.py, line 173, in create_tf_example 'image/object/class/label': dataset_util.int64_list_feature(classes), File <*>/dataset_util.py, line 26, in int64_list_feature return tf.train.Feature(int64_list=tf.train.Int64List(value=value)) TypeError: None has type NoneType, but expected one of: int, long",0
"File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call return fn(*args) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn status, run_metadata) File <*>python3.4/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: cnn()conv2 : Tensor had Inf values [[Node: tower_7/conv2/CheckNumerics_3 = CheckNumerics[T=DT_FLOAT, message=""NaN: cnn()conv2"", _device=""/job:localhost/replica:0/task:0/device:GPU:7""](tower_7/conv2/conv2)]]",0
"File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call return fn(*args) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn status, run_metadata) File <*>python3.4/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: average_gradients(expanded_g) : Tensor had Inf and NaN values [[Node: CheckNumerics_30 = CheckNumerics[T=DT_FLOAT, message=""NaN: average_gradients(expanded_g)"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](ExpandDims_30)]] [[Node: tower_6/total_loss/_2216 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:6"", send_device_incarnation=1, tensor_name=""edge_4923_tower_6/total_loss"", _device=""/job:localhost/replica:0/task:0/device:GPU:6""](tower_6/total_loss)]]",0
"File lec5.py, line 97, in <module> train(epoch) File lec5.py, line 74, in train loss = criterion(y_pred, labels) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 357, in __call__ result = self.forward(*input, **kwargs) File <*>python3.6/site-packages/torch/nn/modules/loss.py, line 679, in forward self.ignore_index, self.reduce) File <*>python3.6/site-packages/torch/nn/functional.py, line 1161, in cross_entropy return nll_loss(log_softmax(input, 1), target, weight, size_average, ignore_index, reduce) File <*>python3.6/site-packages/torch/nn/functional.py, line 1052, in nll_loss return torch._C._nn.nll_loss(input, target, weight, size_average, ignore_index, reduce) RuntimeError: multi-target not supported at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/THNN/generic/ClassNLLCriterion.c:22",0
"File train.py, line 167, in <module> tf.app.run() File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv)) File train.py, line 163, in main worker_job_name, is_chief, FLAGS.train_dir) File <*>/trainer.py, line 284, in train train_config.optimizer) File <*>/optimizer_builder.py, line 50, in build learning_rate = _create_learning_rate(config.learning_rate) File <*>/optimizer_builder.py, line 109, in _create_learning_rate learning_rate_sequence, config.warmup) File <*>/learning_schedules.py, line 156, in manual_stepping raise ValueError('First step cannot be zero.') ValueError: First step cannot be zero.",0
"File <*>/TutorialCIFAR10.py, line 36, in <module> dataiter = iter(trainloader) File <*>/site-packages/torch/utils/data/dataloader.py, line 451, in __iter__ return _DataLoaderIter(self) File <*>/site-packages/torch/utils/data/dataloader.py, line 239, in __init__ w.start() File <*>/process.py, line 105, in start self._popen = self._Popen(self) File <*>/context.py, line 223, in _Popen return _default_context.get_context().Process._Popen(process_obj) File <*>/context.py, line 322, in _Popen return Popen(process_obj) File <*>/popen_spawn_win32.py, line 65, in __init__ reduction.dump(process_obj, to_child) File <*>/reduction.py, line 60, in dump ForkingPickler(file, protocol).dump(obj) BrokenPipeError: [Errno 32] Broken pipe",0
"File test.py, line 7, in [FUNC] [CODE] TypeError: Parameter to MergeFrom() must be instance of same class: expected tensorflow.BytesList got tensorflow.Int64List.",0
"File <string>, line 1, in <module> [CODE] File <*>/setup.py, line 11, in <module> raise RuntimeError(README) RuntimeError: PyTorch does not currently provide packages for PyPI (see status at https://github.com/pytorch/pytorch/issues/566).",0
"File <ipython-input-17-412a606c772f>, line 1, in <module> dataset = tf.data.Dataset.from_tensor_slices((one_hot_dataset)) File <*>python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 235, in from_tensor_slices return TensorSliceDataset(tensors) File <*>python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1030, in __init__ for i, t in enumerate(nest.flatten(tensors)) File <*>python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1030, in <listcomp> for i, t in enumerate(nest.flatten(tensors)) File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 1014, in convert_to_tensor as_ref=False) File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 1104, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python3.5/site-packages/tensorflow/python/framework/constant_op.py, line 235, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name) File <*>python3.5/site-packages/tensorflow/python/framework/constant_op.py, line 214, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape)) File <*>python3.5/site-packages/tensorflow/python/framework/tensor_util.py, line 496, in make_tensor_proto [CODE] ""Cannot create a tensor proto whose content is larger than 2GB."") ValueError: Cannot create a tensor proto whose content is larger than 2GB.",0
"File model_builder_test.py, line 21, in <module> from object_detection.builders import model_builder File <*>/model_builder.py, line 17, in <module> from object_detection.builders import anchor_generator_builder File <*>/anchor_generator_builder.py, line 18, in <module> from object_detection.anchor_generators import grid_anchor_generator File <*>/grid_anchor_generator.py, line 27, in <module> from object_detection.utils import ops File <*>/ops.py, line 282, in <module> dtype=tf.float32): AttributeError: module 'tensorflow' has no attribute 'float32'",0
"File <string>, line 1, in <module> [CODE] ImportError: No module named numpy",0
"File <*>/testing.py, line 10, in <module> model = Model(inputs=model_in, outputs=output) File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) File <*>/site-packages/keras/engine/network.py, line 93, in __init__ self._init_graph_network(*args, **kwargs) File <*>/site-packages/keras/engine/network.py, line 237, in _init_graph_network self.inputs, self.outputs) File <*>/site-packages/keras/engine/network.py, line 1353, in _map_graph_network tensor_index=tensor_index) File <*>/site-packages/keras/engine/network.py, line 1340, in build_map node_index, tensor_index) File <*>/site-packages/keras/engine/network.py, line 1312, in build_map node = layer._inbound_nodes[node_index] AttributeError: 'NoneType' object has no attribute '_inbound_nodes'",0
"File <*>python3.6/site-packages/pip/_internal/basecommand.py, line 141, in main status = self.run(options, args) File <*>python3.6/site-packages/pip/_internal/commands/install.py, line 330, in run self._warn_about_conflicts(to_install) File <*>python3.6/site-packages/pip/_internal/commands/install.py, line 456, in _warn_about_conflicts package_set, _dep_info = check_install_conflicts(to_install) File <*>python3.6/site-packages/pip/_internal/operations/check.py, line 98, in check_install_conflicts package_set = create_package_set_from_installed() File <*>python3.6/site-packages/pip/_internal/operations/check.py, line 41, in create_package_set_from_installed package_set[name] = PackageDetails(dist.version, dist.requires()) File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2607, in requires dm = self._dep_map File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2871, in _dep_map self.__dep_map = self._compute_dependencies() File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2881, in _compute_dependencies reqs.extend(parse_requirements(req)) File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2942, in parse_requirements yield Requirement(line) File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2951, in __init__ raise RequirementParseError(str(e)) pip._vendor.pkg_resources.RequirementParseError: Invalid requirement, parse error at ""'; extra '""",0
"File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 712, in __del__ [CODE] File <*>python3.5/site-packages/tensorflow/python/framework/c_api_util.py, line 31, in __init__ [CODE] TypeError: 'NoneType' object is not callable",0
"File model.py, line 7, in <module> class_labels = 'conv_labels.txt' File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 586, in convert custom_conversion_functions=custom_conversion_functions) File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 153, in _convert_pb_to_mlmodel tf.import_graph_def(gdef, name='') File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 316, in new_func return func(*args, **kwargs) File <*>python3.6/site-packages/tensorflow/python/framework/importer.py, line 541, in import_graph_def raise ValueError('No op named %s in defined operations.' % node.op) ValueError: No op named DecodeWav in defined operations.",0
"File <*>/auto_LSTM_try3.py, line 398, in <module> run_experiments(config, search_alg=algo, scheduler=hyperband) File <*>python3.6/site-packages/ray/tune/tune.py, line 108, in run_experiments runner.step() File <*>python3.6/site-packages/ray/tune/trial_runner.py, line 114, in step next_trial = self._get_next_trial() File <*>python3.6/site-packages/ray/tune/trial_runner.py, line 254, in _get_next_trial self._update_trial_queue(blocking=wait_for_trial) File <*>python3.6/site-packages/ray/tune/trial_runner.py, line 330, in _update_trial_queue trials = self._search_alg.next_trials() File <*>python3.6/site-packages/ray/tune/suggest/suggestion.py, line 67, in next_trials for trial in self._trial_generator: File <*>python3.6/site-packages/ray/tune/suggest/suggestion.py, line 88, in _generate_trials suggested_config = self._suggest(trial_id) File <*>python3.6/site-packages/ray/tune/suggest/hyperopt.py, line 81, in _suggest self.rstate.randint(2**31 - 1)) File <*>python3.6/site-packages/hyperopt/tpe.py, line 835, in suggest = tpe_transform(domain, prior_weight, gamma) File <*>python3.6/site-packages/hyperopt/tpe.py, line 816, in tpe_transform s_prior_weight File <*>python3.6/site-packages/hyperopt/tpe.py, line 690, in build_posterior b_post = fn(*b_args, **dict(named_args)) TypeError: ap_uniform_sampler() missing 1 required positional argument: 'high'",0
"File <*>/WorkOut.py, line 416, in <module> main() File <*>/WorkOut.py, line 412, in main train(args, model, device, train_loader, optimizer, epoch) File <*>/WorkOut.py, line 324, in train loss = F.nll_loss(output, target) File <*>python3.6/site-packages/torch/nn/functional.py, line 1788, in nll_loss .format(input.size(0), target.size(0))) ValueError: Expected input batch_size (4) to match target batch_size (64).",0
"File <*>/testo.py, line 18, in <module> optim.minimize(loss, var_list=network.weights) AttributeError: 'Adam' object has no attribute 'minimize'",0
"File <stdin>, line 1, in <module> [CODE] AttributeError: module 'tensorflow' has no attribute 'estimator'",0
"File <stdin>, line 1, in <module> [CODE] File <*>python3.5/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import File <*>python3.5/site-packages/tensorflow/python/__init__.py, line 52, in <module> from tensorflow.core.framework.graph_pb2 import * File <*>python3.5/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in <module> from google.protobuf import descriptor as _descriptor File <*>python3.5/site-packages/google/protobuf/descriptor.py, line 47, in <module> from google.protobuf.pyext import _message ImportError: /home/work/.conda/envs/tensorflow/lib/python3.5/site-packages/google/protobuf/pyext/_message.cpython-35m-x86_64-linux-gnu.so: undefined symbol: _ZNK6google8protobuf10TextFormat17FieldValuePrinter9PrintBoolEb",0
"File train.py, line 293, in <module> main() File train.py, line 271, in main feed_dict={context: sample_batch()}) File <*>/site-packages/tensorflow/python/client/session.py, line 929, in run run_metadata_ptr) File <*>/site-packages/tensorflow/python/client/session.py, line 1152, in _run feed_dict_tensor, options, run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1328, in _do_run run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1348, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[51200,2304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[node model/h0/attn/c_attn/MatMul (defined at D:\Python and AI\Generative Chatbot\gpt-2\src\model.py:55) ]]",0
"File <*>/model.py, line 24, in <module> image = mnist_example[""image""] TypeError: 'DatasetV1Adapter' object is not subscriptable",0
"File train.py, line 194, in <module> _main() File train.py, line 69, in _main callbacks=[logging, checkpoint]) File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) File <*>/site-packages/keras/engine/training.py, line 1418, in fit_generator initial_epoch=initial_epoch) File <*>/site-packages/keras/engine/training_generator.py, line 251, in fit_generator callbacks.on_epoch_end(epoch, epoch_logs) File <*>/site-packages/keras/callbacks.py, line 79, in on_epoch_end callback.on_epoch_end(epoch, logs) File <*>/site-packages/keras/callbacks.py, line 429, in on_epoch_end filepath = self.filepath.format(epoch=epoch + 1, **logs) KeyError: 'val_loss'",0
"File <*>/debug_multiple_input_model.py, line 39, in <module> model.predict(zipped_input) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1054, in predict callbacks=callbacks) File <*>/site-packages/tensorflow/python/keras/engine/training_generator.py, line 264, in model_iteration batch_outs = batch_function(*batch_data) File <*>/site-packages/tensorflow/python/keras/engine/training_generator.py, line 536, in predict_on_batch return model.predict_on_batch(x) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1281, in predict_on_batch x, extract_tensors_from_dataset=True) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 2651, in _standardize_user_data exception_prefix='input') File <*>/site-packages/tensorflow/python/keras/engine/training_utils.py, line 346, in standardize_input_data str(len(data)) + ' arrays: ' + str(data)[:200] + '...') ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [<tf.Tensor: id=71049, shape=(10, 100, 5), dtype=float64, numpy= array([[[0.54049765, 0.64218937, 0.31734092, 0.81307839, 0.75465237], [0.32371089, 0.85923477, 0.60619924, 0.68692891, 0.186234...",0
"File <*>python3.6/dist-packages/pip/_internal/cli/base_command.py, line 178, in main status = self.run(options, args) File <*>python3.6/dist-packages/pip/_internal/commands/install.py, line 326, in run self.name, wheel_cache File <*>python3.6/dist-packages/pip/_internal/cli/base_command.py, line 268, in populate_requirement_set wheel_cache=wheel_cache File <*>python3.6/dist-packages/pip/_internal/req/constructors.py, line 248, in install_req_from_line ""nor 'pyproject.toml' found."" % name pip._internal.exceptions.InstallationError: Directory './' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.",0
"File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory",0
"File <stdin>, line 1, in <module> [CODE] ModuleNotFoundError: No module named 'torch'",0
"File <input>, line 1, in <module> [CODE] File <*>/pydev_umd.py, line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc) File <*>/train_model_so.py, line 108, in <module> print(""x shape is"" , x.shape()) TypeError: 'TensorShape' object is not callable",0
"File <*>/data.py, line 4, in <module> import torchvision ModuleNotFoundError: No module named 'torchvision'",0
"File <*>/cnn.py, line 70, in <module> validation_steps = 2000) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 1297, in fit_generator steps_name='steps_per_epoch') File <*>/site-packages/tensorflow_core/python/keras/engine/training_generator.py, line 265, in model_iteration batch_outs = batch_function(*batch_data) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 973, in train_on_batch class_weight=class_weight, reset_metrics=reset_metrics) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch output_loss_metrics=model._output_loss_metrics) File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch output_loss_metrics=output_loss_metrics)) File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 252, in _process_single_batch training=training)) File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 127, in _model_loss outs = model(inputs, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 891, in __call__ outputs = self.call(cast_inputs, *args, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/engine/sequential.py, line 256, in call return super(Sequential, self).call(inputs, training=training, mask=mask) File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 708, in call convert_kwargs_to_constants=base_layer_utils.call_context().saving) File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 860, in _run_internal_graph output_tensors = layer(computed_tensors, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/layers/convolutional.py, line 197, in call outputs = self._convolution_op(inputs, self.kernel) File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 1134, in __call__ return self.conv_op(inp, filter) File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 639, in __call__ return self.call(inp, filter) File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 238, in __call__ name=self.name) File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 2010, in conv2d name=name) File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1031, in conv2d data_format=data_format, dilations=dilations, name=name, ctx=_ctx) File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1130, in conv2d_eager_fallback ctx=_ctx, name=name) File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None) File <string>, line 3, in raise_from [CODE] UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]",0
"File <*>/pydevd.py, line 1741, in <module> main() File <*>/pydevd.py, line 1735, in main globals = debugger.run(setup['file'], None, None, is_module) File <*>/pydevd.py, line 1135, in run pydev_imports.execfile(file, globals, locals) # execute the script File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc) File <*>/train_hopenet_with_validation_holdout.py, line 187, in <module> loss_reg_yaw = reg_criterion(yaw_predicted, label_yaw_cont) File <*>/site-packages/torch/nn/modules/module.py, line 541, in __call__ result = self.forward(*input, **kwargs) File <*>/site-packages/torch/nn/modules/loss.py, line 431, in forward return F.mse_loss(input, target, reduction=self.reduction) File <*>/site-packages/torch/nn/functional.py, line 2204, in mse_loss ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction)) RuntimeError: reduce failed to synchronize: cudaErrorAssert: device-side assert triggered",0
"File <*>/main.py, line 17, in <module> history = CNN.fit(TrainImages, TrainMasks, epochs = 3) File <*>python3.6/site-packages/keras/engine/training.py, line 1239, in fit validation_freq=validation_freq) File <*>python3.6/site-packages/keras/engine/training_arrays.py, line 196, in fit_loop outs = fit_function(ins_batch) File <*>python3.6/site-packages/tensorflow_core/python/keras/backend.py, line 3727, in __call__ outputs = self._graph_fn(*converted_inputs) File <*>python3.6/site-packages/tensorflow_core/python/eager/function.py, line 1551, in __call__ return self._call_impl(args, kwargs) File <*>python3.6/site-packages/tensorflow_core/python/eager/function.py, line 1591, in _call_impl return self._call_flat(args, self.captured_inputs, cancellation_manager) File <*>python3.6/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat ctx, args, cancellation_manager=cancellation_manager)) File <*>python3.6/site-packages/tensorflow_core/python/eager/function.py, line 545, in call ctx=ctx) File <*>python3.6/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None) File <string>, line 3, in raise_from [CODE] tensorflow.python.framework.errors_impl.**InvalidArgumentError: BiasGrad requires tensor size <= int32 max** [[node gradients/conv2d_22/BiasAdd_grad/BiasAddGrad (defined at /home/tomhalmos/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_5496]",0
"File TrainTest.py, line 71, in <module> model.save('test', save_format='tf') File <*>/network.py, line 1008, in save signatures, options) File <*>/save.py, line 115, in save_model signatures, options) File <*>/save.py, line 78, in save save_lib.save(model, filepath, signatures, options) File <*>/save.py, line 886, in save checkpoint_graph_view) File <*>/signature_serialization.py, line 74, in find_function_to_export functions = saveable_view.list_functions(saveable_view.root) File <*>/save.py, line 142, in list_functions self._serialization_cache) File <*>/base_layer.py, line 2420, in _list_functions_for_serialization .list_functions_for_serialization(serialization_cache)) File <*>/base_serialization.py, line 91, in list_functions_for_serialization fns = self.functions_to_serialize(serialization_cache) File <*>/layer_serialization.py, line 80, in functions_to_serialize serialization_cache).functions_to_serialize) File <*>/layer_serialization.py, line 95, in _get_serialized_attributes serialization_cache) File <*>/model_serialization.py, line 47, in _get_serialized_attributes_internal default_signature = save_impl.default_save_signature(self.obj) File <*>/save_impl.py, line 212, in default_save_signature fn.get_concrete_function() File <*>/def_function.py, line 909, in get_concrete_function self._initialize(args, kwargs, add_initializers_to=initializers) File <*>/def_function.py, line 497, in _initialize *args, **kwds)) File <*>/function.py, line 2389, in _get_concrete_function_internal_garbage_collected graph_function, _, _ = self._maybe_define_function(args, kwargs) File <*>/function.py, line 2703, in _maybe_define_function graph_function = self._create_graph_function(args, kwargs) File <*>/function.py, line 2593, in _create_graph_function capture_by_value=self._capture_by_value), File <*>/func_graph.py, line 978, in func_graph_from_py_func func_outputs = python_func(*func_args, **func_kwargs) File <*>/def_function.py, line 439, in wrapped_fn return weak_wrapped_fn().__wrapped__(*args, **kwds) File <*>/saving_utils.py, line 150, in _wrapped_model outputs_list = nest.flatten(model(inputs=inputs, training=False)) TypeError: __call__() missing 1 required positional argument: 'x'",0
"File <*>/mmconvert, line 8, in <module> sys.exit(_main()) File <*>python3.5/dist-packages/mmdnn/conversion/_script/convert.py, line 102, in _main ret = convertToIR._convert(ir_args) File <*>python3.5/dist-packages/mmdnn/conversion/_script/convertToIR.py, line 46, in _convert parser = Keras2Parser(model) File <*>python3.5/dist-packages/mmdnn/conversion/keras/keras2_parser.py, line 126, in __init__ model = self._load_model(model[0], model[1]) File <*>python3.5/dist-packages/mmdnn/conversion/keras/keras2_parser.py, line 78, in _load_model 'DepthwiseConv2D': layers.DepthwiseConv2D}) File <*>python3.5/dist-packages/keras/engine/saving.py, line 664, in model_from_json return deserialize(config, custom_objects=custom_objects) File <*>python3.5/dist-packages/keras/layers/__init__.py, line 168, in deserialize printable_module_name='layer') File <*>python3.5/dist-packages/keras/utils/generic_utils.py, line 147, in deserialize_keras_object list(custom_objects.items()))) File <*>python3.5/dist-packages/keras/engine/network.py, line 1056, in from_config process_layer(layer_data) File <*>python3.5/dist-packages/keras/engine/network.py, line 1042, in process_layer custom_objects=custom_objects) File <*>python3.5/dist-packages/keras/utils/generic_utils.py, line 149, in deserialize_keras_object return cls.from_config(config['config']) File <*>python3.5/dist-packages/keras/engine/base_layer.py, line 1179, in from_config return cls(**config) File <*>python3.5/dist-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) File <*>python3.5/dist-packages/keras/layers/convolutional.py, line 484, in __init__ **kwargs) File <*>python3.5/dist-packages/keras/layers/convolutional.py, line 117, in __init__ self.kernel_initializer = initializers.get(kernel_initializer) File <*>python3.5/dist-packages/keras/initializers.py, line 515, in get return deserialize(identifier) File <*>python3.5/dist-packages/keras/initializers.py, line 510, in deserialize printable_module_name='initializer') File <*>python3.5/dist-packages/keras/utils/generic_utils.py, line 140, in deserialize_keras_object ': ' + class_name) ValueError: Unknown initializer: GlorotUniform",0
"File <*>python3.7/site-packages/IPython/core/interactiveshell.py, line 3331, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File <ipython-input-55-cc0dd3d9cbb7>, line 1, in <module> net(cc) File <*>python3.7/site-packages/torch/nn/modules/module.py, line 532, in __call__ result = self.forward(*input, **kwargs) File <ipython-input-2-19e11966d1cd>, line 181, in forward out = self.layer1(x) File <*>python3.7/site-packages/torch/nn/modules/container.py, line 100, in forward input = module(input) File <*>python3.7/site-packages/torch/nn/modules/conv.py, line 480, in forward self.padding, self.dilation, self.groups) RuntimeError: Could not run 'aten::slow_conv3d_forward' with arguments from the 'CUDATensorId' backend. 'aten::slow_conv3d_forward' is only available for these backends: [CPUTensorId, VariableTensorId].",0
"File <*>/train.py, line 74, in <module> model = nn.DataParallel(model, device_ids=[0, 1]).to(device) File <*>/site-packages/torch/nn/parallel/data_parallel.py, line 133, in __init__ _check_balance(self.device_ids) File <*>/site-packages/torch/nn/parallel/data_parallel.py, line 19, in _check_balance dev_props = [torch.cuda.get_device_properties(i) for i in device_ids] File <*>/site-packages/torch/nn/parallel/data_parallel.py, line 19, in <listcomp> dev_props = [torch.cuda.get_device_properties(i) for i in device_ids] File <*>/site-packages/torch/cuda/__init__.py, line 337, in get_device_properties raise AssertionError(""Invalid device id"") AssertionError: Invalid device id",0
"File <*>/train.py, line 66, in <module> train(epochs=20, prefix='test_new_loss_fn') File <*>/train.py, line 46, in train model = create_model((shape[0], shape[1], 3), backbone=backbone, loss_function=loss_fn, freeze_backbone=backbone_freeze, lr=learning_rate) File <*>/__init__.py, line 48, in create_model loss=loss_function, metrics=[mean_relative_percentage_error, metrics.mean_absolute_error]) File <*>/site-packages/keras/engine/training.py, line 342, in compile sample_weight, mask) File <*>/site-packages/keras/engine/training_utils.py, line 404, in weighted score_array = fn(y_true, y_pred) File <*>/losses.py, line 7, in mean_relative_percentage_error ones = K.variable(K.ones_like(err)) File <*>/site-packages/keras/backend/tensorflow_backend.py, line 402, in variable v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name) File <*>/site-packages/tensorflow/python/ops/variables.py, line 183, in __call__ return cls._variable_v1_call(*args, **kwargs) File <*>/site-packages/tensorflow/python/ops/variables.py, line 146, in _variable_v1_call aggregation=aggregation) File <*>/site-packages/tensorflow/python/ops/variables.py, line 125, in <lambda> previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs) File <*>/site-packages/tensorflow/python/ops/variable_scope.py, line 2444, in default_variable_creator expected_shape=expected_shape, import_scope=import_scope) File <*>/site-packages/tensorflow/python/ops/variables.py, line 187, in __call__ return super(VariableMetaclass, cls).__call__(*args, **kwargs) File <*>/site-packages/tensorflow/python/ops/variables.py, line 1329, in __init__ constraint=constraint) File <*>/site-packages/tensorflow/python/ops/variables.py, line 1472, in _init_from_args self._initial_value) ValueError: initial_value must have a shape specified: Tensor(""loss/dense_3_loss/ones_like:0"", shape=(?, ?), dtype=float32)",0
"File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1365, in _do_call return fn(*args) File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1350, in _run_fn target_list, run_metadata) File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1443, in _call_tf_sessionrun run_metadata) tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found. (0) Invalid argument: {{function_node __inference_Dataset_map_transform_and_pad_input_data_fn_3047}} assertion failed: [[0.748][0.758]] [[0.67][0.67]] [[{{node Assert/AssertGuard/else/_123/Assert}}]] [[IteratorGetNext]] (1) Invalid argument: {{function_node __inference_Dataset_map_transform_and_pad_input_data_fn_3047}} assertion failed: [[0.748][0.758]] [[0.67][0.67]] [[{{node Assert/AssertGuard/else/_123/Assert}}]] [[IteratorGetNext]] [[IteratorGetNext/_8451]] 0 successful operations. 0 derived errors ignored.",0
"File <*>/model_main.py, line 114, in <module> tf.app.run() File <*>python3.6/dist-packages/tensorflow_core/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef) File <*>python3.6/dist-packages/absl/app.py, line 299, in run _run_main(main, args) File <*>python3.6/dist-packages/absl/app.py, line 250, in _run_main sys.exit(main(argv)) File <*>/model_main.py, line 110, in main tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0]) File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py, line 473, in train_and_evaluate return executor.run() File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py, line 613, in run return self.run_local() File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py, line 714, in run_local saving_listeners=saving_listeners) File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py, line 370, in train loss = self._train_model(input_fn, hooks, saving_listeners) File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py, line 1161, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners) File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py, line 1195, in _train_model_default saving_listeners) File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py, line 1494, in _train_with_estimator_spec _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss]) File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 754, in run run_metadata=run_metadata) File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1259, in run run_metadata=run_metadata) File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1360, in run raise six.reraise(*original_exc_info) File <*>python3.6/dist-packages/six.py, line 693, in reraise raise value File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1345, in run return self._sess.run(*args, **kwargs) File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1418, in run run_metadata=run_metadata) File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1176, in run return self._sess.run(*args, **kwargs) File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 956, in run run_metadata_ptr) File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1180, in _run feed_dict_tensor, options, run_metadata) File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1359, in _do_run run_metadata) File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1384, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found. (0) Invalid argument: assertion failed: [[0.748][0.758]] [[0.67][0.67]] [[{{node Assert/AssertGuard/else/_123/Assert}}]] [[IteratorGetNext]] (1) Invalid argument: assertion failed: [[0.748][0.758]] [[0.67][0.67]] [[{{node Assert/AssertGuard/else/_123/Assert}}]] [[IteratorGetNext]] [[IteratorGetNext/_8451]] 0 successful operations. 0 derived errors ignored.",0
"File <*>/train.py, line 17, in <module> from pegasus.data import infeed ModuleNotFoundError: No module named 'pegasus'",0
"File <*>/main.py, line 45, in <module> linear_est.train(train_input_fn) File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 349, in train loss = self._train_model(input_fn, hooks, saving_listeners) File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1175, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners) File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1201, in _train_model_default self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN)) File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1037, in _get_features_and_labels_from_input_fn self._call_input_fn(input_fn, mode)) File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1130, in _call_input_fn return input_fn(**kwargs) File <*>/main.py, line 34, in input_function ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df)) File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 682, in from_tensor_slices return TensorSliceDataset(tensors) File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 3001, in __init__ element = structure.normalize_element(element) File <*>/site-packages/tensorflow/python/data/util/structure.py, line 98, in normalize_element ops.convert_to_tensor(t, name=""component_%d"" % i)) File <*>/site-packages/tensorflow/python/framework/ops.py, line 1499, in convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 338, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name) File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 264, in constant allow_broadcast=True) File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 282, in _constant_impl allow_broadcast=allow_broadcast)) File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 563, in make_tensor_proto append_fn(tensor_proto, proto_values) File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 155, in SlowAppendObjectArrayToTensorProto tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values]) File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 155, in <listcomp> tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values]) File <*>/site-packages/tensorflow/python/util/compat.py, line 87, in as_bytes (bytes_or_text,)) TypeError: Expected binary or unicode string, got nan",0
"File <*>/site-packages/flask/app.py, line 2447, in wsgi_app response = self.full_dispatch_request() File <*>/site-packages/flask/app.py, line 1952, in full_dispatch_request rv = self.handle_user_exception(e) File <*>/site-packages/flask/app.py, line 1821, in handle_user_exception reraise(exc_type, exc_value, tb) File <*>/site-packages/flask/_compat.py, line 39, in reraise raise value File <*>/site-packages/flask/app.py, line 1950, in full_dispatch_request rv = self.dispatch_request() File <*>/site-packages/flask/app.py, line 1936, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args) File <*>/app.py, line 70, in predict out = model.predict(img) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 130, in _method_wrapper return method(self, *args, **kwargs) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1562, in predict version_utils.disallow_legacy_graph('Model', 'predict') File <*>/site-packages/tensorflow/python/keras/utils/version_utils.py, line 122, in disallow_legacy_graph raise ValueError(error_msg) ValueError: Calling `Model.predict` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.predict` with eager mode enabled.",0
"File <*>/external_process.py, line 35, in <module> model.fit( File <*>python3.8/site-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper return method(self, *args, **kwargs) File <*>python3.8/site-packages/tensorflow/python/keras/engine/training.py, line 1098, in fit tmp_logs = train_function(iterator) File <*>python3.8/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__ result = self._call(*args, **kwds) File <*>python3.8/site-packages/tensorflow/python/eager/def_function.py, line 840, in _call return self._stateless_fn(*args, **kwds) File <*>python3.8/site-packages/tensorflow/python/eager/function.py, line 2829, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access File <*>python3.8/site-packages/tensorflow/python/eager/function.py, line 1843, in _filtered_call return self._call_flat( File <*>python3.8/site-packages/tensorflow/python/eager/function.py, line 1923, in _call_flat return self._build_call_outputs(self._inference_function.call( File <*>python3.8/site-packages/tensorflow/python/eager/function.py, line 545, in call outputs = execute.execute( File <*>python3.8/site-packages/tensorflow/python/eager/execute.py, line 59, in quick_execute tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name, tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 1328 values, but the requested shape has 16 [[{{node TripletSemiHardLoss/PartitionedCall/Reshape}}]] [Op:__inference_train_function_13749]",0
"File evaluate_spect.py, line 63, in <module> main() File evaluate_spect.py, line 51, in main pred_audio = torchaudio.transforms.GriffinLim(n_fft=256)(inverse_mel_pred) File <*>python3.8/site-packages/torch/nn/modules/module.py, line 727, in _call_impl result = self.forward(*input, **kwargs) File <*>python3.8/site-packages/torchaudio/transforms.py, line 169, in forward return F.griffinlim(specgram, self.window, self.n_fft, self.hop_length, self.win_length, self.power, File <*>python3.8/site-packages/torchaudio/functional.py, line 179, in griffinlim inverse = torch.istft(specgram * angles, RuntimeError: The size of tensor a (256) must match the size of tensor b (129) at non-singleton dimension 1",0
"File [FILE], line 1, in <module>() import input_data ImportError: No module named input_data",0
"File [FILE], line 1, in <module>() T.grad(cost=cost, wrt=reg.weights) File <*>python2.7/site-packages/theano/gradient.pyc, line 432, in grad(c ost, wrt, consider_constant, disconnected_inputs, add_names, known_grads, return_disconnected ) raise TypeError(""cost must be a scalar."") TypeError: cost must be a scalar.",0
"File [FILE], line 10, in <module>() left.save('left.h5') # creates a HDF5 file 'my_model.h5' File <*>python3.4/dist-packages/keras/engine/topology.py, line 2506, in save(self, filepath, overwrite, include_optimizer) save_model(self, filepath, overwrite, include_optimizer) File <*>python3.4/dist-packages/keras/models.py, line 55, in save_model(model, filepath, overwrite, include_optimizer) raise ImportError('`save_model` requires h5py.') ImportError: `save_model` requires h5py.",0
"File <*>python3.5/site-packages/keras/utils/vis_utils.py, line 27, in _check_pydot() raise ImportError('Failed to import pydot. You must install pydot' AttributeError: 'NoneType' object has no attribute 'Dot'",0
"File [FILE], line 4, in <module>() (x_train, y_train), (x_test, y_test) = mnist.load_data() File <*>python3.6/site-packages/keras/datasets/mnist.py, line 23, in load_data(path) file_hash='8a61469f7ea1b51cbae51d4f78837e45') File <*>python3.6/site-packages/keras/utils/data_utils.py, line 224, in get_file(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir) raise Exception(error_msg.format(origin, e.errno, e.reason)) Exception: URL fetch failure on https://s3.amazonaws.com/img-datasets/mnist.npz: None -- [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1327, in _do_call(self, fn, *args) return fn(*args) File <*>/site-packages/tensorflow/python/client/session.py, line 1306, in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata) status, run_metadata) File <*>/contextlib.py, line 89, in __exit__(self, type, value, traceback) next(self.gen) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 466, in raise_exception_on_not_ok_status() pywrap_tensorflow.TF_GetCode(status)) InvalidArgumentError: You must feed a value for placeholder tensor 'dense_84_target' with dtype float and shape [?,?] [[Node: dense_84_target = Placeholder[dtype=DT_FLOAT, shape=[?,?], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]",0
"File [FILE], line 49, in <module>() sess.run(train_iter) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 900, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1120, in _run(self, handle, fetches, feed_dict, options, run_metadata) self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 427, in __init__(self, graph, fetches, feeds, feed_handles) self._fetch_mapper = _FetchMapper.for_fetch(fetches) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 253, in for_fetch(fetch) return _ElementFetchMapper(fetches, contraction_fn) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 286, in __init__(self, fetches, contraction_fn) (fetch, type(fetch), str(e))) TypeError: Fetch argument <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x7fa2c0697c88> has invalid type <class 'tensorflow.python.data.ops.iterator_ops.Iterator'>, must be a string or Tensor. (Can not convert a Iterator into a Tensor or Operation.)",0
"File [FILE], line 16, in <module>() grads = grad(model, x, y) File [FILE], line 8, in grad(model, inputs, targets) return tape.gradient(loss_value, model.variables) File <*>/site-packages/tensorflow/python/eager/backprop.py, line 767, in gradient(self, target, sources, output_gradients) output_gradients=output_gradients) File <*>/site-packages/tensorflow/python/eager/imperative_grad.py, line 63, in imperative_grad(vspace, tape, target, sources, output_gradients) tape._tape, vspace, target, sources, output_gradients) # pylint: disable=protected-access RuntimeError: Trying to call tape.gradient on a non-persistent tape while it is still active.",0
"File [FILE], line 1, in <module>() df = pd.DataFrame((dataset)) File <*>python3.6/site-packages/pandas/core/frame.py, line 404, in __init__(self, data, index, columns, dtype, copy) raise ValueError('DataFrame constructor not properly called!') ValueError: DataFrame constructor not properly called!",0
"File [FILE], line 116, in <module>() print('Test_accuracy : ',sess.run(accuracy, feed_dict={input: x, output: y,keep_prob:1.0})) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 908, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1143, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1324, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1343, in _do_call(self, fn, *args) raise type(e)(node_def, op, message) FailedPreconditionError: Attempting to use uninitialized value W_4 [[Node: W_4/read = Identity[T=DT_FLOAT, _class=[""loc:@W_4""], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](W_4)]]",0
"File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 510, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype) File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1144, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 981, in _TensorTensorConversionFunction(t, dtype, name, as_ref) (dtype.name, t.dtype.name, str(t))) ValueError: Tensor conversion requested dtype float16 for Tensor with dtype float32: 'Tensor(""sampled_softmax_loss/Log:0"", shape=(64, 1), dtype=float32)'",0
"File [FILE], line 5, in <module>() for i, data in enumerate(trainloader, 0): File <*>python3.7/site-packages/torch/utils/data/dataloader.py, line 313, in __next__(self) indices = next(self.sample_iter) # may raise StopIteration File <*>python3.7/site-packages/torch/utils/data/sampler.py, line 138, in __iter__(self) for idx in self.sampler: File <*>python3.7/site-packages/torch/utils/data/sampler.py, line 34, in __iter__(self) return iter(range(len(self.data_source))) TypeError: 'torch.Size' object cannot be interpreted as an integer",0
"File [FILE], line 4, in <module>() module_spec=""https://tfhub.dev/google/nnlm-en-dim128/1"") File <*>python3.6/site-packages/tensorflow_hub/feature_column.py, line 74, in text_embedding_column(key, module_spec, trainable) module_spec = module.as_module_spec(module_spec) File <*>python3.6/site-packages/tensorflow_hub/module.py, line 33, in as_module_spec(spec) return load_module_spec(spec) File <*>python3.6/site-packages/tensorflow_hub/module.py, line 58, in load_module_spec(path) return registry.loader(path) File <*>python3.6/site-packages/tensorflow_hub/registry.py, line 45, in __call__(self, *args, **kwargs) self._name, args, kwargs)) RuntimeError: Missing implementation that supports: loader(*('/var/folders/pc/h0fr0z2x1pjbmdb63mhn84_w0000gn/T/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997',), **{})",0
"File [FILE], line 1, in <module> tflite_quantized_model = converter.convert() File <*>python3.5/site-packages/tensorflow/contrib/lite/python/lite.py, line 453, in convert(self) **converter_kwargs) File <*>python3.5/site-packages/tensorflow/contrib/lite/python/convert.py, line 342, in toco_convert_impl(input_data, input_tensors, output_tensors, *args, **kwargs) input_data.SerializeToString()) File <*>python3.5/site-packages/tensorflow/contrib/lite/python/convert.py, line 135, in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str) (stdout, stderr)) RuntimeError: TOCO failed see console for info.",0
"File [FILE], line 34, in <module>() train_op.minimize(cost, var_list=[w]) File <*>python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py, line 296, in minimize(self, loss, var_list, grad_loss, name) loss, var_list=var_list, grad_loss=grad_loss) File <*>python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py, line 328, in _compute_gradients(self, loss, var_list, grad_loss) loss_value = loss() TypeError: 'tensorflow.python.framework.ops.EagerTensor' object is not callable",0
"File [FILE], line 4, in <module>() validation_steps=10, verbose=1, callbacks=[lr_reduction]) File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/training.py, line 1418, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) initial_epoch=initial_epoch) File <*>python3.6/site-packages/keras/engine/training_generator.py, line 181, in fit_generator(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) generator_output = next(output_generator) File <*>python3.6/site-packages/keras/utils/data_utils.py, line 601, in get(self) six.reraise(*sys.exc_info()) File <*>python3.6/site-packages/six.py, line 693, in reraise(tp, value, tb) raise value File <*>python3.6/site-packages/keras/utils/data_utils.py, line 595, in get(self) inputs = self.queue.get(block=True).get() File <*>python3.6/pool.py, line 644, in get(self, timeout) raise self._value File <*>python3.6/pool.py, line 119, in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception) result = (True, func(*args, **kwds)) File <*>python3.6/site-packages/keras/utils/data_utils.py, line 401, in get_index(uid, i) return _SHARED_SEQUENCES[uid][i] File <*>python3.6/site-packages/keras_preprocessing/image/iterator.py, line 65, in __getitem__(self, idx) return self._get_batches_of_transformed_samples(index_array) File <*>python3.6/site-packages/keras_preprocessing/image/iterator.py, line 235, in _get_batches_of_transformed_samples(self, index_array) x = self.image_data_generator.standardize(x) File <*>python3.6/site-packages/keras_preprocessing/image/image_data_generator.py, line 697, in standardize(self, x) x = self.preprocessing_function(x) File [FILE], line 2, in preprocess(im) im = cv2.imread(im, 1) TypeError: bad argument type for built-in operation",0
"File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1659, in _create_c_op(graph, node_def, inputs, control_inputs) c_op = c_api.TF_FinishOperation(op_desc) InvalidArgumentError: Shapes must be equal rank, but are 2 and 3 for 'ScatterUpdate' (op: 'ScatterUpdate') with input shapes: [?,10], [?,2], [?,2].",0
"File [FILE], line 29, in <module>() output_data = top_n_filter_layer(input_layer) File [FILE], line 20, in top_n_filter_layer(input_data, n, tf_dtype) output = tf.scatter_update(zeros_variable, indices_to_keep, values_to_keep) File <*>python3.6/site-packages/tensorflow/python/ops/state_ops.py, line 299, in scatter_update(ref, indices, updates, use_locking, name) use_locking=use_locking, name=name) File <*>python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py, line 1275, in scatter_update(ref, indices, updates, use_locking, name) use_locking=use_locking, name=name) File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 788, in _apply_op_helper(self, op_type_name, name, **keywords) op_def=op_def) File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func(*args, **kwargs) return func(*args, **kwargs) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3300, in create_op(***failed resolving arguments***) op_def=op_def) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1823, in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def) control_input_ops) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1662, in _create_c_op(graph, node_def, inputs, control_inputs) raise ValueError(str(e)) ValueError: Shapes must be equal rank, but are 2 and 3 for 'ScatterUpdate' (op: 'ScatterUpdate') with input shapes: [?,10], [?,2], [?,2].",0
"File [FILE], line 70, in <module>() filtered_output = keras.layers.merge.Multiply()([output, actions_input]) File <*>python3.6/dist-packages/keras/layers/merge.py, line 61, in _compute_elemwise_op_output_shape(self, shape1, shape2) str(shape1) + ' ' + str(shape2)) ValueError: Operands could not be broadcast together with shapes (2592,) (4,)",0
"File [FILE], line 22, in <module> dydx = tape.gradient(y, YIELDS) File <*>/site-packages/tensorflow/python/eager/backprop.py, line 1002, in gradient(self, target, sources, output_gradients, unconnected_gradients) unconnected_gradients=unconnected_gradients) File <*>/site-packages/tensorflow/python/eager/imperative_grad.py, line 76, in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients) compat.as_str(unconnected_gradients.value)) File <*>/site-packages/tensorflow/python/eager/function.py, line 906, in backward_function(*args) list(args) + side_outputs) File <*>/site-packages/tensorflow/python/eager/function.py, line 612, in _call_flat(self, args) ""but got CompositeTensor: %r"" % args) AssertionError: Expected all args to be Tensors or Variables; but got CompositeTensor: [<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x00000203013C2128>, <tf.Tensor: id=1024, shape=(), dtype=float32, numpy=-1.0>, <tf.Tensor: id=1025, shape=(10,), dtype=float32, numpy= array([0.04153733, 0.0851776 , 0.13988876, 0.27034396, 0.40101147, dtype=float32)>, <tf.Tensor: id=1026, shape=(10,), dtype=float32, numpy=array([ 1., 2., 3., 5., 7., 10., 12., 15., 20., 25.], dtype=float32)>, <tf.Tensor: id=1027, shape=(10,), dtype=float32, numpy= array([0.04153733, 0.0425888 , 0.04662959, 0.05406879, 0.05728735, dtype=float32)>]",0
"File [FILE], line 16, in <module> print(stock_prediction()) File [FILE], line 25, in stock_prediction() model.fit(trainX, trainY, batch_size=1, epochs=200, verbose=2) File <*>/site-packages/keras/engine/training.py, line 1178, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) validation_freq=validation_freq) File <*>/site-packages/keras/engine/training_arrays.py, line 213, in fit_loop(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq) if batch_index == len(batches) - 1: # Last batch. UnboundLocalError: local variable 'batch_index' referenced before assignment",0
"File [FILE], line 8, in <module> print (sess.run(c)) File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 950, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr) File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1173, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata) File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1350, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata) File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1370, in _do_call(self, fn, *args) raise type(e)(node_def, op, message) InvalidArgumentError: Cannot assign a device for operation MatMul: node MatMul (defined at <ipython-input-9-b145a02709f7>:5) was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.",0
"File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 2897, in get_loc(self, key, method, tolerance) return self._engine.get_loc(key) File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE] File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE] KeyError: 40592",0
"File [FILE], line 24, in <module> loaded_regressor.load_weights(latest_checkpoint(checkpoint_path)) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 162, in load_weights(self, filepath, by_name) return super(Model, self).load_weights(filepath, by_name) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/network.py, line 1377, in load_weights(self, filepath, by_name) if _is_hdf5_filepath(filepath): File <*>python3.6/dist-packages/tensorflow/python/keras/engine/network.py, line 1672, in _is_hdf5_filepath(filepath) return (filepath.endswith('.h5') or filepath.endswith('.keras') or AttributeError: 'NoneType' object has no attribute 'endswith'",0
"File [FILE], line 10, in <module>() scan_object = ta.Scan(x_train, y_train, params=p, model=iris_model, experiment_name='test', x_val=x_val, y_val=y_val, fraction_limit=0.1) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 2309, in _distribution_standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, validation_split, shuffle, epochs, allow_partial_batch) if dataset_size % batch_size == 0: TypeError: unsupported operand type(s) for %: 'int' and 'NoneType'",0
"File [FILE], line 1, in <module>() learn.lr_find() File <*>python3.6/dist-packages/fastai/train.py, line 41, in lr_find(learn, start_lr, end_lr, num_it, stop_div, wd) learn.fit(epochs, start_lr, callbacks=[cb], wd=wd) File <*>python3.6/dist-packages/fastai/basic_train.py, line 200, in fit(self, epochs, lr, wd, callbacks) fit(epochs, self, metrics=self.metrics, callbacks=self.callbacks+callbacks) File <*>python3.6/dist-packages/fastai/basic_train.py, line 101, in fit(epochs, learn, callbacks, metrics) loss = loss_batch(learn.model, xb, yb, learn.loss_func, learn.opt, cb_handler) File <*>python3.6/dist-packages/fastai/basic_train.py, line 30, in loss_batch(model, xb, yb, loss_func, opt, cb_handler) loss = loss_func(out, *yb) File <*>python3.6/dist-packages/fastai/layers.py, line 243, in __call__(self, input, target, **kwargs) return self.func.__call__(input, target.view(-1), **kwargs) File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.6/dist-packages/torch/nn/modules/loss.py, line 916, in forward(self, input, target) ignore_index=self.ignore_index, reduction=self.reduction) File <*>python3.6/dist-packages/torch/nn/functional.py, line 2009, in cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction) return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction) File <*>python3.6/dist-packages/torch/nn/functional.py, line 1838, in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction) ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index) RuntimeError: Assertion `cur_target >= 0 &amp;&amp; cur_target < n_classes' failed. at /pytorch/aten/src/THNN/generic/ClassNLLCriterion.c:97",0
"File [FILE], line 1, in <module> foo[0] TypeError: 'TakeDataset' object does not support indexing",0
"File [FILE], line 2, in <module> (X_train_full, y_train_full), (X_test, y_test) = (fashion_mnist) TypeError: cannot unpack non-iterable module object",0
"File [FILE], line 7, in <module>() loss_log = train(net, train_set, EPOCHS, LEARNING_RATE, BATCH_SIZE) File [FILE], line 15, in train(net, training_set, EPOCHS, LEARNING_RATE, BATCH_SIZE) output, sm = net(x_batch) File [FILE], line 43, in forward(self, x) x = self.convs(x) File [FILE], line 33, in convs(self, x) x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=(2, 2)) File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.6/dist-packages/torch/nn/modules/conv.py, line 345, in forward(self, input) return self.conv2d_forward(input, self.weight) File <*>python3.6/dist-packages/torch/nn/modules/conv.py, line 342, in conv2d_forward(self, input, weight) self.padding, self.dilation, self.groups) RuntimeError: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same",0
"File <*>/site-packages/tensorflow_datasets/core/download/extractor.py, line 89, in _sync_extract(self, from_path, method, to_path) for path, handle in iter_archive(from_path, method): File <*>/site-packages/tensorflow_datasets/core/download/extractor.py, line 177, in iter_zip(arch_f) z = zipfile.ZipFile(fobj) File <*>/zipfile.py, line 1131, in __init__(self, file, mode, compression, allowZip64) self._RealGetContents() File <*>/zipfile.py, line 1194, in _RealGetContents(self) endrec = _EndRecData(fp) File <*>/zipfile.py, line 264, in _EndRecData(fpin) fpin.seek(0, 2) File <*>/site-packages/tensorflow_core/python/util/deprecation.py, line 507, in new_func(*args, **kwargs) return func(*args, **kwargs) File <*>/site-packages/tensorflow_core/python/lib/io/file_io.py, line 167, in seek(self, offset, whence, position) offset += self.size() File <*>/site-packages/tensorflow_core/python/lib/io/file_io.py, line 102, in size(self) return stat(self.__name).length File <*>/site-packages/tensorflow_core/python/lib/io/file_io.py, line 727, in stat(filename) return stat_v2(filename) File <*>/site-packages/tensorflow_core/python/lib/io/file_io.py, line 744, in stat_v2(path) pywrap_tensorflow.Stat(compat.as_bytes(path), file_statistics) OutOfRangeError: C:\Users\%user%\tensorflow_datasets\downloads\images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip; Unknown error",0
"File [FILE], line 3, in <module> pooling='avg') File <*>python3.6/site-packages/keras/applications/__init__.py, line 20, in wrapper(*args, **kwargs) return base_fun(*args, **kwargs) File <*>python3.6/site-packages/keras/applications/resnet.py, line 14, in ResNet50(*args, **kwargs) return resnet.ResNet50(*args, **kwargs) File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 435, in ResNet50(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs) **kwargs) File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 413, in ResNet(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs) model.load_weights(weights) File <*>python3.6/site-packages/keras/engine/saving.py, line 492, in load_wrapper(*args, **kwargs) return load_function(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/network.py, line 1230, in load_weights(self, filepath, by_name, skip_mismatch, reshape) f, self.layers, reshape=reshape) File <*>python3.6/site-packages/keras/engine/saving.py, line 1237, in load_weights_from_hdf5_group(f, layers, reshape) K.batch_set_value(weight_value_tuples) File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 2960, in batch_set_value(tuples) tf_keras_backend.batch_set_value(tuples) File <*>python3.6/site-packages/tensorflow_core/python/keras/backend.py, line 3323, in batch_set_value(tuples) x.assign(np.asarray(value, dtype=dtype(x))) File <*>python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py, line 819, in assign(self, value, use_locking, name, read_value) self._shape.assert_is_compatible_with(value_tensor.shape) File <*>python3.6/site-packages/tensorflow_core/python/framework/tensor_shape.py, line 1110, in assert_is_compatible_with(self, other) raise ValueError(""Shapes %s and %s are incompatible"" % (self, other)) ValueError: Shapes (1, 1, 256, 512) and (512, 128, 1, 1) are incompatible",0
"File [FILE], line 26, in <module>() images, labels = next(iter(train_loader)) File <*>python3.6/dist-packages/torch/utils/data/dataloader.py, line 345, in __next__(self) data = self._next_data() File <*>python3.6/dist-packages/torch/utils/data/dataloader.py, line 385, in _next_data(self) data = self._dataset_fetcher.fetch(index) # may raise StopIteration File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch(self, possibly_batched_index) data = [self.dataset[idx] for idx in possibly_batched_index] File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp>(.0) data = [self.dataset[idx] for idx in possibly_batched_index] File <*>python3.6/dist-packages/torchvision/datasets/mnist.py, line 97, in __getitem__(self, index) img = self.transform(img) File <*>python3.6/dist-packages/torchvision/transforms/transforms.py, line 70, in __call__(self, img) img = t(img) File <*>python3.6/dist-packages/torchvision/transforms/transforms.py, line 1003, in __call__(self, img) return F.rotate(img, angle, self.resample, self.expand, self.center, self.fill) File <*>python3.6/dist-packages/torchvision/transforms/functional.py, line 729, in rotate(img, angle, resample, expand, center, fill) return img.rotate(angle, resample, expand, center, fillcolor=fill) File <*>python3.6/dist-packages/PIL/Image.py, line 2005, in rotate(self, angle, resample, expand, center, translate, fillcolor) return self.transform((w, h), AFFINE, matrix, resample, fillcolor=fillcolor) File <*>python3.6/dist-packages/PIL/Image.py, line 2299, in transform(self, size, method, data, resample, fill, fillcolor) im = new(self.mode, size, fillcolor) File <*>python3.6/dist-packages/PIL/Image.py, line 2505, in new(mode, size, color) return im._new(core.fill(mode, size, color)) TypeError: function takes exactly 1 argument (3 given)",0
"File [FILE], line 6, in <module> num_epochs=25) File [FILE], line 33, in train_model(model, criterion, optimizer, scheduler, num_epochs) _, preds = torch.max(outputs, 1) TypeError: max() received an invalid combination of arguments - got (Linear, int), but expected one of: * (Tensor input) * (Tensor input, name dim, bool keepdim, tuple of Tensors out) * (Tensor input, Tensor other, Tensor out) * (Tensor input, int dim, bool keepdim, tuple of Tensors out)",0
"File [FILE], line 8, in <module> layers['flatten'] = nn.Flatten() AttributeError: module 'torch.nn' has no attribute 'Flatten'",0
"File [FILE], line 13, in <module>() validation_steps = validation_steps, File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e) ValueError: in user code: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function * outputs = self.distribute_strategy.run( /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run ** return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica return fn(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step ** y, y_pred, sample_weight, regularization_losses=self.losses) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__ loss_value = loss_obj(y_t, y_p, sample_weight=sw) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:143 __call__ losses = self.call(y_true, y_pred) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:246 call return self.fn(y_true, y_pred, **self._fn_kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1527 categorical_crossentropy return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4561 categorical_crossentropy target.shape.assert_is_compatible_with(output.shape) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1117 assert_is_compatible_with raise ValueError(""Shapes %s and %s are incompatible"" % (self, other)) ValueError: Shapes (None, 1) and (None, 2) are incompatible",0
"File [FILE], line 1, in <module>() model.fit(train_dataset, epochs=15) File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e) TypeError: in user code: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function * outputs = self.distribute_strategy.run( /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run ** return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica return fn(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step ** y, y_pred, sample_weight, regularization_losses=self.losses) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__ loss_value = loss_obj(y_t, y_p, sample_weight=sw) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:145 __call__ losses, sample_weight, reduction=self._get_reduction()) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:104 compute_weighted_loss losses = ops.convert_to_tensor_v2(losses) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1283 convert_to_tensor_v2 as_ref=False) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1341 convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:321 _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:262 constant allow_broadcast=True) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:300 _constant_impl allow_broadcast=allow_broadcast)) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py:547 make_tensor_proto ""supported type."" % (type(values), values)) TypeError: Failed to convert object of type <class 'tensorflow.python.keras.losses.BinaryCrossentropy'> to Tensor. Contents: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f76215279b0>. Consider casting elements to a supported type.",0
"File [FILE], line 8, in <module>() h = model.fit(x_train, y_train, epochs=10, batch_size=256) File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e) ValueError: in user code: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function * outputs = self.distribute_strategy.run( /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run ** return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica return fn(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step ** y, y_pred, sample_weight, regularization_losses=self.losses) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__ loss_value = loss_obj(y_t, y_p, sample_weight=sw) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:143 __call__ losses = self.call(y_true, y_pred) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:246 call return self.fn(y_true, y_pred, **self._fn_kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1527 categorical_crossentropy return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4561 categorical_crossentropy target.shape.assert_is_compatible_with(output.shape) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1117 assert_is_compatible_with raise ValueError(""Shapes %s and %s are incompatible"" % (self, other)) ValueError: Shapes (None, 1) and (None, 10) are incompatible",0
"File [FILE], line 5, in <module>() loaded_model = load_model('save_at_47.h5') File <*>python3.6/dist-packages/tensorflow/python/keras/saving/save.py, line 184, in load_model(filepath, custom_objects, compile) return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile) File <*>python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py, line 178, in load_model_from_hdf5(filepath, custom_objects, compile) custom_objects=custom_objects) File <*>python3.6/dist-packages/tensorflow/python/keras/saving/model_config.py, line 55, in model_from_config(config, custom_objects) return deserialize(config, custom_objects=custom_objects) File <*>python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py, line 109, in deserialize(config, custom_objects) printable_module_name='layer') File <*>python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py, line 362, in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name) config, module_objects, custom_objects, printable_module_name) File <*>python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py, line 321, in class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name) raise ValueError('Unknown ' + printable_module_name + ': ' + class_name) ValueError: Unknown layer: Functional",0
"File [FILE], line 1, in <module> from transformers import AutoModelWithLMHead, AutoTokenizer ImportError: cannot import name 'AutoModelWithLMHead' from 'transformers' (c:\python38\lib\site-packages\transformers\__init__.py)",0
"File [FILE], line 4, in <module>() validation_data = validation_dataset) File <*>python3.6/dist-packages/tensorflow/python/eager/def_function.py, line 807, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) # pylint: disable=not-callable TypeError: 'NoneType' object is not callable",0
"File [FILE], line 15, in <module> outi.backward(torch.tensor([0.,1.])) File <*>python3.8/site-packages/torch/tensor.py, line 185, in backward(self, gradient, retain_graph, create_graph) torch.autograd.backward(self, gradient, retain_graph, create_graph) File <*>python3.8/site-packages/torch/autograd/__init__.py, line 125, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables) Variable._execution_engine.run_backward( RuntimeError: leaf variable has been moved into the graph interior",0
"File [FILE], line 1, in <module>() model = tf.keras.models.load_model('/content/saved_models/model_best.h5',custom_objects={'TemporalReshape':TemporalReshape}) File <*>python3.6/dist-packages/tensorflow/python/keras/saving/save.py, line 182, in load_model(filepath, custom_objects, compile, options) return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile) File <*>python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py, line 178, in load_model_from_hdf5(filepath, custom_objects, compile) custom_objects=custom_objects) File <*>python3.6/dist-packages/tensorflow/python/keras/saving/model_config.py, line 55, in model_from_config(config, custom_objects) return deserialize(config, custom_objects=custom_objects) File <*>python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py, line 358, in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name) list(custom_objects.items()))) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/functional.py, line 617, in from_config(cls, config, custom_objects) config, custom_objects) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/functional.py, line 1204, in reconstruct_from_config(config, custom_objects, created_layers) process_layer(layer_data) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/functional.py, line 1186, in process_layer(layer_data) layer = deserialize_layer(layer_data, custom_objects=custom_objects) File <*>python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py, line 175, in deserialize(config, custom_objects) printable_module_name='layer') File <*>python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py, line 360, in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name) return cls.from_config(cls_config) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 697, in from_config(cls, config) return cls(**config) TypeError: __init__() got an unexpected keyword argument 'name'",0
"File <*>python3.6/dist-packages/optkeras/optkeras.py, line 367, in get_trial_default() num_fields = optuna.structs.FrozenTrial._field_types.__len__() AttributeError: type object 'FrozenTrial' has no attribute '_field_types'",0
"File [FILE], line 11, in <module> foo_test.main() File <*>/foo_test.py, line 25, in main() tf.test.main() File <*>/site-packages/tensorflow/python/platform/test.py, line 58, in main(argv) return _googletest.main(argv) File <*>/site-packages/tensorflow/python/platform/googletest.py, line 66, in main(argv) benchmark.benchmarks_main(true_main=main_wrapper) File <*>/site-packages/tensorflow/python/platform/benchmark.py, line 486, in benchmarks_main(true_main, argv) true_main() File <*>/site-packages/tensorflow/python/platform/googletest.py, line 65, in main_wrapper() return app.run(main=g_main, argv=args) File <*>/site-packages/tensorflow/python/platform/app.py, line 40, in run(main, argv) _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef) File <*>/site-packages/absl/app.py, line 303, in run(main, argv, flags_parser) _run_main(main, args) File <*>/site-packages/absl/app.py, line 251, in _run_main(main, argv) sys.exit(main(argv)) File <*>/site-packages/tensorflow/python/platform/googletest.py, line 56, in g_main(argv) absltest_main(argv=argv) File <*>/site-packages/absl/testing/absltest.py, line 2002, in main(*args, **kwargs) _run_in_app(run_tests, args, kwargs) File <*>/site-packages/absl/testing/absltest.py, line 2105, in _run_in_app(function, args, kwargs) argv = FLAGS(sys.argv) File <*>/site-packages/absl/flags/_flagvalues.py, line 654, in __call__(self, argv, known_only) raise _exceptions.UnrecognizedFlagError( UnrecognizedFlagError: Unknown command line flag 'f'",0
