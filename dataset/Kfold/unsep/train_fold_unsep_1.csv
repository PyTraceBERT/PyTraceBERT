Templates,label
"File <pyshell#146>, line 1, in <module> that[~(that>=5).nonzero()].max().eval() AttributeError: 'TensorVariable' object has no attribute 'nonzero'",1
"File <stdin>, line 1, in <module> [CODE] File <*>python2.7/site-packages/tensorflow/__init__.py, line 4, in <module> from tensorflow.python import * File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 13, in <module> from tensorflow.core.framework.graph_pb2 import * File <*>python2.7/site-packages/tensorflow/core/framework/graph_pb2.py, line 16, in <module> from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2 File <*>python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py, line 16, in <module> from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2 File <*>python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py, line 16, in <module> from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2 File <*>python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py, line 22, in <module> serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto \x12\ntensorflow\""d\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tb\x06proto3') TypeError: __init__() got an unexpected keyword argument 'syntax'",1
"File classify.py, line 14, in <module> import caffe File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver File <*>/pycaffe.py, line 13, in <module> from ._caffe import Net, SGDSolver ImportError: dynamic module does not define module export function (PyInit__caffe)",1
"File <*>python3.5/site-packages/theano/gof/opt.py, line 1772, in process_node replacements = lopt.transform(node) File <*>python3.5/site-packages/theano/sandbox/gpuarray/opt.py, line 140, in local_opt new_op = maker(node, context_name) File <*>python3.5/site-packages/theano/sandbox/gpuarray/opt.py, line 732, in local_gpua_hgemm if nvcc_compiler.nvcc_version < '7.5': TypeError: unorderable types: NoneType() < str()",1
"File <stdin>, line 1, in <module> [CODE] File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import * File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow import contrib File <*>python2.7/site-packages/tensorflow/contrib/__init__.py, line 23, in <module> from tensorflow.contrib import layers File <*>python2.7/site-packages/tensorflow/contrib/layers/__init__.py, line 68, in <module> from tensorflow.contrib.layers.python.layers import * File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/__init__.py, line 22, in <module> from tensorflow.contrib.layers.python.layers.initializers import * File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/initializers.py, line 24, in <module> from tensorflow.python.ops import random_ops File <*>python2.7/site-packages/tensorflow/python/ops/random_ops.py, line 23, in <module> from tensorflow.python.framework import ops File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 39, in <module> from tensorflow.python.framework import versions File <*>python2.7/site-packages/tensorflow/python/framework/versions.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper() File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description) ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory",1
"File <stdin>, line 1, in <module> [CODE] ImportError: No module named data_utils",1
"File <stdin>, line 1, in <module> [CODE] File <*>python2.7/site-packages/prettytensor-0.6.0-py2.7.egg/prettytensor/__init__.py, line 25, in <module> from prettytensor import funcs File <*>python2.7/site-packages/prettytensor-0.6.0-py2.7.egg/prettytensor/funcs.py, line 25, in <module> from prettytensor.pretty_tensor_image_methods import * File <*>python2.7/site-packages/prettytensor-0.6.0-py2.7.egg/prettytensor/pretty_tensor_image_methods.py, line 20, in <module> from prettytensor import layers ImportError: cannot import name layers",1
"File <*>/fully_connected_feed.py, line 27, in [FUNC] [CODE] File <*>/input_data.py, line 29, in [FUNC] [CODE] ImportError: No module named contrib.learn.python.learn.datasets.mnist",1
"File <stdin>, line 1, in <module> [CODE] File <*>python2.7/site-packages/tflearn/__init__.py, line 22, in <module> from . import activations File <*>python2.7/site-packages/tflearn/activations.py, line 7, in <module> from . import initializations File <*>python2.7/site-packages/tflearn/initializations.py, line 5, in <module> from tensorflow.contrib.layers.python.layers.initializers import \ ImportError: cannot import name variance_scaling_initializer",1
"File <*>/worker.py, line 98, in main command = pickleSer._read_with_length(infile) File <*>/serializers.py, line 164, in _read_with_length return self.loads(obj) File <*>/serializers.py, line 422, in loads return pickle.loads(obj) File <*>python2.7/site-packages/six.py, line 118, in __getattr__ _module = self._resolve() File <*>python2.7/site-packages/six.py, line 115, in _resolve return _import_module(self.mod) RuntimeError: maximum recursion depth exceeded",1
"File <stdin>, line 1, in <module> [CODE] File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import * File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 48, in <module> from tensorflow.python import pywrap_tensorflow File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper() File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description) ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.19' not found (required by /home/anirudh/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so)",1
"File <*>/census.py, line 73, in <module> df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int) File <*>python2.7/dist-packages/pandas/core/series.py, line 2023, in apply mapped = lib.map_infer(values, f, convert=convert_dtype) File inference.pyx, line 920, in pandas.lib.map_infer (pandas/lib.c:44780) File <*>/census.py, line 73, in <lambda> df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int) TypeError: argument of type 'float' is not iterable",1
"File <pyshell#0>, line 1, in <module> from keras.layers import Dense ImportError: cannot import name 'Dense'",1
"File mnist_softmax.py, line 78, in <module> tf.app.run(main=main, argv=[sys.argv[0]] + unparsed) TypeError: run() got an unexpected keyword argument 'argv'",1
"File [FILE], line 4, in `<module>`() tf.global_variables_initializer().run() AttributeError: 'module' object has no attribute 'global_variables_initializer'",1
"File <*>python3.5/site-packages/keras/backend/tensorflow_backend.py, line 5, in <module>() from tensorflow.python.ops import ctc_ops as ctc ImportError: cannot import name 'ctc_ops'",1
"File [FILE], line 1, in <module>() import keras File <*>python3.5/site-packages/keras/__init__.py, line 2, in <module>() from . import backend File <*>python3.5/site-packages/keras/backend/__init__.py, line 69, in <module>() from .tensorflow_backend import * File <*>python3.5/site-packages/keras/backend/tensorflow_backend.py, line 7, in <module>() import tensorflow.contrib.ctc as ctc ImportError: No module named 'tensorflow.contrib.ctc'",1
"File <*>/test3.py, line 5, in [FUNC] [CODE] AttributeError: module 'tensorflow.contrib.learn' has no attribute 'TensorFlowDNNClassifier'",1
"File [FILE], line 1, in <module>() writer = tf.train.SummaryWriter('./my_graph', sess.graph) AttributeError: 'module' object has no attribute 'SummaryWriter'",1
"File [FILE], line 1, in <module>() writer = tf.train.FileWriter('./my_graph', sess.graph) AttributeError: 'module' object has no attribute 'FileWriter'",1
"File <stdin>, line 1, in <module> [CODE] AttributeError: 'module' object has no attribute 'FileWriter'",1
"File DA_test_pred.py, line 24, in <module> logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False) File <*>/inception_v1.py, line 290, in inception_v1 net, end_points = inception_v1_base(inputs, scope=scope) File <*>/inception_v1.py, line 96, in inception_v1_base net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3]) File <*>python2.7/dist-packages/tensorflow/python/ops/array_ops.py, line 1053, in concat dtype=dtypes.int32).get_shape( File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 651, in convert_to_tensor as_ref=False) File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 716, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python2.7/dist-packages/tensorflow/python/framework/constant_op.py, line 176, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name) File <*>python2.7/dist-packages/tensorflow/python/framework/constant_op.py, line 165, in constant tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape)) File <*>python2.7/dist-packages/tensorflow/python/framework/tensor_util.py, line 367, in make_tensor_proto _AssertCompatible(values, dtype) File <*>python2.7/dist-packages/tensorflow/python/framework/tensor_util.py, line 302, in _AssertCompatible (dtype.name, repr(mismatch), type(mismatch).__name__)) TypeError: Expected int32, got list containing Tensors of type '_Message' instead.",1
"File <*>python2.7/dist-packages/pip/basecommand.py, line 122, in main status = self.run(options, args) File <*>python2.7/dist-packages/pip/commands/install.py, line 278, in run requirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle) File /usr/lib/python2.7/dist-packages/pip/req.py, line 1178, in prepare_files url = finder.find_requirement(req_to_install, upgrade=self.upgrade)",1
"File ptb_word_lm.py, line 374, in <module> tf.app.run() File <*>python3.6/site-packages/tensorflow/python/platform/app.py, line 43, in run sys.exit(main(sys.argv[:1] + flags_passthrough)) File ptb_word_lm.py, line 334, in main train_input = PTBInput(config=config, data=train_data, name=""TrainInput"") File ptb_word_lm.py, line 94, in __init__ data, batch_size, num_steps, name=name) File <*>/reader.py, line 117, in ptb_producer [batch_size, (i + 1) * num_steps]) TypeError: strided_slice() missing 1 required positional argument: 'strides'",1
"File mnist_test.py, line 19, in <module> cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_, logits=y) TypeError: sigmoid_cross_entropy_with_logits() got an unexpected keyword argument 'labels'",1
"File <*>python3.6/site-packages/theano/gof/opt.py, line 1772, in process_node replacements = lopt.transform(node) File <*>python3.6/site-packages/theano/tensor/opt.py, line 5825, in constant_folding no_recycling=[]) File <*>python3.6/site-packages/theano/gof/op.py, line 970, in make_thunk no_recycling) File <*>python3.6/site-packages/theano/gof/op.py, line 879, in make_c_thunk output_storage=node_output_storage) File <*>python3.6/site-packages/theano/gof/cc.py, line 1200, in make_thunk keep_lock=keep_lock) File <*>python3.6/site-packages/theano/gof/cc.py, line 1143, in __compile__ keep_lock=keep_lock) File <*>python3.6/site-packages/theano/gof/cc.py, line 1595, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock) File <*>python3.6/site-packages/theano/gof/cmodule.py, line 1142, in module_from_key module = lnk.compile_cmodule(location) File <*>python3.6/site-packages/theano/gof/cc.py, line 1506, in compile_cmodule preargs=preargs) File <*>python3.6/site-packages/theano/gof/cmodule.py, line 2213, in compile_str return dlimport(lib_filename) File <*>python3.6/site-packages/theano/gof/cmodule.py, line 299, in dlimport rval = __import__(module_name, {}, {}, [module_name]) ImportError: /home/puck/.theano/compiledir_Linux-4.4--MANJARO-x86_64-with-glibc2.2.5--3.6.0-64/tmpre6vph8g/mdb219947724f79219f7dbd36f0f52c77.so: undefined symbol: _ZdlPvm",1
"File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 61, in <module> from tensorflow.python import pywrap_tensorflow File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper() File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description) ImportError: dlopen(/Users/smahesh/src/tensorflow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.8.0.dylib",1
"File cnn.py, line 258, in <module> models = run_cross_validation_create_models(num_folds) File cnn.py, line 205, in run_cross_validation_create_models validation_data=(X_valid, Y_valid)) TypeError: fit_generator() takes at least 4 arguments (5 given)",1
"File <*>/test_model.py, line 2, in <module> from models import NN_with_EntityEmbedding File <*>/models.py, line 8, in <module> from keras.layers.core import Dense, Dropout, Activation, Merge, Reshape ImportError: cannot import name Merge",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper() return importlib.import_module(mname) File <*>/importlib__init__.py, line 126, in import_module(name, package) return _bootstrap._gcd_import(name[level:], package, level) File <*>/importlib_bootstrap.py, line [NUM], in _gcd_import(name, package, level) [CODE] File <*>/importlib_bootstrap.py, line [NUM], in _find_and_load(name, import_) [CODE] File <*>/importlib_bootstrap.py, line [NUM], in _find_and_load_unlocked(name, import_) [CODE] File <*>/importlib_bootstrap.py, line [NUM], in _load_unlocked(spec) [CODE] File <*>/importlib_bootstrap.py, line [NUM], in module_from_spec(spec ) [CODE] File <*>/importlib_bootstrap_external.py, line [NUM], in create_module(self, spec) [CODE] File <*>/importlib_bootstrap.py, line [NUM], in _call_with_frames_removed(f, *args, **kwds) [CODE] ImportError: DLL load failed: The specified module could not be found.",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in () from tensorflow.python.pywrap_tensorflow_internal import * File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in () _pywrap_tensorflow_internal = swig_import_helper() File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper() return importlib.import_module('_pywrap_tensorflow_internal' ) File <*>/importlib__init__.py, line 126, in import_module(name, pac kage) return _bootstrap._gcd_import(name[level:], package, level) ImportError: No module named '_pywrap_tensorflow_internal'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper return importlib.import_module(mname) File <*>/importlib__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File [FILE], line 126, in [FUNC] [CODE] ImportError: DLL load failed: The specified module could not be found.",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in from tensorflow.python.pywrap_tensorflow_internal import * File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in _pywrap_tensorflow_internal = swig_import_helper() File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal') File <*>/importlib__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) ImportError: No module named '_pywrap_tensorflow_internal'",1
"File <*>python3.5/site-packages/tensorflow/python/framework/op_def_library.py, line 491, in apply_op(self, op_type_name, name, **keywords) preferred_dtype=default_dtype) File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 704, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 577, in _TensorTensorConversionFunction(t, dtype, name, as_ref) % (dtype.name, t.dtype.name, str(t))) ValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(""nce_loss/Reshape_1:0"", shape=(?, 1, ?), dtype=float32)'",1
"File [FILE], line 44, in <module>() num_sampled, vocabulary_size)) File <*>python3.5/site-packages/tensorflow/python/ops/nn_impl.py, line 1166, in nce_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name) name=name) File <*>python3.5/site-packages/tensorflow/python/ops/nn_impl.py, line 1001, in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name) array_ops.reshape(true_w, new_true_w_shape)) File <*>python3.5/site-packages/tensorflow/python/ops/math_ops.py, line 278, in multiply(x, y, name) return gen_math_ops._mul(x, y, name) File <*>python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py, line 1434, in _mul(x, y, name) result = _op_def_lib.apply_op(""Mul"", x=x, y=y, name=name) File <*>python3.5/site-packages/tensorflow/python/framework/op_def_library.py, line 527, in apply_op(self, op_type_name, name, **keywords) inferred_from[input_arg.type_attr])) TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int32 of argument 'x'.",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper return importlib.import_module(mname) File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File <frozen importlib._bootstrap>, line 986, in _gcd_import [CODE] File <frozen importlib._bootstrap>, line 969, in _find_and_load [CODE] File <frozen importlib._bootstrap>, line 958, in _find_and_load_unlocked [CODE] File <frozen importlib._bootstrap>, line 666, in _load_unlocked [CODE] File <frozen importlib._bootstrap>, line 577, in module_from_spec [CODE] File <frozen importlib._bootstrap_external>, line 906, in create_module [CODE] File <frozen importlib._bootstrap>, line 222, in _call_with_frames_removed [CODE] ImportError: DLL load failed: The specified module could not be found.",1
"File <*>/tensorboard, line 7, in <module> from tensorflow.tensorboard.tensorboard import main ModuleNotFoundError: No module named 'tensorflow.tensorboard.tensorboard'",1
"File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) ImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory Failed to load the native TensorFlow runtime.",1
"File <*>/running_template.py, line 65, in <module> cytoplasm_predictions = run_models_on_directory(data_location,cyto_channel_names, cyto_location, model_fn = cyto_fn,list_of_weights = list_of_cyto_weights, image_size_x = image_size_x, image_size_y = image_size_y,win_x = win_cyto, win_y = win_cyto, std = False, split = False) File <*>/cnn_functions.py, line 1491, in run_models_on_directory model = model_fn(batch_input_shape = batch_input_shape, n_features = n_features, weights_path = list_of_weights[0]) File <*>/model_zoo.py, line 528, in sparse_bn_feature_net_61x61 model.add(sparse_Convolution2D(64, 3, 3, d = d, init = init, batch_input_shape = batch_input_shape, border_mode='valid', W_regularizer = l2(reg))) File <*>python2.7/site-packages/keras/models.py, line 436, in add layer(x) File <*>python2.7/site-packages/keras/engine/topology.py, line 569, in __call__ self.build(input_shapes[0]) File <*>/cnn_functions.py, line 1012, in build self.W = self.init(self.W_shape, name='{}_W'.format(self.name)) TypeError: __call__() got an unexpected keyword argument 'name'",1
"File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in _pywrap_tensorflow_internal = swig_import_helper() File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File <*>python3.6/imp.py, line 242, in load_module return load_dynamic(name, filename, file) File <*>python3.6/imp.py, line 342, in load_dynamic return _load(spec) ImportError: dlopen(/Users/joson/tensorflow/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 10): Library not loaded: @rpath/libcublas.8.0.dylib",1
"File <string>, line 1, in <module> [CODE] File <*>python3.4/site-packages/pandas/__init__.py, line 35, in <module> ""the C extensions first."".format(module)) ImportError: C extension: numpy.core.multiarray failed to import not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.",1
"File <pyshell#6>, line 1, in <module> import tensorflow as tf File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import * File <*>/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 30, in <module> self_check.preload_check() File <*>/site-packages/tensorflow/python/platform/self_check.py, line 82, in preload_check % (build_info.cudart_dll_name, build_info.cuda_version_number)) ImportError: Could not find 'cudart64_90.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 9.0 from this URL: https://developer.nvidia.com/cuda-toolkit",1
"File <*>python2.7/runpy.py, line 174, in _run_module_as_main ""__main__"", fname, loader, pkg_name) File <*>python2.7/runpy.py, line 72, in _run_code exec code in run_globals File <*>python2.7/site-packages/object_detection/train.py, line 49, in <module> from object_detection import trainer File <*>python2.7/site-packages/object_detection/trainer.py, line 27, in <module> from object_detection.builders import preprocessor_builder File <*>python2.7/site-packages/object_detection/builders/preprocessor_builder.py, line 21, in <module> from object_detection.protos import preprocessor_pb2 File <*>python2.7/site-packages/object_detection/protos/preprocessor_pb2.py, line 71, in <module> options=None, file=DESCRIPTOR), TypeError: __new__() got an unexpected keyword argument 'file'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper return importlib.import_module(mname) File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File <frozen importlib._bootstrap>, line 994, in _gcd_import [CODE] File <frozen importlib._bootstrap>, line 971, in _find_and_load [CODE] File <frozen importlib._bootstrap>, line 955, in _find_and_load_unlocked [CODE] File <frozen importlib._bootstrap>, line 658, in _load_unlocked [CODE] File <frozen importlib._bootstrap>, line 571, in module_from_spec [CODE] File <frozen importlib._bootstrap_external>, line 922, in create_module [CODE] File <frozen importlib._bootstrap>, line 219, in _call_with_frames_removed [CODE] ImportError: DLL load failed with error code -1073741795",1
"File <stdin>, line 1, in <module> [CODE] File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer File <*>/pycaffe.py, line 15, in <module> import caffe.io File <*>/io.py, line 2, in <module> import skimage.io File <*>python3.6/site-packages/skimage/io/__init__.py, line 15, in <module> reset_plugins() File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 93, in reset_plugins _load_preferred_plugins() File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 73, in _load_preferred_plugins _set_plugin(p_type, preferred_plugins['all']) File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 85, in _set_plugin use_plugin(plugin, kind=plugin_type) File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 255, in use_plugin _load(name) File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 299, in _load fromlist=[modname]) File <*>python3.6/site-packages/skimage/io/_plugins/matplotlib_plugin.py, line 3, in <module> import matplotlib.pyplot as plt File <*>python3.6/site-packages/matplotlib/pyplot.py, line 40, in <module> from matplotlib.figure import Figure, figaspect File <*>python3.6/site-packages/matplotlib/figure.py, line 39, in <module> from matplotlib.axes import Axes, SubplotBase, subplot_class_factory File <*>python3.6/site-packages/matplotlib/axes/__init__.py, line 4, in <module> from ._subplots import * File <*>python3.6/site-packages/matplotlib/axes/_subplots.py, line 10, in <module> from matplotlib.axes._axes import Axes File <*>python3.6/site-packages/matplotlib/axes/_axes.py, line 23, in <module> import matplotlib.dates as _ # <-registers a date unit converter File <*>python3.6/site-packages/matplotlib/dates.py, line 148, in <module> from dateutil.rrule import (rrule, MO, TU, WE, TH, FR, SA, SU, YEARLY, File <*>python3.6/site-packages/dateutil/rrule.py, line 55, in [FUNC] [CODE] SyntaxError: invalid syntax",1
"File [FILE], line 9, in <module>() features, label = iter(train_dataset).next() TypeError: 'BatchDataset' object is not iterable",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 14, in swig_import_helper return importlib.import_module(mname) File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File <frozen importlib._bootstrap>, line 994, in _gcd_import [CODE] File <frozen importlib._bootstrap>, line 971, in _find_and_load [CODE] File <frozen importlib._bootstrap>, line 955, in _find_and_load_unlocked [CODE] File <frozen importlib._bootstrap>, line 658, in _load_unlocked [CODE] File <frozen importlib._bootstrap>, line 571, in module_from_spec [CODE] File <frozen importlib._bootstrap_external>, line 922, in create_module [CODE] File <frozen importlib._bootstrap>, line 219, in _call_with_frames_removed [CODE] ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.",1
"File kerasbottleneck.py, line 104, in <module> train_top_model() File kerasbottleneck.py, line 82, in train_top_model train_data = np.load(open('bottleneck_features_train.npy')) File <*>python3.6/site-packages/numpy/lib/npyio.py, line 404, in load magic = fid.read(N) File <*>python3.6/codecs.py, line 321, in decode (result, consumed) = self._buffer_decode(data, self.errors, final) UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte",1
"File <stdin>, line 1, in <module> [CODE] File <*>python3.6/site-packages/keras/models.py, line 243, in load_model model = model_from_config(model_config, custom_objects=custom_objects) File <*>python3.6/site-packages/keras/models.py, line 317, in model_from_config return layer_module.deserialize(config, custom_objects=custom_objects) File <*>python3.6/site-packages/keras/layers/__init__.py, line 55, in deserialize printable_module_name='layer') File <*>python3.6/site-packages/keras/utils/generic_utils.py, line 143, in deserialize_keras_object list(custom_objects.items()))) File <*>python3.6/site-packages/keras/models.py, line 1352, in from_config layer = layer_module.deserialize(conf, custom_objects=custom_objects) File <*>python3.6/site-packages/keras/utils/generic_utils.py, line 145, in deserialize_keras_object return cls.from_config(config['config']) File <*>python3.6/site-packages/keras/engine/topology.py, line 1269, in from_config return cls(**config) File <*>python3.6/site-packages/keras/layers/core.py, line 483, in __init__ super(Flatten, self).__init__(**kwargs) File <*>python3.6/site-packages/keras/engine/topology.py, line 292, in __init__ raise TypeError('Keyword argument not understood:', kwarg) TypeError: ('Keyword argument not understood:', 'data_format')",1
"File <stdin>, line 1, in <module> [CODE] File <*>python3.7/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import File <*>python3.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 114, in [FUNC] [CODE] SyntaxError: invalid syntax",1
"File <stdin>, line 1, in <module> [CODE] AttributeError: module 'tensorflow.python.keras.datasets.fashion_mnist' has no attribute 'load_data'",1
"File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File <*>python3.6/imp.py, line 243, in load_module return load_dynamic(name, filename, file) File <*>python3.6/imp.py, line 343, in load_dynamic return _load(spec) ImportError: dlopen(/Users/me/tensorflow/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation",1
"File [FILE], line 1, in <module>() from keras.layers import Merge ImportError: cannot import name 'Merge'",1
"File tSNE-images.py, line 95, in <module> run_tsne(images_path, output_path, tsne_dimensions, tsne_perplexity, tsne_learning_rate) File tSNE-images.py, line 75, in run_tsne images, pca_features = analyze_images(images_path) File tSNE-images.py, line 50, in analyze_images feat_extractor = Model(inputs=model.input, outputs=model.get_layer(""fc2"").output) File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/network.py, line 91, in __init__ self._init_graph_network(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/network.py, line 251, in _init_graph_network input_shapes=[x._keras_shape for x in self.inputs], File <*>python3.6/site-packages/keras/engine/network.py, line 251, in <listcomp> input_shapes=[x._keras_shape for x in self.inputs], AttributeError: 'Tensor' object has no attribute '_keras_shape'",1
"File [FILE], line 2, in <module>() from keras.utils import model_to_dot ImportError: cannot import name 'model_to_dot'",1
"File <input>, line 3, in <module> [CODE] AttributeError: 'Tensor' object has no attribute '_keras_shape'",1
"File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in make_tensor_proto str_values = [compat.as_bytes(x) for x in proto_values] File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in <listcomp> str_values = [compat.as_bytes(x) for x in proto_values] File <*>python3.6/site-packages/tensorflow/python/util/compat.py, line 61, in as_bytes (bytes_or_text,)) TypeError: Expected binary or unicode string, got {'DispositionSoldAmount': <tf.Tensor 'random_shuffle_queue_DequeueMany:4' shape=(128,) dtype=float64>}",1
"File tuto.py, line 85, in <module> estimator.train(input_fn=get_input_fn(num_epochs=None,n_batch = 128,shuffle=True),steps=1000) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 354, in train loss = self._train_model(input_fn, hooks, saving_listeners) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 1207, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 1237, in _train_model_default features, labels, model_fn_lib.ModeKeys.TRAIN, self.config) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 1195, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/, line 537, in _model_fn sparse_combiner=sparse_combiner) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/, line 215, in _linear_model_fn logits=logits) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 239, in create_estimator_spec regularization_losses)) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 1482, in _create_tpu_estimator_spec features=features, mode=mode, logits=logits, labels=labels) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 1381, in create_loss expected_labels_dimension=self._logits_dimension) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 305, in _check_dense_labels_match_logits_and_reshape labels = sparse_tensor.convert_to_tensor_or_sparse_tensor(labels) File <*>python3.6/site-packages/tensorflow/python/framework/sparse_tensor.py, line 279, in convert_to_tensor_or_sparse_tensor value, dtype=dtype, name=name) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1146, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 229, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name) File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 208, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape)) File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 531, in make_tensor_proto ""supported type."" % (type(values), values)) TypeError: Failed to convert object of type <class 'dict'> to Tensor. Contents: {'DispositionSoldAmount': <tf.Tensor 'random_shuffle_queue_DequeueMany:4' shape=(128,) dtype=float64>}. Consider casting elements to a supported type.",1
"File <*>/test_callback.py, line 34, in <module> model.evaluate_generator(generator=test_generator, steps=STEP_SIZE_TEST, callbacks=[test_callback]) File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) TypeError: evaluate_generator() got an unexpected keyword argument 'callbacks'",1
"File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File <*>python3.6/imp.py, line 243, in load_module return load_dynamic(name, filename, file) File <*>python3.6/imp.py, line 343, in load_dynamic return _load(spec) ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory",1
"File [FILE], line 2, in () model = InceptionV3(include_top=True,weights='imagenet') File <*>python3.6/site-packages/keras/applications/__init__.py, line 28, in wrapper(*args, **kwargs) return base_fun(*args, **kwargs) File <*>python3.6/site-packages/keras/applications/inception_v3.py, line 11, in InceptionV3(*args, **kwargs) return inception_v3.InceptionV3(*args, **kwargs) File <*>python3.6/site-packages/keras_applications/inception_v3.py, line 157, in InceptionV3(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs) img_input = layers.Input(shape=input_shape) File <*>python3.6/site-packages/keras/engine/input_layer.py, line 178, in Input(shape, batch_shape, name, dtype, sparse, tensor) input_tensor=tensor) File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/input_layer.py, line 39, in __init__(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name) name = prefix + '_' + str(K.get_uid(prefix)) File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 74, in get_uid(prefix) graph = tf.get_default_graph() AttributeError: module 'tensorflow' has no attribute 'get_default_graph'",1
"File <*>/train.py, line 326, in <module> batch_size=params.batch_size, is_binary=params.is_b_binary) File <*>/models.py, line 378, in g_unet i = Input(shape=(in_ch, 512, 512)) File <*>/site-packages/keras/engine/input_layer.py, line 178, in Input input_tensor=tensor) File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) File <*>/site-packages/keras/engine/input_layer.py, line 39, in __init__ name = prefix + '_' + str(K.get_uid(prefix)) File <*>/site-packages/keras/backend/tensorflow_backend.py, line 74, in get_uid graph = tf.get_default_graph() AttributeError: module 'tensorflow' has no attribute 'get_default_graph'",1
"File <*>/train.py, line 7, in <module> import models as m File <*>/models.py, line 25, in <module> K.set_image_dim_ordering('th') AttributeError: module 'tensorflow.python.keras.api._v2.keras.backend' has no attribute 'set_image_dim_ordering'",1
"File model_main.py, line 26, in <module> from object_detection import model_lib File <*>/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py, line 28, in <module> from object_detection import eval_util File <*>/site-packages/object_detection-0.1-py3.7.egg/object_detection/eval_util.py, line 35, in <module> slim = tf.contrib.slim File <*>/site-packages/tensorflow/python/util/lazy_loader.py, line 62, in __getattr__ module = self._load() File <*>/site-packages/tensorflow/python/util/lazy_loader.py, line 45, in _load module = importlib.import_module(self.__name__) File <*>/__init__.py, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level) File <*>/site-packages/tensorflow/contrib/__init__.py, line 33, in <module> from tensorflow.contrib import compiler File <*>/site-packages/tensorflow/contrib/compiler/__init__.py, line 22, in <module> from tensorflow.contrib.compiler import xla File <*>/site-packages/tensorflow/contrib/compiler/xla.py, line 22, in <module> from tensorflow.python.estimator import model_fn as model_fn_lib File <*>/site-packages/tensorflow/python/estimator/__init__.py, line 26, in <module> from tensorflow_estimator.python import estimator File <*>/site-packages/tensorflow_estimator/python/estimator/__init__.py, line 25, in <module> import tensorflow_estimator.python.estimator.estimator_lib File <*>/site-packages/tensorflow_estimator/python/estimator/estimator_lib.py, line 69, in <module> from tensorflow_estimator.python.estimator.tpu.tpu_estimator import TPUEstimator File <*>/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py, line 83, in <module> from tensorflow_estimator.python.estimator import estimator as estimator_lib File <*>/site-packages/tensorflow_estimator/__init__.py, line 8, in <module> from tensorflow_estimator._api.v1 import estimator File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py, line 11, in <module> from tensorflow_estimator._api.v1.estimator import tpu File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/tpu/__init__.py, line 8, in <module> from tensorflow_estimator._api.v1.estimator.tpu import experimental File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/tpu/experimental/__init__.py, line 8, in <module> from tensorflow_estimator.python.estimator.tpu._tpu_estimator_embedding import EmbeddingConfigSpec File <*>/site-packages/tensorflow_estimator/python/estimator/tpu/_tpu_estimator_embedding.py, line 32, in <module> from tensorflow.python.tpu import feature_column_v2 as tpu_fc_v2 ImportError: cannot import name 'feature_column_v2' from 'tensorflow.python.tpu' (C:\Users\Rodolfo\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\tpu\__init__.py)",1
"File <*>/image.py, line 7, in <module> detector = ObjectDetection() File <*>python3.5/site-packages/imageai/Detection/__init__.py, line 88, in __init__ self.sess = K.get_session() File <*>python3.5/site-packages/keras/backend/tensorflow_backend.py, line 174, in get_session default_session = tf.get_default_session() AttributeError: module 'tensorflow' has no attribute 'get_default_session'",1
"File [FILE], line 28, in () callbacks=callbacks_list File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 247, in _call_batch_hook(self, mode, hook, batch, logs) batch_hook = getattr(callback, hook_name) AttributeError: 'ModelCheckpoint' object has no attribute 'on_train_batch_begin'",1
"File [FILE], line 3, in <module> model.add(Embedding(vocabulary_size, embedding_size, input_length=MAXLEN)) File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs) File <*>/site-packages/keras/layers/embeddings.py, line 90, in __init__(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, activity_regularizer, embeddings_constraint, mask_zero, input_length, **kwargs) super(Embedding, self).__init__(**kwargs) File <*>/site-packages/keras/engine/base_layer.py, line 132, in __init__(self, **kwargs) name = _to_snake_case(prefix) + '_' + str(K.get_uid(prefix)) File <*>/site-packages/keras/backend/tensorflow_backend.py, line 74, in get_uid(prefix) graph = tf.get_default_graph() AttributeError: module 'tensorflow' has no attribute 'get_default_graph'",1
"File [FILE], line 1, in <module> from tensorflow.python.util.tf_export import keras_export ImportError: cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (C:\Users\DILAW\Anaconda3\lib\site-packages\tensorflow\python\util\tf_export.py)",1
"File [FILE], line 1, in <module>() plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True) File <*>python3.6/dist-packages/keras/utils/vis_utils.py, line 132, in plot_model(model, to_file, show_shapes, show_layer_names, rankdir) dot = model_to_dot(model, show_shapes, show_layer_names, rankdir) File <*>python3.6/dist-packages/keras/utils/vis_utils.py, line 109, in model_to_dot(model, show_shapes, show_layer_names, rankdir) for inbound_layer in node.inbound_layers: TypeError: 'InputLayer' object is not iterable",1
"File <*>/Testing.py, line 82, in <module> model.fit(x_train, y_train, batch_size=50, epochs = 3, callbacks= [tensorboard]) File <*>/site-packages/keras/engine/training.py, line 1178, in fit validation_freq=validation_freq) File <*>/site-packages/keras/engine/training_arrays.py, line 125, in fit_loop callbacks.set_model(callback_model) File <*>/site-packages/keras/callbacks.py, line 68, in set_model callback.set_model(model) File <*>/site-packages/tensorflow/python/keras/callbacks.py, line 1509, in set_model if not model.run_eagerly: AttributeError: 'Sequential' object has no attribute 'run_eagerly'",1
"File [FILE], line 4, in <module>() model =load_model('Leavesnet Model.h5') File <*>python3.6/dist-packages/keras/backend/tensorflow_backend.py, line 541, in placeholder(shape, ndim, dtype, sparse, name) x = tf.placeholder(dtype, shape=shape, name=name) AttributeError: module 'tensorflow' has no attribute 'placeholder'",1
"File [FILE], line 9, in <module> from tensorflow import set_random_seed ImportError: cannot import name 'set_random_seed' from 'tensorflow' (C:\Users\polon\Anaconda3\lib\site-packages\tensorflow\__init__.py)",1
"File <stdin>, line 1, in <module> [CODE] File <*>python3.6/dist-packages/torch/cuda/__init__.py, line 386, in current_device _lazy_init() File <*>python3.6/dist-packages/torch/cuda/__init__.py, line 192, in _lazy_init _check_driver() File <*>python3.6/dist-packages/torch/cuda/__init__.py, line 111, in _check_driver of the CUDA driver."""""".format(str(torch._C._cuda_getDriverVersion()))) AssertionError: The NVIDIA driver on your system is too old (found version 10000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",1
"File train_initialize.py, line 18, in agent = Agent(""horoscope_domain.yml"", policies = [MemoizationPolicy(), KerasPolicy()]) File <*>/site-packages/rasa_core/policies/keras_policy.py, line 31, in init if KerasPolicy.is_using_tensorflow() and not graph: File <*>/site-packages/rasa_core/policies/keras_policy.py, line 48, in is_using_tensorflow return keras.backend._BACKEND == ""tensorflow"" AttributeError: module 'keras.backend' has no attribute '_BACKEND'",1
"File [FILE], line 6, in <module> output = tensorflow.keras.layers.Dropout(dropout_rate, name=""dropout_out"")(vgg_output) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 663, in __call__(self, inputs, *args, **kwargs) inputs, outputs, args, kwargs) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1708, in _set_connectivity_metadata_(self, inputs, outputs, args, kwargs) input_tensors=inputs, output_tensors=outputs, arguments=kwargs) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1795, in _add_inbound_node(self, input_tensors, output_tensors, arguments) input_tensors) File <*>/site-packages/tensorflow/python/util/nest.py, line 515, in map_structure(func, *structure, **kwargs) structure[0], [func(*x) for x in entries], File <*>/site-packages/tensorflow/python/util/nest.py, line 515, in <listcomp>(.0) structure[0], [func(*x) for x in entries], File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1794, in <lambda>(t) inbound_layers = nest.map_structure(lambda t: t._keras_history.layer, AttributeError: 'tuple' object has no attribute 'layer'",1
"File [FILE], line 3, in <module> model.add(tensorflow.keras.layers.GlobalMaxPooling2D(name=""gap"")) File <*>/site-packages/keras/engine/sequential.py, line 133, in add(self, layer) 'Found: ' + str(layer)) TypeError: The added layer must be an instance of class Layer. Found: <tensorflow.python.keras.layers.core.Flatten object at 0x00000000B74364A8>",1
"File [FILE], line 1, in <module> var_init_1 = tf.get_variable(""var_init_1"", [1, 2], dtype=tf.int32, initializer=tf.zeros_initializer) AttributeError: module 'tensorflow' has no attribute 'get_variable'",1
"File <stdin>, line 1, in <module> [CODE] File <*>python3.6/site-packages/deepposekit/__init__.py, line 20, in <module> from deepposekit.io import TrainingGenerator, DataGenerator File <*>python3.6/site-packages/deepposekit/io/__init__.py, line 18, in <module> from deepposekit.io.BaseGenerator import BaseGenerator File <*>python3.6/site-packages/deepposekit/io/BaseGenerator.py, line 16, in <module> from tensorflow.keras.utils import Sequence ModuleNotFoundError: No module named 'tensorflow'",1
"File <*>python3.6/dist-packages/numpy/core/function_base.py, line 117, in linspace num = operator.index(num) TypeError: 'numpy.float64' object cannot be interpreted as an integer",1
"File <*>/tv-training-code.py, line 166, in <module> main() File <*>/tv-training-code.py, line 161, in main evaluate(model, data_loader_test, device=device) File <*>python3.6/dist-packages/torch/autograd/grad_mode.py, line 49, in decorate_no_grad return func(*args, **kwargs) File <*>/engine.py, line 80, in evaluate coco_evaluator = CocoEvaluator(coco, iou_types) File <*>/coco_eval.py, line 28, in __init__ self.coco_eval[iou_type] = COCOeval(coco_gt, iouType=iou_type) File <*>/cocoeval.py, line 75, in __init__ self.params = Params(iouType=iouType) # parameters File <*>/cocoeval.py, line 527, in __init__ self.setDetParams() File <*>/cocoeval.py, line 506, in setDetParams self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True) File <__array_function__ internals>, line 6, in linspace [CODE] File <*>python3.6/dist-packages/numpy/core/function_base.py, line 121, in linspace .format(type(num))) TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.",1
"File <*>/train.py, line 165, in <module> main() File <*>/train.py, line 65, in main tf.set_random_seed(args.random_seed) AttributeError: 'module' object has no attribute 'set_random_seed'",1
"File [FILE], line 3, in <module> images_flat = tf.contrib.layers.flatten(x) AttributeError: module 'tensorflow_core.compat.v1' has no attribute 'contrib'",1
"File <*>/model_loggingfinal.py, line 35, in <module> callbacks=[logger] File <*>python3.7/site-packages/keras/engine/training.py, line 1239, in fit validation_freq=validation_freq) File <*>python3.7/site-packages/keras/engine/training_arrays.py, line 119, in fit_loop callbacks.set_model(callback_model) File <*>python3.7/site-packages/keras/callbacks/callbacks.py, line 68, in set_model callback.set_model(model) File <*>python3.7/site-packages/keras/callbacks/tensorboard_v2.py, line 116, in set_model super(TensorBoard, self).set_model(model) File <*>python3.7/site-packages/tensorflow_core/python/keras/callbacks.py, line 1532, in set_model self.log_dir, self.model._get_distribution_strategy()) # pylint: disable=protected-access AttributeError: 'Sequential' object has no attribute '_get_distribution_strategy'",1
"File <stdin>, line 1, in <module> [CODE] AttributeError: module 'tensorflow' has no attribute 'random_normal'",1
"File [FILE], line 8, in <module> trainer.trainModel() File <*>python3.6/site-packages/imageai/Detection/Custom/__init__.py, line 274, in trainModel(self) class_scale=self.__train_class_scale, File <*>python3.6/site-packages/imageai/Detection/Custom/__init__.py, line 553, in _create_model(self, nb_class, anchors, max_box_per_image, max_grid, batch_size, warmup_batches, ignore_thresh, multi_gpu, lr, grid_scales, obj_scale, noobj_scale, xywh_scale, class_scale) class_scale=class_scale File <*>python3.6/site-packages/imageai/Detection/Custom/yolo.py, line 294, in create_yolov3_model(nb_class, anchors, max_box_per_image, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scales, obj_scale, noobj_scale, xywh_scale, class_scale) class_scale)([input_image, pred_yolo_1, true_yolo_1, true_boxes]) File <*>python3.6/site-packages/imageai/Detection/Custom/yolo.py, line 24, in __init__(self, anchors, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scale, obj_scale, noobj_scale, xywh_scale, class_scale, **kwargs) cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(max_grid_w), [max_grid_h]), (1, max_grid_h, max_grid_w, 1, 1))) AttributeError: module 'tensorflow' has no attribute 'to_float'",1
"File <*>python3.6/dist-packages/fastai/data_block.py, line 594, in _check_kwargs(ds, tfms, **kwargs) try: x.apply_tfms(tfms, **kwargs) File <*>python3.6/dist-packages/fastai/vision/image.py, line 123, in apply_tfms(self, tfms, do_resolve, xtra, size, resize_method, mult, padding_mode, mode, remove_out) else: x = tfm(x) File <*>python3.6/dist-packages/fastai/vision/image.py, line 524, in __call__(self, x, *args, **kwargs) return self.tfm(x, *args, **{**self.resolved, **kwargs}) if self.do_run else x File <*>python3.6/dist-packages/fastai/vision/image.py, line 470, in __call__(self, p, is_random, use_on_y, *args, **kwargs) if args: return self.calc(*args, **kwargs) File <*>python3.6/dist-packages/fastai/vision/image.py, line 475, in calc(self, x, *args, **kwargs) if self._wrap: return getattr(x, self._wrap)(self.func, *args, **kwargs) File <*>python3.6/dist-packages/fastai/vision/image.py, line 183, in affine(self, func, *args, **kwargs) self.affine_mat = self.affine_mat @ m RuntimeError: Expected object of scalar type Float but got scalar type Double for argument #3 'mat2' in call to _th_addmm_out",1
"File [FILE], line 8, in <module>() data= (src.transform(tfms,size=sz) #Data augmentation File <*>python3.6/dist-packages/fastai/data_block.py, line 505, in transform(self, tfms, **kwargs) self.train.transform(tfms[0], **kwargs) File <*>python3.6/dist-packages/fastai/data_block.py, line 724, in transform(self, tfms, tfm_y, **kwargs) _check_kwargs(self.x, tfms, **kwargs) File <*>python3.6/dist-packages/fastai/data_block.py, line 596, in _check_kwargs(ds, tfms, **kwargs) raise Exception(f""It's not possible to apply those transforms to your dataset:\n {e}"") Exception: It's not possible to apply those transforms to your dataset: Expected object of scalar type Float but got scalar type Double for argument #3 'mat2' in call to _th_addmm_out",1
"File [FILE], line 2, in <module> from object_detection.utils import label_map_util File <*>/site-packages/object_detection/utils/label_map_util.py, line 27, in <module> from object_detection.protos import string_int_label_map_pb2 File <*>/site-packages/object_detection/protos/string_int_label_map_pb2.py, line 21, in <module> create_key=_descriptor._internal_create_key, AttributeError: module 'google.protobuf.descriptor' has no attribute '_internal_create_key'",1
"File <stdin>, line 1, in <module> [CODE] File <*>python3.7/site-packages/torch/__init__.py, line 81, in <module> from torch._C import * ImportError: /lib/arm-linux-gnueabihf/libc.so.6: version `GLIBC_2.28' not found (required by /usr/local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)",1
"File <stdin>, line 1, in <module> [CODE] File <*>/site-packages/tensorflow/__init__.py, line 101, in <module> from tensorflow_core import * File <*>/site-packages/tensorflow_core/__init__.py, line 46, in <module> from . _api.v2 import compat File <*>/site-packages/tensorflow_core/_api/v2/compat/__init__.py, line 39, in <module> from . import v1 File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/__init__.py, line 32, in <module> from . import compat File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/compat/__init__.py, line 39, in <module> from . import v1 File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/compat/v1/__init__.py, line 29, in <module> from tensorflow._api.v2.compat.v1 import app File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/compat/v1/__init__.py, line 667, in <module> from tensorflow_estimator.python.estimator.api._v1 import estimator File <*>/site-packages/tensorflow_estimator/__init__.py, line 10, in <module> from tensorflow_estimator._api.v1 import estimator File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py, line 10, in <module> from tensorflow_estimator._api.v1.estimator import experimental File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py, line 10, in <module> from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder File <*>/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py, line 33, in <module> from tensorflow_estimator.python.estimator import estimator File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 53, in <module> from tensorflow_estimator.python.estimator import util as estimator_util File <*>/site-packages/tensorflow_estimator/python/estimator/util.py, line 75, in <module> class _DatasetInitializerHook(tf.compat.v1.train.SessionRunHook): AttributeError: module 'tensorflow' has no attribute 'compat'",1
"File test.py, line 2, in <module> model = load_model(filepath = 'saved_model/model2.h5',custom_objects=None,compile=True, ) File <*>python3.8/site-packages/tensorflow/python/keras/saving/save.py, line 184, in load_model return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile) File <*>python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py, line 177, in load_model_from_hdf5 model = model_config_lib.model_from_config(model_config, File <*>python3.8/site-packages/tensorflow/python/keras/saving/model_config.py, line 55, in model_from_config return deserialize(config, custom_objects=custom_objects) File <*>python3.8/site-packages/tensorflow/python/keras/layers/serialization.py, line 105, in deserialize return deserialize_keras_object( File <*>python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 369, in deserialize_keras_object return cls.from_config( File <*>python3.8/site-packages/tensorflow/python/keras/engine/sequential.py, line 397, in from_config layer = layer_module.deserialize(layer_config, File <*>python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 375, in deserialize_keras_object return cls.from_config(cls_config) File <*>python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py, line 655, in from_config return cls(**config) File <*>python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py, line 582, in __init__ super(Conv2D, self).__init__( File <*>python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py, line 121, in __init__ super(Conv, self).__init__( File <*>python3.8/site-packages/tensorflow/python/training/tracking/base.py, line 456, in _method_wrapper result = method(self, *args, **kwargs) File <*>python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py, line 294, in __init__ generic_utils.validate_kwargs(kwargs, allowed_kwargs) File <*>python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 792, in validate_kwargs raise TypeError(error_message, kwarg) TypeError: ('Keyword argument not understood:', 'groups')",1
"File <*>/site-packages/keras/models.py, line 1211, in from_config if 'class_name' not in config[0] or config[0]['class_name'] == 'Merge': KeyError: 0",1
"File <*>/coco.py, line 456, in <module> model_dir=args.logs) File <*>/site-packages/mrcnn/model.py, line 1832, in __init__ self.keras_model = self.build(mode=mode, config=config) File <*>/site-packages/mrcnn/model.py, line 1871, in build x, K.shape(input_image)[1:3]))(input_gt_boxes) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 952, in __call__ input_list) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1091, in _functional_construction_call inputs, input_masks, args, kwargs) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 822, in _keras_tensor_symbolic_call return self._infer_output_signature(inputs, args, kwargs, input_masks) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 869, in _infer_output_signature keras_tensor.keras_tensor_from_tensor, outputs) File <*>/site-packages/tensorflow/python/util/nest.py, line 659, in map_structure structure[0], [func(*x) for x in entries], File <*>/site-packages/tensorflow/python/util/nest.py, line 659, in <listcomp> structure[0], [func(*x) for x in entries], File <*>/site-packages/tensorflow/python/keras/engine/keras_tensor.py, line 606, in keras_tensor_from_tensor out = keras_tensor_cls.from_tensor(tensor) File <*>/site-packages/tensorflow/python/keras/engine/keras_tensor.py, line 205, in from_tensor type_spec = type_spec_module.type_spec_from_value(tensor) File <*>/site-packages/tensorflow/python/framework/type_spec.py, line 554, in type_spec_from_value (value, type(value).__name__)) TypeError: Could not build a TypeSpec for <KerasTensor: shape=(None, None, 4) dtype=float32 (created by layer 'tf.math.truediv')> with type KerasTensor",1
"File [FILE], line 1, in <module>() tokenizer = tfds.features.text.VocabTokenizer() AttributeError: module 'tensorflow_datasets.core.features' has no attribute 'text'",1
"File <*>/test.py, line 13, in <module> lstm = Bidirectional(lstm_nobi, name=""layerC"")(embedding_layer) File <*>python3.9/site-packages/tensorflow/python/keras/layers/wrappers.py, line 539, in __call__ return super(Bidirectional, self).__call__(inputs, **kwargs) File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 951, in __call__ return self._functional_construction_call(inputs, args, kwargs, File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1090, in _functional_construction_call outputs = self._keras_tensor_symbolic_call( File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 822, in _keras_tensor_symbolic_call return self._infer_output_signature(inputs, args, kwargs, input_masks) File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 863, in _infer_output_signature outputs = call_fn(inputs, *args, **kwargs) File <*>python3.9/site-packages/tensorflow/python/keras/layers/wrappers.py, line 652, in call y = self.forward_layer(forward_inputs, File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 660, in __call__ return super(RNN, self).__call__(inputs, **kwargs) File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1012, in __call__ outputs = call_fn(inputs, *args, **kwargs) File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py, line 1157, in call inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None) File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 859, in _process_inputs initial_state = self.get_initial_state(inputs) File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 642, in get_initial_state init_state = get_initial_state_fn( File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 2506, in get_initial_state return list(_generate_zero_filled_state_for_cell( File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 2987, in _generate_zero_filled_state_for_cell return _generate_zero_filled_state(batch_size, cell.state_size, dtype) File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 3003, in _generate_zero_filled_state return nest.map_structure(create_zeros, state_size) File <*>python3.9/site-packages/tensorflow/python/util/nest.py, line 659, in map_structure structure[0], [func(*x) for x in entries], File <*>python3.9/site-packages/tensorflow/python/util/nest.py, line 659, in <listcomp> structure[0], [func(*x) for x in entries], File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 3000, in create_zeros return array_ops.zeros(init_state_size, dtype=dtype) File <*>python3.9/site-packages/tensorflow/python/util/dispatch.py, line 201, in wrapper return target(*args, **kwargs) File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2819, in wrapped tensor = fun(*args, **kwargs) File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2868, in zeros output = _constant_if_small(zero, shape, dtype, name) File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2804, in _constant_if_small if np.prod(shape) < 1000: File <__array_function__ internals>, line 5, in prod [CODE] File <*>python3.9/site-packages/numpy/core/fromnumeric.py, line 3030, in prod return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out, File <*>python3.9/site-packages/numpy/core/fromnumeric.py, line 87, in _wrapreduction return ufunc.reduce(obj, axis, dtype, out, **passkwargs) File <*>python3.9/site-packages/tensorflow/python/framework/ops.py, line 852, in __array__ raise NotImplementedError( NotImplementedError: Cannot convert a symbolic Tensor (layerC/forward_layerB/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",1
"File main.py, line 60, in <module> main() File main.py, line 50, in main train_iters, dev_iters, test_iters, vocab = load_dataset(config) File <*>/data.py, line 23, in load_dataset TEXT = data.Field(batch_first=True, eos_token='<eos>') AttributeError: module 'torchtext.data' has no attribute 'Field'",1
"File [FILE], line 1, in <module> last_hidden_state.shape AttributeError: 'str' object has no attribute 'shape'",1
"File [FILE], line 9, in <module>() from keras.preprocessing import image File <*>python3.7/dist-packages/keras/backend.py, line 37, in <module>() from tensorflow.python.eager.context import get_config ImportError: cannot import name 'get_config' from 'tensorflow.python.eager.context' (/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/context.py)",1
"File <*>/main_dist_maml_l2l.py, line 1423, in <module> main() File <*>/main_dist_maml_l2l.py, line 1365, in main train(args=args) File <*>/main_dist_maml_l2l.py, line 1385, in train args.opt = move_opt_to_cherry_opt_and_sync_params(args) if is_running_parallel(args.rank) else args.opt File <*>/distributed.py, line 456, in move_opt_to_cherry_opt_and_sync_params args.opt = cherry.optim.Distributed(args.model.parameters(), opt=args.opt, sync=syn) File <*>python3.9/site-packages/cherry/optim.py, line 62, in __init__ self.sync_parameters() File <*>python3.9/site-packages/cherry/optim.py, line 78, in sync_parameters dist.broadcast(p.data, src=root) File <*>python3.9/site-packages/torch/distributed/distributed_c10d.py, line 1090, in broadcast work = default_pg.broadcast([tensor], opts) RuntimeError: NCCL error in: ../torch/lib/c10d/ProcessGroupNCCL.cpp:911, unhandled system error, NCCL version 2.7.8",1
"File train.py, line 28, in <module> tf.keras.mixed_precision.set_global_policy('mixed_float16') AttributeError: module 'tensorflow.keras.mixed_precision' has no attribute 'set_global_policy'",1
"File train.py, line 29, in <module> policy = tf.keras.mixed_precision.Policy('mixed_float16') AttributeError: module 'tensorflow.keras.mixed_precision' has no attribute 'Policy'",1
"File <*>/CNN_Image_Denoising.py, line 15, in <module> from keras.optimizers import SGD, Adam ImportError: cannot import name 'SGD' from 'keras.optimizers'",1
"File [FILE], line 1, in <module>() from keras.utils import to_categorical ImportError: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",1
"File <*>/script.py, line 654, in <module> prediction_result, (r, t) = cf.to(model_runner.predict(processed_feature_dict, random_seed=seed), ""cpu"") File <*>python3.7/site-packages/alphafold/model/model.py, line 134, in predict result, recycles = self.apply(self.params, jax.random.PRNGKey(random_seed), feat) File <*>python3.7/site-packages/jax/_src/traceback_util.py, line 183, in reraise_with_filtered_traceback return fun(*args, **kwargs) File <*>python3.7/site-packages/jax/_src/api.py, line 402, in cache_miss donated_invars=donated_invars, inline=inline) File <*>python3.7/site-packages/jax/core.py, line 1561, in bind return call_bind(self, fun, *args, **params) File <*>python3.7/site-packages/jax/core.py, line 1552, in call_bind outs = primitive.process(top_trace, fun, tracers, params) File <*>python3.7/site-packages/jax/core.py, line 1564, in process return trace.process_call(self, fun, tracers, params) File <*>python3.7/site-packages/jax/core.py, line 607, in process_call return primitive.impl(f, *tracers, **params) File <*>python3.7/site-packages/jax/interpreters/xla.py, line 608, in _xla_call_impl *unsafe_map(arg_spec, args)) File <*>python3.7/site-packages/jax/, line 262, in memoized_fun ans = call(fun, *args) File <*>python3.7/site-packages/jax/interpreters/xla.py, line 758, in _xla_callable compiled = compile_or_get_cached(backend, built, options) File env/lib/python3.7/site-packages/jax/interpreters/xla.py, line 76, in compile_or_get_cached return backend_compile(backend, computation, compile_options)",1
"File <*>/script.py, line 654, in <module> prediction_result, (r, t) = cf.to(model_runner.predict(processed_feature_dict, random_seed=seed), ""cpu"") File <*>python3.7/site-packages/alphafold/model/model.py, line 134, in predict result, recycles = self.apply(self.params, jax.random.PRNGKey(random_seed), feat) File <*>python3.7/site-packages/jax/interpreters/xla.py, line 373, in backend_compile return backend.compile(built_c, compile_options=options) RuntimeError: Resource exhausted: Out of memory while trying to allocate 4649385984 bytes.",1
"File [FILE], line 41, in <module>() from theano.tensor import shared_randomstreams File <*>python3.7/dist-packages/theano/gof/cmodule.py, line 37, in <module>() from theano.configdefaults import gcc_version_str, local_bitwidth ImportError: cannot import name 'local_bitwidth' from 'theano.configdefaults' (/usr/local/lib/python3.7/dist-packages/theano/configdefaults.py)",1
"File <*>/train_model.py, line 10, in <module> from cancernet.cancernet import CancerNet File <*>/cancernet.py, line 2, in <module> from keras.layers.normalization import BatchNormalization ImportError: cannot import name 'BatchNormalization' from 'keras.layers.normalization' (C:\Users\Catalin\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\layers\normalization\__init__.py)",1
"File <*>/model_main_tf2.py, line 32, in <module> from object_detection import model_lib_v2 File <*>python3.7/dist-packages/object_detection/model_lib_v2.py, line 29, in <module> from object_detection import eval_util File <*>python3.7/dist-packages/object_detection/eval_util.py, line 36, in <module> from object_detection.metrics import lvis_evaluation File <*>python3.7/dist-packages/object_detection/metrics/lvis_evaluation.py, line 23, in <module> from lvis import results as lvis_results File <*>python3.7/dist-packages/lvis/__init__.py, line 5, in <module> from lvis.vis import LVISVis File <*>python3.7/dist-packages/lvis/vis.py, line 1, in <module> import cv2 File <*>python3.7/dist-packages/cv2/__init__.py, line 9, in <module> from .cv2 import _registerMatType ImportError: cannot import name '_registerMatType' from 'cv2.cv2' (/usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so)",1
"File <*>/site-packages/theano/configparser.py, line 168, in fetch_val_for_key return theano_cfg.get(section, option) File <*>/configparser.py, line 781, in get d = self._unify_values(section, vars) File <*>/configparser.py, line 1149, in _unify_values raise NoSectionError(section) from None configparser.NoSectionError: No section: 'blas'",1
"File <*>/site-packages/theano/configparser.py, line 327, in __get__ val_str = fetch_val_for_key(self.fullname, File <*>/site-packages/theano/configparser.py, line 172, in fetch_val_for_key raise KeyError(key) KeyError: 'blas.ldflags'",1
"File <*>/test.py, line 156, in <module> import network3 File <*>/network3.py, line 37, in <module> import theano File <*>/site-packages/theano/__init__.py, line 124, in <module> from theano.scan_module import (scan, map, reduce, foldl, foldr, clone, File <*>/site-packages/theano/scan_module/__init__.py, line 41, in <module> from theano.scan_module import scan_opt File <*>/site-packages/theano/scan_module/scan_opt.py, line 60, in <module> from theano import tensor, scalar File <*>/site-packages/theano/tensor/__init__.py, line 17, in <module> from theano.tensor import blas File <*>/site-packages/theano/tensor/blas.py, line 155, in <module> from theano.tensor.blas_headers import blas_header_text File <*>/site-packages/theano/tensor/blas_headers.py, line 987, in <module> if not config.blas.ldflags: File <*>/site-packages/theano/configparser.py, line 332, in __get__ val_str = self.default() File <*>/site-packages/theano/configdefaults.py, line 1284, in default_blas_ldflags blas_info = np.distutils.__config__.blas_opt_info AttributeError: module 'numpy.distutils.__config__' has no attribute 'blas_opt_info'",1
"File [FILE], line 3, in <module>() from keras.applications.resnet50 import preprocess_input, ResNet50 ModuleNotFoundError: No module named 'keras.applications.resnet50'",1
"File <*>/ai.py, line 15, in <module> from keras.models import Sequential, load_model File <*>/site-packages/keras/__init__.py, line 24, in <module> from keras import models File <*>/site-packages/keras/models/__init__.py, line 18, in <module> from keras.engine.functional import Functional File <*>/site-packages/keras/engine/functional.py, line 24, in <module> from keras.dtensor import layout_map as layout_map_lib File <*>/site-packages/keras/dtensor/__init__.py, line 22, in <module> from tensorflow.compat.v2.experimental import dtensor as dtensor_api # pylint: disable=g-import-not-at-top ImportError: cannot import name 'dtensor' from 'tensorflow.compat.v2.experimental' (C:\Users\Fynn\AppData\Local\Programs\Python\Python39\lib\site-packages\tensorflow\_api\v2\compat\v2\experimental\__init__.py)",1
"File <stdin>, line 1, in <module> [CODE] File <*>/site-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 540, in runfile execfile(filename, namespace) File <*>/untitled4.py, line 603, in <module> params = test_mlp() File <*>/untitled4.py, line 553, in test_mlp minibatch_avg_cost = train_model(minibatch_index) File <*>/site-packages/theano-0.6.0-py2.7.egg/theano/compile/function_module.py, line 588, in __call__ self.fn.thunks[self.fn.position_of_error]) File <*>/site-packages/theano-0.6.0-py2.7.egg/theano/compile/function_module.py, line 579, in __call__ outputs = self.fn() ValueError: y_i value out of bounds Apply node that caused the error: CrossentropySoftmaxArgmax1HotWithBias(Dot22.0, b, Elemwise{Cast{int32}}.0) Inputs shapes: [(10L, 1L), (1L,), (10L,)] Inputs strides: [(8L, 8L), (8L,), (4L,)] Inputs types: [TensorType(float64, matrix), TensorType(float64, vector), TensorType(int32, vector)] Use the Theano flag 'exception_verbosity=high' for a debugprint of this apply node.",0
"File <string>, line 1, in <module> [CODE] ImportError: No module named caffe",0
"File <*>/io.py, line 2, in <module> import skimage.io File <*>python2.7/dist-packages/skimage/io/__init__.py, line 11, in <module> from ._io import * File <*>python2.7/dist-packages/skimage/io/_io.py, line 1, in <module> from io import BytesIO ImportError: cannot import name BytesIO",0
"File <*>/output.py, line 13, in <module> import caffe File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver File <*>/pycaffe.py, line 10, in <module> from ._caffe import Net, SGDSolver ImportError: No module named _caffe",0
"File <*>/classify.py, line 130, in <module> main(sys.argv) File <*>/classify.py, line 103, in main channel_swap=channel_swap) TypeError: __init__() got an unexpected keyword argument 'gpu'",0
"File las_mnist.py, line 39, in <module> net1.fit(X[i], y[i]) File <*>python2.7/dist-packages/nolearn/lasagne.py, line 266, in fit self.train_loop(X, y) File <*>python2.7/dist-packages/nolearn/lasagne.py, line 273, in train_loop X, y, self.eval_size) File <*>python2.7/dist-packages/nolearn/lasagne.py, line 377, in train_test_split kf = KFold(y.shape[0], round(1. / eval_size)) IndexError: tuple index out of range",0
"File <*>/site-packages/IPython/core/interactiveshell.py, line 3032, in run_code =============================== C:\Users\aleja_000\AppData\Local\Theano\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.9-64\lazylinker_ext\mod.cpp:1:0: sorry, unimplemented: 64-bit mode not compiled in #include <Python.h> ^ exec(code_obj, self.user_global_ns, self.user_ns) File <ipython-input-2-1e86b04c8a9c>, line 6, in <module> from lasagne.layers import DenseLayer File <*>/pydev_import_hook.py, line 21, in do_import module = self._system_import(name, *args, **kwargs) File <*>/__init__.py, line 5, in <module> from . import nonlinearities File <*>/non, line 6, in <module> from theano.tensor.nnet import sigmoid File <*>/site-packages/theano/__init__.py, line 55, in <module> from theano.compile import ( File <*>/site-packages/theano/compile/__init__.py, line 9, in <module> from theano.compile.function_module import * File <*>/site-packages/theano/compile/function_module.py, line 17, in <module> import theano.compile.mode File <*>/site-packages/theano/compile/mode.py, line 11, in <module> import theano.gof.vm File <*>/site-packages/theano/gof/vm.py, line 654, in <module> import lazylinker_c File <*>/site-packages/theano/gof/lazylinker_c.py, line 125, in <module> preargs=args) File <*>/site-packages/theano/gof/cmodule.py, line 2042, in compile_str (status, compile_stderr.replace('\n', '. '))) Exception: Compilation failed (return status=1): C:\Users\aleja_000\AppData\Local\Theano\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.9-64\lazylinker_ext\mod.cpp:1:0: sorry, unimplemented: 64-bit mode not compiled in . #include <Python.h> . ^",0
"File <stdin>, line 1, in <module> [CODE] ImportError: No module named lmdb",0
"File <stdin>, line 1, in <module> [CODE] ImportError: No module named deepdish",0
"File <stdin>, line 1, in <module> [CODE] AttributeError: 'TensorVariable' object has no attribute 'get_value'",0
"File <*>python2.7/site-packages/pip/basecommand.py, line 211, in main status = self.run(options, args) File <*>python2.7/site-packages/pip/commands/install.py, line 311, in run root=options.root_path, File <*>python2.7/site-packages/pip/req/req_set.py, line 640, in install requirement.uninstall(auto_confirm=True) File <*>python2.7/site-packages/pip/req/req_install.py, line 716, in uninstall paths_to_remove.remove(auto_confirm) File <*>python2.7/site-packages/pip/req/req_uninstall.py, line 125, in remove renames(path, new_path) File <*>python2.7/site-packages/pip/utils/__init__.py, line 315, in renames shutil.move(old, new) File <*>python2.7/shutil.py, line 303, in move os.unlink(src) OSError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/site-packages/six-1.9.0.dist-info/DESCRIPTION.rst'",0
"File word2vec_basic.py, line 171, in <module> _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 345, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 419, in _do_run e.code) tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'GradientDescent/update_Variable_2/ScatterSub': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/GPU:0' [[Node: GradientDescent/update_Variable_2/ScatterSub = ScatterSub[T=DT_FLOAT, Tindices=DT_INT64, use_locking=false](Variable_2, gradients/concat_1, GradientDescent/update_Variable_2/mul)]]",0
"File <*>/convolutional.py, line 13, in <module> import tensorflow.python.platform File <*>/__init__.py, line 4, in <module> from tensorflow.python import * File <*>/__init__.py, line 13, in <module> from tensorflow.core.framework.graph_pb2 import * ImportError: No module named core.framework.graph_pb2",0
"File <*>/translate.py, line 28, in <module> from tensorflow.models.rnn.translate import data_utils ImportError: No module named translate",0
"File run_deep_trainer.py, line 404, in <module> main() File run_deep_trainer.py, line 400, in main layer_trainers[-1].main_loop() File <*>/train.py, line 141, in main_loop self.setup() File <*>/train.py, line 121, in setup self.algorithm.setup(model=self.model, dataset=self.dataset) File <*>/sgd.py, line 243, in setup inf_params = [param for param in model.get_params() File <*>/model.py, line 503, in get_params return list(self._params) AttributeError: 'Softmax' object has no attribute '_params'",0
"File <stdin>, line 1, in <module> [CODE] File <*>/py1053173el, line 12, in <module> [CODE] File <*>python2.7/dist-packages/tensorflow/models/rnn/seq2seq.py, line 82, in basic_rnn_seq2seq _, enc_states = rnn.rnn(cell, encoder_inputs, dtype=dtype) File <*>python2.7/dist-packages/tensorflow/models/rnn/rnn.py, line 85, in rnn output_state = cell(input_, state) File <*>python2.7/dist-packages/tensorflow/models/rnn/rnn_cell.py, line 161, in __call__ concat = linear.linear([inputs, h], 4 * self._num_units, True) File <*>python2.7/dist-packages/tensorflow/models/rnn/, line 32, in linear raise ValueError(""Linear is expecting 2D arguments: %s"" % str(shapes)) ValueError: Linear is expecting 2D arguments: [[None], [None, 512]]",0
"File ae.py, line 330, in <module> main() File ae.py, line 305, in main ae.train(n_epochs=n_epochs, mini_batch_size=100, learning_rate=0.002, train_data= train_sentence_embeddings, test_data= test_sentence_embeddings) File ae.py, line 87, in train givens={x:self.X[index:index+mini_batch_size,:]}) File <*>python2.7/dist-packages/theano/compile/function.py, line 266, in function profile=profile) File <*>python2.7/dist-packages/theano/compile/pfunc.py, line 489, in pfunc no_default_updates=no_default_updates) File <*>python2.7/dist-packages/theano/compile/pfunc.py, line 194, in rebuild_collect_shared store_into) TypeError: ('update target must be a SharedVariable', Subtensor{::, int64}.0)",0
"File test_theano.py, line 9, in <module> for iter in range(n_iters): TypeError: range() integer end argument expected, got TensorVariable.",0
"File <*>/convolutional.py, line 133, in <module> train_accuracy = accuracy.eval(feed_dict = {x: batch[0], y_: batch[1], keep_prob: 1.0}) File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 405, in eval return _eval_using_default_session(self, feed_dict, self.graph, session) File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 2728, in _eval_using_default_session return session.run(tensors, feed_dict) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 345, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 419, in _do_run e.code) tensorflow.python.framework.errors.InvalidArgumentError: Incompatible shapes: [8] vs. [20] [[Node: Equal = Equal[T=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](ArgMax, ArgMax_1)]]",0
"File <string>, line 1, in <module> [CODE] AttributeError: 'module' object has no attribute 'getsitepackages'",0
"File <*>/convolutional_network_batch_2d2c_clean_64f.py, line 213, in <module> pred = conv_net(x, weights, biases, keep_prob) File <*>/convolutional_network_batch_2d2c_clean_64f.py, line 153, in conv_net conv1 = max_pool(conv1, k=2) # Normally K=2 File <*>/convolutional_network_batch_2d2c_clean_64f.py, line 135, in max_pool return tf.nn.max_pool(img, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME') File <*>python2.7/site-packages/tensorflow/python/ops/nn_ops.py, line 235, in max_pool name=name) File <*>python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 449, in _max_pool strides=strides, padding=padding, name=name) File <*>python2.7/site-packages/tensorflow/python/ops/op_def_library.py, line 430, in apply_op (prefix, dtypes.as_dtype(input_arg.type).name)) TypeError: Input 'input' of 'MaxPool' Op has type float64 that does not match expected type of float32.",0
"File <*>/Layer.py, line 113, in <module> train_model(i) File <*>python2.7/site-packages/theano/compile/function_module.py, line 595, in __call__ outputs = self.fn() File <*>python2.7/site-packages/theano/gof/link.py, line 485, in streamline_default_f raise_with_op(node, thunk) File <*>python2.7/site-packages/theano/gof/link.py, line 481, in streamline_default_f thunk() File <*>python2.7/site-packages/theano/gof/op.py, line 768, in rval r = p(n, [x[0] for x in i], o) File <*>python2.7/site-packages/theano/tensor/nnet/nnet.py, line 896, in perform nll[i] = -row[y_idx[i]] + m + numpy.log(sum_j) IndexError: index 1 is out of bounds for axis 0 with size 1",0
"File [FILE], line <*>, in [FUNC] [CODE] File <*>/site-packages/nolearn/lasagne/base.py, line 457, in fit self.initialize() File <*>/site-packages/nolearn/lasagne/base.py, line 303, in initialize self.y_tensor_type, File <*>/site-packages/nolearn/lasagne/base.py, line 435, in _create_iter_funcs allow_input_downcast=True, File <*>/site-packages/theano/compile/function.py, line 317, in function output_keys=output_keys) File <*>/site-packages/theano/compile/pfunc.py, line 526, in pfunc output_keys=output_keys) File <*>/site-packages/theano/compile/function_module.py, line 1778, in orig_function defaults) File <*>/site-packages/theano/compile/function_module.py, line 1642, in create input_storage=input_storage_lists, storage_map=storage_map) File <*>/site-packages/theano/gof/link.py, line 690, in make_thunk storage_map=storage_map)[:3] File <*>/site-packages/theano/gof/vm.py, line 1037, in make_all no_recycling)) File <*>/site-packages/theano/gof/op.py, line 932, in make_thunk no_recycling) File <*>/site-packages/theano/gof/op.py, line 850, in make_c_thunk output_storage=node_output_storage) File <*>/site-packages/theano/gof/cc.py, line 1207, in make_thunk keep_lock=keep_lock) File <*>/site-packages/theano/gof/cc.py, line 1152, in __compile__ keep_lock=keep_lock) File <*>/site-packages/theano/gof/cc.py, line 1602, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock) File <*>/site-packages/theano/gof/cmodule.py, line 1174, in module_from_key module = lnk.compile_cmodule(location) File <*>/site-packages/theano/gof/cc.py, line 1513, in compile_cmodule preargs=preargs) File <*>/site-packages/theano/gof/cmodule.py, line 2187, in compile_str (status, compile_stderr.replace('\n', '. '))) Exception: ('The following error happened while compiling the node', CorrMM{valid, (1, 1)}(input.input, Subtensor{::, ::, ::int64, ::int64}.0), '\n', ""Compilation failed (return status=1): C:\\Users\\Michal\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64\\tmpgdh7ov2i\\mod.cpp: In member function 'int {anonymous}::__struct_compiled_op_mf217e5b3a6b61b4ef70844368439f6cb::run()':\r. C:\\Users\\Michal\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64\\tmpgdh7ov2i\\mod.cpp:947:16: warning: converting to non-pointer type 'int' from NULL [-Wconversion-null]\r. kH = NULL;\r. ^\r. C:\\Users\\Michal\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64\\tmpgdh7ov2i\\mod.cpp:958:16: warning: converting to non-pointer type 'int' from NULL [-Wconversion-null]\r. kW = NULL;\r. ^\r. C:\\Users\\Michal\\AppData\\Local\\Temp\\cc67su6o.o: In function `corrMM(tagPyArrayObject*, tagPyArrayObject*, tagPyArrayObject*, int, int, int, int, int)':\r. C:/Users/Michal/AppData/Local/Theano/compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64/tmpgdh7ov2i/mod.cpp:431: undefined reference to `dgemm_'\r. C:/Users/Michal/AppData/Local/Theano/compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64/tmpgdh7ov2i/mod.cpp:528: undefined reference to `dgemm_'\r. C:/Users/Michal/AppData/Local/Theano/compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64/tmpgdh7ov2i/mod.cpp:483: undefined reference to `dgemm_'\r. collect2.exe: error: ld returned 1 exit status\r. "", '[CorrMM{valid, (1, 1)}(input.input, )]')",0
"File cifar10.py, line 54, in <module> """"""Number of images to process in a batch."""""") File <*>python2.7/site-packages/tensorflow/python/platform/default/_flags.py, line 86, in DEFINE_integer _define_helper(flag_name, default_value, docstring, int) File <*>python2.7/site-packages/tensorflow/python/platform/default/_flags.py, line 60, in _define_helper type=flagtype) File <*>python2.7/argparse.py, line 1297, in add_argument return self._add_action(action) File <*>python2.7/argparse.py, line 1671, in _add_action self._optionals._add_action(action) File <*>python2.7/argparse.py, line 1498, in _add_action action = super(_ArgumentGroup, self)._add_action(action) File <*>python2.7/argparse.py, line 1311, in _add_action self._check_conflict(action) File <*>python2.7/argparse.py, line 1449, in _check_conflict conflict_handler(action, confl_optionals) File <*>python2.7/argparse.py, line 1456, in _handle_conflict_error raise ArgumentError(action, message % conflict_string) argparse.ArgumentError: argument --batch_size: conflicting option string(s): --batch_size",0
"File <*>/lstmNetwork.py, line 54, in <module> model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=3, validation_data=(X_test, Y_test), show_accuracy=True) File <*>python2.7/dist-packages/keras/models.py, line 581, in fit shuffle=shuffle, metrics=metrics) File <*>python2.7/dist-packages/keras/models.py, line 239, in _fit outs = f(ins_batch) File <*>python2.7/dist-packages/keras/backend/theano_backend.py, line 365, in __call__ return self.function(*inputs) File <*>/function_module.py, line 786, in __call__ allow_downcast=s.allow_downcast) File <*>/type.py, line 177, in filter data.shape)) TypeError: ('Bad input argument to theano function with name ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py:362"" at index 1(0-based)', 'Wrong number of dimensions: expected 3, got 2 with shape (5, 10).')",0
"File tensor_restore.py, line 14, in <module> saver.restore(sess, ""/tmp/model.ckpt"") File <*>python2.7/site-packages/tensorflow/python/training/saver.py, line 891, in restore sess.run([self._restore_op_name], {self._filename_tensor_name: save_path}) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 368, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 444, in _do_run e.code) tensorflow.python.framework.errors.NotFoundError: Tensor name ""v2"" not found in checkpoint files /tmp/model.ckpt [[Node: save/restore_slice_1 = RestoreSlice[dt=DT_INT32, preferred_shard=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_1/tensor_name, save/restore_slice_1/shape_and_slice)]]",0
"File <*>/teste2.py, line 1479, in Pred model.fit(X=predictor_train, y=target_train, nb_epoch=2, batch_size=90,show_accuracy=True) File <*>/site-packages/keras/models.py, line 581, in fit shuffle=shuffle, metrics=metrics) File <*>/site-packages/keras/models.py, line 239, in _fit outs = f(ins_batch) File <*>/site-packages/keras/backend/theano_backend.py, line 365, in __call__ return self.function(*inputs) File <*>/site-packages/theano/compile/function_module.py, line 595, in __call__ outputs = self.fn() File <*>/site-packages/theano/gof/vm.py, line 233, in __call__ link.raise_with_op(node, thunk) File <*>/site-packages/theano/gof/vm.py, line 229, in __call__ thunk() File <*>/site-packages/theano/gof/op.py, line 768, in rval r = p(n, [x[0] for x in i], o) File <*>/site-packages/theano/tensor/elemwise.py, line 808, in perform raise ValueError(base_exc_str) ValueError: Dimension mismatch; shapes are (98, 10), (98, 1)",0
"File kaggle_otto_nn.py, line 28, in <module> from keras.models import Sequential File <*>/models.py, line 15, in <module> [CODE] File <*>/__init__.py, line 46, in <module> [CODE] File <*>/theano_backend.py, line 1, in <module> [CODE] File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/__init__.py, line 111, in <module> theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1() File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/sandbox/cuda/tests/test_driver.py, line 38, in test_nvidia_driver1 if not numpy.allclose(f(), a.sum()): File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.py, line 871, in __call__ storage_map=getattr(self.fn, 'storage_map', None)) File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/link.py, line 314, in raise_with_op reraise(exc_type, exc_value, exc_trace) File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.py, line 859, in __call__ outputs = self.fn() RuntimeError: Cuda error: kernel_reduce_ccontig_node_97496c4d3cf9a06dc4082cc141f918d2_0: out of memory. (grid: 1 x 1; block: 256 x 1 x 1)",0
"File <stdin>, line 1, in <module> [CODE] ImportError: No module named tensorflow",0
"File <stdin>, line 1, in <module> [CODE] File <*>/site-packages/theano/__init__.py, line 111, in <module> theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1() File <*>/site-packages/theano/sandbox/cuda/tests/test_driver.py, line 31, in test_nvidia_driver1 profile=False) File <*>/site-packages/theano/compile/function.py, line 320, in function output_keys=output_keys) File <*>/site-packages/theano/compile/pfunc.py, line 479, in pfunc output_keys=output_keys) File <*>/site-packages/theano/compile/function_module.py, line 1776, in orig_function output_keys=output_keys).create( File <*>/site-packages/theano/compile/function_module.py, line 1456, in __init__ optimizer_profile = optimizer(fgraph) File <*>/site-packages/theano/gof/opt.py, line 101, in __call__ return self.optimize(fgraph) File <*>/site-packages/theano/gof/opt.py, line 89, in optimize ret = self.apply(fgraph, *args, **kwargs) File <*>/site-packages/theano/gof/opt.py, line 230, in apply sub_prof = optimizer.optimize(fgraph) File <*>/site-packages/theano/sandbox/cuda/dnn.py, line 2508, in apply dnn_available.msg) AssertionError: cuDNN optimization was enabled, but Theano was not able to use it. We got this error: Theano can not compile with cuDNN.",0
"File <*>/tensorboard, line 4, in <module> import tensorflow.tensorboard.tensorboard ImportError: No module named 'tensorflow.tensorboard.tensorboard'",0
"File <*>/tensorflow.py, line 2, in <module> import tensorflow as tf File <*>/tensorflow.py, line 53, in <module> tf_in = tf.placeholder(""float"", [None, A]) # Features AttributeError: 'module' object has no attribute 'placeholder'",0
"File detectGoNo.py, line 95, in <module> sess.run(train_step, feed_dict={x: image_batch, y_: label_batch}) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 340, in run run_metadata_ptr) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 545, in _run raise TypeError('The value of a feed cannot be a tf.Tensor object. ' TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, or numpy ndarrays.",0
"File <ipython-input-1-adf2ca85bb77>, line 1, in <module> runfile('/home/kang/Documents/work_code_PC1/py_tensorflow_learning/cifar10CNN_test/cifar10_eval_test.py', wdir='/home/kang/Documents/work_code_PC1/py_tensorflow_learning/cifar10CNN_test') File <*>python3/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 685, in runfile execfile(filename, namespace) File <*>python3/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 85, in execfile exec(compile(open(filename, 'rb').read(), filename, 'exec'), namespace) File <*>/cifar10_eval_test.py, line 107, in <module> tf.app.run() File <*>python3.4/dist-packages/tensorflow/python/platform/default/_app.py, line 30, in run sys.exit(main(sys.argv)) File <*>/cifar10_eval_test.py, line 104, in main evaluate() File <*>/cifar10_eval_test.py, line 94, in evaluate eval_once(saver, summary_writer, top_k_op, summary_op) File <*>/cifar10_eval_test.py, line 72, in eval_once coord.join(threads, stop_grace_period_secs = 10) File <*>python3.4/dist-packages/tensorflow/python/training/coordinator.py, line 264, in join six.reraise(*self._exc_info_to_raise) File <*>python3/dist-packages/six.py, line 659, in reraise raise value File <*>python3.4/dist-packages/tensorflow/python/training/queue_runner.py, line 185, in _run sess.run(enqueue_op) File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 315, in run return self._run(None, fetches, feed_dict) File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 473, in _run raise RuntimeError('Attempted to use a closed Session.') RuntimeError: Attempted to use a closed Session.",0
"File <ipython-input-29-4e06de0b7af3>, line 1, in <module> sess.run(edit_distances, feed_dict=feed_dict) File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 372, in run run_metadata_ptr) File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 597, in _run for subfeed, subfeed_val in _feed_fn(feed, feed_val): File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 558, in _feed_fn return feed_fn(feed, feed_val) File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 268, in <lambda> [feed.indices, feed.values, feed.shape], feed_val)), TypeError: zip argument #2 must support iteration",0
"File <*>/pool.py, line 119, in worker result = (True, func(*args, **kwds)) TypeError: func1() got multiple values for argument 'func'",0
"File <stdin>, line 1, in <module> [CODE] File caffepb.py, line 28, in <module> type=None), File <*>python2.7/site-packages/google/protobuf/descriptor.py, line 652, in __new__ _message.Message._CheckCalledFromGeneratedFile() TypeError: Descriptors should not be created directly, but only retrieved from their parent.",0
"File <stdin>, line 1, in <module> [CODE] File <*>python3.4/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import * File <*>python3.4/site-packages/tensorflow/python/__init__.py, line 48, in <module> from tensorflow.python import pywrap_tensorflow File <*>python3.4/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper() File <*>python3.4/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description) File <*>python3.4/imp.py, line 243, in load_module return load_dynamic(name, filename, file) ImportError: dlopen(/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.7.5.dylib",0
"File custom_op.py, line 19, in <module> grad = tf.gradients(my_op(a), [a])[0] File <*>python3.5/site-packages/tensorflow/python/framework/function.py, line 528, in __call__ return call_function(self._definition, *args, **kwargs) File <*>python3.5/site-packages/tensorflow/python/framework/function.py, line 267, in call_function compute_shapes=False) File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 2285, in create_op raise TypeError(""Input #%d is not a tensor: %s"" % (idx, a)) TypeError: Input #0 is not a tensor: <tensorflow.python.ops.variables.Variable object at 0x1080d2710>",0
"File trainer_deepMnist.py, line 109, in <module> x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})) File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 559, in eval return _eval_using_default_session(self, feed_dict, self.graph, session) File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 3648, in _eval_using_default_session return session.run(tensors, feed_dict) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 710, in run run_metadata_ptr) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 908, in _run feed_dict_string, options, run_metadata) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 958, in _do_run target_list, options, run_metadata) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 978, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[10000,32,28,28] [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Reshape, Variable_2/read)]]",0
"File <*>/model.py, line 109, in <module> output_actual: batch[1] File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 698, in run run_metadata_ptr) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 838, in _run fetch_handler = _FetchHandler(self._graph, fetches) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 355, in __init__ self._fetch_mapper = _FetchMapper.for_fetch(fetches) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 181, in for_fetch return _ListFetchMapper(fetch) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 288, in __init__ self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches] File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 178, in for_fetch (fetch, type(fetch))) TypeError: Fetch argument None has invalid type <type 'NoneType'>",0
"File <*>/xxx.py, line 262, in <module> model.add(SimpleRNN(output_dim=vocab_size, input_shape=train_x.shape)) File <*>/site-packages/keras/models.py, line 275, in add layer.create_input_layer(batch_input_shape, input_dtype) File <*>/site-packages/keras/engine/topology.py, line 367, in create_input_layer self(x) File <*>/site-packages/keras/engine/topology.py, line 467, in __call__ self.assert_input_compatibility(x) File <*>/site-packages/keras/engine/topology.py, line 408, in assert_input_compatibility str(K.ndim(x))) Exception: Input 0 is incompatible with layer simplernn_1: expected ndim=3, found ndim=4",0
"File <*>python2.7/site-packages/theano/sandbox/gpuarray/__init__.py, line 20, in <module> import pygpu File <*>/__init__.py, line 7, in <module> from . import gpuarray, elemwise, reduction File <*>/elemwise.py, line 3, in <module> from .dtypes import dtype_to_ctype, get_common_dtype File <*>/dtypes.py, line 6, in <module> from . import gpuarray ImportError: cannot import name gpuarray",0
"File train_lstm.py, line 66, in <module> model.embedding_placeholder: data.glove_vec}) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 382, in run run_metadata_ptr) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 655, in _run feed_dict_string, options, run_metadata) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 723, in _do_run target_list, options, run_metadata) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 743, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors.OutOfRangeError: PaddingFIFOQueue '_0_batching/padding_fifo_queue' is closed and has insufficient elements (requested 50, current size 0) [[Node: batching = QueueDequeueMany[_class=[""loc:@batching/padding_fifo_queue""], component_types=[DT_INT32, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](batching/padding_fifo_queue, batching/n)]] [[Node: batching/_9 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_1191_batching"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]",0
"File test_classifier.py, line 48, in <module> score = model.evaluate(x, y, batch_size=16) File <*>/site-packages/keras/models.py, line 655, in evaluate sample_weight=sample_weight) File <*>/site-packages/keras/engine/training.py, line 1131, in evaluate batch_size=batch_size) File <*>/site-packages/keras/engine/training.py, line 959, in _standardize_user_data exception_prefix='model input') File <*>/site-packages/keras/engine/training.py, line 108, in standardize_input_data str(array.shape)) Exception: Error when checking model input: expected convolution2d_input_1 to have shape (None, 3, 150, 150) but got array with shape (1, 3, 150, 198)`",0
"File <*>/main, line 132, in <module> apply_weights_OP = tf.matmul(activation_OP, Weights, name=""apply_weights"") File <*>python3.5/dist-packages/tensorflow/python/ops/math_ops.py, line 1346, in matmul name=name) File <*>python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 1271, in _mat_mul transpose_b=transpose_b, name=name) File <*>python3.5/dist-packages/tensorflow/python/framework/op_def_library.py, line 703, in apply_op op_def=op_def) File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 2312, in create_op set_shapes_for_outputs(ret) File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 1704, in set_shapes_for_outputs shapes = shape_func(op) File <*>python3.5/dist-packages/tensorflow/python/framework/common_shapes.py, line 94, in matmul_shape inner_a.assert_is_compatible_with(inner_b) File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 108, in assert_is_compatible_with % (self, other)) ValueError: Dimensions 3 and 4 are not compatible",0
"File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 715, in _do_call return fn(*args) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 697, in _run_fn status, run_metadata) File <*>python3.5/contextlib.py, line 66, in __exit__ next(self.gen) File <*>python3.5/dist-packages/tensorflow/python/framework/errors.py, line 450, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value auc/false_positives [[Node: auc/false_positives/read = Identity[T=DT_FLOAT, _class=[""loc:@auc/false_positives""], _device=""/job:localhost/replica:0/task:0/cpu:0""](auc/false_positives)]]",0
"File <*>/mlp_.py, line 152, in <module> train_auc = sess.run(auc, feed_dict={X: batch_xs, y: batch_ys, dropout_keep_prob:1.}) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 372, in run run_metadata_ptr) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 636, in _run feed_dict_string, options, run_metadata) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 708, in _do_run target_list, options, run_metadata) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 728, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value auc/false_positives [[Node: auc/false_positives/read = Identity[T=DT_FLOAT, _class=[""loc:@auc/false_positives""], _device=""/job:localhost/replica:0/task:0/cpu:0""](auc/false_positives)]]",0
"File dummy.py, line 16, in <module> features = tf.pack([col1, col2, col3]) File <*>python2.7/dist-packages/tensorflow/python/ops/array_ops.py, line 487, in pack return gen_array_ops._pack(values, axis=axis, name=name) File <*>python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py, line 1462, in _pack result = _op_def_lib.apply_op(""Pack"", values=values, axis=axis, name=name) File <*>python2.7/dist-packages/tensorflow/python/framework/op_def_library.py, line 437, in apply_op raise TypeError(""%s that don't all match."" % prefix) TypeError: Tensors in list passed to 'values' of 'Pack' Op have types [int32, int32, float32] that don't all match.",0
"File <*>/gridsearch.py, line 43, in <module> model.fit(x,y) File <*>/site-packages/keras/wrappers/scikit_learn.py, line 135, in fit **self.filter_sk_params(self.build_fn.__call__)) TypeError: __call__() missing 1 required positional argument: 'x'",0
"File <*>/main.py, line 13, in <module> autoencoder1.train() File <*>/AutoEncoder.py, line 74, in train _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs}) TypeError: unhashable type: 'numpy.ndarray'",0
"File <*>/__init__.py, line 79, in <module> model = baseline_model() File <*>/training_module.py, line 31, in baseline_model model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(3, IMG_WIDTH, IMG_HEIGHT))) File <*>python2.7/site-packages/keras/models.py, line 276, in add layer.create_input_layer(batch_input_shape, input_dtype) File <*>python2.7/site-packages/keras/engine/topology.py, line 370, in create_input_layer self(x) File <*>python2.7/site-packages/keras/engine/topology.py, line 514, in __call__ self.add_inbound_node(inbound_layers, node_indices, tensor_indices) File <*>python2.7/site-packages/keras/engine/topology.py, line 572, in add_inbound_node Node.create_node(self, inbound_layers, node_indices, tensor_indices) File <*>python2.7/site-packages/keras/engine/topology.py, line 149, in create_node output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0])) File <*>python2.7/site-packages/keras/layers/convolutional.py, line 466, in call filter_shape=self.W_shape) File <*>python2.7/site-packages/keras/backend/tensorflow_backend.py, line 1579, in conv2d x = tf.nn.conv2d(x, kernel, strides, padding=padding) File <*>python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 394, in conv2d data_format=data_format, name=name) File <*>python2.7/site-packages/tensorflow/python/framework/op_def_library.py, line 703, in apply_op op_def=op_def) File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 2319, in create_op set_shapes_for_outputs(ret) File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 1711, in set_shapes_for_outputs shapes = shape_func(op) File <*>python2.7/site-packages/tensorflow/python/framework/common_shapes.py, line 246, in conv2d_shape padding) File <*>python2.7/site-packages/tensorflow/python/framework/common_shapes.py, line 184, in get2d_conv_output_size (row_stride, col_stride), padding_type) File <*>python2.7/site-packages/tensorflow/python/framework/common_shapes.py, line 149, in get_conv_output_size ""Filter: %r Input: %r"" % (filter_size, input_size)) ValueError: Filter must not be larger than the input: Filter: (5, 5) Input: (3, 350)",0
"File single_model_conv.py, line 108, in <module> gan = GAN(num_latent, 28, 'single') File single_model_conv.py, line 23, in __init__ self.adversary(self.gen_image) File single_model_conv.py, line 93, in adversary h2_flattened = tf.reshape(h2, [-1, num_units]) File <*>python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py, line 1977, in reshape name=name) File <*>python2.7/site-packages/tensorflow/python/framework/op_def_library.py, line 490, in apply_op preferred_dtype=default_dtype) File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 657, in convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python2.7/site-packages/tensorflow/python/framework/constant_op.py, line 180, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name) File <*>python2.7/site-packages/tensorflow/python/framework/constant_op.py, line 163, in constant tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape)) File <*>python2.7/site-packages/tensorflow/python/framework/tensor_util.py, line 422, in make_tensor_proto tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values]) File <*>python2.7/site-packages/tensorflow/python/util/compat.py, line 64, in as_bytes (bytes_or_text,)) TypeError: Expected binary or unicode string, got -1",0
"File <*>python2.7/dist-packages/django/core/handlers/base.py, line 149, in get_response response = self.process_exception_by_middleware(e, request) File <*>python2.7/dist-packages/django/core/handlers/base.py, line 147, in get_response response = wrapped_callback(request, *callback_args, **callback_kwargs) File <*>/views.py, line 27, in home output=loaded_model.predict(img_np) File <*>python2.7/dist-packages/keras/models.py, line 671, in predict return self.model.predict(x, batch_size=batch_size, verbose=verbose) File <*>python2.7/dist-packages/keras/engine/training.py, line 1161, in predict check_batch_dim=False) File <*>python2.7/dist-packages/keras/engine/training.py, line 108, in standardize_input_data str(array.shape)) Exception: Error when checking : expected dense_input_1 to have shape (None, 784) but got array with shape (784, 1)",0
"File my_test.py, line 51, in [FUNC] [CODE] File <*>python3.5/dist-packages/tensorflow/python/ops/parsing_ops.py, line 640, in parse_single_sequence_example feature_list_dense_defaults, example_name, name) File <*>python3.5/dist-packages/tensorflow/python/ops/parsing_ops.py, line 837, in _parse_single_sequence_example_raw name=name) File <*>python3.5/dist-packages/tensorflow/python/ops/gen_parsing_ops.py, line 285, in _parse_single_sequence_example name=name) File <*>python3.5/dist-packages/tensorflow/python/framework/op_def_library.py, line 749, in apply_op op_def=op_def) File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 2382, in create_op set_shapes_for_outputs(ret) File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 1783, in set_shapes_for_outputs shapes = shape_func(op) File <*>python3.5/dist-packages/tensorflow/python/framework/common_shapes.py, line 596, in call_cpp_shape_fn raise ValueError(err.message) ValueError: Shape must be rank 0 but is rank 1",0
"File test.py, line 45, in <module> (x_train, _), (x_test, _) = data ValueError: too many values to unpack (expected 2)",0
"File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 972, in _do_call return fn(*args) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 954, in _run_fn status, run_metadata) File <*>python3/contextlib.py, line 66, in __exit__ next(self.gen) File <*>python3.5/site-packages/tensorflow/python/framework/errors.py, line 463, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors.InvalidArgumentError: Input to reshape is a tensor with 313600 values, but the requested shape requires a multiple of 4608 [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](dropout/mul, Reshape_1/shape)]]",0
"File mnist_tensorflow.py, line 60, in <module> x: batch[0], y_: batch[1], keep_prob1: 1.0, keep_prob2: 1.0}) File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 559, in eval return _eval_using_default_session(self, feed_dict, self.graph, session) File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 3761, in _eval_using_default_session return session.run(tensors, feed_dict) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 717, in run run_metadata_ptr) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 915, in _run feed_dict_string, options, run_metadata) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 965, in _do_run target_list, options, run_metadata) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 985, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors.InvalidArgumentError: Input to reshape is a tensor with 313600 values, but the requested shape requires a multiple of 4608 [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](dropout/mul, Reshape_1/shape)]]",0
"File <stdin>, line 1, in <module> [CODE] File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import * File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 21, in <module> _pywrap_tensorflow = swig_import_helper() File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow') File <*>python2.7/__init__.py, line 37, in import_module __import__(name) ImportError: No module named _pywrap_tensorflow",0
"File <*>python3.4/site-packages/pip/basecommand.py, line 215, in main status = self.run(options, args) File <*>python3.4/site-packages/pip/commands/install.py, line 342, in run prefix=options.prefix_path, File <*>python3.4/site-packages/pip/req/req_set.py, line 784, in install **kwargs File <*>python3.4/site-packages/pip/req/req_install.py, line 851, in install self.move_wheel_files(self.source_dir, root=root, prefix=prefix) File <*>python3.4/site-packages/pip/req/req_install.py, line 1064, in move_wheel_files isolated=self.isolated, File <*>python3.4/site-packages/pip/wheel.py, line 345, in move_wheel_files clobber(source, lib_dir, True) File <*>python3.4/site-packages/pip/wheel.py, line 329, in clobber os.utime(destfile, (st.st_atime, st.st_mtime)) PermissionError: [Errno 1] Operation not permitted",0
"File <*>/demo.py, line 18, in <module> from fast_rcnn.test import im_detect File <*>/test.py, line 16, in <module> import caffe File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver File <*>/pycaffe.py, line 13, in <module> from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \ ImportError: No module named _caffe",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1021, in _do_call return fn(*args) File <*>/site-packages/tensorflow/python/client/session.py, line 1003, in _run_fn status, run_metadata) File <*>/contextlib.py, line 66, in __exit__ next(self.gen) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 469, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(100, 784), b.shape=(784, 256), m=100, n=256, k=784 [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_Placeholder_0/_7, Variable/read)]] [[Node: Mean/_15 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_35_Mean"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]",0
"File add_1.py, line 13, in <module> saver = tf.train.Saver([y]) raise TypeError(""Variable to save is not a Variable: %s"" % var) TypeError: Variable to save is not a Variable: Tensor(""add_3:0"", shape=(), dtype=int32, device=/job:local/task:3)",0
"File <*>/test_counter.py, line 61, in <module> saver = tf.train.Saver({'w':temp}) File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 1043, in __init__ self.build() File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 1073, in build restore_sequentially=self._restore_sequentially) File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 649, in build saveables = self._ValidateAndSliceInputs(names_to_saveables) File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 578, in _ValidateAndSliceInputs variable) TypeError: names_to_saveables must be a dict mapping string names to Tensors/Variables. Not a variable: Tensor(""TransformFeatureToIndex:0"", shape=(100,), dtype=string)",0
"File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 451, in __init__ dims_iter = iter(dims) File <*>/site-packages/tensorflow/python/framework/ops.py, line 510, in __iter__ raise TypeError(""'Tensor' object is not iterable."") TypeError: 'Tensor' object is not iterable.",0
"File <*>/test_placeholder.py, line 5, in <module> input = tf.placeholder(tf.int32, tf.pack([batchSize, 5])) File <*>/site-packages/tensorflow/python/ops/array_ops.py, line 1579, in placeholder shape = tensor_shape.as_shape(shape) File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 821, in as_shape return TensorShape(shape) File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 454, in __init__ self._dims = [as_dimension(dims)] File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 378, in as_dimension return Dimension(value) File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 33, in __init__ self._value = int(value) TypeError: int() argument must be a string, a bytes-like object or a number, not 'Tensor'",0
"File <*>python2.7/dist-packages/tensorflow/python/__init__.py, line 61, in <module> from tensorflow.python import pywrap_tensorflow File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper() File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description) ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory",0
"File test_keras.py, line 52, in <module> model.fit(x_train, y_train, validation_data=(x_test, y_test), nb_epoch=epochs, batch_size=32) File <*>python2.7/dist-packages/keras/models.py, line 664, in fit sample_weight=sample_weight) File <*>python2.7/dist-packages/keras/engine/training.py, line 1068, in fit batch_size=batch_size) File <*>python2.7/dist-packages/keras/engine/training.py, line 981, in _standardize_user_data exception_prefix='model input') File <*>python2.7/dist-packages/keras/engine/training.py, line 113, in standardize_input_data str(array.shape)) ValueError: Error when checking model input: expected convolution2d_input_1 to have shape (None, 3, 32, 32) but got array with shape (50000, 32, 32, 3)",0
"File <stdin>, line 1, in <module> [CODE] File <*>/site-packages/sklearn/model_selection/_validation.py, line 140, in cross_val_score for train, test in cv_iter) File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 758, in __call__ while self.dispatch_one_batch(iterator): File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 603, in dispatch_one_batch tasks = BatchedCalls(itertools.islice(iterator, batch_size)) File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 127, in __init__ self.items = list(iterator_slice) File <*>/site-packages/sklearn/model_selection/_validation.py, line 140, in <genexpr> for train, test in cv_iter) File <*>/site-packages/sklearn/base.py, line 67, in clone new_object_params = estimator.get_params(deep=False) TypeError: get_params() got an unexpected keyword argument 'deep'",0
"File <*>python2.7/threading.py, line 810, in __bootstrap_inner self.run() File <*>python2.7/threading.py, line 763, in run self.__target(*self.__args, **self.__kwargs) File <*>python2.7/site-packages/keras/engine/training.py, line 409, in data_generator_task generator_output = next(generator) File <*>python2.7/site-packages/keras/preprocessing/image.py, line 691, in next target_size=self.target_size) File <*>python2.7/site-packages/keras/preprocessing/image.py, line 191, in load_img img = img.convert('RGB') File <*>python2.7/site-packages/PIL/Image.py, line 844, in convert self.load() File <*>python2.7/site-packages/PIL/ImageFile.py, line 248, in load return Image.Image.load(self) AttributeError: 'NoneType' object has no attribute 'Image'",0
"File <string>, line 1, in <module> [CODE] IOError: [Errno 2] No such file or directory: '/private/var/folders/1p/7km73m0s2cvdfb1js3ct8_mh0000gn/T/pip-JMMIRP-build/setup.py'",0
"File convolutional.py, line 339, in <module> tf.app.run(main=main, argv=[sys.argv[0]] + unparsed) File <*>python2.7/dist-packages/tensorflow/python/platform/app.py, line 44, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough)) File convolutional.py, line 284, in main with tf.Session() as sess: File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 1187, in __init__ super(Session, self).__init__(target, graph, config=config) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 552, in __init__ self._session = tf_session.TF_NewDeprecatedSession(opts, status) File <*>python2.7/contextlib.py, line 24, in __exit__ self.gen.next() File <*>python2.7/dist-packages/tensorflow/python/framework/errors_impl.py, line 469, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors_impl.InternalError: Failed to create session.",0
"File <stdin>, line 1, in <module> [CODE] File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import * File <*>/site-packages/tensorflow/python/__init__.py, line 63, in <module> from tensorflow.core.framework.graph_pb2 import * File <*>/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in <module> from google.protobuf import descriptor as _descriptor ImportError: No module named 'google'",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 10, in [FUNC] [CODE] File <*>/contextlib.py, line 66, in __exit__ next(self.gen) File <*>/contextlib.py, line 66, in [FUNC] [CODE] n_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [10000,10] vs. [10000] [[Node: sub = Sub[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](Add, _recv_Placeholder_1_0/_7)]]",0
"File test1.py, line 43, in <module> c = sess.run(cost, feed_dict={X: train_X, Y: train_Y}) File <*>/site-packages/tensorflow/python/client/session.py, line 76, in [FUNC] [CODE] File <*>/site-packages/tensorflow/python/client/session.py, line 96, in [FUNC] [CODE] File <*>/site-packages/tensorflow/python/client/session.py, line 10, in [FUNC] [CODE] tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [10000,10] vs. [10000] [[Node: sub = Sub[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](Add, _recv_Placeholder_1_0/_7)]]",0
"File board.py, line 3, in <module> mnist = input_data.read_data_sets(r'Z:/downloads/MNIST dataset', one_hot=True) File <*>/input_data.py, line 150, in read_data_sets train_images = extract_images(local_file) File <*>/input_data.py, line 40, in extract_images buf = bytestream.read(rows * cols * num_images) File <*>/gzip.py, line 274, in read return self._buffer.read(size) TypeError: only integer scalar arrays can be converted to a scalar index",0
"File helloWorld.py, line 10, in <module> import matplotlib.pyplot as plt ImportError: No module named 'matplotlib'",0
"File pymask.py, line 303, in <module> main(sys.argv) File pymask.py, line 285, in main keras.callbacks.ProgbarLogger() File <*>python3.6/site-packages/keras/engine/training.py, line 1557, in fit_generator class_weight=class_weight) File <*>python3.6/site-packages/keras/engine/training.py, line 1314, in train_on_batch check_batch_axis=True) File <*>python3.6/site-packages/keras/engine/training.py, line 1029, in _standardize_user_data exception_prefix='model input') File <*>python3.6/site-packages/keras/engine/training.py, line 52, in standardize_input_data str(names)) ValueError: No data provided for ""input_1"". Need data for each key in: ['input_1']",0
"File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1022, in _do_call return fn(*args) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1004, in _run_fn status, run_metadata) File <*>python3.5/contextlib.py, line 66, in __exit__ next(self.gen) File <*>python3.5/site-packages/tensorflow/python/framework/errors_impl.py, line 469, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[14525,14000] [[Node: rnn/basic_lstm_cell/weights/Initializer/random_uniform = Add[T=DT_FLOAT, _class=[""loc:@rnn/basic_lstm_cell/weights""], _device=""/job:localhost/replica:0/task:0/gpu:0""](rnn/basic_lstm_cell/weights/Initializer/random_uniform/mul, rnn/basic_lstm_cell/weights/Initializer/random_uniform/min)]]",0
"File Netzwerk_v0.5.1_gamma.py, line 171, in <module> session.run(tf.global_variables_initializer()) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 767, in run run_metadata_ptr) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 965, in _run feed_dict_string, options, run_metadata) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1015, in _do_run target_list, options, run_metadata) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1035, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[14525,14000] [[Node: rnn/basic_lstm_cell/weights/Initializer/random_uniform = Add[T=DT_FLOAT, _class=[""loc:@rnn/basic_lstm_cell/weights""], _device=""/job:localhost/replica:0/task:0/gpu:0""](rnn/basic_lstm_cell/weights/Initializer/random_uniform/mul, rnn/basic_lstm_cell/weights/Initializer/random_uniform/min)]]",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call return fn(*args) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1293, in _run_fn self._extend_graph() File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1354, in _extend_graph self._session, graph_def.SerializeToString(), status) File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.UnavailableError: Trying to connect an http1.x server",0
"File <*>/pydevd.py, line 1599, in <module> globals = debugger.run(setup['file'], None, None, is_module) File <*>/pydevd.py, line 1026, in run pydev_imports.execfile(file, globals, locals) # execute the script File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc) File worker.py, line 426, in <module> main() File worker.py, line 418, in main run(args, server) File worker.py, line 174, in run sess.run(trainer.sync) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.UnavailableError: Trying to connect an http1.x server",0
"File <*>/rock_detector.py, line 155, in <module> main() File <*>/rock_detector.py, line 117, in main est_vgg16.train(input_fn=dataset_input_fn, steps=10) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 302, in train loss = self._train_model(input_fn, hooks, saving_listeners) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 711, in _train_model features, labels, model_fn_lib.ModeKeys.TRAIN, self.config) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 694, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs) File <*>python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py, line 145, in model_fn labels) File <*>python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py, line 92, in _clone_and_build_model keras_model, features) File <*>python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py, line 58, in _create_ordered_io for key in estimator_io_dict: File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 505, in __iter__ raise TypeError(""'Tensor' object is not iterable."") TypeError: 'Tensor' object is not iterable.",0
"File <*>python3.5/dist-packages/Theano-1.0.0rc1-py3.5.egg/theano/gpuarray/__init__.py, line 220, in <module> use(config.device) File <*>python3.5/dist-packages/Theano-1.0.0rc1-py3.5.egg/theano/gpuarray/__init__.py, line 207, in use init_dev(device, preallocate=preallocate) File <*>python3.5/dist-packages/Theano-1.0.0rc1-py3.5.egg/theano/gpuarray/__init__.py, line 152, in init_dev pygpu.blas.gemm(0, tmp, tmp, 0, tmp, overwrite_c=True) File <*>/blas.pyx, line 149, in pygpu.blas.gemm [CODE] File <*>/blas.pyx, line 47, in pygpu.blas.pygpu_blas_rgemm [CODE] pygpu.gpuarray.GpuArrayException: (b'cuLinkCreate: CUDA_ERROR_JIT_COMPILER_NOT_FOUND: PTX JIT compiler library not found', 3)",0
"File <ipython-input-6-b5da44e251a5>, line 1, in <module> from keras.layers import Input, Dense ModuleNotFoundError: No module named 'keras'",0
"File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 62, in _pin_memory_loop batch = pin_memory_batch(batch) File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 123, in pin_memory_batch return [pin_memory_batch(sample) for sample in batch] File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 123, in <listcomp> return [pin_memory_batch(sample) for sample in batch] File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 117, in pin_memory_batch return batch.pin_memory() File <*>python3.6/site-packages/torch/tensor.py, line 82, in pin_memory return type(self)().set_(storage.pin_memory()).view_as(self) File <*>python3.6/site-packages/torch/storage.py, line 83, in pin_memory allocator = torch.cuda._host_allocator() File <*>python3.6/site-packages/torch/cuda/__init__.py, line 220, in _host_allocator _lazy_init() File <*>python3.6/site-packages/torch/cuda/__init__.py, line 84, in _lazy_init _check_driver() File <*>python3.6/site-packages/torch/cuda/__init__.py, line 51, in _check_driver raise AssertionError(""Torch not compiled with CUDA enabled"") AssertionError: Torch not compiled with CUDA enabled",0
"File SAMME_train_all.py, line 47, in <module> ce = K.categorical_crossentropy(label, label_pred) File <*>/tensorflow_backend.py, line 2754, in categorical_c axis=len(output.get_shape()) - 1, AttributeError: 'numpy.ndarray' object has no attribute 'get_shape'",0
"File modeltrain.py, line 180, in <module> model.fit_generator(next_batch(X_train_r, y_train_r, batch_size), steps_per_epoch=(X_train_r.shape[0]/batch_size), validation_data=(X_val_r, y_val_r), epochs=100, callbacks=[csv_logger, model_check]) File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 87, in wrapper return func(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/training.py, line 1978, in fit_generator val_x, val_y, val_sample_weight) File <*>python3.6/site-packages/keras/engine/training.py, line 1382, in _standardize_user_data exception_prefix='target') File <*>python3.6/site-packages/keras/engine/training.py, line 111, in _standardize_input_data 'Found: array with shape ' + str(data.shape)) ValueError: The model expects 9 target arrays, but only received one array. Found: array with shape (70, 512, 512, 1)",0
"File test_python.py, line 1, in [FUNC] [CODE] ModuleNotFoundError: No module named 'numpy'",0
"File main.py, line 36, in <module> model.fit(X,Y, epochs=50, batch_size=100) File <*>/site-packages/keras/models.py, line 960, in fit validation_steps=validation_steps) File <*>/site-packages/keras/engine/training.py, line 1574, in fit batch_size=batch_size) File <*>/site-packages/keras/engine/training.py, line 1407, in _standardize_user_data exception_prefix='input') File <*>/site-packages/keras/engine/training.py, line 128, in _standardize_input_data arrays[i] = array ValueError: could not broadcast input array from shape (14,1) into shape (14)",0
"File <*>/main.py, line 89, in <module> _ = sess.run([update_step]) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[500,80] [[Node: decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](decoder/while/BasicDecoderStep/basic_lstm_cell/concat, decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul/Enter)]] [[Node: gradients/Add/_282 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_457_gradients/Add"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](^_cloopdecoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y/_181)]]",0
"File <ipython-input-6-06fadd69ae8f>, line 1, in <module> runfile('C:/Users/1/Desktop/transfer_learning_tutorial-master/MCVE.py', wdir='C:/Users/1/Desktop/transfer_learning_tutorial-master') File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 710, in runfile execfile(filename, namespace) File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 101, in execfile exec(compile(f.read(), filename, 'exec'), namespace) File <*>/MCVE.py, line 77, in <module> tf.app.run(main=main, argv=[sys.argv[0]]) File <*>/site-packages/tensorflow/python/platform/app.py, line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough)) File <*>/MCVE.py, line 68, in main steps=1000) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 302, in train loss = self._train_model(input_fn, hooks, saving_listeners) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 780, in _train_model log_step_count_steps=self._config.log_step_count_steps) as mon_sess: File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 368, in MonitoredTrainingSession stop_grace_period_secs=stop_grace_period_secs) File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 673, in __init__ stop_grace_period_secs=stop_grace_period_secs) File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 493, in __init__ self._sess = _RecoverableSession(self._coordinated_creator) File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 851, in __init__ _WrappedSession.__init__(self, self._create_session()) File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 856, in _create_session return self._sess_creator.create_session() File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 554, in create_session self.tf_sess = self._session_creator.create_session() File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 428, in create_session init_fn=self._scaffold.init_fn) File <*>/site-packages/tensorflow/python/training/session_manager.py, line 279, in prepare_session sess.run(init_op, feed_dict=init_feed_dict) File <*>/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr) File <*>/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message) InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [900] rhs shape= [1001] [[Node: Assign_1145 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionResnetV2/Logits/Logits/biases""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionResnetV2/Logits/Logits/biases, checkpoint_initializer_1145)]]",0
"File <stdin>, line 1, in <module> [CODE] RuntimeError: invalid argument 2: dimension 1 out of range of 1D tensor at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensor.c:24",0
"File <stdin>, line 1, in <module> [CODE] RuntimeError: matrices expected, got 1D, 2D tensors at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensorMath.c:1288",0
"File <*>/site-packages/tensorflow/python/platform/self_check.py, line 75, in preload_check ctypes.WinDLL(build_info.cudart_dll_name) File <*>/__init__.py, line 351, in __init__ self._handle = _dlopen(self._name, mode) OSError: [WinError 126] This specified module could not be found",0
"File <stdin>, line 1, in <module> [CODE] File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import * File <*>/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 30, in <module> self_check.preload_check() File <*>/site-packages/tensorflow/python/platform/self_check.py, line 82, in preload_check % (build_info.cudart_dll_name, build_info.cuda_version_number)) ImportError: Could not find 'cudart64_80.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 8.0 from this URL: https://developer.nvidia.com/cuda-toolkit",0
"File <*>/site-packages/google/protobuf/internal/python_message.py, line 545, in _GetFieldByName return message_descriptor.fields_by_name[field_name] KeyError: 'layout_optimizer'",0
"File export_inference_graph.py, line 119, in <module> tf.app.run() File <*>/site-packages/tensorflow/python/platform/app.py, line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough)) File export_inference_graph.py, line 115, in main FLAGS.output_directory, input_shape) File <*>/site-packages/object_detection-0.1-py3.5.egg/object_detection/exporter.py, line 427, in export_inference_graph input_shape, optimize_graph, output_collection_name) File <*>/site-packages/object_detection-0.1-py3.5.egg/object_detection/exporter.py, line 391, in _export_inference_graph initializer_nodes='') File <*>/site-packages/object_detection-0.1-py3.5.egg/object_detection/exporter.py, line 72, in freeze_graph_with_def_protos layout_optimizer=rewriter_config_pb2.RewriterConfig.ON) File <*>/site-packages/google/protobuf/internal/python_message.py, line 484, in init field = _GetFieldByName(message_descriptor, field_name) File <*>/site-packages/google/protobuf/internal/python_message.py, line 548, in _GetFieldByName (message_descriptor.name, field_name)) ValueError: Protocol message RewriterConfig has no ""layout_optimizer"" field.",0
"File <ipython-input-7-e80e82960eb9>, line 1, in <module> cross = cross_val_score(estimator=classfier, X=Xtrain, y=Ytrain, cv=10 , n_jobs=-1) File <*>/site-packages/sklearn/model_selection/_validation.py, line 342, in cross_val_score pre_dispatch=pre_dispatch) File <*>/site-packages/sklearn/model_selection/_validation.py, line 206, in cross_validate for train, test in cv.split(X, y, groups)) File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 779, in __call__ while self.dispatch_one_batch(iterator): File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 620, in dispatch_one_batch tasks = BatchedCalls(itertools.islice(iterator, batch_size)) File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 127, in __init__ self.items = list(iterator_slice) File <*>/site-packages/sklearn/model_selection/_validation.py, line 206, in <genexpr> for train, test in cv.split(X, y, groups)) File <*>/site-packages/sklearn/base.py, line 62, in clone new_object_params[name] = clone(param, safe=False) File <*>/site-packages/sklearn/base.py, line 53, in clone return copy.deepcopy(estimator) File <*>/copy.py, line 180, in deepcopy y = _reconstruct(x, memo, *rv) File <*>/copy.py, line 280, in _reconstruct state = deepcopy(state, memo) File <*>/copy.py, line 150, in deepcopy y = copier(x, memo) File <*>/copy.py, line 240, in _deepcopy_dict y[deepcopy(key, memo)] = deepcopy(value, memo) File <*>/copy.py, line 215, in _deepcopy_list append(deepcopy(a, memo)) File <*>/copy.py, line 169, in deepcopy rv = reductor(4) TypeError: can't pickle _thread.lock objects",0
"File testJan17.py, line 13, in <module> sample_model() File testJan17.py, line 8, in sample_model att_mull = Multiply([dense_all, dense_att]) #merge([dense_all, dense_att], output_shape=10, mode='mul') TypeError: __init__() takes exactly 1 argument (2 given)",0
"File predict.py, line 34, in <module> preds = learn.predict_array(im[None]) File <*>/learner.py, line 266, in predict_array def predict_array(self, arr): return to_np(self.model(V(T(arr).cuda()))) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 325, in __call__ result = self.forward(*input, **kwargs) File <*>python3.6/site-packages/torch/nn/modules/container.py, line 67, in forward input = module(input) File <*>python3.6/site-packages/torch/nn/modules/batchnorm.py, line 37, in forward self.training, self.momentum, self.eps) File <*>python3.6/site-packages/torch/nn/functional.py, line 1011, in batch_norm raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size)) ValueError: Expected more than 1 value per channel when training, got input size [1, 1024]",0
"File cnn_base.py, line 1703, in <module> training() File cnn_base.py, line 1314, in training _, loss_value = sess.run([train_op, loss]) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: cnn()conv2 : Tensor had Inf values [[Node: tower_7/conv2/CheckNumerics_3 = CheckNumerics[T=DT_FLOAT, message=""NaN: cnn()conv2"", _device=""/job:localhost/replica:0/task:0/device:GPU:7""](tower_7/conv2/conv2)]]",0
"File cnn_base.py, line 1704, in <module> training() File cnn_base.py, line 1312, in training nan_debug, _, loss_value = sess.run([check_op, train_op, loss]) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata) File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: average_gradients(expanded_g) : Tensor had Inf and NaN values [[Node: CheckNumerics_30 = CheckNumerics[T=DT_FLOAT, message=""NaN: average_gradients(expanded_g)"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](ExpandDims_30)]] [[Node: tower_6/total_loss/_2216 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:6"", send_device_incarnation=1, tensor_name=""edge_4923_tower_6/total_loss"", _device=""/job:localhost/replica:0/task:0/device:GPU:6""](tower_6/total_loss)]]",0
"File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.5/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File <*>python3.5/imp.py, line 242, in load_module return load_dynamic(name, filename, file) File <*>python3.5/imp.py, line 342, in load_dynamic return _load(spec) ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory",0
"File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File <*>python3.5/imp.py, line 242, in load_module return load_dynamic(name, filename, file) File <*>python3.5/imp.py, line 342, in load_dynamic return _load(spec) ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory",0
"File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File <*>python3.5/imp.py, line 242, in load_module return load_dynamic(name, filename, file) File <*>python3.5/imp.py, line 342, in load_dynamic return _load(spec) ImportError: /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow9ConcatCPUINS_8bfloat16EEEvPNS_10DeviceBaseERKSt6vectorISt10unique_ptrINS_6TTypesIT_Li2EiE11ConstMatrixESt14default_deleteIS9_EESaISC_EEPNS8_6MatrixE",0
"File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory",0
"File <*>/hackerearth_project.py, line 90, in <module> model(X_train, X_test, Y_train, Y_test) File <*>/hackerearth_project.py, line 71, in model optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1, beta2=beta2).minimize(cost) File <*>/site-packages/tensorflow/python/training/optimizer.py, line 343, in minimize grad_loss=grad_loss) File <*>/site-packages/tensorflow/python/training/optimizer.py, line 394, in compute_gradients self._assert_valid_dtypes([loss]) File <*>/site-packages/tensorflow/python/training/optimizer.py, line 543, in _assert_valid_dtypes dtype = t.dtype.base_dtype AttributeError: 'NoneType' object has no attribute 'dtype'",0
"File <*>/cli.py, line 797, in Execute resources = calliope_command.Run(cli=self, args=args) File <*>/backend.py, line 757, in Run resources = command_instance.Run(args) File <*>/predict.py, line 65, in Run args.text_instances) File <*>/local_utils.py, line 89, in RunPredict raise LocalPredictRuntimeError(err) LocalPredictRuntimeError: RuntimeError: Bad magic number in .pyc file ERROR: (gcloud.ml-engine.local.predict) RuntimeError: Bad magic number in .pyc file",0
"File <*>/site-packages/cx_Freeze/initscripts/__startup__.py, line 14, in run module.run() File <*>/site-packages/cx_Freeze/initscripts/Console.py, line 26, in run exec(code, m.__dict__) File app.py, line 2, in <module> [CODE] File <*>/retrain.py, line 16, in <module> import tensorflow as tf File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import * File <*>/site-packages/tensorflow/python/__init__.py, line 52, in <module> from tensorflow.core.framework.graph_pb2 import * File <*>/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in <module> from google.protobuf import descriptor as _descriptor ImportError: No module named 'google'",0
"File <*>/new_main.py, line 35, in <module> b = sess.run(correct_prediction, feed_dict={a: a1, b: b1, y: y1}) TypeError: unhashable type: 'numpy.ndarray'",0
"File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1350, in _do_call return fn(*args) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1329, in _run_fn status, run_metadata) File <*>python3.5/dist-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,32,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[Node: FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Preprocessor/sub, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read)]]",0
"File eval.py, line 146, in <module> tf.app.run() File <*>python3.5/dist-packages/tensorflow/python/platform/app.py, line 124, in run _sys.exit(main(argv)) File eval.py, line 142, in main FLAGS.checkpoint_dir, FLAGS.eval_dir) File <*>/evaluator.py, line 240, in evaluate save_graph_dir=(eval_dir if eval_config.save_graph else '')) File <*>/eval_util.py, line 407, in repeated_checkpoint_run save_graph_dir) File <*>/eval_util.py, line 286, in _run_checkpoint_once result_dict = batch_processor(tensor_dict, sess, batch, counters) File <*>/evaluator.py, line 183, in _process_batch result_dict = sess.run(tensor_dict) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 895, in run run_metadata_ptr) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1128, in _run feed_dict_tensor, options, run_metadata) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1344, in _do_run options, run_metadata) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1363, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,32,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[Node: FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Preprocessor/sub, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read)]]",0
"File <*>python3.6/configparser.py, line 1138, in _unify_values sectiondict = self._sections[section] KeyError: 'blas'",0
"File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl input_tensors_as_shapes, status) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[1], expected a dimension of 1, got 3 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [100,3].",0
"File <*>/cnn_mnist.py, line 214, in <module> tf.app.run() File <*>/site-packages/tensorflow/python/platform/app.py, line 124, in run _sys.exit(main(argv)) File <*>/cnn_mnist.py, line 203, in main hooks=[logging_hook]) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 314, in train loss = self._train_model(input_fn, hooks, saving_listeners) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 743, in _train_model features, labels, model_fn_lib.ModeKeys.TRAIN, self.config) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 725, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs) File <*>/cnn_mnist.py, line 67, in cnn_model_fn loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits) File <*>/site-packages/tensorflow/python/ops/losses/losses_impl.py, line 790, in sparse_softmax_cross_entropy labels, logits, weights, expected_rank_diff=1) File <*>/site-packages/tensorflow/python/ops/losses/losses_impl.py, line 720, in _remove_squeezable_dimensions labels, predictions, expected_rank_diff=expected_rank_diff) File <*>/site-packages/tensorflow/python/ops/confusion_matrix.py, line 76, in remove_squeezable_dimensions labels = array_ops.squeeze(labels, [-1]) File <*>/site-packages/tensorflow/python/ops/array_ops.py, line 2490, in squeeze return gen_array_ops._squeeze(input, axis, name) File <*>/site-packages/tensorflow/python/ops/gen_array_ops.py, line 7049, in _squeeze ""Squeeze"", input=input, squeeze_dims=axis, name=name) File <*>/site-packages/tensorflow/python/framework/op_def_library.py, line 787, in _apply_op_helper op_def=op_def) File <*>/site-packages/tensorflow/python/framework/ops.py, line 3162, in create_op compute_device=compute_device) File <*>/site-packages/tensorflow/python/framework/ops.py, line 3208, in _create_op_helper set_shapes_for_outputs(op) File <*>/site-packages/tensorflow/python/framework/ops.py, line 2427, in set_shapes_for_outputs return _set_shapes_for_outputs(op) File <*>/site-packages/tensorflow/python/framework/ops.py, line 2400, in _set_shapes_for_outputs shapes = shape_func(op) File <*>/site-packages/tensorflow/python/framework/ops.py, line 2330, in call_with_requiring return call_cpp_shape_fn(op, require_shape_fn=True) File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 627, in call_cpp_shape_fn require_shape_fn) File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 691, in _call_cpp_shape_fn_impl raise ValueError(err.message) ValueError: Can not squeeze dim[1], expected a dimension of 1, got 3 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [100,3].",0
"File <*>python3.6/inspect.py, line 1119, in getfullargspec sigcls=Signature) File <*>python3.6/inspect.py, line 2186, in _signature_from_callable raise TypeError('{!r} is not a callable object'.format(obj)) TypeError: (<tf.Tensor 'IteratorGetNext:0' shape=(?, 40, 40, ?) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=int32>) is not a callable object",0
"File <*>/task2_new.py, line 78, in <module> loss = compute_loss(h_fc2, margin) File <*>/task2_new.py, line 37, in compute_loss Ltriplet = np.maximum(0, 1 - tf.square(diff_neg)/(tf.square(diff_pos) + margin)) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 614, in __bool__ raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. "" TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",0
"File <*>/try2.py, line 45, in <module> classifier.train(input_fn=lambda: my_input_fn(is_shuffle=True, repeat_count=100)) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 352, in train loss = self._train_model(input_fn, hooks, saving_listeners) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 812, in _train_model features, labels, model_fn_lib.ModeKeys.TRAIN, self.config) File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 793, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py, line 354, in _model_fn config=config) File <*>python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py, line 161, in _dnn_model_fn 'Given type: {}'.format(type(features))) ValueError: features should be a dictionary of `Tensor`s. Given type: <class 'tensorflow.python.framework.ops.Tensor'>",0
"File <*>/generate_tfrecord.py, line 99, in <module> tf.app.run() File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv)) File <*>/generate_tfrecord.py, line 85, in main writer = tf.python_io.TFRecordWriter(FLAGS.output_path) File <*>/site-packages/tensorflow/python/lib/io/tf_record.py, line 111, in __init__ compat.as_bytes(path), compat.as_bytes(compression_type), status) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a NewWriteableFile: : The system cannot find the path specified.",0
"File <*>/main.py, line 6, in <module> watcher = Watcher('res/vid/planet_earth_s01e01/video.mp4', 'res/vid/planet_earth_s01e01/english.srt') File <*>/watch.py, line 9, in __init__ self.detector = Detector() File <*>/detect.py, line 6, in __init__ self.tfnet = TFNet(self.options) File <*>python3.6/site-packages/darkflow/net/build.py, line 75, in __init__ self.build_forward() File <*>python3.6/site-packages/darkflow/net/build.py, line 105, in build_forward self.inp = tf.placeholder(tf.float32, inp_size, 'input') File <*>python3.6/site-packages/tensorflow/python/ops/array_ops.py, line 1677, in placeholder raise RuntimeError(""tf.placeholder() is not compatible with "" RuntimeError: tf.placeholder() is not compatible with eager execution.",0
"File <*>/lstm.py, line 128, in <module> main() File <*>/lstm.py, line 108, in main model.fit_generator(generator=training_sequence) File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) File <*>/site-packages/keras/models.py, line 1253, in fit_generator initial_epoch=initial_epoch) File <*>/site-packages/keras/engine/training.py, line 2244, in fit_generator class_weight=class_weight) File <*>/site-packages/keras/engine/training.py, line 1884, in train_on_batch class_weight=class_weight) File <*>/site-packages/keras/engine/training.py, line 1487, in _standardize_user_data exception_prefix='target') File <*>/site-packages/keras/engine/training.py, line 113, in _standardize_input_data 'with shape ' + str(data_shape)) ValueError: Error when checking target: expected dense_1 to have 5 dimensions, but got array with shape (1, 1939, 9)",0
"File <*>/lstm.py, line 131, in <module> main() File <*>/lstm.py, line 111, in main model.fit_generator(generator=training_sequence) File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) File <*>/site-packages/keras/models.py, line 1253, in fit_generator initial_epoch=initial_epoch) File <*>/site-packages/keras/engine/training.py, line 2244, in fit_generator class_weight=class_weight) File <*>/site-packages/keras/engine/training.py, line 1884, in train_on_batch class_weight=class_weight) File <*>/site-packages/keras/engine/training.py, line 1487, in _standardize_user_data exception_prefix='target') File <*>/site-packages/keras/engine/training.py, line 113, in _standardize_input_data 'with shape ' + str(data_shape)) ValueError: Error when checking target: expected dense_1 to have 2 dimensions, but got array with shape (1, 1034, 9)",0
"File train.py, line 167, in <module> tf.app.run() File <*>python3.5/app.py, line 126, in run _sys.exit(main(argv)) File train.py, line 163, in main worker_job_name, is_chief, FLAGS.train_dir) File <*>python3.5/dist-packages/object_detection-0.1-py3.5.egg/object_detection/trainer.py, line 211, in train detection_model = create_model_fn() File <*>python3.5/dist-packages/object_detection-0.1-py3.5.egg/object_detection/builders/model_builder.py, line 96, in build add_summaries) File <*>python3.5/dist-packages/object_detection-0.1-py3.5.egg/object_detection/builders/model_builder.py, line 272, in _build_faster_rcnn_model frcnn_config.inplace_batchnorm_update) AttributeError: 'FasterRcnn' object has no attribute 'inplace_batchnorm_update'",0
"File <*>/freeze_graph, line 11, in <module> sys.exit(main()) TypeError: main() missing 1 required positional argument: unused_args",0
"File [FILE], line 337, in [FUNC] [CODE] TypeError: 'UnimplementedError' object is not iterable",0
"File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 579, in merge_with new_dims.append(dim.merge_with(other[i])) File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 138, in merge_with self.assert_is_compatible_with(other) File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 111, in assert_is_compatible_with other)) ValueError: Dimensions 5 and 4 are not compatible",0
"File <*>python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py, line 602, in gradients in_grad.set_shape(t_in.get_shape()) File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 407, in set_shape self._shape = self._shape.merge_with(shape) File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 582, in merge_with raise ValueError(""Shapes %s and %s are not compatible"" % (self, other)) ValueError: Shapes (?, 5, 15, 1) and (?, 4, 15, 1) are not compatible",0
"File experiment.py, line 65, in <module> batches_per_lot=batches_per_lot, sigma=dp_sigma, dp=dp) File <*>/model.py, line 247, in GAN_solvers G_solver = tf.train.AdamOptimizer().minimize(G_loss_mean_over_batch, var_list=generator_vars) File <*>python3.5/dist-packages/tensorflow/python/training/optimizer.py, line 343, in minimize grad_loss=grad_loss) File <*>python3.5/dist-packages/tensorflow/python/training/optimizer.py, line 414, in compute_gradients colocate_gradients_with_ops=colocate_gradients_with_ops) File <*>python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py, line 609, in gradients % (op.name, i, t_in.shape, in_grad.shape)) ValueError: Incompatible shapes between op input and calculated input gradient. Forward operation: generator/conv2d_transpose_1. Input index: 2. Original input shape: (?, 4, 15, 1). Calculated input gradient shape: (?, 5, 15, 1)",0
"File <stdin>, line 1, in <module> [CODE] File <*>/k_means.py, line 10, in prepare_dataset dataset = tf.data.Dataset.from_tensor_slices(dm_data) File <*>python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 222, in from_tensor_slices return TensorSliceDataset(tensors) File <*>python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1017, in __init__ for i, t in enumerate(nest.flatten(tensors)) File <*>python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1017, in <listcomp> for i, t in enumerate(nest.flatten(tensors)) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 950, in convert_to_tensor as_ref=False) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1040, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 235, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name) File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 185, in constant t = convert_to_eager_tensor(value, ctx, dtype) File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 131, in convert_to_eager_tensor return ops.EagerTensor(value, context=handle, device=device, dtype=dtype) ValueError: Can't convert Python sequence with mixed types to Tensor.",0
"File processing_2a_1.py, line 96, in <module> model.add(Conv1D(60,32, strides=1, activation='relu',padding='causal',input_shape=(None,64,1))) File <*>/models.py, line 442, in add [CODE] File <*>/topology.py, line 558, in __call__ [CODE] File <*>/topology.py, line 457, in assert_input_compatibility [CODE] ValueError: Input 0 is incompatible with layer conv1d_1: expected ndim=3, found ndim=4",0
"File processing_2a_1.py, line 125, in <module> history=model.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_val,Y_val), epochs=nr_of_epochs,verbose=2) File <*>/models.py, line 871, in fit [CODE] File <*>/training.py, line 1524, in fit [CODE] File <*>/training.py, line 1382, in _standardize_user_data [CODE] File <*>/training.py, line 132, in _standardize_input_data [CODE] ValueError: Error when checking target: expected dense_2 to have 3 dimensions, but got array with shape (1496000, 1)",0
"File [FILE], line <*>, in [FUNC] [CODE] AttributeError: module 'tensorflow' has no attribute 'Session'",0
"File <*>/train.py, line 167, in <module> tf.app.run() File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv)) File <*>/train.py, line 92, in main FLAGS.pipeline_config_path) File <*>/config_util.py, line 93, in get_configs_from_pipeline_file text_format.Merge(proto_str, pipeline_config) File <*>/site-packages/google/protobuf/text_format.py, line 533, in Merge descriptor_pool=descriptor_pool) File <*>/site-packages/google/protobuf/text_format.py, line 587, in MergeLines return parser.MergeLines(lines, message) File <*>/site-packages/google/protobuf/text_format.py, line 620, in MergeLines self._ParseOrMerge(lines, message) File <*>/site-packages/google/protobuf/text_format.py, line 635, in _ParseOrMerge self._MergeField(tokenizer, message) File <*>/site-packages/google/protobuf/text_format.py, line 735, in _MergeField merger(tokenizer, message, field) File <*>/site-packages/google/protobuf/text_format.py, line 823, in _MergeMessageField self._MergeField(tokenizer, sub_message) File <*>/site-packages/google/protobuf/text_format.py, line 703, in _MergeField (message_descriptor.full_name, name)) google.protobuf.text_format.ParseError: 108:7 : Message type ""object_detection.protos.SsdFeatureExtractor"" has no field named ""batch_norm_trainable"".",0
"File train.py, line 167, in <module> tf.app.run() File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv)) File train.py, line 92, in main FLAGS.pipeline_config_path) File <*>/config_util.py, line 93, in get_configs_from_pipeline_file text_format.Merge(proto_str, pipeline_config) File <*>/site-packages/google/protobuf/text_format.py, line 533, in Merge descriptor_pool=descriptor_pool) File <*>/site-packages/google/protobuf/text_format.py, line 587, in MergeLines return parser.MergeLines(lines, message) File <*>/site-packages/google/protobuf/text_format.py, line 620, in MergeLines self._ParseOrMerge(lines, message) File <*>/site-packages/google/protobuf/text_format.py, line 635, in _ParseOrMerge self._MergeField(tokenizer, message) File <*>/site-packages/google/protobuf/text_format.py, line 735, in _MergeField merger(tokenizer, message, field) File <*>/site-packages/google/protobuf/text_format.py, line 823, in _MergeMessageField self._MergeField(tokenizer, sub_message) File <*>/site-packages/google/protobuf/text_format.py, line 703, in _MergeField (message_descriptor.full_name, name)) google.protobuf.text_format.ParseError: 108:7 : Message type ""object_detection.protos.SsdFeatureExtractor"" has no field named ""batch_norm_trainable"".",0
"File train.py, line 167, in <module> tf.app.run() File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv)) File train.py, line 163, in main worker_job_name, is_chief, FLAGS.train_dir) File <*>/trainer.py, line 275, in train clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue]) File <*>/model_deploy.py, line 193, in create_clones outputs = model_fn(*args, **kwargs) File <*>/trainer.py, line 198, in _create_losses prediction_dict = detection_model.predict(images, true_image_shapes) File <*>/ssd_meta_arch.py, line 384, in predict preprocessed_inputs) File <*>/ssd_mobilenet_v2_feature_extractor.py, line 123, in extract_features scope=scope) File <*>/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py, line 183, in func_with_args return func(*args, **current_args) File <*>/mobilenet_v2.py, line 162, in mobilenet_base base_only=True, **kwargs) File <*>/mobilenet_v2.py, line 154, in mobilenet **kwargs) File <*>/mobilenet.py, line 325, in mobilenet net, end_points = mobilenet_base(inputs, scope=scope, **mobilenet_args) File <*>/mobilenet.py, line 244, in mobilenet_base net = opdef.op(net, **params) File <*>/site-packages/tensorflow/contrib/layers/python/layers/layers.py, line 1058, in convolution outputs = normalizer_fn(outputs, **normalizer_params) File <*>/site-packages/tensorflow/contrib/layers/python/layers/layers.py, line 650, in batch_norm outputs = layer.apply(inputs, training=is_training) File <*>/site-packages/tensorflow/python/layers/base.py, line 825, in apply return self.__call__(inputs, *args, **kwargs) File <*>/site-packages/tensorflow/python/layers/base.py, line 714, in __call__ outputs = self.call(inputs, *args, **kwargs) File <*>/site-packages/tensorflow/python/layers/normalization.py, line 549, in call training_value = utils.constant_value(training) File <*>/site-packages/tensorflow/python/layers/utils.py, line 232, in constant_value return smart_module.smart_constant_value(pred) File <*>/site-packages/tensorflow/python/framework/smart_cond.py, line 93, in smart_constant_value ""Found instead: %s"" % pred) TypeError: `pred` must be a Tensor, or a Python bool, or 1 or 0. Found instead: None",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1330, in _do_call return fn(*args) File <*>/site-packages/tensorflow/python/client/session.py, line 1315, in _run_fn options, feed_dict, fetch_list, target_list, run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1423, in _call_tf_sessionrun status, run_metadata) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,25] vs. shape[1] = [30,100] [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](rnn/while/TensorArrayReadV3, rnn/while/Switch_4:1, rnn/while/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/Const)]]",0
"File <*>/dnn_gragh.py, line 198, in <module> model.train(5000, 0.0001, my_input_fn, training_examples, training_targets, sequenceLenth=trainSequenceL) File <*>/dnn_gragh.py, line 124, in train state2, current_loss, nowAccuracy = sess.run([state, loss, accuracy]) File <*>/site-packages/tensorflow/python/client/session.py, line 908, in run run_metadata_ptr) File <*>/site-packages/tensorflow/python/client/session.py, line 1143, in _run feed_dict_tensor, options, run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1324, in _do_run run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1343, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,25] vs. shape[1] = [30,100] [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](rnn/while/TensorArrayReadV3, rnn/while/Switch_4:1, rnn/while/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/Const)]]",0
"File <*>/mnist_test.py, line 24, in <module> from official.mnist import mnist ModuleNotFoundError: No module named 'official'",0
"File main.py, line 69, in <module> main(); File main.py, line 66, in main train_model(iris_dataset, model, optimizer); File main.py, line 41, in train_model gradients = gradient_tune(features, label, model); File main.py, line 27, in gradient_tune prediction_loss = prediction_loss_diff(features, targets, model); File main.py, line 23, in prediction_loss_diff return tf.losses.sparse_softmax_cross_entropy(label, predicted_label); File <*>python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py, line 853, in sparse_softmax_cross_entropy name=""xentropy"") File <*>python3.6/site-packages/tensorflow/python/ops/nn_ops.py, line 2050, in sparse_softmax_cross_entropy_with_logits precise_logits, labels, name=name) File <*>python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 7504, in sparse_softmax_cross_entropy_with_logits _six.raise_from(_core._status_to_exception(e.code, message), None) File <string>, line 2, in raise_from [CODE] tensorflow.python.framework.errors_impl.InternalError: Could not find valid device for node name: ""SparseSoftmaxCrossEntropyWithLogits""",0
"File <*>/scratch_4.py, line 11, in <module> assert type(elem) == tf.python.framework.ops.EagerTensor AttributeError: module 'tensorflow' has no attribute 'python'",0
"File <*>python2.7/site-packages/tensorflow/python/ops/script_ops.py, line 147, in __call__ ret = func(*args) File <*>python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 378, in generator_py_func nest.flatten_up_to(output_types, values), flattened_types) AttributeError: 'numpy.dtype' object has no attribute 'as_numpy_dtype'",0
"File pipe, line 320, in <module> tf.app.run() File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv)) File pipe, line 316, in main train(FLAGS.num_training_iterations, FLAGS.report_interval, FLAGS.report_interval_verbose) File pipe, line 120, in train print(sess.run(next_element)) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 905, in run run_metadata_ptr) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1140, in _run feed_dict_tensor, options, run_metadata) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1321, in _do_run run_metadata) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1340, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.UnknownError: exceptions.AttributeError: 'numpy.dtype' object has no attribute 'as_numpy_dtype'",0
"File <string>, line 1, in <module> [CODE] File <*>/spawn.py, line 105, in spawn_main exitcode = _main(fd) File <*>/spawn.py, line 114, in _main prepare(preparation_data) File <*>/spawn.py, line 225, in prepare _fixup_main_from_path(data['init_main_from_path']) File <*>/spawn.py, line 277, in _fixup_main_from_path run_name=""__mp_main__"") File <*>/runpy.py, line 263, in run_path pkg_name=pkg_name, script_name=fname) File <*>/runpy.py, line 96, in _run_module_code mod_name, mod_spec, pkg_name, script_name) File <*>/runpy.py, line 85, in _run_code exec(code, run_globals) File <*>/TutorialCIFAR10.py, line 36, in <module> dataiter = iter(trainloader) File <*>/site-packages/torch/utils/data/dataloader.py, line 451, in __iter__ return _DataLoaderIter(self) File <*>/site-packages/torch/utils/data/dataloader.py, line 239, in __init__ w.start() File <*>/process.py, line 105, in start self._popen = self._Popen(self) File <*>/context.py, line 223, in _Popen return _default_context.get_context().Process._Popen(process_obj) File <*>/context.py, line 322, in _Popen return Popen(process_obj) File <*>/popen_spawn_win32.py, line 33, in __init__ prep_data = spawn.get_preparation_data(process_obj._name) File <*>/spawn.py, line 143, in get_preparation_data _check_not_importing_main() File <*>/spawn.py, line 136, in _check_not_importing_main is not going to be frozen to produce an executable.) RuntimeError: An attempt has been made to start a new process before the current process has finished its bootstrapping phase.",0
"File <*>/label_map_util.py, line 135, in load_labelmap text_format.Merge(label_map_string, label_map) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 525, in Merge descriptor_pool=descriptor_pool) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 579, in MergeLines return parser.MergeLines(lines, message) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 612, in MergeLines self._ParseOrMerge(lines, message) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 627, in _ParseOrMerge self._MergeField(tokenizer, message) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 727, in _MergeField merger(tokenizer, message, field) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 815, in _MergeMessageField self._MergeField(tokenizer, sub_message) File <*>python3.6/site-packages/google/protobuf/text_format.py, line 695, in _MergeField (message_descriptor.full_name, name)) google.protobuf.text_format.ParseError: 23:20 : Message type ""object_detection.protos.StringIntLabelMapItem"" has no field named ""s"".",0
"File train.py, line 184, in <module> tf.app.run() File <*>python3.6/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv)) File train.py, line 180, in main graph_hook_fn=graph_rewriter_fn) File <*>/trainer.py, line 264, in train train_config.prefetch_queue_capacity, data_augmentation_options) File <*>/trainer.py, line 59, in create_input_queue tensor_dict = create_tensor_dict_fn() File train.py, line 121, in get_next dataset_builder.build(config)).get_next() File <*>/dataset_builder.py, line 155, in build label_map_proto_file=label_map_proto_file) File <*>/tf_example_decoder.py, line 245, in init use_display_name) File <*>/label_map_util.py, line 152, in get_label_map_dict label_map = load_labelmap(label_map_path) File <*>/label_map_util.py, line 137, in load_labelmap label_map.ParseFromString(label_map_string) TypeError: a bytes-like object is required, not 'str'",0
"File <*>/site-packages/theano/gof/lazylinker_c.py, line 81, in <module> actual_version, force_compile, _need_reload)) ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True",0
"File <*>/site-packages/theano/gof/lazylinker_c.py, line 105, in <module> actual_version, force_compile, _need_reload)) ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True",0
"File <ipython-input-11-9a561e7b074b>, line 1, in <module> runfile('C:/Users/emile/Desktop/tensorflow.py', wdir='C:/Users/emile/Desktop') File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 705, in runfile execfile(filename, namespace) File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 102, in execfile exec(compile(f.read(), filename, 'exec'), namespace) File <*>/tensorflow.py, line 6, in <module> import tensorflow as tf File <*>/tensorflow.py, line 7, in <module> import tensorflow.contrib.eager as tfe ModuleNotFoundError: No module named 'tensorflow.contrib'; 'tensorflow' is not a package",0
"File seq2seq_train.py, line 5, in <module> from keras_text_summarization.library.utility.plot_utils import plot_and_save_history ModuleNotFoundError: No module named 'keras_text_summarization'",0
"File model.py, line 91, in <module> model = Model(inputs=[x1, x2], outputs=[out]) File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/network.py, line 91, in __init__ self._init_graph_network(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/network.py, line 183, in _init_graph_network 'The tensor that caused the issue was: ' + AttributeError: 'Model' object has no attribute 'name'",0
"File generate_tfrecord.py, line 17, in <module> import tensorflow as tf File <*>/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import File <*>/site-packages/tensorflow/python/__init__.py, line 81, in <module> from tensorflow.python import keras File <*>/site-packages/tensorflow/python/keras/__init__.py, line 24, in <module> from tensorflow.python.keras import activations File <*>/site-packages/tensorflow/python/keras/activations/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.activations import elu File <*>/site-packages/tensorflow/python/keras/_impl/keras/__init__.py, line 21, in <module> from tensorflow.python.keras._impl.keras import activations File <*>/site-packages/tensorflow/python/keras/_impl/keras/activations.py, line 23, in <module> from tensorflow.python.keras._impl.keras import backend as K File <*>/site-packages/tensorflow/python/keras/_impl/keras/backend.py, line 38, in <module> from tensorflow.python.layers import base as tf_base_layers File <*>/site-packages/tensorflow/python/layers/base.py, line 25, in <module> from tensorflow.python.keras.engine import base_layer File <*>/site-packages/tensorflow/python/keras/engine/__init__.py, line 21, in <module> from tensorflow.python.keras.engine.base_layer import InputSpec File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 33, in <module> from tensorflow.python.keras import backend File <*>/site-packages/tensorflow/python/keras/backend/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.backend import abs ImportError: cannot import name 'abs'",0
"File test.py, line 13, in <module> layers.Dense(64, activation='sigmoid') NameError: name 'layers' is not defined",0
"File <stdin>, line 1, in <module> [CODE] File <*>python3.5/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import File <*>python3.5/site-packages/tensorflow/python/__init__.py, line 52, in <module> from tensorflow.core.framework.graph_pb2 import * ImportError: No module named 'tensorflow.core'",0
"File <ipython-input-2-25b92e4d5dec>, line 2, in <module> hello = tf.constant('Hello, TensorFlow!') AttributeError: module 'tensorflow' has no attribute 'constant'",0
"File train_v2.py, line 110, in <module> main() File train_v2.py, line 81, in main model.update(batch) File <*>/model.py, line 131, in update loss_adv = self.adversarial_loss(batch, loss, self.network.lexicon_encoder.embedding.weight, y) File <*>/model.py, line 94, in adversarial_loss adv_embedding = torch.LongTensor(adv_embedding) TypeError: expected torch.LongTensor (got torch.cuda.FloatTensor)",0
"File main.py, line 109, in <module> train(loader_train, model, criterion, optimizer) File main.py, line 54, in train optimizer.step() File <*>python3.6/site-packages/torch/optim/sgd.py, line 93, in step d_p.add_(weight_decay, p.data) RuntimeError: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/THC/generated/../generic/THCTensorMathPointwise.cu:265",0
"File deparser.py, line 402, in <module> d.train() File deparser.py, line 331, in train total, correct, avgloss = self.train_util() File deparser.py, line 362, in train_util loss = self.step(X_train, Y_train, correct, total) File deparser.py, line 214, in step loss = nn.CrossEntropyLoss()(out.long(), y) File <*>python3.5/site-packages/torch/nn/modules/module.py, line 477, in __call__ result = self.forward(*input, **kwargs) File <*>python3.5/site-packages/torch/nn/modules/loss.py, line 862, in forward ignore_index=self.ignore_index, reduction=self.reduction) File <*>python3.5/site-packages/torch/nn/functional.py, line 1550, in cross_entropy return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction) File <*>python3.5/site-packages/torch/nn/functional.py, line 975, in log_softmax return input.log_softmax(dim) RuntimeError: ""host_softmax"" not implemented for 'torch.cuda.LongTensor'",0
"File pytorch.py, line 14, in <module> test_tensor = torch.tensor(test) ValueError: could not determine the shape of object type 'DataFrame'",0
"File [FILE], line <*>, in [FUNC] [CODE] File <*>/setup.py, line 108, in [FUNC] [CODE] ImportError: No module named tools.setup_helpers.env",0
"File hello-world.py, line 1, in <module> from keras.models import Sequential File <*>python3.6/site-packages/keras/__init__.py, line 3, in <module> from . import utils File <*>python3.6/site-packages/keras/utils/__init__.py, line 2, in <module> from . import np_utils File <*>python3.6/site-packages/keras/utils/np_utils.py, line 6, in <module> import numpy as np File <*>python3.6/site-packages/numpy/__init__.py, line 142, in <module> from . import add_newdocs File <*>python3.6/site-packages/numpy/add_newdocs.py, line 13, in <module> from numpy.lib import add_newdoc File <*>python3.6/site-packages/numpy/lib/__init__.py, line 8, in <module> from .type_check import * File <*>python3.6/site-packages/numpy/lib/type_check.py, line 11, in <module> import numpy.core.numeric as _nx File <*>python3.6/site-packages/numpy/core/__init__.py, line 16, in <module> from . import multiarray SystemError: initialization of multiarray raised unreported exception",0
"File <ipython-input-7-2ef5e6514df7>, line 33, in data_generator [CODE] File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1530, in __exit__ self._default_graph_context_manager.__exit__(exec_type, exec_value, exec_tb) File <*>python3.6/contextlib.py, line 99, in __exit__ self.gen.throw(type, value, traceback) File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 5025, in get_controller context.context().context_switches.pop() File <*>python3.6/dist-packages/tensorflow/python/eager/context.py, line 136, in pop self.stack.pop() IndexError: pop from empty list",0
"File <*>/predict.py, line 74, in <module> print(get_grad(x_cloned, x)) File <*>/predict.py, line 68, in get_grad A.backward() File <*>python3.5/site-packages/torch/tensor.py, line 93, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph) File <*>python3.5/site-packages/torch/autograd/__init__.py, line 90, in backward allow_unreachable=True) # allow_unreachable flag RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn",0
"File <*>/playground.py, line 22, in <module> print(get_grad(x_cloned, x)) File <*>/playground.py, line 16, in get_grad A.backward() File <*>python3.5/site-packages/torch/tensor.py, line 93, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph) File <*>python3.5/site-packages/torch/autograd/__init__.py, line 84, in backward grad_tensors = _make_grads(tensors, grad_tensors) File <*>python3.5/site-packages/torch/autograd/__init__.py, line 28, in _make_grads raise RuntimeError(""grad can be implicitly created only for scalar outputs"") RuntimeError: grad can be implicitly created only for scalar outputs",0
"File <*>/all_good.py, line 15, in <module> import matplotlib.pyplot as plt File <*>/site-packages/matplotlib/pyplot.py, line 115, in <module> _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup() File <*>/site-packages/matplotlib/backends/__init__.py, line 62, in pylab_setup [backend_name], 0) File <*>/site-packages/matplotlib/backends/backend_qt5agg.py, line 15, in <module> from .backend_qt5 import ( File <*>/site-packages/matplotlib/backends/backend_qt5.py, line 19, in <module> import matplotlib.backends.qt_editor.figureoptions as figureoptions File <*>/site-packages/matplotlib/backends/qt_editor/figureoptions.py, line 20, in <module> import matplotlib.backends.qt_editor.formlayout as formlayout File <*>/site-packages/matplotlib/backends/qt_editor/formlayout.py, line 54, in <module> from matplotlib.backends.qt_compat import QtGui, QtWidgets, QtCore File <*>/site-packages/matplotlib/backends/qt_compat.py, line 158, in <module> raise ImportError(""Failed to import any qt binding"") ImportError: Failed to import any qt binding",0
"File lstm_test.py, line 152, in <module> model.fit(samples_train, labels_train, epochs=1, batch_size=1) File <*>/site-packages/keras/models.py, line 1002, in fit validation_steps=validation_steps) File <*>/site-packages/keras/engine/training.py, line 1630, in fit batch_size=batch_size) File <*>/site-packages/keras/engine/training.py, line 1476, in _standardize_user_data exception_prefix='input') File <*>/site-packages/keras/engine/training.py, line 113, in _standardize_input_data 'with shape ' + str(data_shape)) ValueError: Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (134, 1)",0
"File run.py, line 64, in <module> model.fit(images, labels, epochs=1, steps_per_epoch=2) File <*>python2.7/site-packages/tensorflow/python/keras/engine/training.py, line 1363, in fit validation_steps=validation_steps) File <*>python2.7/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 205, in fit_loop outs = f(ins) File <*>python2.7/site-packages/tensorflow/python/keras/backend.py, line 2914, in __call__ fetched = self._callable_fn(*array_vals) File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1382, in __call__ run_metadata_ptr) File <*>python2.7/site-packages/tensorflow/python/framework/errors_impl.py, line 519, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: Matrix size-incompatible: In[0]: [10000,1], In[1]: [3,1] [[Node: rgb_to_grayscale/Tensordot/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](rgb_to_grayscale/Tensordot/Reshape, rgb_to_grayscale/Tensordot/Reshape_1)]] [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,100,100,1], [?,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](OneShotIterator)]]",0
"File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2869, in _dep_map return self.__dep_map File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2663, in __getattr__ raise AttributeError(attr) AttributeError: _DistInfoDistribution__dep_map",0
"File <*>python3.6/site-packages/pip/_vendor/packaging/requirements.py, line 93, in __init__ req = REQUIREMENT.parseString(requirement_string) File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 1632, in parseString raise exc File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 1622, in parseString loc, tokens = self._parse( instring, 0 ) File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 1379, in _parseNoCache loc,tokens = self.parseImpl( instring, preloc, doActions ) File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 3395, in parseImpl loc, exprtokens = e._parse( instring, loc, doActions ) File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 1383, in _parseNoCache loc,tokens = self.parseImpl( instring, preloc, doActions ) File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 3183, in parseImpl raise ParseException(instring, loc, self.errmsg, self) pip._vendor.pyparsing.ParseException: Expected stringEnd (at char 33), (line:1, col:34)",0
"File noveou_train_netvlad.py, line 226, in <module> minu = keras.layers.Maximum()( [ minu, K.zeros(nN, nP) ] ) File <*>python2.7/dist-packages/keras/engine/base_layer.py, line 457, in __call__ output = self.call(inputs, **kwargs) File <*>python2.7/dist-packages/keras/layers/merge.py, line 115, in call return self._merge_function(reshaped_inputs) File <*>python2.7/dist-packages/keras/layers/merge.py, line 301, in _merge_function output = K.maximum(output, inputs[i]) File <*>python2.7/dist-packages/keras/backend/tensorflow_backend.py, line 1672, in maximum return tf.maximum(x, y) File <*>python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 4707, in maximum ""Maximum"", x=x, y=y, name=name) File <*>python2.7/dist-packages/tensorflow/python/framework/op_def_library.py, line 546, in _apply_op_helper inferred_from[input_arg.type_attr])) TypeError: Input 'y' of 'Maximum' Op has type string that does not match type float32 of argument 'x'.",0
"File <string>, line 1, in <module> [CODE] File <*>/setup.py, line 25, in <module> cythonize(ext_modules) File <*>/site-packages/Cython/Build/Dependencies.py, line 956, in cythonize aliases=aliases) File <*>/site-packages/Cython/Build/Dependencies.py, line 801, in create_extension_list for file in nonempty(sorted(extended_iglob(filepattern)), ""'%s' doesn't match any files"" % filepattern): File <*>/site-packages/Cython/Build/Dependencies.py, line 111, in nonempty raise ValueError(error_msg) ValueError: 'pycocotools/_mask.pyx' doesn't match any files",0
"File <*>/QuestionStackoverflow.py, line 26, in <module> q_vals_v = net(state_v.view(1, state_v.shape[0], state_v.shape[1])) File <*>python3.5/site-packages/torch/nn/modules/module.py, line 477, in __call__ result = self.forward(*input, **kwargs) File <*>/QuestionStackoverflow.py, line 15, in forward out = self.hidden2tag(out) File <*>python3.5/site-packages/torch/nn/modules/, line 55, in forward return F.linear(input, self.weight, self.bias) File <*>python3.5/site-packages/torch/nn/functional.py, line 1022, in linear if input.dim() == 2 and bias is not None: AttributeError: 'tuple' object has no attribute 'dim'",0
"File <*>/tensor01.py, line 4, in <module> x = torch.Tensor([[.5, .3, 2.1]], requires_grad=False) TypeError: new() received an invalid combination of arguments - got (list, requires_grad=bool), but expected one of: * (torch.device device) * (torch.Storage storage) * (Tensor other) * (tuple of ints size, torch.device device) didn't match because some of the keywords were incorrect: requires_grad * (object data, torch.device device) didn't match because some of the keywords were incorrect: requires_grad",0
"File convolutional_network_raw.py, line 137, in <module> writer.add_summary(summary=summary, global_step=step) File <*>python3.6/site-packages/tensorflow/python/summary/writer/writer.py, line 126, in add_summary for value in summary.value: AttributeError: 'numpy.float32' object has no attribute 'value'",0
"File binary_classification.py, line 59, in <module> history=model.fit(X, y,batch_size=10, epochs=25,validation_split=0.7) File <*>python3.6/site-packages/keras/engine/training.py, line 1039, in fit validation_steps=validation_steps) File <*>python3.6/site-packages/keras/engine/training_arrays.py, line 217, in fit_loop callbacks.on_epoch_end(epoch, epoch_logs) File <*>python3.6/site-packages/keras/callbacks.py, line 79, in on_epoch_end callback.on_epoch_end(epoch, logs) File <*>python3.6/site-packages/keras/callbacks.py, line 338, in on_epoch_end self.progbar.update(self.seen, self.log_values) AttributeError: 'ProgbarLogger' object has no attribute 'log_values'",0
"File test_loocv.py, line 245, in <module> output = model_ft(test_data) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 477, in __call__ result = self.forward(*input, **kwargs) File <*>python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/resnet.py, line 139, in forward [CODE] File <*>python3.6/site-packages/torch/nn/modules/conv.py, line 301, in forward self.padding, self.dilation, self.groups) RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[3, 1, 224, 224] to have 3 channels, but got 1 channels instead",0
"File <*>/lesson4-imdb2.py, line 27, in <module> pickle.dump(md, file) TypeError: 'generator' object is not callable",0
"File app.py, line 16, in <module> from modules.xvision import Xvision File <*>/xvision.py, line 84, in <module> tf.import_graph_def(net['graph_def'], name='vgg') TypeError: 'Model' object has no attribute '__getitem__'",0
"File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 204, in _convert_pb_to_mlmodel shape_list = shape.as_list() File <*>python3.6/site-packages/tensorflow/python/framework/tensor_shape.py, line 900, in as_list raise ValueError(""as_list() is not defined on an unknown TensorShape."") ValueError: as_list() is not defined on an unknown TensorShape.",0
"File model.py, line 6, in <module> class_labels = 'conv_labels.txt' File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 586, in convert custom_conversion_functions=custom_conversion_functions) File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 206, in _convert_pb_to_mlmodel raise ValueError('Please provide the shape for the input {} through the argument \'input_name_shape_dict\''.format(input_name)) ValueError: Please provide the shape for the input wav_data:0 through the argument 'input_name_shape_dict'",0
"File <*>/tst1.py, line 110, in <module> classifier.fit(X_train, y_train, batch_size = 10, epochs = 100) File <*>/site-packages/keras/engine/training.py, line 950, in fit batch_size=batch_size) File <*>/site-packages/keras/engine/training.py, line 787, in _standardize_user_data exception_prefix='target') File <*>/site-packages/keras/engine/training_utils.py, line 137, in standardize_input_data str(data_shape)) ValueError: Error when checking target: expected dense_3 to have shape (1,) but got array with shape (6,)",0
"File <*>/site-packages/keras/engine/topology.py, line 442, in assert_input_compatibility K.is_keras_tensor(x) File <*>/site-packages/keras/backend/tensorflow_backend.py, line 468, in is_keras_tensor raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. ' ValueError: Unexpectedly found an instance of type `<class 'keras.layers.core.Masking'>`. Expected a symbolic tensor instance.",0
"File <*>/testcompile.py, line 46, in <module> model = network_structure(32, 44, 125) File <*>/testcompile.py, line 12, in network_structure lstm_h1 = keras.layers.LSTM(lstm_neurons)(masking) File <*>/site-packages/keras/layers/recurrent.py, line 499, in __call__ return super(RNN, self).__call__(inputs, **kwargs) File <*>/site-packages/keras/engine/topology.py, line 575, in __call__ self.assert_input_compatibility(inputs) File <*>/site-packages/keras/engine/topology.py, line 448, in assert_input_compatibility str(inputs) + '. All inputs to the layer ' ValueError: Layer lstm_1 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.core.Masking'>. Full input: [<keras.layers.core.Masking object at 0x000002224683A780>]. All inputs to the layer should be tensors.",0
"File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 3078, in get_loc return self._engine.get_loc(key) File <*>/index.pyx, line 140, in pandas._libs.index.IndexEngine.get_loc [CODE] File <*>/index.pyx, line 162, in pandas._libs.index.IndexEngine.get_loc [CODE] File <*>/hashtable_class_helper.pxi, line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE] File <*>/hashtable_class_helper.pxi, line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE] KeyError: range(418, 419)",0
"File <*>/main.py, line 94, in <module> data_menu() File <*>/main.py, line 42, in data_menu data_menu() File <*>/main.py, line 56, in data_menu nn_menu() File <*>/main.py, line 76, in nn_menu nn.nn_gen(pre_processed_data) File <*>/nn.py, line 33, in nn_gen x, y = train[0] File <*>python3.6/site-packages/keras_preprocessing/sequence.py, line 378, in __getitem__ samples[j] = self.data[indices] File <*>python3.6/site-packages/pandas/core/frame.py, line 2688, in __getitem__ return self._getitem_column(key) File <*>python3.6/site-packages/pandas/core/frame.py, line 2695, in _getitem_column return self._get_item_cache(key) File <*>python3.6/site-packages/pandas/core/generic.py, line 2489, in _get_item_cache values = self._data.get(item) File <*>python3.6/site-packages/pandas/core/internals.py, line 4115, in get loc = self.items.get_loc(item) File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 3080, in get_loc return self._engine.get_loc(self._maybe_cast_indexer(key)) File <*>/index.pyx, line 140, in pandas._libs.index.IndexEngine.get_loc [CODE] File <*>/index.pyx, line 162, in pandas._libs.index.IndexEngine.get_loc [CODE] File <*>/hashtable_class_helper.pxi, line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE] File <*>/hashtable_class_helper.pxi, line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE] KeyError: range(418, 419)",0
"File <*>/site-packages/flask/app.py, line 1813, in full_dispatch_request rv = self.dispatch_request() File <*>/site-packages/flask/app.py, line 1799, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args) File <*>/site-packages/flask_restful/__init__.py, line 458, in wrapper resp = resource(*args, **kwargs) File <*>/site-packages/flask/views.py, line 88, in view return self.dispatch_request(*args, **kwargs) File <*>/site-packages/flask_restful/__init__.py, line 573, in dispatch_request resp = meth(*args, **kwargs) File app.py, line 41, in get print(ann.predict(x_test)) File <*>/site-packages/keras/engine/training.py, line 1164, in predict self._make_predict_function() File <*>/site-packages/keras/engine/training.py, line 554, in _make_predict_function **kwargs) File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2744, in function return Function(inputs, outputs, updates=updates, **kwargs) File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2546, in __init__ with tf.control_dependencies(self.outputs): File <*>/site-packages/tensorflow/python/framework/ops.py, line 5004, in control_dependencies return get_default_graph().control_dependencies(control_inputs) File <*>/site-packages/tensorflow/python/framework/ops.py, line 4543, in control_dependencies c = self.as_graph_element(c) File <*>/site-packages/tensorflow/python/framework/ops.py, line 3490, in as_graph_element return self._as_graph_element_locked(obj, allow_tensor, allow_operation) File <*>/site-packages/tensorflow/python/framework/ops.py, line 3569, in _as_graph_element_locked raise ValueError(""Tensor %s is not an element of this graph."" % obj) ValueError: Tensor Tensor(""dense_3/Sigmoid:0"", shape=(?, 1), dtype=float32) is not an element of this graph.",0
"File <ipython-input-286-e49b6fac918b>, line 1, in <module> output=model(input_) File <*>/site-packages/torch/nn/modules/module.py, line 489, in __call__ result = self.forward(*input, **kwargs) TypeError: forward() missing 1 required positional argument: 'p'",0
"File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 138, in _worker_loop samples = collate_fn([dataset[i] for i in batch_indices]) File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 138, in <listcomp> samples = collate_fn([dataset[i] for i in batch_indices]) File <*>python3.6/site-packages/torch/utils/data/dataset.py, line 103, in __getitem__ return self.dataset[self.indices[idx]] File <ipython-input-27-107e03bc3c6a>, line 12, in __getitem__ x = torch.tensor(self.x_data.iloc[index].values, dtype=torch.float) File <*>python3.6/site-packages/pandas/core/indexing.py, line 1478, in __getitem__ return self._getitem_axis(maybe_callable, axis=axis) File <*>python3.6/site-packages/pandas/core/indexing.py, line 2091, in _getitem_axis return self._get_list_axis(key, axis=axis) File <*>python3.6/site-packages/pandas/core/indexing.py, line 2070, in _get_list_axis return self.obj._take(key, axis=axis) File <*>python3.6/site-packages/pandas/core/generic.py, line 2789, in _take verify=True) File <*>python3.6/site-packages/pandas/core/internals.py, line 4537, in take new_labels = self.axes[axis].take(indexer) File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 2195, in take return self._shallow_copy(taken) File <*>python3.6/site-packages/pandas/core/indexes/range.py, line 267, in _shallow_copy return self._int64index._shallow_copy(values, **kwargs) File <*>python3.6/site-packages/pandas/core/indexes/numeric.py, line 68, in _shallow_copy return self._shallow_copy_with_infer(values=values, **kwargs) File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 538, in _shallow_copy_with_infer if not len(values) and 'dtype' not in kwargs: TypeError: object of type 'numpy.int64' has no len()",0
"File <*>/tensorboard-script.py, line 6, in <module> from tensorboard.main import run_main File <*>/site-packages/tensorboard/main.py, line 40, in <module> from tensorboard import default File <*>/site-packages/tensorboard/default.py, line 38, in <module> from tensorboard.plugins.beholder import beholder_plugin File <*>/site-packages/tensorboard/plugins/beholder/__init__.py, line 15, in <module> from tensorboard.plugins.beholder.beholder import Beholder File <*>/site-packages/tensorboard/plugins/beholder/beholder.py, line 25, in <module> from tensorboard.plugins.beholder import im_util File <*>/site-packages/tensorboard/plugins/beholder/im_util.py, line 89, in <module> class PNGDecoder(util.PersistentOpEvaluator): AttributeError: module 'tensorboard.util' has no attribute 'PersistentOpEvaluator'",0
"File test.py, line 4, in <module> model = load_model(""test.h5"") File <*>python3.7/site-packages/keras/engine/saving.py, line 419, in load_model model = _deserialize_model(f, custom_objects, compile) File <*>python3.7/site-packages/keras/engine/saving.py, line 258, in _deserialize_model .format(len(layer_names), len(filtered_layers)) ValueError: You are trying to load a weight file containing 6 layers into a model with 0 layers",0
"File test.py, line 7, in <module> print(model.summary()) AttributeError: 'NoneType' object has no attribute 'summary'",0
"File <stdin>, line 1, in <module> [CODE] File <*>python3.5/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import File <*>python3.5/site-packages/tensorflow/python/__init__.py, line 47, in <module> import numpy as np File <*>python3.5/site-packages/numpy/__init__.py, line 142, in <module> from . import core File <*>python3.5/site-packages/numpy/core/__init__.py, line 57, in <module> from . import numerictypes as nt File <*>python3.5/site-packages/numpy/core/numerictypes.py, line 111, in <module> from ._type_aliases import ( File <*>python3.5/site-packages/numpy/core/_type_aliases.py, line 63, in <module> _concrete_types = {v.type for k, v in _concrete_typeinfo.items()} File <*>python3.5/site-packages/numpy/core/_type_aliases.py, line 63, in <setcomp> _concrete_types = {v.type for k, v in _concrete_typeinfo.items()} AttributeError: 'tuple' object has no attribute 'type'",0
"File <*>/SVM_Stock.py, line 71, in <module> estimator.fit(x,y) File <*>/site-packages/keras/wrappers/scikit_learn.py, line 210, in fit return super(KerasClassifier, self).fit(x, y, **kwargs) File <*>/site-packages/keras/wrappers/scikit_learn.py, line 139, in fit **self.filter_sk_params(self.build_fn.__call__)) TypeError: __call__() missing 1 required positional argument: 'inputs'",0
"File test.py, line 141, in <module> max_queue_size=2) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 2177, in fit_generator initial_epoch=initial_epoch) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 147, in fit_generator generator_output = next(output_generator) File <*>python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py, line 831, in get six.reraise(value.__class__, value, value.__traceback__) File <*>python3.6/site-packages/six.py, line 693, in reraise raise value TypeError: 'My_Generator' object is not an iterator",0
"File 6_reconstruct_alphabet_image.py, line 17, in <module> import caffe File <*>python3/dist-packages/caffe/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer File <*>python3/dist-packages/caffe/pycaffe.py, line 15, in <module> import caffe.io File <*>python3/dist-packages/caffe/io.py, line 2, in <module> import skimage.io File <*>python3/dist-packages/skimage/__init__.py, line 158, in <module> from .util.dtype import * File <*>python3/dist-packages/skimage/util/__init__.py, line 7, in <module> from .arraycrop import crop File <*>python3/dist-packages/skimage/util/arraycrop.py, line 8, in <module> from numpy.lib.arraypad import _validate_lengths ImportError: cannot import name '_validate_lengths'",0
"File <frozen importlib._bootstrap>, line 980, in _find_and_load [CODE] SystemError: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set ImportError: numpy.core._multiarray_umath failed to import ImportError: numpy.core.umath failed to import",0
"File [FILE], line <*>, in [FUNC] [CODE] File <*>/site-packages/tensorflow_<em>init</em>_.py, line 24, in [FUNC] [CODE] File <*>/site-packages/tensorflow/python_<em>init</em>_.py, line 59, in [FUNC] [CODE] File <*>/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in [FUNC] [CODE] File <*>/site-packages/google/protobuf/descriptor.py, line 47, in [FUNC] [CODE] ImportError: DLL load failed: The specified procedure could not be found.",0
"File <frozen importlib._bootstrap>, line 968, in _find_and_load [CODE] SystemError: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set ImportError: numpy.core._multiarray_umath failed to import ImportError: numpy.core.umath failed to import",0
"File <*>python3.6/site-packages/theano/compile/function_module.py, line 884, in __call__ self.fn() if output_subset is None else\ ValueError: Input dimension mis-match. (input[0].shape[1] = 50, input[1].shape[1] = 100)",0
"File <*>/textClassfierHATT2D.py, line 187, in <module> nb_epoch=10, batch_size=50,verbose=2) File <*>python3.6/site-packages/keras/engine/training.py, line 1631, in fit validation_steps=validation_steps) File <*>python3.6/site-packages/keras/engine/training.py, line 1213, in _fit_loop outs = f(ins_batch) File <*>python3.6/site-packages/keras/backend/theano_backend.py, line 1223, in __call__ return self.function(*inputs) File <*>python3.6/site-packages/theano/compile/function_module.py, line 898, in __call__ storage_map=getattr(self.fn, 'storage_map', None)) File <*>python3.6/site-packages/theano/gof/link.py, line 325, in raise_with_op reraise(exc_type, exc_value, exc_trace) File <*>python3.6/site-packages/six.py, line 692, in reraise raise value.with_traceback(tb) File <*>python3.6/site-packages/theano/compile/function_module.py, line 884, in __call__ self.fn() if output_subset is None else\ ValueError: Input dimension mis-match. (input[0].shape[1] = 50, input[1].shape[1] = 100)",0
"File <*>/pydevd.py, line 1741, in <module> main() File <*>/pydevd.py, line 1735, in main globals = debugger.run(setup['file'], None, None, is_module) File <*>/pydevd.py, line 1135, in run pydev_imports.execfile(file, globals, locals) # execute the script File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc) File <*>/MnistTrainer.py, line 100, in <module> main() File <*>/MnistTrainer.py, line 92, in main mnist_trainer.train(train_steps=100, log_interval=1, save_interval=1) File <*>/MnistTrainer.py, line 56, in train self.save_models(output_folder_path, i + 1) File <*>/MnistTrainer.py, line 69, in save_models os.path.join(output_folder_path, 'discriminator_model_{0}.h5'.format(iteration_no))) File <*>python3.6/site-packages/keras/engine/network.py, line 1090, in save save_model(self, filepath, overwrite, include_optimizer) File <*>python3.6/site-packages/keras/engine/saving.py, line 382, in save_model _serialize_model(model, f, include_optimizer) File <*>python3.6/site-packages/keras/engine/saving.py, line 83, in _serialize_model model_config['config'] = model.get_config() File <*>python3.6/site-packages/keras/engine/sequential.py, line 278, in get_config 'config': layer.get_config() File <*>python3.6/site-packages/keras/layers/convolutional.py, line 493, in get_config config = super(Conv2D, self).get_config() File <*>python3.6/site-packages/keras/layers/convolutional.py, line 226, in get_config 'activation': activations.serialize(self.activation), File <*>python3.6/site-packages/keras/activations.py, line 176, in serialize return activation.__name__ AttributeError: 'LeakyReLU' object has no attribute '__name__'",0
"File <*>/train.py, line 107, in <module> callbacks=[Saver(save_every), Evaluation(evaluate_every)]) File <*>/site-packages/keras/engine/training.py, line 1039, in fit validation_steps=validation_steps) File <*>/site-packages/keras/engine/training_arrays.py, line 204, in fit_loop callbacks.on_batch_end(batch_index, batch_logs) File <*>/site-packages/keras/callbacks.py, line 115, in on_batch_end callback.on_batch_end(batch, logs) File <*>/train.py, line 83, in on_batch_end self.model.save(name) File <*>/site-packages/keras/engine/network.py, line 1090, in save save_model(self, filepath, overwrite, include_optimizer) File <*>/site-packages/keras/engine/saving.py, line 382, in save_model _serialize_model(model, f, include_optimizer) File <*>/site-packages/keras/engine/saving.py, line 83, in _serialize_model model_config['config'] = model.get_config() File <*>/site-packages/keras/engine/network.py, line 931, in get_config return copy.deepcopy(config) File <*>/copy.py, line 150, in deepcopy y = copier(x, memo) File <*>/copy.py, line 240, in _deepcopy_dict y[deepcopy(key, memo)] = deepcopy(value, memo) File <*>/copy.py, line 215, in _deepcopy_list append(deepcopy(a, memo)) File <*>/copy.py, line 220, in _deepcopy_tuple y = [deepcopy(a, memo) for a in x] File <*>/copy.py, line 220, in <listcomp> y = [deepcopy(a, memo) for a in x] File <*>/copy.py, line 180, in deepcopy y = _reconstruct(x, memo, *rv) File <*>/copy.py, line 280, in _reconstruct state = deepcopy(state, memo) File <*>/copy.py, line 169, in deepcopy rv = reductor(4) TypeError: can't pickle _thread.RLock objects",0
"File <stdin>, line 1, in <module> [CODE] RuntimeError: Could not infer dtype of generator",0
"File <*>/min_working_example.py, line 37, in <module> model.fit(data_generator) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 880, in fit validation_steps=validation_steps) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 310, in model_iteration ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]] File <*>python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 526, in slice_arrays return [None if x is None else x[start] for x in arrays] File <*>python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 526, in <listcomp> return [None if x is None else x[start] for x in arrays] File <*>python3.6/site-packages/tensorflow/python/ops/array_ops.py, line 654, in _slice_helper name=name) File <*>python3.6/site-packages/tensorflow/python/ops/array_ops.py, line 820, in strided_slice shrink_axis_mask=shrink_axis_mask) File <*>python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py, line 9334, in strided_slice _six.raise_from(_core._status_to_exception(e.code, message), None) File <string>, line 3, in raise_from [CODE] tensorflow.python.framework.errors_impl.InvalidArgumentError: Attr shrink_axis_mask has value 4294967295 out of range for an int32 [Op:StridedSlice] name: strided_slice/",0
"File <*>/min_working_example.py, line 37, in <module> model.fit(data_generator) File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 873, in fit steps_name='steps_per_epoch') File <*>python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 352, in model_iteration batch_outs = f(ins_batch) File <*>python3.7/site-packages/tensorflow/python/keras/backend.py, line 3217, in __call__ outputs = self._graph_fn(*converted_inputs) File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 558, in __call__ return self._call_flat(args) File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 627, in _call_flat outputs = self._inference_function.call(ctx, args) File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 397, in call (len(args), len(list(self.signature.input_arg)))) ValueError: Arguments and signature arguments do not match: 21 23",0
"File <*>/min_working_example.py, line 37, in <module> model.fit_generator(data_generator) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1426, in fit_generator initial_epoch=initial_epoch) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 115, in model_iteration shuffle=shuffle) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 377, in convert_to_generator_like num_samples = int(nest.flatten(data)[0].shape[0]) TypeError: __int__ returned non-int (type NoneType)",0
"File <*>/min_working_example.py, line 37, in <module> model.fit_generator(data_generator) File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 1515, in fit_generator steps_name='steps_per_epoch') File <*>python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py, line 140, in model_iteration shuffle=shuffle) File <*>python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py, line 477, in convert_to_generator_like raise ValueError('You must specify `batch_size`') ValueError: You must specify `batch_size`",0
"File pretrain_lm.py, line 7, in <module> import fastai File <*>python3.7/site-packages/fastai/__init__.py, line 1, in <module> from .basic_train import * File <*>python3.7/site-packages/fastai/basic_train.py, line 2, in <module> from .torch_core import * File <*>python3.7/site-packages/fastai/torch_core.py, line 2, in <module> from .imports.torch import * File <*>python3.7/site-packages/fastai/imports/__init__.py, line 2, in <module> from .torch import * File <*>python3.7/site-packages/fastai/imports/torch.py, line 1, in <module> import torch, torch.nn.functional as F File <*>python3.7/site-packages/torch/__init__.py, line 84, in <module> from torch._C import * ImportError: libtorch_python.so: cannot open shared object file: No such file or directory",0
"File <*>/train.py, line 184, in <module> tf.app.run() File <*>python3.6/site-packages/tensorflow/python/platform/app.py, line 125, in run _sys.exit(main(argv)) File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 324, in new_func return func(*args, **kwargs) File <*>/train.py, line 180, in main graph_hook_fn=graph_rewriter_fn) File <*>/trainer.py, line 416, in train saver=saver) File <*>python3.6/site-packages/tensorflow/contrib/slim/python/slim/learning.py, line 785, in train ignore_live_threads=ignore_live_threads) File <*>python3.6/site-packages/tensorflow/python/training/supervisor.py, line 832, in stop ignore_live_threads=ignore_live_threads) File <*>python3.6/site-packages/tensorflow/python/training/coordinator.py, line 389, in join six.reraise(*self._exc_info_to_raise) File <*>python3.6/site-packages/six.py, line 693, in reraise raise value File <*>python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py, line 257, in _run enqueue_callable() File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1257, in _single_operation_run self._call_tf_sessionrun(None, {}, [], target_list, None) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1407, in _call_tf_sessionrun run_metadata) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[15,1,1755,2777,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [[{{node batch}}]]",0
"File <*>/main.py, line 182, in <module> batch_size=128, epochs=1) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 880, in fit validation_steps=validation_steps) File <*>/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 329, in model_iteration batch_outs = f(ins_batch) File <*>/site-packages/tensorflow/python/keras/backend.py, line 3076, in __call__ run_metadata=self.run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1439, in __call__ run_metadata_ptr) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [10,2] vs. [10] [[{{node metrics/acc/Equal}}]] [[{{node loss/mul}}]]",0
"File <*>/vis.py, line 28, in <module> from deeplab import common ModuleNotFoundError: No module named 'deeplab'",0
"File <*>python3.7/site-packages/conda/exceptions.py, line 819, in __call__ return func(*args, **kwargs) File <*>python3.7/site-packages/conda/cli/main.py, line 78, in _main exit_code = do_call(args, p) File <*>python3.7/site-packages/conda/cli/conda_argparse.py, line 77, in do_call exit_code = getattr(module, func_name)(args, parser) File <*>python3.7/site-packages/conda/cli/main_update.py, line 14, in execute install(args, parser, 'update') File <*>python3.7/site-packages/conda/cli/install.py, line 253, in install handle_txn(unlink_link_transaction, prefix, args, newenv) File <*>python3.7/site-packages/conda/cli/install.py, line 282, in handle_txn unlink_link_transaction.execute() File <*>python3.7/site-packages/conda/core/link.py, line 223, in execute self.verify() File <*>python3.7/site-packages/conda/common/io.py, line 46, in decorated return f(*args, **kwds) File <*>python3.7/site-packages/conda/core/link.py, line 200, in verify self.prepare() File <*>python3.7/site-packages/conda/core/link.py, line 192, in prepare stp.remove_specs, stp.update_specs) File <*>python3.7/site-packages/conda/core/link.py, line 282, in _prepare mkdir_p(transaction_context['temp_dir']) File <*>python3.7/site-packages/conda/gateways/disk/__init__.py, line 60, in mkdir_p makedirs(path) File <*>python3.7/os.py, line 221, in makedirs mkdir(name, mode) PermissionError: [Errno 13] Permission denied: '/usr/share/anaconda3/.condatmp'",0
"File <stdin>, line 1, in <module> [CODE] ImportError: cannot import name 'estimator' from 'tensorflow' (/home/cjs/.conda/envs/my-env/lib/python3.7/site-packages/tensorflow/__init__.py)",0
"File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File <*>python3.7/imp.py, line 242, in load_module return load_dynamic(name, filename, file) File <*>python3.7/imp.py, line 342, in load_dynamic return _load(spec) ImportError: /usr/lib/libcublas.so.10.0: version `libcublas.so.10.0' not found (required by /home/techievin/.local/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)",0
"File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in make_tensor_proto str_values = [compat.as_bytes(x) for x in proto_values] File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in <listcomp> str_values = [compat.as_bytes(x) for x in proto_values] File <*>/site-packages/tensorflow/python/util/compat.py, line 61, in as_bytes (bytes_or_text,)) TypeError: Expected binary or unicode string, got Dimension(4)",0
"File <*>/extra_classes.py, line 31, in <module> model_out = MyLayer(2)(model_in) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 746, in __call__ self.build(input_shapes) File <*>/extra_classes.py, line 20, in build trainable=True) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 609, in add_weight aggregation=aggregation) File <*>/site-packages/tensorflow/python/training/checkpointable/base.py, line 639, in _add_variable_with_custom_getter **kwargs_for_getter) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1977, in make_variable aggregation=aggregation) File <*>/site-packages/tensorflow/python/ops/variables.py, line 183, in __call__ return cls._variable_v1_call(*args, **kwargs) File <*>/site-packages/tensorflow/python/ops/variables.py, line 146, in _variable_v1_call aggregation=aggregation) File <*>/site-packages/tensorflow/python/ops/variables.py, line 125, in <lambda> previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs) File <*>/site-packages/tensorflow/python/ops/variable_scope.py, line 2437, in default_variable_creator import_scope=import_scope) File <*>/site-packages/tensorflow/python/ops/variables.py, line 187, in __call__ return super(VariableMetaclass, cls).__call__(*args, **kwargs) File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 297, in __init__ constraint=constraint) File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 409, in _init_from_args initial_value() if init_from_fn else initial_value, File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1959, in <lambda> shape, dtype=dtype, partition_info=partition_info) File <*>/site-packages/tensorflow/python/ops/init_ops.py, line 255, in __call__ shape, self.minval, self.maxval, dtype, seed=self.seed) File <*>/site-packages/tensorflow/python/ops/random_ops.py, line 235, in random_uniform shape = _ShapeTensor(shape) File <*>/site-packages/tensorflow/python/ops/random_ops.py, line 44, in _ShapeTensor return ops.convert_to_tensor(shape, dtype=dtype, name=""shape"") File <*>/site-packages/tensorflow/python/framework/ops.py, line 1050, in convert_to_tensor as_ref=False) File <*>/site-packages/tensorflow/python/framework/ops.py, line 1146, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 229, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name) File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 208, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape)) File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 531, in make_tensor_proto ""supported type."" % (type(values), values)) TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (Dimension(4), 2). Consider casting elements to a supported type.",0
"File classifier_model.py, line 115, in <module> model.fit_generator(generator.flow(train_images, train_labels, batch_size=BATCH_SIZE), epochs=num_epochs) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1426, in fit_generator initial_epoch=initial_epoch) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 191, in model_iteration batch_outs = batch_function(*batch_data) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1191, in train_on_batch outputs = self._fit_function(ins) # pylint: disable=not-callable File <*>python3.6/site-packages/tensorflow/python/keras/backend.py, line 3076, in __call__ run_metadata=self.run_metadata) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1439, in __call__ run_metadata_ptr) File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: logits and labels must have the same first dimension, got logits shape [1,7] and labels shape [7] [[{{node loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1334, in _do_call return fn(*args) File <*>/site-packages/tensorflow/python/client/session.py, line 1319, in _run_fn options, feed_dict, fetch_list, target_list, run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1407, in _call_tf_sessionrun run_metadata) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[51200,2304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[{{node model/h0/attn/c_attn/MatMul}}]]",0
"File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File <*>python3.5/imp.py, line 242, in load_module return load_dynamic(name, filename, file) File <*>python3.5/imp.py, line 342, in load_dynamic return _load(spec) ImportError: /usr/lib/aarch64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.22' not found (required by /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so)",0
"File TestServe.py, line 62, in <module> ts.train() File TestServe.py, line 56, in train epochs=2, verbose=1, callbacks=callbacks, steps_per_epoch=20) #The steps_per_epoch is typically samples_per_epoch / batch_size File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 880, in fit validation_steps=validation_steps) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 364, in model_iteration validation_in_fit=True) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 202, in model_iteration steps_per_epoch) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 76, in _get_num_samples_or_steps 'steps_per_epoch') File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 230, in check_num_samples if check_steps_argument(ins, steps, steps_name): File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 960, in check_steps_argument input_type=input_type_str, steps_name=steps_name)) ValueError: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument.",0
"File <*>/mnist.py, line 69, in <module> train(epoch) File <*>/mnist.py, line 60, in train loss = criterion(out, target) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 493, in __call__ result = self.forward(*input, **kwargs) File <*>python3.6/site-packages/torch/nn/modules/loss.py, line 942, in forward ignore_index=self.ignore_index, reduction=self.reduction) File <*>python3.6/site-packages/torch/nn/functional.py, line 2056, in cross_entropy return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction) File <*>python3.6/site-packages/torch/nn/functional.py, line 1869, in nll_loss .format(input.size(0), target.size(0))) ValueError: Expected input batch_size (12) to match target batch_size (64).",0
"File <*>/pydevd.py, line 1758, in <module> main() File <*>/pydevd.py, line 1752, in main globals = debugger.run(setup['file'], None, None, is_module) File <*>/pydevd.py, line 1147, in run pydev_imports.execfile(file, globals, locals) # execute the script File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc) File <*>/deep_test_conv1d.py, line 231, in <module> main() File <*>/deep_test_conv1d.py, line 149, in main for i, (images, labels) in enumerate(train_loader): File <*>/site-packages/torch/utils/data/dataloader.py, line 615, in __next__ batch = self.collate_fn([self.dataset[i] for i in indices]) File <*>/site-packages/torch/utils/data/dataloader.py, line 615, in <listcomp> batch = self.collate_fn([self.dataset[i] for i in indices]) File <*>/deep_test_conv1d.py, line 102, in __getitem__ return self.transform(self.features[index]), self.transform(self.classes[index]) File <*>/site-packages/torchvision/transforms/transforms.py, line 60, in __call__ img = t(img) File <*>/site-packages/torchvision/transforms/transforms.py, line 91, in __call__ return F.to_tensor(pic) File <*>/site-packages/torchvision/transforms/functional.py, line 50, in to_tensor raise TypeError('pic should be PIL Image or ndarray. Got {}'.format(type(pic))) TypeError: pic should be PIL Image or ndarray. Got <class 'numpy.ndarray'>",0
"File <*>/toco, line 11, in <module> sys.exit(main()) File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 503, in main app.run(main=run_main, argv=sys.argv[:1]) File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef) File <*>python2.7/site-packages/absl/app.py, line 300, in run _run_main(main, args) File <*>python2.7/site-packages/absl/app.py, line 251, in _run_main sys.exit(main(argv)) File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 499, in run_main _convert_tf1_model(tflite_flags) File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 124, in _convert_tf1_model converter = _get_toco_converter(flags) File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 111, in _get_toco_converter return converter_fn(**converter_kwargs) File <*>python2.7/site-packages/tensorflow/lite/python/lite.py, line 628, in from_frozen_graph _import_graph_def(graph_def, name="""") File <*>python2.7/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func return func(*args, **kwargs) File <*>python2.7/site-packages/tensorflow/python/framework/importer.py, line 431, in import_graph_def raise ValueError(str(e)) ValueError: Input 0 of node dense_1/weights_quant/AssignMinLast was passed float from dense_1/weights_quant/min:0 incompatible with expected float_ref.",0
"File <*>/train_fit.py, line 286, in <module> validation_steps=None) #devset_steps_per_epoch) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 780, in fit steps_name='steps_per_epoch') File <*>/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 374, in model_iteration callbacks._call_batch_hook(mode, 'end', batch_index, batch_logs) File <*>/site-packages/tensorflow/python/keras/callbacks.py, line 248, in _call_batch_hook batch_hook(batch, logs) File <*>/site-packages/tensorflow/python/keras/callbacks.py, line 531, in on_train_batch_end self.on_batch_end(batch, logs=logs) File <*>/site-packages/tensorflow/python/keras/callbacks_v1.py, line 362, in on_batch_end profiler.save(self.log_dir, profiler.stop()) File <*>/site-packages/tensorflow/python/eager/profiler.py, line 144, in save gfile.MakeDirs(plugin_dir) File <*>/site-packages/tensorflow/python/lib/io/file_io.py, line 438, in recursive_create_dir recursive_create_dir_v2(dirname) File <*>/site-packages/tensorflow/python/lib/io/file_io.py, line 453, in recursive_create_dir_v2 pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(path)) tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: ./logs\plugins\profile\2019-07-02_13-04-26; No such file or directory",0
"File <*>python3.6/site-packages/tensorflow/python/framework/importer.py, line 427, in import_graph_def graph._c_graph, serialized, options) # pylint: disable=protected-access tensorflow.python.framework.errors_impl.InvalidArgumentError: Input 1 of node StatefulPartitionedCall was passed float from conv2d/kernel:0 incompatible with expected resource.",0
"File <*>/tensorrt.py, line 23, in <module> converter.save(saved_model_dir_trt) File <*>python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py, line 822, in save super(TrtGraphConverter, self).save(output_saved_model_dir) File <*>python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py, line 432, in save importer.import_graph_def(self._converted_graph_def, name="""") File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func return func(*args, **kwargs) File <*>python3.6/site-packages/tensorflow/python/framework/importer.py, line 431, in import_graph_def raise ValueError(str(e)) ValueError: Input 1 of node StatefulPartitionedCall was passed float from conv2d/kernel:0 incompatible with expected resource.",0
"File <*>/site-packages/tensorflow/python/platform/self_check.py, line 62, in preload_check ctypes.WinDLL(build_info.nvcuda_dll_name) File <*>/__init__.py, line 356, in __init__ self._handle = _dlopen(self._name, mode) OSError: [WinError 126] Das angegebene Modul wurde nicht gefunden",0
"File test_model.py, line 5, in <module> import tensorflow as tf File <*>/site-packages/tensorflow/__init__.py, line 28, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import File <*>/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 30, in <module> self_check.preload_check() File <*>/site-packages/tensorflow/python/platform/self_check.py, line 70, in preload_check % build_info.nvcuda_dll_name) ImportError: Could not find 'nvcuda.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Typically it is installed in 'C:\Windows\System32'. If it is not present, ensure that you have a CUDA-capable GPU with the correct driver installed.",0
"File <*>python3.6/managers.py, line 228, in serve_client request = recv() File <*>python3.6/connection.py, line 251, in recv return _ForkingPickler.loads(buf.getbuffer()) File <*>python3.6/site-packages/torch/multiprocessing/reductions.py, line 276, in rebuild_storage_fd fd = df.detach() File <*>python3.6/resource_sharer.py, line 58, in detach return reduction.recv_handle(conn) File <*>python3.6/reduction.py, line 182, in recv_handle return recvfds(s, 1)[0] File <*>python3.6/reduction.py, line 161, in recvfds len(ancdata)) RuntimeError: received 0 items of ancdata",0
"File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1473, in __del__ self._session._session, self._handle) tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')",0
"File <*>/bacteria_rcnn_train.py, line 53, in <module> import keras File <*>python3.5/dist-packages/keras/__init__.py, line 3, in <module> from . import utils File <*>python3.5/dist-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils File <*>python3.5/dist-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K File <*>python3.5/dist-packages/keras/backend/__init__.py, line 84, in <module> from .tensorflow_backend import * File <*>python3.5/dist-packages/keras/backend/tensorflow_backend.py, line 5, in <module> import tensorflow as tf File <*>python3.5/dist-packages/tensorflow/__init__.py, line 28, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import File <*>python3.5/dist-packages/tensorflow/python/__init__.py, line 83, in <module> from tensorflow.python import keras File <*>python3.5/dist-packages/tensorflow/python/keras/__init__.py, line 26, in <module> from tensorflow.python.keras import activations File <*>python3.5/dist-packages/tensorflow/python/keras/activations/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.activations import elu File <*>python3.5/dist-packages/tensorflow/python/keras/_impl/keras/__init__.py, line 21, in <module> from tensorflow.python.keras._impl.keras import activations File <*>python3.5/dist-packages/tensorflow/python/keras/_impl/keras/activations.py, line 23, in <module> from tensorflow.python.keras._impl.keras import backend as K File <*>python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py, line 38, in <module> from tensorflow.python.layers import base as tf_base_layers File <*>python3.5/dist-packages/tensorflow/python/layers/base.py, line 25, in <module> from tensorflow.python.keras import backend File <*>python3.5/dist-packages/tensorflow/python/keras/backend/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.backend import abs ImportError: cannot import name 'abs'",0
"File <*>/script3.py, line 9, in <module> model = load_model(model_path, custom_objects={'MyMeanPooling': MyMeanPooling}) File <*>/site-packages/keras/engine/saving.py, line 419, in load_model model = _deserialize_model(f, custom_objects, compile) File <*>/site-packages/keras/engine/saving.py, line 225, in _deserialize_model model = model_from_config(model_config, custom_objects=custom_objects) File <*>/site-packages/keras/engine/saving.py, line 458, in model_from_config return deserialize(config, custom_objects=custom_objects) File <*>/site-packages/keras/layers/__init__.py, line 55, in deserialize printable_module_name='layer') File <*>/site-packages/keras/utils/generic_utils.py, line 145, in deserialize_keras_object list(custom_objects.items()))) File <*>/site-packages/keras/engine/network.py, line 1022, in from_config process_layer(layer_data) File <*>/site-packages/keras/engine/network.py, line 1008, in process_layer custom_objects=custom_objects) File <*>/site-packages/keras/utils/generic_utils.py, line 147, in deserialize_keras_object return cls.from_config(config['config']) File <*>/site-packages/keras/engine/base_layer.py, line 1109, in from_config return cls(**config) TypeError: __init__() missing 1 required positional argument: 'pool_size'",0
"File <*>/main.py, line 41, in <module> predics = nmodel.predict([x_test]) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 821, in predict use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 705, in predict x, check_steps=True, steps_name='steps', steps=steps) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 2335, in _standardize_user_data self._set_inputs(cast_inputs) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 2553, in _set_inputs outputs = self(inputs, **kwargs) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 662, in __call__ outputs = call_fn(inputs, *args, **kwargs) File <*>/site-packages/tensorflow/python/keras/engine/sequential.py, line 262, in call outputs = layer(inputs, **kwargs) File <*>/site-packages/tensorflow/python/keras/layers/core.py, line 580, in call inputs, (tensor_shape.dimension_value(inputs.shape[0]) or AttributeError: 'list' object has no attribute 'shape'",0
"File <string>, line 1, in <module> [CODE] File <*>python3.6/site-packages/torch/cuda/__init__.py, line 163, in _lazy_init torch._C._cuda_init() RuntimeError: cuda runtime error (38) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1556653099582/work/aten/src/THC/THCGeneral.cpp:51",0
"File <stdin>, line 1, in <module> [CODE] File <*>python3.6/site-packages/keras/__init__.py, line 3, in <module> from . import utils File <*>python3.6/site-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils File <*>python3.6/site-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K File <*>python3.6/site-packages/keras/backend/__init__.py, line 1, in <module> from .load_backend import epsilon File <*>python3.6/site-packages/keras/backend/load_backend.py, line 90, in <module> from .tensorflow_backend import * File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 13, in <module> from tensorflow.python.keras.utils import tf_utils ImportError: cannot import name 'tf_utils'",0
"File <*>/pathtoproject, line 75, in predict cm_prediction = self.model.predict([face, reye, leye, fg])[0] File <*>/pathtoproject, line 1462, in predict callbacks=callbacks) File <*>/site-packages/keras/engine/training_arrays.py, line 276, in predict_loop callbacks.model.stop_training = False File <*>/site-packages/keras/engine/network.py, line 323, in __setattr__ super(Network, self).__setattr__(name, value) File <*>/site-packages/keras/engine/base_layer.py, line 1215, in __setattr__ if not _DISABLE_TRACKING.value: AttributeError: '_thread._local' object has no attribute 'value'",0
"File train.py, line 6, in <module> import keras.backend as K File <*>/site-packages/keras/__init__.py, line 3, in <module> from . import utils File <*>/site-packages/keras/utils/__init__.py, line 27, in <module> from .multi_gpu_utils import multi_gpu_model File <*>/site-packages/keras/utils/multi_gpu_utils.py, line 7, in <module> from ..layers.merge import concatenate File <*>/site-packages/keras/layers/__init__.py, line 4, in <module> from ..engine.base_layer import Layer File <*>/site-packages/keras/engine/__init__.py, line 8, in <module> from .training import Model File <*>/site-packages/keras/engine/training.py, line 21, in <module> from . import training_arrays File <*>/site-packages/keras/engine/training_arrays.py, line 14, in <module> from .. import callbacks as cbks File <*>/site-packages/keras/callbacks/__init__.py, line 19, in <module> if K.backend() == 'tensorflow' and not K.tensorflow_backend._is_tf_1(): AttributeError: module 'keras.backend.tensorflow_backend' has no attribute '_is_tf_1'",0
"File file.py, line 2, in <module> from torch.utils.data import Dataset, DataLoader ModuleNotFoundError: No module named 'torch'",0
"File test_transform.py, line 87, in <module> for batch_idx, image, mask in enumerate(train_loader): File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 314, in __next__ batch = self.collate_fn([self.dataset[i] for i in indices]) File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 314, in <listcomp> batch = self.collate_fn([self.dataset[i] for i in indices]) File <*>python3.6/site-packages/torch/utils/data/dataset.py, line 103, in __getitem__ return self.dataset[self.indices[idx]] File <*>/data.py, line 164, in __getitem__ img, mask = self.transforms(img, mask) File <*>/augmentations.py, line 17, in __call__ img, mask = a(img, mask) TypeError: __call__() takes 2 positional arguments but 3 were given",0
"File classify_in_out_tf2.py, line 81, in [FUNC] [CODE] AttributeError: 'AutoTrackable' object has no attribute 'summary'",0
"File <ipython-input-12-f8636d3ba083>, line 26, in <module> predict(model, ""/home/x//Deep_Learning/pytorch/MNIST/test/2/QQ20191022093955.png"") File <ipython-input-12-f8636d3ba083>, line 9, in predict test_image_tensor = transform(test_image) File <*>python3.6/site-packages/torchvision/transforms/transforms.py, line 61, in __call__ img = t(img) File <*>python3.6/site-packages/torchvision/transforms/transforms.py, line 166, in __call__ return F.normalize(tensor, self.mean, self.std, self.inplace) File <*>python3.6/site-packages/torchvision/transforms/functional.py, line 217, in normalize tensor.sub_(mean[:, None, None]).div_(std[:, None, None]) RuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0",0
"File <*>/prova_bert.py, line 230, in <module> model = baseline_model(output_size, max_seq_len, visualize=True) File <*>/prova_bert.py, line 165, in baseline_model )(bert_embeddings) File <*>/site-packages/tensorflow/python/keras/layers/wrappers.py, line 473, in __call__ return super(Bidirectional, self).__call__(inputs, **kwargs) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 746, in __call__ self.build(input_shapes) File <*>/site-packages/tensorflow/python/keras/layers/wrappers.py, line 612, in build self.forward_layer.build(input_shape) File <*>/site-packages/tensorflow/python/keras/utils/tf_utils.py, line 149, in wrapper output_shape = fn(instance, input_shape) File <*>/site-packages/tensorflow/python/keras/layers/recurrent.py, line 552, in build self.cell.build(step_input_shape) File <*>/site-packages/tensorflow/python/keras/layers/recurrent.py, line 1934, in build constraint=self.kernel_constraint) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 609, in add_weight aggregation=aggregation) File <*>/site-packages/tensorflow/python/training/checkpointable/base.py, line 639, in _add_variable_with_custom_getter **kwargs_for_getter) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1977, in make_variable aggregation=aggregation) File <*>/site-packages/tensorflow/python/ops/variables.py, line 183, in __call__ return cls._variable_v1_call(*args, **kwargs) File <*>/site-packages/tensorflow/python/ops/variables.py, line 146, in _variable_v1_call aggregation=aggregation) File <*>/site-packages/tensorflow/python/ops/variables.py, line 125, in <lambda> previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs) File <*>/site-packages/tensorflow/python/ops/variable_scope.py, line 2437, in default_variable_creator import_scope=import_scope) File <*>/site-packages/tensorflow/python/ops/variables.py, line 187, in __call__ return super(VariableMetaclass, cls).__call__(*args, **kwargs) File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 297, in __init__ constraint=constraint) File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 409, in _init_from_args initial_value() if init_from_fn else initial_value, File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1959, in <lambda> shape, dtype=dtype, partition_info=partition_info) File <*>/site-packages/tensorflow/python/ops/init_ops.py, line 473, in __call__ scale /= max(1., (fan_in + fan_out) / 2.) TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 738, in __del__ [CODE] TypeError: 'NoneType' object is not callable",0
"File <*>/Program.py, line 88, in FitModel model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test)) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 224, in fit distribution_strategy=strategy) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 547, in _process_training_inputs use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 606, in _process_inputs use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 479, in __init__ batch_size=batch_size, shuffle=shuffle, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 321, in __init__ dataset_ops.DatasetV2.from_tensors(inputs).repeat() File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 414, in from_tensors return TensorDataset(tensors) File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 2335, in __init__ element = structure.normalize_element(element) File <*>/site-packages/tensorflow_core/python/data/util/structure.py, line 111, in normalize_element ops.convert_to_tensor(t, name=""component_%d"" % i)) File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1184, in convert_to_tensor return convert_to_tensor_v2(value, dtype, preferred_dtype, name) File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1242, in convert_to_tensor_v2 as_ref=False) File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1296, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py, line 52, in _default_conversion_function return constant_op.constant(value, dtype, name=name) File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 227, in constant allow_broadcast=True) File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 235, in _constant_impl t = convert_to_eager_tensor(value, ctx, dtype) File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 96, in convert_to_eager_tensor return ops.EagerTensor(value, ctx.device_name, dtype) ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float).",0
"File <input>, line 1, in <module> [CODE] AttributeError: module 'keras.applications' has no attribute 'resnet_v2'",0
"File <input>, line 1, in <module> [CODE] File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 495, in ResNet50V2 **kwargs) File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 348, in ResNet data_format=backend.image_data_format(), AttributeError: 'NoneType' object has no attribute 'image_data_format'",0
"File <*>/train_model.py, line 110, in <module> model.fit(train_dataset, epochs=5) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit 1/Unknown - 0s 13ms/step 1/Unknown - 0s 13ms/step use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 324, in fit total_epochs=epochs) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 123, in run_one_epoch batch_outs = execution_function(iterator) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 86, in execution_function distributed_function(input_fn)) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__ result = self._call(*args, **kwds) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call self._initialize(args, kwds, add_initializers_to=initializer_map) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize *args, **kwds)) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected graph_function, _, _ = self._maybe_define_function(args, kwargs) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function graph_function = self._create_graph_function(args, kwargs) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function capture_by_value=self._capture_by_value), File <*>/site-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func func_outputs = python_func(*func_args, **func_kwargs) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn return weak_wrapped_fn().__wrapped__(*args, **kwds) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 66, in distributed_function model, input_iterator, mode) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 112, in _prepare_feed_values inputs, targets, sample_weights = _get_input_from_iterator(inputs) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 149, in _get_input_from_iterator distribution_strategy_context.get_strategy(), x, y, sample_weights) File <*>/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py, line 308, in validate_distributed_dataset_inputs x_values_list = validate_per_replica_inputs(distribution_strategy, x) File <*>/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py, line 356, in validate_per_replica_inputs validate_all_tensor_shapes(x, x_values) File <*>/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py, line 373, in validate_all_tensor_shapes x_shape = x_values[0].shape.as_list() File <*>/site-packages/tensorflow_core/python/framework/tensor_shape.py, line 1171, in as_list raise ValueError(""as_list() is not defined on an unknown TensorShape."") ValueError: as_list() is not defined on an unknown TensorShape.",0
"File <ipython-input-1-f9d072fc6a73>, line 19, in <module> onnx_model = keras2onnx.convert_keras(model) File <*>/site-packages/keras2onnx/main.py, line 67, in convert_keras "" Please set environment variable TF_KERAS = 1."") Exception: This is a tensorflow keras model, but keras standalone converter is used. Please set environment variable TF_KERAS = 1.",0
"File <*>python3.6/dist-packages/torch/utils/data/_utils/worker.py, line 178, in _worker_loop data = fetcher.fetch(index) File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch data = [self.dataset[idx] for idx in possibly_batched_index] File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp> data = [self.dataset[idx] for idx in possibly_batched_index] File <ipython-input-180-0b00b175e18c>, line 72, in __getitem__ image = self.transform(image) File <*>python3.6/dist-packages/torchvision/transforms/transforms.py, line 70, in __call__ img = t(img) File <*>python3.6/dist-packages/torchvision/transforms/transforms.py, line 175, in __call__ return F.normalize(tensor, self.mean, self.std, self.inplace) File <*>python3.6/dist-packages/torchvision/transforms/functional.py, line 217, in normalize tensor.sub_(mean[:, None, None]).div_(std[:, None, None]) RuntimeError: output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]",0
"File tf_1_day_scikit_dnn.py, line 12, in <module> from sklearn import decomposition File <*>python3.6/site-packages/sklearn/decomposition/__init__.py, line 19, in <module> from ._online_lda import LatentDirichletAllocation ImportError: cannot import name 'LatentDirichletAllocation'",0
"File <*>python37/runpy.py, line 193, in _run_module_as_main ""__main__"", mod_spec) File <*>python37/runpy.py, line 85, in _run_code exec(code, run_globals) File <*>/__main__.py, line 9, in <module> [CODE] File <*>/site-packages/flask/cli.py, line 966, in main cli.main(prog_name=""python -m flask"" if as_module else None) File <*>/site-packages/flask/cli.py, line 586, in main return super(FlaskGroup, self).main(*args, **kwargs) File <*>/site-packages/click/core.py, line 717, in main rv = self.invoke(ctx) File <*>/site-packages/click/core.py, line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File <*>/site-packages/click/core.py, line 956, in invoke return ctx.invoke(self.callback, **ctx.params) File <*>/site-packages/click/core.py, line 555, in invoke return callback(*args, **kwargs) File <*>/site-packages/click/decorators.py, line 64, in new_func return ctx.invoke(f, obj, *args, **kwargs) File <*>/site-packages/flask/cli.py, line 860, in run_command extra_files=extra_files, File <*>/site-packages/werkzeug/serving.py, line 1008, in run_simple run_with_reloader(inner, extra_files, reloader_interval, reloader_type) File <*>/site-packages/werkzeug/_reloader.py, line 337, in run_with_reloader reloader.run() File <*>/site-packages/werkzeug/_reloader.py, line 202, in run for filename in chain(_iter_module_files(), self.extra_files): File <*>/site-packages/werkzeug/_reloader.py, line 24, in _iter_module_files filename = getattr(module, ""__file__"", None) File <*>/site-packages/tensorflow/__init__.py, line 50, in __getattr__ module = self._load() File <*>/site-packages/tensorflow/__init__.py, line 44, in _load module = _importlib.import_module(self.__name__) File <*>python37/__init__.py, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level) File <frozen importlib._bootstrap>, line 1006, in _gcd_import [CODE] File <frozen importlib._bootstrap>, line 983, in _find_and_load [CODE] File <frozen importlib._bootstrap>, line 965, in _find_and_load_unlocked [CODE] ModuleNotFoundError: No module named 'tensorflow_core.keras'",0
"File main.py, line 69, in <module> pickle.dump(history, f) TypeError: can't pickle _thread._local objects",0
"File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 61, in quick_execute num_outputs) TypeError: An op outside of the function building code is being passed",0
"File <*>/N09.py, line 363, in <module> main() File <*>/N09.py, line 343, in main args.save_interval) File <*>/N09.py, line 92, in train_model verbose=self.verbose) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 1297, in fit_generator steps_name='steps_per_epoch') File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py, line 265, in model_iteration batch_outs = batch_function(*batch_data) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 973, in train_on_batch class_weight=class_weight, reset_metrics=reset_metrics) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch output_loss_metrics=model._output_loss_metrics) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch output_loss_metrics=output_loss_metrics)) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 268, in _process_single_batch grads = tape.gradient(scaled_total_loss, trainable_weights) File <*>python3.7/site-packages/tensorflow_core/python/eager/backprop.py, line 1014, in gradient unconnected_gradients=unconnected_gradients) File <*>python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py, line 76, in imperative_grad compat.as_str(unconnected_gradients.value)) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 911, in _backward_function_wrapper processed_args, remapped_captures) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1224, in _call_flat ctx, args, cancellation_manager=cancellation_manager) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 511, in call ctx=ctx) File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 75, in quick_execute ""tensors, but found {}"".format(keras_symbolic_tensors)) tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'StridedSliceGrad:0' shape=(16, 64, 64, 3) dtype=float32>]",0
"File model_main.py, line 109, in [FUNC] [CODE] File <*>/site-packages/tensorflow/python/platform/app.py, line 125, in run _sys.exit(main(argv)) File model_main.py, line 105, in main tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0]) File <*>/site-packages/tensorflow/python/estimator/training.py, line 471, in train_and_evaluate return executor.run() File <*>/site-packages/tensorflow/python/estimator/training.py, line 610, in run return self.run_local() File <*>/site-packages/tensorflow/python/estimator/training.py, line 711, in run_local saving_listeners=saving_listeners) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 354, in train loss = self._train_model(input_fn, hooks, saving_listeners) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 1207, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 1241, in _train_model_default saving_listeners) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 1471, in _train_with_estimator_spec _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss]) File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 783, in exit self._close_internal(exception_type) File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 816, in _close_internal h.end(self._coordinated_creator.tf_sess) File <*>/site-packages/tensorflow/python/training/basic_session_run_hooks.py, line 590, in end l.end(session, last_step) File <*>/site-packages/tensorflow/python/estimator/training.py, line 531, in end self._evaluate(global_step_value) File <*>/site-packages/tensorflow/python/estimator/training.py, line 537, in _evaluate self._evaluator.evaluate_and_export()) File <*>/site-packages/tensorflow/python/estimator/training.py, line 924, in evaluate_and_export is_the_final_export) File <*>/site-packages/tensorflow/python/estimator/training.py, line 957, in _export_eval_result is_the_final_export=is_the_final_export)) File <*>/site-packages/tensorflow/python/estimator/exporter.py, line 418, in export is_the_final_export) File <*>/site-packages/tensorflow/python/estimator/exporter.py, line 126, in export strip_default_attrs=self._strip_default_attrs) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 663, in export_savedmodel mode=model_fn_lib.ModeKeys.PREDICT) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 789, in _export_saved_model_for_mode strip_default_attrs=strip_default_attrs) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 883, in _export_all_saved_models builder = saved_model_builder.SavedModelBuilder(temp_export_dir) File <*>/site-packages/tensorflow/python/saved_model/builder_impl.py, line 97, in init file_io.recursive_create_dir(self._export_dir) File <*>/site-packages/tensorflow/python/lib/io/file_io.py, line 379, in recursive_create_dir pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in exit c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: training/export\Servo\temp-b'1576742954'; No such file or directory",0
"File <*>/maxmem.py, line 11, in <module> dic[x]=tf.random.normal((nn,dd)) File <*>python3.7/site-packages/tensorflow_core/python/ops/random_ops.py, line 76, in random_normal value = math_ops.add(mul, mean_tensor, name=name) File <*>python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py, line 391, in add _six.raise_from(_core._status_to_exception(e.code, message), None) File <string>, line 3, in raise_from [CODE] tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1000,250000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add] name: random_normal/",0
"File DL_Ensemble.py, line 145, in <module> fused = concatenate([graph, graph_1], axis= 1 ) File <*>python3.8/site-packages/tensorflow_core/python/keras/layers/merge.py, line 705, in concatenate return Concatenate(axis=axis, **kwargs)(inputs) File <*>python3.8/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 887, in __call__ self._maybe_build(inputs) File <*>python3.8/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 2141, in _maybe_build self.build(input_shapes) File <*>python3.8/site-packages/tensorflow_core/python/keras/utils/tf_utils.py, line 306, in wrapper output_shape = fn(instance, input_shape) File <*>python3.8/site-packages/tensorflow_core/python/keras/layers/merge.py, line 378, in build raise ValueError('A `Concatenate` layer should be called ' ValueError: A `Concatenate` layer should be called on a list of at least 2 inputs",0
"File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1455, in __del__ self._session._session, self._handle, status) File <*>python3.7/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: No such callable handle: 94697914208640",0
"File tf2_main.py, line 50, in <module> model = CycleGAN(args) File <*>/tf2_model.py, line 55, in __init__ self._build_model(args) File <*>/tf2_model.py, line 63, in _build_model name='Generator_A2B') File <*>/tf2_module.py, line 154, in build_generator name='IN_1')(x) File <*>python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 773, in __call__ outputs = call_fn(cast_inputs, *args, **kwargs) File <*>python3.6/site-packages/tensorflow_core/python/keras/layers/core.py, line 847, in call self._check_variables(created_variables, tape.watched_variables()) File <*>python3.6/site-packages/tensorflow_core/python/keras/layers/core.py, line 873, in _check_variables raise ValueError(error_str) ValueError: The following Variables were created within a Lambda layer (IN_1) but are not tracked by said layer: <tf.Variable 'IN_1/SCALE:0' shape=(64,) dtype=float32> <tf.Variable 'IN_1/OFFSET:0' shape=(64,) dtype=float32> The layer cannot safely ensure proper Variable reuse across multiple calls, and consquently this behavior is disallowed for safety. Lambda layers are not well suited to stateful computation; instead, writing a subclassed Layer is the recommend way to define layers with Variables.",0
"File <*>/main.py, line 81, in <module> train(epoch) File <*>/main.py, line 48, in train for iteration, batch in enumerate(training_data_loader, 1): File <*>/site-packages/torch/utils/data/dataloader.py, line 345, in __next__ data = self._next_data() File <*>/site-packages/torch/utils/data/dataloader.py, line 841, in _next_data idx, data = self._get_data() File <*>/site-packages/torch/utils/data/dataloader.py, line 808, in _get_data success, data = self._try_get_data() File <*>/site-packages/torch/utils/data/dataloader.py, line 774, in _try_get_data raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) RuntimeError: DataLoader worker (pid(s) 16596, 9376, 12756, 9844) exited unexpectedly",0
"File <*>/Wrong.py, line 33, in <module> net.forward(dataset[0]) File <*>/Wrong.py, line 23, in forward x = F.relu(self.layer(x)) File <*>/site-packages/torch/nn/modules/module.py, line 532, in __call__ result = self.forward(*input, **kwargs) File <*>/site-packages/torch/nn/modules/, line 87, in forward return F.linear(input, self.weight, self.bias) File <*>/site-packages/torch/nn/functional.py, line 1372, in linear output = input.matmul(weight.t()) RuntimeError: Expected object of scalar type Double but got scalar type Float for argument #2 'mat2' in call to _th_mm",0
"File <*>/test2.py, line 73, in <module> grads = gradients(model, x, y) File <*>/test2.py, line 58, in gradients print(model.get_layer('minimalrnn').output) File <*>python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 1553, in output raise AttributeError('Layer ' + self.name + ' has no inbound nodes.') AttributeError: Layer minimalrnn has no inbound nodes.",0
"File <*>/unet_trainer.py, line 82, in <module> results = model.fit_generator(train_generator, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, validation_data=val_generator, validation_steps=VALIDATION_STEPS, callbacks=callbacks) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 1297, in fit_generator steps_name='steps_per_epoch') File <*>/site-packages/tensorflow_core/python/keras/engine/training_generator.py, line 265, in model_iteration batch_outs = batch_function(*batch_data) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 973, in train_on_batch class_weight=class_weight, reset_metrics=reset_metrics) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch output_loss_metrics=model._output_loss_metrics) File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch output_loss_metrics=output_loss_metrics)) File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 252, in _process_single_batch training=training)) File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 127, in _model_loss outs = model(inputs, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 891, in __call__ outputs = self.call(cast_inputs, *args, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 708, in call convert_kwargs_to_constants=base_layer_utils.call_context().saving) File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 860, in _run_internal_graph output_tensors = layer(computed_tensors, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/layers/convolutional.py, line 197, in call outputs = self._convolution_op(inputs, self.kernel) File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 1134, in __call__ return self.conv_op(inp, filter) File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 639, in __call__ return self.call(inp, filter) File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 238, in __call__ name=self.name) File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 2010, in conv2d name=name) File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1031, in conv2d data_format=data_format, dilations=dilations, name=name, ctx=_ctx) File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1130, in conv2d_eager_fallback ctx=_ctx, name=name) File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None) File <string>, line 3, in raise_from [CODE] tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,16,1536,1536] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",0
"File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 61, in quick_execute num_outputs) TypeError: An op outside of the function building code is being passed a ""Graph"" tensor. It is possible to have Graph tensors leak out of the function building context by including a tf.init_scope in your function building code.",0
"File <stdin>, line 1, in <module> [CODE] File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 1013, in predict use_multiprocessing=use_multiprocessing) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 498, in predict workers=workers, use_multiprocessing=use_multiprocessing, **kwargs) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 475, in _model_iteration total_epochs=1) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch batch_outs = execution_function(iterator) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function distributed_function(input_fn)) File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__ result = self._call(*args, **kwds) File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 638, in _call return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds) # pylint: disable=protected-access File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call self.captured_inputs) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat ctx, args, cancellation_manager=cancellation_manager)) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 545, in call ctx=ctx) File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 75, in quick_execute ""tensors, but found {}"".format(keras_symbolic_tensors)) tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'conv_name_base_1/Identity:0' shape=(None, 160, 160, 64) dtype=float32>]",0
"File <*>/mmconvert, line 8, in <module> sys.exit(_main()) File <*>python3.5/dist-packages/mmdnn/conversion/_script/convert.py, line 102, in _main ret = convertToIR._convert(ir_args) File <*>python3.5/dist-packages/mmdnn/conversion/_script/convertToIR.py, line 62, in _convert from mmdnn.conversion.tensorflow.tensorflow_parser import TensorflowParser File <*>python3.5/dist-packages/mmdnn/conversion/tensorflow/tensorflow_parser.py, line 15, in <module> from tensorflow.tools.graph_transforms import TransformGraph ImportError: No module named 'tensorflow.tools.graph_transforms'",0
"File <*>/3D_tf_data_generator.py, line 181, in <module> evaluation_ad = model.evaluate(ad_test, ad_test_labels, verbose=0) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 930, in evaluate use_multiprocessing=use_multiprocessing) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 490, in evaluate use_multiprocessing=use_multiprocessing, **kwargs) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 426, in _model_iteration use_multiprocessing=use_multiprocessing) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 646, in _process_inputs x, y, sample_weight=sample_weights) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 2383, in _standardize_user_data batch_size=batch_size) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 2489, in _standardize_tensors y, self._feed_loss_fns, feed_output_shapes) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py, line 810, in check_loss_and_target_compatibility ' while using as loss `' + loss_name + '`. ' ValueError: A target array with shape (5, 2) was passed for an output of shape (None, 1) while using as loss `binary_crossentropy`. This loss expects targets to have the same shape as the output.",0
"File pytorch_test.py, line 14, in <module> a_copy.resize_(1, 1) RuntimeError: set_sizes_contiguous is not allowed on a Tensor created from .data or .detach().",0
"File pytorch_test.py, line 21, in <module> a_copy.resize_(1, 1) RuntimeError: cannot resize variables that require grad",0
"File <*>/site-packages/IPython/core/interactiveshell.py, line 3296, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File <ipython-input-2-78553e2886de>, line 1, in <module> runfile('F:/experiment_code/U-net/train.py', wdir='F:/experiment_code/U-net') File <*>/pydev_umd.py, line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc) File <*>/train.py, line 99, in <module> loss.backward() File <*>/site-packages/torch/tensor.py, line 107, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph) File <*>/site-packages/torch/autograd/__init__.py, line 93, in backward allow_unreachable=True) # allow_unreachable flag RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [4, 2, 224, 224]], which is output 0 of SigmoidBackward, is at version 2; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",0
"File <*>python2.7/process.py, line 267, in _bootstrap self.run() File <*>python2.7/process.py, line 114, in run self._target(*self._args, **self._kwargs) File <*>python2.7/pool.py, line 102, in worker task = get() File <*>python2.7/queues.py, line 376, in get return recv() AttributeError: 'module' object has no attribute 'prediction'",0
"File stackoverflow.py, line 47, in <module> with multiprocessing.Pool() as p: AttributeError: __exit__",0
"File trial_mult-ips.py, line 240, in <module> predops=p.map(prediction,new_all_t) File <*>python2.7/pool.py, line 253, in map return self.map_async(func, iterable, chunksize).get() File <*>python2.7/pool.py, line 572, in get raise self._value NotImplementedError: numpy() is only available when eager execution is enabled.",0
"File the_other_end-mp.py, line 216, in <module> predops=p.map(prediction,modelon) File <*>python2.7/pool.py, line 253, in map return self.map_async(func, iterable, chunksize).get() File <*>python2.7/pool.py, line 572, in get raise self._value ValueError: Resource handles are not convertible to numpy.",0
"File main.py, line 95, in <module> model.load_weights(checkpoint_dir) File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 162, in load_weights return super(Model, self).load_weights(filepath, by_name) File <*>python3.7/site-packages/tensorflow/python/keras/engine/network.py, line 1398, in load_weights status.assert_nontrivial_match() File <*>python3.7/site-packages/tensorflow/python/training/tracking/util.py, line 917, in assert_nontrivial_match return self.assert_consumed() File <*>python3.7/site-packages/tensorflow/python/training/tracking/util.py, line 894, in assert_consumed (unused_attributes,)) AssertionError: Some objects had attributes which were not restored: {<tf.Variable 'embedding_1/embeddings:0' shape=(65, 256) dtype=float32, numpy= array([[-0.00044268, -0.02351714, -0.01139065, ..., -0.00327835, 0.00074228, -0.00383734], [-0.02313181, 0.04697707, -0.02350216, ..., 0.040385 , 0.03087702, 0.02765551], [ 0.0410727 , 0.00130001, 0.0051438 , ..., 0.02899202, 0.04258115, -0.03773504], ..., [-0.03134514, 0.01370119, 0.00993627, ..., -0.02257681, 0.02617678, 0.03761976], [-0.02954974, 0.02407967, 0.02768463, ..., -0.0056519 , -0.01507735, 0.04617763], [-0.04113789, -0.03544737, 0.01056757, ..., 0.01236727, -0.01791535, -0.01635399]], dtype=float32)>: ['embedding_1/embeddings'], <tf.Variable 'dense_1/kernel:0' shape=(1024, 65) dtype=float32, numpy= array([[-6.7811467e-02, -2.5536597e-02, 5.1763237e-02, ..., -6.9665730e-02, 3.9457709e-02, -5.3290475e-02], [ 1.5835620e-02, -3.0763537e-02, -7.4058644e-02, ..., 3.8087368e-05, -9.1508478e-03, 5.5485427e-02], [ 3.8143486e-02, 8.8131428e-04, -2.3478847e-02, ..., -1.5135627e-02, -5.2146181e-02, 7.1185097e-02], ..., [-6.6591002e-02, 4.7627889e-02, 5.7474524e-02, ..., 4.1528463e-02, 4.6467118e-02, -3.0670539e-02], [-5.0804108e-02, 5.4505378e-02, -1.5776977e-03, ..., 2.1875933e-02, -2.9637258e-02, 2.0201296e-02], [-4.7325939e-02, -8.0013275e-03, -3.6348965e-02, ..., -7.0560835e-02, -4.9752403e-02, 1.0509960e-02]], dtype=float32)>: ['dense_1/kernel'], <tf.Variable 'dense_1/bias:0' shape=(65,) dtype=float32, numpy= array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>: ['dense_1/bias'], <tf.Variable 'gru_1/kernel:0' shape=(256, 3072) dtype=float32, numpy= array([[ 0.00432818, 0.03131782, 0.00038544, ..., -0.00559966, 0.03458985, -0.03219106], [-0.00865119, 0.01648769, -0.00768028, ..., 0.01366192, -0.03043955, -0.01382086], [-0.01379537, 0.00547716, -0.00385967, ..., -0.00027269, -0.01285852, 0.0377048 ], ..., [-0.01940641, 0.01454895, 0.03349226, ..., -0.04234404, -0.02699661, 0.0376601 ], [ 0.00186675, -0.00547577, -0.02205843, ..., -0.01287581, -0.02314153, 0.04158166], [ 0.00954719, -0.02883693, -0.03259185, ..., -0.02587803, 0.02906795, -0.00559821]], dtype=float32)>: ['gru_1/kernel'], <tf.Variable 'gru_1/recurrent_kernel:0' shape=(1024, 3072) dtype=float32, numpy= array([[ 9.11542401e-03, 1.50135346e-02, 2.96630897e-02, ..., 2.25223936e-02, 2.31253020e-02, -2.96920985e-02], [-2.21075956e-02, -8.46013427e-06, -2.16848943e-02, ..., -1.26914177e-02, -3.49153839e-02, -3.01396102e-02], [-3.59148793e-02, 9.98445973e-03, 2.60963626e-02, ..., 3.15430500e-02, 1.28889643e-02, 3.37569825e-02], ..., [ 3.39106433e-02, 6.54980540e-03, -1.27352085e-02, ..., -4.14674729e-03, 3.53236459e-02, -1.36333425e-02], [-3.50691415e-02, -1.76392253e-02, 1.67468414e-02, ..., -2.06982102e-02, -1.06042419e-02, 2.26641595e-02], [-1.14825107e-02, -3.46554294e-02, -1.83847174e-03, ..., 2.25809850e-02, 2.45791934e-02, -2.70933360e-02]], dtype=float32)>: ['gru_1/recurrent_kernel'], <tf.Variable 'gru_1/bias:0' shape=(2, 3072) dtype=float32, numpy= array([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>: ['gru_1/bias']}",0
"File <*>/train.py, line 66, in <module> train(epochs=20, prefix='test_new_loss_fn') File <*>/train.py, line 46, in train model = create_model((shape[0], shape[1], 3), backbone=backbone, loss_function=loss_fn, freeze_backbone=backbone_freeze, lr=learning_rate) File <*>/__init__.py, line 48, in create_model loss=loss_function, metrics=[mean_relative_percentage_error, metrics.mean_absolute_error]) File <*>/site-packages/keras/engine/training.py, line 342, in compile sample_weight, mask) File <*>/site-packages/keras/engine/training_utils.py, line 404, in weighted score_array = fn(y_true, y_pred) File <*>/losses.py, line 8, in mean_relative_percentage_error diff = K.update_sub(ones, e) File <*>/site-packages/keras/backend/tensorflow_backend.py, line 999, in update_sub return tf.assign_sub(x, decrement) File <*>/site-packages/tensorflow/python/ops/state_ops.py, line 160, in assign_sub return ref.assign_sub(value) AttributeError: 'Tensor' object has no attribute 'assign_sub'",0
"File test_dist_1.py, line 25, in <module> dist.broadcast(tensor=a, src=0) File <*>python3.7/site-packages/torch/distributed/distributed_c10d.py, line 806, in broadcast work = _default_pg.broadcast([tensor], opts) RuntimeError: NCCL error in: /tmp/pip-req-build-58y_cjjl/torch/lib/c10d/ProcessGroupNCCL.cpp:290, unhandled system error",0
"File <*>/rks.py, line 14, in <module> from tf.keras.preprocessing.image import ImageDataGenerator ModuleNotFoundError: No module named 'tf'",0
"File <*>/site-packages/torch/_utils_internal.py, line 46, in get_source_lines_and_file [CODE] File inspect.py, line 967, in getsourcelines [CODE] File inspect.py, line 798, in findsource [CODE] OSError: could not get source code",0
"File extractor.py, line 3, in <module> import torch File <frozen importlib._bootstrap>, line 991, in _find_and_load [CODE] File <frozen importlib._bootstrap>, line 975, in _find_and_load_unlocked [CODE] File <frozen importlib._bootstrap>, line 671, in _load_unlocked [CODE] File <*>/site-packages/PyInstaller/loader/pyimod03_importers.py, line 623, in exec_module exec(bytecode, module.__dict__) File <*>/site-packages/torch/__init__.py, line 367, in <module> [CODE] File <*>/site-packages/torch/distributions/__init__.py, line 112, in <module> [CODE] File <*>/site-packages/torch/distributions/von_mises.py, line 55, in <module> [CODE] File <*>/site-packages/torch/jit/__init__.py, line 1287, in script [CODE] File <*>/site-packages/torch/jit/frontend.py, line 164, in get_jit_def [CODE] File <*>/site-packages/torch/_utils_internal.py, line 53, in get_source_lines_and_file [CODE] OSError: Can't get source for <function _rejection_sample at 0x0000000006892F70>. TorchScript requires source access in order to carry out compilation, make sure original .py files are available.",0
"File <*>python3.6/dist-packages/torch/utils/data/_utils/worker.py, line 178, in _worker_loop data = fetcher.fetch(index) File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch data = [self.dataset[idx] for idx in possibly_batched_index] File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp> data = [self.dataset[idx] for idx in possibly_batched_index] File <ipython-input-114-e0ccd94603fd>, line 31, in __getitem__ xs = label_data[:,0:8:2]; IndexError: too many indices for array",0
"File plot_parametric_pytorch_cifar100.py, line 130, in <module> loss_fn = F.nll_loss(ops, tgts) File <*>python3.7/site-packages/torch/nn/functional.py, line 2115, in nll_loss ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index) IndexError: Target 42 is out of bounds.",0
"File <*>/tempCodeRunnerFile.python, line 1234, in <module> df_enc = tensorflow.one_hot(df, 2, on_value=None, off_value=None, axis=None, dtype=None, name=None) File <*>python3.7/site-packages/tensorflow_core/python/util/dispatch.py, line 180, in wrapper return target(*args, **kwargs) File <*>python3.7/site-packages/tensorflow_core/python/ops/array_ops.py, line 3645, in one_hot name) File <*>python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py, line 5549, in one_hot _ops.raise_from_not_ok_status(e, name) File <*>python3.7/site-packages/tensorflow_core/python/framework/ops.py, line 6606, in raise_from_not_ok_status six.raise_from(core._status_to_exception(e.code, message), None) File <string>, line 3, in raise_from [CODE] tensorflow.python.framework.errors_impl.NotFoundError: Could not find valid device for node.",0
"File trainer.py, line 629, in <module> clear_outputs=True File <*>/utils.py, line 62, in wrapper result = func(*args, **kwargs) File trainer.py, line 490, in train validation_data=valid_dataset, File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper return method(self, *args, **kwargs) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1090, in fit tmp_logs = train_function(iterator) File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 766, in __call__ result = self._call(*args, **kwds) File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 826, in _call return self._stateless_fn(*args, **kwds) File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 2811, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1838, in _filtered_call cancellation_manager=cancellation_manager) File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1914, in _call_flat ctx, args, cancellation_manager=cancellation_manager)) File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 549, in call ctx=ctx) File <*>python3.6/site-packages/tensorflow/python/eager/execute.py, line 60, in quick_execute inputs, attrs, num_outputs) tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [4,76,76,3,1] vs. [4,19,19,3,1] [[node yolo_loss/logistic_loss/mul (defined at ../Helpers/utils.py:260) ]] [Op:__inference_train_function_38735]",0
"File <*>/trainer.py, line 693, in <module> clear_outputs=True, File <*>/utils.py, line 62, in wrapper result = func(*args, **kwargs) File <*>/trainer.py, line 526, in train validation_data=valid_dataset, File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper return method(self, *args, **kwargs) File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 848, in fit tmp_logs = train_function(iterator) File <*>python3.7/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__ result = self._call(*args, **kwds) File <*>python3.7/site-packages/tensorflow/python/eager/def_function.py, line 644, in _call return self._stateless_fn(*args, **kwds) File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 2420, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 1665, in _filtered_call self.captured_inputs) File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 1746, in _call_flat ctx, args, cancellation_manager=cancellation_manager)) File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 598, in call ctx=ctx) File <*>python3.7/site-packages/tensorflow/python/eager/execute.py, line 60, in quick_execute inputs, attrs, num_outputs) tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [8,13,13,3,2] vs. [8,52,52,3,2] [[node gradient_tape/yolo_loss/sub_5/BroadcastGradientArgs (defined at Users/emadboctor/Desktop/Code/yolov3-keras-tf2/Main/trainer.py:526) ]] [Op:__inference_train_function_42744]",0
"File <*>python3.6/dist-packages/optkeras/optkeras.py, line 230, in synch_with_optuna self.best_trial = self.study.best_trial File <*>python3.6/dist-packages/optuna/study.py, line 97, in best_trial return copy.deepcopy(self._storage.get_best_trial(self._study_id)) File <*>python3.6/dist-packages/optuna/storages/in_memory.py, line 293, in get_best_trial raise ValueError(""No trials are completed yet."") ValueError: No trials are completed yet.",0
"File <*>python3.6/dist-packages/optuna/study.py, line 734, in _run_trial result = func(trial) File <*>python3.6/dist-packages/optkeras/optkeras.py, line 130, in fun_tf return fun(trial) File <ipython-input-11-45495c9f2ae9>, line 65, in optima_run self.model.fit(self.train_images, self.train_labels, epochs=10, callbacks = self.ok.callbacks(trial), verbose = self.ok.keras_verbose) File <*>python3.6/dist-packages/optkeras/optkeras.py, line 172, in callbacks self.synch_with_optuna() File <*>python3.6/dist-packages/optkeras/optkeras.py, line 232, in synch_with_optuna self.best_trial = get_trial_default() File <*>python3.6/dist-packages/optkeras/optkeras.py, line 367, in get_trial_default num_fields = optuna.structs.FrozenTrial._field_types.__len__() AttributeError: type object 'FrozenTrial' has no attribute '_field_types'",0
"File <*>python3.6/site-packages/uvicorn/protocols/http/httptools_impl.py, line 385, in run_asgi result = await app(self.scope, self.receive, self.send) File <*>python3.6/site-packages/uvicorn/middleware/proxy_headers.py, line 45, in __call__ return await self.app(scope, receive, send) File <*>python3.6/site-packages/fastapi/applications.py, line 183, in __call__ await super().__call__(scope, receive, send) # pragma: no cover File <*>python3.6/site-packages/starlette/applications.py, line 102, in __call__ await self.middleware_stack(scope, receive, send) File <*>python3.6/site-packages/starlette/middleware/errors.py, line 181, in __call__ raise exc from None File <*>python3.6/site-packages/starlette/middleware/errors.py, line 159, in __call__ await self.app(scope, receive, _send) File <*>python3.6/site-packages/starlette/exceptions.py, line 82, in __call__ raise exc from None File <*>python3.6/site-packages/starlette/exceptions.py, line 71, in __call__ await self.app(scope, receive, sender) File <*>python3.6/site-packages/starlette/routing.py, line 550, in __call__ await route.handle(scope, receive, send) File <*>python3.6/site-packages/starlette/routing.py, line 227, in handle await self.app(scope, receive, send) File <*>python3.6/site-packages/starlette/routing.py, line 41, in app response = await func(request) File <*>python3.6/site-packages/fastapi/routing.py, line 197, in app dependant=dependant, values=values, is_coroutine=is_coroutine File <*>python3.6/site-packages/fastapi/routing.py, line 149, in run_endpoint_function return await run_in_threadpool(dependant.call, **values) File <*>python3.6/site-packages/starlette/concurrency.py, line 34, in run_in_threadpool return await loop.run_in_executor(None, func, *args) File <*>python3.6/thread.py, line 56, in run result = self.fn(*self.args, **self.kwargs) File <*>/main.py, line 155, in API_call raise e File <*>/main.py, line 129, in API_call model = pickle.load(open('models/' + current_model, 'rb')) File <*>python3.6/site-packages/dill/_dill.py, line 270, in load return Unpickler(file, ignore=ignore, **kwds).load() File <*>python3.6/site-packages/dill/_dill.py, line 473, in load obj = StockUnpickler.load(self) File <*>python3.6/site-packages/dill/_dill.py, line 463, in find_class return StockUnpickler.find_class(self, module, name) AttributeError: Can't get attribute 'Model_II_b' on <module '__mp_main__' from '/opt/apps/env/bin/uvicorn'>",0
"File <*>python3.6/pool.py, line 119, in worker result = (True, func(*args, **kwds)) File <*>python3.6/pool.py, line 44, in mapstar return list(map(*args)) File <ipython-input-35-6529ab6dac60>, line 11, in X_power_func X_power = X**j RuntimeError: CUDA error: initialization error",0
"File <*>/site-packages/tensorflow/python/data/util/structure.py, line 93, in normalize_element spec = type_spec_from_value(t, use_fallback=False) File <*>/site-packages/tensorflow/python/data/util/structure.py, line 466, in type_spec_from_value (element, type(element).__name__)) TypeError: Could not build a TypeSpec for 0 Tecmo Koei 1 Nippon Ichi Software 2 Ubisoft 3 Activision 4 Atari ... 6594 Kemco 6595 Infogrames 6596 Activision 6597 7G//AMES 6598 Wanadoo Name: Publisher, Length: 6599, dtype: object with type Series",0
"File imdb_classification.py, line 65, in <module> history = model.fit(x_train,y_train,epochs=50,batch_size=32,verbose=1) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 819, in fit use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 235, in fit use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 593, in _process_training_inputs use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 706, in _process_inputs use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 357, in __init__ dataset = self.slice_inputs(indices_dataset, inputs) File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 383, in slice_inputs dataset_ops.DatasetV2.from_tensors(inputs).repeat() File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 566, in from_tensors return TensorDataset(tensors) File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 2765, in __init__ element = structure.normalize_element(element) File <*>/site-packages/tensorflow_core/python/data/util/structure.py, line 113, in normalize_element ops.convert_to_tensor(t, name=""component_%d"" % i)) File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1314, in convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py, line 52, in _default_conversion_function return constant_op.constant(value, dtype, name=name) File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 258, in constant allow_broadcast=True) File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 266, in _constant_impl t = convert_to_eager_tensor(value, ctx, dtype) File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 96, in convert_to_eager_tensor return ops.EagerTensor(value, ctx.device_name, dtype) ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list)",0
"File [FILE], line <*>, in [FUNC] [CODE] File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 349, in train loss = self._train_model(input_fn, hooks, saving_listeners) File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1182, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners) File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1208, in _train_model_default self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN)) File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1044, in _get_features_and_labels_from_input_fn self._call_input_fn(input_fn, mode)) File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1137, in _call_input_fn return input_fn(**kwargs) File [FILE], line 1137, in [FUNC] [CODE] File <*>python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 406, in __iter__ raise RuntimeError(""__iter__() is only supported inside of tf.function "" RuntimeError: __iter__() is only supported inside of tf.function or when eager execution is enabled.",0
"File <stdin>, line 1, in <module> [CODE] File <*>python3.6/site-packages/torch_xla/core/xla_model.py, line 231, in xla_device devkind=devkind if devkind is not None else None) File <*>python3.6/site-packages/torch_xla/core/xla_model.py, line 136, in get_xla_supported_devices xla_devices = _DEVICES.value File <*>python3.6/site-packages/torch_xla/utils/utils.py, line 32, in value self._value = self._gen_fn() File <*>python3.6/site-packages/torch_xla/core/xla_model.py, line 18, in <lambda> _DEVICES = xu.LazyProperty(lambda: torch_xla._XLAC._xla_get_devices()) RuntimeError: tensorflow/compiler/xla/xla_client/computation_client.cc:274 : Missing XLA configuration",0
"File <*>/convert.py, line 13, in <module> tflite_model = converter.convert() File <*>/site-packages/tensorflow/lite/python/lite.py, line 1076, in convert return super(TFLiteConverterV2, self).convert() File <*>/site-packages/tensorflow/lite/python/lite.py, line 899, in convert return super(TFLiteFrozenGraphConverterV2, File <*>/site-packages/tensorflow/lite/python/lite.py, line 629, in convert result = _toco_convert_impl( File <*>/site-packages/tensorflow/lite/python/convert.py, line 569, in toco_convert_impl data = toco_convert_protos( File <*>/site-packages/tensorflow/lite/python/convert.py, line 202, in toco_convert_protos raise ConverterError(str(e)) tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types <unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x?x?x3x!tf.quint8>) -> tensor<1x?x?x3xui8>",0
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 64, in <module> from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.",0
"File <*>/site-packages/IPython/core/interactiveshell.py, line 3331, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File <ipython-input-2-d2317d03e1c1>, line 1, in <module> runfile('F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news/bitcoin.py', wdir='F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news') File <*>/pydev_umd.py, line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc) File <*>/bitcoin.py, line 41, in <module> model.fit(x=x_train, y=y_train, batch_size=64, epochs=5, shuffle=True, validation_split=0.1) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 819, in fit use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 342, in fit total_epochs=epochs) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch batch_outs = execution_function(iterator) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function distributed_function(input_fn)) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__ result = self._call(*args, **kwds) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 632, in _call return self._stateless_fn(*args, **kwds) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2363, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call self.captured_inputs) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat ctx, args, cancellation_manager=cancellation_manager)) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 545, in call ctx=ctx) File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None) File <string>, line 3, in raise_from [CODE] tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Condition x == y did not hold element-wise:] [x (loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [64 1] [y (loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [64 14] [[node loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news/bitcoin.py:41) ]] [Op:__inference_distributed_function_2970]",0
"File <*>/model_main_tf2.py, line 113, in <module> tf.compat.v1.app.run() File <*>python3.6/dist-packages/tensorflow/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef) File <*>python3.6/dist-packages/absl/app.py, line 300, in run _run_main(main, args) File <*>python3.6/dist-packages/absl/app.py, line 251, in _run_main sys.exit(main(argv)) File <*>/model_main_tf2.py, line 110, in main record_summaries=FLAGS.record_summaries) File <*>python3.6/dist-packages/object_detection/model_lib_v2.py, line 630, in train_loop manager.save() File <*>python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py, line 819, in save self._record_state() File <*>python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py, line 728, in _record_state save_relative_paths=True) File <*>python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py, line 248, in update_checkpoint_state_internal text_format.MessageToString(ckpt)) File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 570, in atomic_write_string_to_file rename(temp_pathname, filename, overwrite) File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 529, in rename rename_v2(oldname, newname, overwrite) File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 546, in rename_v2 compat.as_bytes(src), compat.as_bytes(dst), overwrite) tensorflow.python.framework.errors_impl.FailedPreconditionError: /content/drive/My Drive/Tensorflow/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint.tmp91048f3bf67645619be6603094546de1; Is a directory",0
"File <*>/emotion.py, line 4, in <module> emotion_detector = EmotionRecognition(device='gpu', gpu_id=1) File <*>python3.7/site-packages/facial_emotion_recognition/facial_emotion_recognition.py, line 25, in __init__ self.network = NetworkV2(in_c=1, nl=32, out_f=7).to(self.device) File <*>python3.7/site-packages/torch/nn/modules/module.py, line 607, in to return self._apply(convert) File <*>python3.7/site-packages/torch/nn/modules/module.py, line 354, in _apply module._apply(fn) File <*>python3.7/site-packages/torch/nn/modules/module.py, line 376, in _apply param_applied = fn(param) File <*>python3.7/site-packages/torch/nn/modules/module.py, line 605, in convert return t.to(device, dtype if t.is_floating_point() else None, non_blocking) RuntimeError: CUDA error: invalid device ordinal",0
"File <stdin>, line 1, in <module> [CODE] File <*>/site-packages/tensorflow/__init__.py, line 101, in <module> from tensorflow_core import * File <*>/site-packages/tensorflow_core/__init__.py, line 40, in <module> from tensorflow.python.tools import module_util as _module_util File <frozen importlib._bootstrap>, line 983, in _find_and_load [CODE] File <frozen importlib._bootstrap>, line 959, in _find_and_load_unlocked [CODE] File <*>/site-packages/tensorflow/__init__.py, line 50, in __getattr__ module = self._load() File <*>/site-packages/tensorflow/__init__.py, line 44, in _load module = _importlib.import_module(self.__name__) File <*>/__init__.py, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level) File <*>/site-packages/tensorflow_core/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py, line 15, in swig_import_helper import imp ValueError: source code string cannot contain null bytes",0
"File foo_test.py, line 21, in test3 self.assertEqual(3,4) AssertionError: 3 != 4",0
"File ml_model.py, line 1, in <module> import torch File <*>/site-packages/torch/__init__.py, line 117, in <module> import torch File <*>/site-packages/torch/__init__.py, line 117, in <module> raise err OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading ""C:\Users\user\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\lib\cudnn_cnn_infer64_8.dll"" or one of its dependencies. raise err",0
"File model_main_tf2.py, line 113, in <module> tf.compat.v1.app.run() File <*>/site-packages/tensorflow/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef) File <*>/site-packages/absl/app.py, line 303, in run _run_main(main, args) File <*>/site-packages/absl/app.py, line 251, in _run_main sys.exit(main(argv)) File model_main_tf2.py, line 104, in main model_lib_v2.train_loop( File <*>/site-packages/object_detection/model_lib_v2.py, line 639, in train_loop loss = _dist_train_step(train_input_iter) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__ result = self._call(*args, **kwds) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 840, in _call return self._stateless_fn(*args, **kwds) File <*>/site-packages/tensorflow/python/eager/function.py, line 2829, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access File <*>/site-packages/tensorflow/python/eager/function.py, line 1843, in _filtered_call return self._call_flat( File <*>/site-packages/tensorflow/python/eager/function.py, line 1923, in _call_flat return self._build_call_outputs(self._inference_function.call( File <*>/site-packages/tensorflow/python/eager/function.py, line 545, in call outputs = execute.execute( File <*>/site-packages/tensorflow/python/eager/execute.py, line 59, in quick_execute tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name, tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found. (0) Resource exhausted: OOM when allocating tensor with shape[64,256,17,17] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[node functional_3/conv2d_160/Conv2D (defined at \site-packages\object_detection\meta_architectures\faster_rcnn_meta_arch.py:1149) ]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. [[Identity_1/_432]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. (1) Resource exhausted: OOM when allocating tensor with shape[64,256,17,17] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[node functional_3/conv2d_160/Conv2D (defined at \site-packages\object_detection\meta_architectures\faster_rcnn_meta_arch.py:1149) ]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. 0 successful operations. 0 derived errors ignored. [Op:__inference__dist_train_step_79248]",0
"File <ipython-input-39-17211d5a107c>, line 8, in <module> train_loss, _ = modhelper.train(proc.train_dataloader) File <*>/model.py, line 71, in train preds = self.model(sent_id, mask) File <*>/site-packages/torch/nn/modules/module.py, line 727, in _call_impl result = self.forward(*input, **kwargs) File <*>/model.py, line 181, in forward #pass the inputs to the model File <*>/site-packages/transformers/modeling_bert.py, line 837, in forward embedding_output = self.embeddings( File <*>/site-packages/transformers/modeling_bert.py, line 201, in forward embeddings = inputs_embeds + position_embeddings + token_type_embeddings RuntimeError: The size of tensor a (4000) must match the size of tensor b (512) at non-singleton dimension 1",0
"File <*>/site-packages/pytorch_lightning/trainer/trainer.py, line 521, in train self.train_loop.run_training_epoch() File <*>/site-packages/pytorch_lightning/trainer/training_loop.py, line 588, in run_training_epoch self.trainer.run_evaluation(test_mode=False) File <*>/site-packages/pytorch_lightning/trainer/trainer.py, line 613, in run_evaluation self.evaluation_loop.log_evaluation_step_metrics(output, batch_idx) File <*>/site-packages/pytorch_lightning/trainer/evaluation_loop.py, line 346, in log_evaluation_step_metrics self.__log_result_step_metrics(step_log_metrics, step_pbar_metrics, batch_idx) File <*>/site-packages/pytorch_lightning/trainer/evaluation_loop.py, line 350, in __log_result_step_metrics cached_batch_pbar_metrics, cached_batch_log_metrics = cached_results.update_logger_connector() File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 378, in update_logger_connector batch_log_metrics = self.get_latest_batch_log_metrics() File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 418, in get_latest_batch_log_metrics batch_log_metrics = self.run_batch_from_func_name(""get_batch_log_metrics"") File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 414, in run_batch_from_func_name results = [func(include_forked_originals=False) for func in results] File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 414, in <listcomp> results = [func(include_forked_originals=False) for func in results] File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 122, in get_batch_log_metrics return self.run_latest_batch_metrics_with_func_name(""get_batch_log_metrics"", *args, **kwargs) File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 115, in run_latest_batch_metrics_with_func_name for dl_idx in range(self.num_dataloaders) File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 115, in <listcomp> for dl_idx in range(self.num_dataloaders) File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 100, in get_latest_from_func_name results.update(func(*args, add_dataloader_idx=add_dataloader_idx, **kwargs)) File <*>/site-packages/pytorch_lightning/core/step_result.py, line 298, in get_batch_log_metrics result[dl_key] = self[k]._forward_cache.detach() AttributeError: 'NoneType' object has no attribute 'detach'",0
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 64, in <module> from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.",0
"File <stdin>, line 24, in <module> [CODE] TypeError: expected CPU (got CUDA)",0
"File <stdin>, line 1, in <module> [CODE] File <*>python3.6/site-packages/smdistributed/dataparallel/__init__.py, line 16, in <module> import smddpcommon as hc ImportError: libc10.so: cannot open shared object file: No such file or directory",0
"File <*>python3.4/site-packages/theano/gof/op.py, line 517, in __call__(self, *inputs, **kwargs) storage_map[ins] = [self._get_test_value(ins)] File <*>python3.4/site-packages/theano/gof/op.py, line 479, in _get_test_value(cls, v) raise AttributeError('%s has no test value' % v) AttributeError: x has no test value",0
"File [FILE], line 5, in <module>() z = x + y File <*>python3.4/site-packages/theano/tensor/var.py, line 128, in __add__(self, other) return theano.tensor.basic.add(self, other) File <*>python3.4/site-packages/theano/gof/op.py, line 525, in __call__(self, *inputs, **kwargs) raise ValueError('Cannot compute test value: input %i (%s) of Op %s missing default value' % (i, ins, node)) ValueError: Cannot compute test value: input 0 (x) of Op Elemwise{add,no_inplace}(x, y) missing default value",0
"File [FILE], line 16, in <module>() caffe.Net(net_param, caffe.TEST) ArgumentError: Python argument types in Net.__init__(Net, NetParameter, int) did not match C++ signature: __init__(boost::python::api::object, std::string, std::string, int) __init__(boost::python::api::object, std::string, int)",0
"File [FILE], line 19, in <module>() rotate_x_axis_theano = theano.function([angle_var],rotate_x_axis_expr(angle_var)) File [FILE], line 14, in rotate_x_axis_expr(angle) R[1][1] = cosa; R[1][2] = -sina TypeError: 'TensorVariable' object does not support item assignment",0
"File [FILE], line 2, in <module>() y_pred = model.predict(X_nn) File <*>/site-packages/keras/models.pyc, line 493, in predict(self, X, batch_size, verbose) return self._predict_loop(self._predict, X, batch_size, verbose)[0] AttributeError: 'Sequential' object has no attribute '_predict'",0
"File [FILE], line 9, in <module>() example, label = sess.run([features, col1]) File <*>python2.7/site-packages/tensorflow/python/client/session.pyc, line 345, in run(self, fetches, feed_dict) results = self._do_run(target_list, unique_fetch_targets, feed_dict_string) File <*>python2.7/site-packages/tensorflow/python/client/session.pyc, line 419, in _do_run(self, target_list, fetch_list, feed_dict) e.code) InvalidArgumentError: Field 1 in record 0 is not a valid int32: 0.766126609",0
"File [FILE], line 1, in <module>() saver.restore(sess, ""params.ckpt"") File <*>python3.5/site-packages/tensorflow/python/training/saver.py, line 891, in restore(self, sess, save_path) sess.run([self._restore_op_name], {self._filename_tensor_name: save_path}) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 368, in run(self, fetches, feed_dict) results = self._do_run(target_list, unique_fetch_targets, feed_dict_string) File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 428, in _do_run(self, target_list, fetch_list, feed_dict) target_list) SystemError: <built-in function delete_Status> returned a result with an error set",0
"File [FILE], line 3, in <module>() batch_size=16) File <*>python2.7/site-packages/keras/models.pyc, line 402, in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs) sample_weight=sample_weight) File <*>python2.7/site-packages/keras/engine/training.pyc, line 971, in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight) batch_size=batch_size) File <*>python2.7/site-packages/keras/engine/training.pyc, line 911, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size) check_loss_and_target_compatibility(y, self.loss_functions, self.internal_output_shapes) File <*>python2.7/site-packages/keras/engine/training.pyc, line 184, in check_loss_and_target_compatibility(targets, losses, output_shapes) ' while using as loss `categorical_crossentropy`. ' Exception: You are passing a target array of shape (10105, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via: ``` from keras.utils.np_utils import to_categorical y_binary = to_categorical(y_int) ``` Alternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",0
"File [FILE], line 30, in <module>() sess.run(optimizer, feed_dict={X: x, y: y}) File <*>python2.7/site-packages/tensorflow/python/client/session.pyc, line 340, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr) File <*>python2.7/site-packages/tensorflow/python/client/session.pyc, line 542, in _run(self, handle, fetches, feed_dict, options, run_metadata) + e.args[0]) TypeError: Cannot interpret feed_dict key as Tensor: Can not convert a float64 into a Tensor.",0
"File [FILE], line 2, in <module>() sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys}) File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 340, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr) File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 564, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_string, options, run_metadata) File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 637, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) target_list, options, run_metadata) File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 659, in _do_call(self, fn, *args) e.code) InternalError: Blas SGEMM launch failed : a.shape=(100, 784), b.shape=(784, 10), m=100, n=10, k=784 [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_Placeholder_0/_4, Variable/read)]]",0
"File [FILE], line 1, in <module>() biases = tf.get_variable('biases', [64], tf.constant_initializer(0.0)) File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 732, in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape) partitioner=partitioner, validate_shape=validate_shape) File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 596, in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape) partitioner=partitioner, validate_shape=validate_shape) File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 161, in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape) caching_device=caching_device, validate_shape=validate_shape) File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 425, in _get_single_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, validate_shape) dtype = dtypes.as_dtype(dtype) File <*>python2.7/site-packages/tensorflow/python/framework/dtypes.pyc, line 536, in as_dtype(type_value) if key == type_value: TypeError: data type not understood",0
"File [FILE], line 14, in <module>() p.fit(x=df_train, y=df_train, steps=10, batch_size=100) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 173, in fit(self, x, y, input_fn, steps, batch_size, monitors) input_fn, feed_fn = _get_input_fn(x, y, batch_size) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 67, in _get_input_fn(x, y, batch_size) x, y, n_classes=None, batch_size=batch_size) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.pyc, line 99, in setup_train_data_feeder(X, y, n_classes, batch_size, shuffle, epochs) X, y = _data_type_filter(X, y) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.pyc, line 67, in _data_type_filter(X, y) X = extract_pandas_data(X) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/pandas_io.pyc, line 53, in extract_pandas_data(data) raise ValueError('Data types for data must be int, float, or bool.') ValueError: Data types for data must be int, float, or bool.",0
"File [FILE], line 7, in <module>() input_map={'import/pool5':out_pool}) File <*>python3.4/dist-packages/tensorflow/python/framework/importer.py, line 335, in import_graph_def(graph_def, input_map, return_elements, name, op_dict) ops.set_shapes_for_outputs(op) File <*>python3.4/dist-packages/tensorflow/python/framework/ops.py, line 1612, in set_shapes_for_outputs(op) shapes = shape_func(op) File <*>/roi_pooling_op_grad.py, line 15, in _roi_pool_shape(op) dims_rois = op.inputs[1].get_shape().as_list() File <*>python3.4/dist-packages/tensorflow/python/framework/tensor_shape.py, line 747, in as_list(self) return [dim.value for dim in self._dims] TypeError: 'NoneType' object is not iterable",0
"File [FILE], line 7, in <module>() hidden1 = tf.nn.relu(tf.matmul(images_placeholder, weights) + biases) File <*>python3.4/site-packages/tensorflow/python/ops/math_ops.py, line 1325, in matmul(a, b, transpose_a, transpose_b, a_is_sparse, b_is_sparse, name) with ops.op_scope([a, b], name, ""MatMul"") as name: File <*>python3.4/contextlib.py, line 59, in __enter__(self) return next(self.gen) File <*>python3.4/site-packages/tensorflow/python/framework/ops.py, line 4016, in op_scope(values, name, default_name) g = _get_graph_from_inputs(values) File <*>python3.4/site-packages/tensorflow/python/framework/ops.py, line 3814, in _get_graph_from_inputs(op_input_list, graph) _assert_same_graph(original_graph_element, graph_element) File <*>python3.4/site-packages/tensorflow/python/framework/ops.py, line 3759, in _assert_same_graph(original_item, item) ""%s must be from the same graph as %s."" % (item, original_item)) ValueError: Tensor(""weights:0"", shape=(1024, 200), dtype=float32_ref) must be from the same graph as Tensor(""Placeholder:0"", shape=(100, 1024), dtype=float32).`",0
"File [FILE], line 13, in <module>() m.fit(input_fn=train_input_fn, steps=200) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 240, in fit(self, x, y, input_fn, steps, batch_size, monitors, max_steps) max_steps=max_steps) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 550, in _train_model(self, input_fn, steps, feed_fn, init_op, init_feed_fn, init_fn, device_fn, monitors, log_every_steps, fail_on_nan_loss, max_steps) train_op, loss_op = self._get_train_ops(features, targets) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.pyc, line 336, in _get_train_ops(self, features, targets) return super(LinearRegressor, self)._get_train_ops(features, targets) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.pyc, line 182, in _get_train_ops(self, features, targets) logits = self._logits(features, is_training=True) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.pyc, line 271, in _logits(self, features, is_training) logits = self._linear_logits(features, is_training) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.pyc, line 233, in _linear_logits(self, features, is_training) features, self._linear_feature_columns, is_training) File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/composable_model.pyc, line 177, in build_model(self, features, feature_columns, is_training) scope=scope) File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/feature_column_ops.pyc, line 178, in weighted_sum_from_feature_columns(columns_to_tensors, feature_columns, num_outputs, weight_collections, trainable, scope) transformed_tensor = transformer.transform(column) File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/feature_column_ops.pyc, line 384, in transform(self, feature_column) feature_column.insert_transformed_feature(self._columns_to_tensors) File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/feature_column.pyc, line 364, in insert_transformed_feature(self, columns_to_tensors) name=self.name + ""_lookup"") File <*>python2.7/site-packages/tensorflow/python/ops/gen_string_ops.pyc, line 185, in string_to_hash_bucket_fast(input, num_buckets, name) num_buckets=num_buckets, name=name) File <*>python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc, line 463, in apply_op(self, op_type_name, name, **keywords) (prefix, dtypes.as_dtype(input_arg.type).name)) TypeError: Input 'input' of 'StringToHashBucketFast' Op has type int64 that does not match expected type of string.",0
"File [FILE], line 27, in () train = model.train(images, labels) File [FILE], line 62, in train(self, images, labels) logits = model._create_model(images) File [FILE], line 41, in _create_model(self, inputs) inputs = self._create_dense_layer(name, inputs, n_in, n_out) File [FILE], line 27, in _create_dense_layer(self, name, inputs, n_in, n_out, activation) weights = self._weights([n_in, n_out]) File <*>python3.5/site-packages/tensorflow/python/ops/template.py, line 267, in __call__(self, *args, **kwargs) return self._call_func(args, kwargs, check_for_new_variables=False) File <*>python3.5/site-packages/tensorflow/python/ops/template.py, line 208, in _call_func(self, args, kwargs, check_for_new_variables) result = self._func(*args, **kwargs) TypeError: _real_weights() missing 1 required positional argument: 'shape'",0
"File [FILE], line 1, in <module>() audiocnn(input) File <*>python2.7/site-packages/torch/nn/modules/module.pyc, line 224, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File [FILE], line 17, in forward(self, x) _, (_, _) = self.lstm(x,(h_0,c_0)) # x dim : 2 x 1 x 256 File <*>python2.7/site-packages/torch/nn/modules/rnn.pyc, line 162, in forward(self, input, hx) output, hidden = func(input, self.all_weights, hx) File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 351, in forward(input, *fargs, **fkwargs) return func(input, *fargs, **fkwargs) File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 244, in forward(input, weight, hidden) nexth, output = func(input, hidden, weight) File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 84, in forward(input, hidden, weight) hy, output = inner(input, hidden[l], weight[l]) File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 113, in forward(input, hidden, weight) hidden = inner(input[i], hidden, *weight) File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 31, in LSTMCell(input, hidden, w_ih, w_hh, b_ih, b_hh) gates = F.linear(input, w_ih, b_ih) + F.linear(hx, w_hh, b_hh) File <*>python2.7/site-packages/torch/nn/functional.pyc, line 553, in linear(input, weight, bias) return torch.addmm(bias, input, weight.t()) File <*>python2.7/site-packages/torch/autograd/variable.pyc, line 924, in addmm(cls, *args) return cls._blas(Addmm, args, False) File <*>python2.7/site-packages/torch/autograd/variable.pyc, line 920, in _blas(cls, args, inplace) return cls.apply(*(tensors + (alpha, beta, inplace))) RuntimeError: save_for_backward can only save input or output tensors, but argument 0 doesn't satisfy this condition",0
"File [FILE], line 1, in <module>() from imagenet_utils import preprocess_input, decode_predictions ImportError: No module named 'imagenet_utils'",0
"File [FILE], line 18, in <module>() curr_loss = train(train_loader, model, criterion, epoch, num_epochs) File [FILE], line 18, in train(train_loader, model, criterion, epoch, num_epochs) loss = criterion(outputs, labels) File <*>python3.5/dist-packages/torch/nn/modules/module.py, line 325, in _ _call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File [FILE], line 11, in forward(self, logits, targets) return self.crossEntropy_loss(probs_flat, targets_flat) File <*>python3.5/dist-packages/torch/nn/modules/module.py, line 325, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.5/dist-packages/torch/nn/modules/loss.py, line 601, in f orward(self, input, target) self.ignore_index, self.reduce) File <*>python3.5/dist-packages/torch/nn/functional.py, line 1140, in cross_entropy(input, target, weight, size_average, ignore_index, reduce) return nll_loss(log_softmax(input, 1), target, weight, size_average, ignore_index, reduce) File <*>python3.5/dist-packages/torch/nn/functional.py, line 786, in log_softmax(input, dim, _stacklevel) return torch._C._nn.log_softmax(input, dim) RuntimeError: dimension out of range (expected to be in range of [-1, 0], but got 1)",0
"File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn) input_tensors_as_shapes, status) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status)) InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 4096 and 1000 for 'Assign_30' (op: 'Assign') with input shapes: [4096,3], [1000,3].",0
"File [FILE], line 2, in <module>() loaded_model = load_model('my_model_vgg16.h5') File <*>/site-packages/keras/models.py, line 246, in load_model(filepath, custom_objects, compile) topology.load_weights_from_hdf5_group(f['model_weights'], model.layers) File <*>/site-packages/keras/engine/topology.py, line 3166, in load_weights_from_hdf5_group(f, layers) K.batch_set_value(weight_value_tuples) File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2365, in batch_set_value(tuples) assign_op = x.assign(assign_placeholder) File <*>/site-packages/tensorflow/python/ops/variables.py, line 573, in assign(self, value, use_locking) return state_ops.assign(self._variable, value, use_locking=use_locking) File <*>/site-packages/tensorflow/python/ops/state_ops.py, line 276, in assign(ref, value, validate_shape, use_locking, name) validate_shape=validate_shape) File <*>/site-packages/tensorflow/python/ops/gen_state_ops.py, line 56, in assign(ref, value, validate_shape, use_locking, name) use_locking=use_locking, name=name) File <*>/site-packages/tensorflow/python/framework/op_def_library.py, line 787, in _apply_op_helper(self, op_type_name, name, **keywords) op_def=op_def) File <*>/site-packages/tensorflow/python/framework/ops.py, line 2958, in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device) set_shapes_for_outputs(ret) File <*>/site-packages/tensorflow/python/framework/ops.py, line 2209, in set_shapes_for_outputs(op) shapes = shape_func(op) File <*>/site-packages/tensorflow/python/framework/ops.py, line 2159, in call_with_requiring(op) return call_cpp_shape_fn(op, require_shape_fn=True) File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 627, in call_cpp_shape_fn(op, require_shape_fn) require_shape_fn) File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 691, in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn) raise ValueError(err.message) ValueError: Dimension 0 in both shapes must be equal, but are 4096 and 1000 for 'Assign_30' (op: 'Assign') with input shapes: [4096,3], [1000,3].",0
"File <*>python3.6/dist-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn) input_tensors_as_shapes, status) File <*>python3.6/dist-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status)) InvalidArgumentError: Negative dimension size caused by subtracting 3 from 1 for 'conv1d_26/convolution/Conv2D' (op: 'Conv2D') with input shapes: [?,1,1,256], [1,3,256,256].",0
"File [FILE], line 1, in <module>() import tensorflow as tf ModuleNotFoundError: No module named 'tensorflow'",0
"File <*>/train.py, line 58, in <module>() flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.') File <*>python3.6/dist-packages/tensorflow/python/platform/flags.py, line 58, in wrapper(*args, **kwargs) return original_function(*args, **kwargs) File <*>python3.6/dist-packages/absl/flags/_defines.py, line 241, in DEFINE_string(name, default, help, flag_values, **args) DEFINE(parser, name, default, help, flag_values, serializer, **args) File <*>python3.6/dist-packages/absl/flags/_defines.py, line 82, in DEFINE(parser, name, default, help, flag_values, serializer, module_name, **args) flag_values, module_name) File <*>python3.6/dist-packages/absl/flags/_defines.py, line 104, in DEFINE_flag(flag, flag_values, module_name) fv[flag.name] = flag File <*>python3.6/dist-packages/absl/flags/_flagvalues.py, line 427, in __setitem__(self, name, flag) raise _exceptions.DuplicateFlagError.from_flag(name, self) DuplicateFlagError: The flag 'master' is defined twice. First from object_detection/train.py, Second from object_detection/train.py. Description from first occurrence: Name of the TensorFlow master to use.",0
"File <*>/train.py, line 167, in <module>() tf.app.run() File <*>python3.6/dist-packages/tensorflow/python/platform/app.py, line 126, in run(main, argv) _sys.exit(main(argv)) File <*>/train.py, line 107, in main(_) overwrite=True) File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 392, in copy(oldpath, newpath, overwrite) compat.as_bytes(oldpath), compat.as_bytes(newpath), overwrite, status) File <*>python3.6/dist-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status)) NotFoundError: ; No such file or directory",0
"File [FILE], line 35, in <module>() mean , variance = tf.nn.moments(X_train, axes = 1, keep_dims = True) File <*>python2.7/nn_impl.pyc, line 666, in moments(x, axes, shift, name, keep_dims) y = math_ops.cast(x, dtypes.float32) if x.dtype == dtypes.float16 else x TypeError: data type not understood",0
"File [FILE], line [NUM], in () [CODE] File [FILE], line [NUM], in [FUNC] [CODE] File <*>python3.6/site-packages/torch/autograd/variable.py, line [NUM], in setitem(self, key, value) [CODE] RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.",0
"File <*>/model_finegrained.py, line 1, in <module>() tf.Variable(2, name='a:b') File <*>python3.6/site-packages/tensorflow/python/ops/variables.py, line 213, in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint) constraint=constraint) File <*>python3.6/site-packages/tensorflow/python/ops/variables.py, line 289, in _init_from_args(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint) [initial_value]) as name: File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 4932, in __enter__(self) return self._name_scope.__enter__() File <*>python3.6/contextlib.py, line 81, in __enter__(self) return next(self.gen) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3514, in name_scope(self, name) raise ValueError(""'%s' is not a valid scope name"" % name) ValueError: 'a:b' is not a valid scope name",0
"File [FILE], line 1, in <module>() for batch_idx, (data, target) in enumerate(train_loader): File <*>python2.7/dist-packages/torch/utils/data/dataloader.pyc, line 259, in __next__(self) batch = self.collate_fn([self.dataset[i] for i in indices]) File <*>python2.7/dist-packages/torch/utils/data/dataloader.pyc, line 135, in default_collate(batch) return [default_collate(samples) for samples in transposed] File <*>python2.7/dist-packages/torch/utils/data/dataloader.pyc, line 112, in default_collate(batch) return torch.stack(batch, 0, out=out) File <*>python2.7/dist-packages/torch/functional.pyc, line 64, in stack(sequence, dim, out) return torch.cat(inputs, dim) RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 400 and 487 in dimension 2 at /pytorch/torch/lib/TH/generic/THTensorMath.c:2897",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 282, in __init__(self, fetches, contraction_fn) fetch, allow_tensor=True, allow_operation=True)) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3590, in as_graph_element(self, obj, allow_tensor, allow_operation) return self._as_graph_element_locked(obj, allow_tensor, allow_operation) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3679, in _as_graph_element_locked(self, obj, allow_tensor, allow_operation) types_str)) TypeError: Can not convert a Iterator into a Tensor or Operation.",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call(self, fn, *args) return fn(*args) File <*>/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata) status, run_metadata) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status)) InvalidArgumentError: You must feed a value for placeholder tensor 'time_distributed_2_target' with dtype float and shape [?,?,?] [[Node: time_distributed_2_target = Placeholder[dtype=DT_FLOAT, shape=[?,?,?], _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1322, in _do_call(self, fn, *args) return fn(*args) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1307, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1409, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata) InvalidArgumentError: slice index 0 of dimension 0 out of bounds. [[Node: lstm_25/strided_slice_13 = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](lstm_25/transpose, loss_11/dense_58_loss/Const_2, lstm_25/strided_slice_9/stack_2, lstm_25/strided_slice_9/stack_2)]]",0
"File [FILE], line 57, in <module>() feed_dict=feed_dict) TypeError: 'NoneType' object is not iterable",0
"File [FILE], line 2, in <module>() steps_per_epoch=1, epochs=15, verbose=2) File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs) File <*>/site-packages/keras/engine/training.py, line 2230, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) class_weight=class_weight) File <*>/site-packages/keras/engine/training.py, line 1877, in train_on_batch(self, x, y, sample_weight, class_weight) class_weight=class_weight) File <*>/site-packages/keras/engine/training.py, line 1480, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size) exception_prefix='target') File <*>/site-packages/keras/engine/training.py, line 76, in _standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data] File <*>/site-packages/keras/engine/training.py, line 76, in <listcomp>(.0) data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data] AttributeError: 'Tensor' object has no attribute 'ndim'",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1322, in _do_call(self, fn, *args) return fn(*args) File <*>/site-packages/tensorflow/python/client/session.py, line 1307, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1409, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata) InvalidArgumentError: Matrix size-incompatible: In[0]: [1,16384], In[1]: [1024,10] [[Node: dense_251/MatMul = MatMul[T=DT_FLOAT, _class=[""loc:@training_22/RMSprop/gradients/dense_251/MatMul_grad/MatMul""], transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](flatten_153/Reshape, dense_251/kernel/read)]] [[Node: loss_26/mul/_579 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1108_loss_26/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]",0
"File [FILE], line 7, in <module>() X = AttentionLayer()(X) File <*>python3.6/site-packages/keras/engine/topology.py, line 619, in __call__(self, inputs, **kwargs) output = self.call(inputs, **kwargs) File <*>/attention.py, line 51, in call(self, x) flatten_g = hw_flatten(g) File <*>/attention.py, line 41, in hw_flatten(x) return K.reshape(x, shape=[x.shape[0], x.shape[1]*x.shape[2], x.shape[-1]]) File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 1898, in reshape(x, shape) return tf.reshape(x, shape) File <*>python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py, line 6113, in reshape(tensor, shape, name) ""Reshape"", tensor=tensor, shape=shape, name=name) File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 513, in _apply_op_helper(self, op_type_name, name, **keywords) raise err File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 510, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1104, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 235, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name) File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 214, in constant(value, dtype, shape, name, verify_shape) value, dtype=dtype, shape=shape, verify_shape=verify_shape)) File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 521, in make_tensor_proto(values, dtype, shape, verify_shape) ""supported type."" % (type(values), values)) TypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [Dimension(None), Dimension(64), Dimension(8)]. Consider casting elements to a supported type.",0
"File [FILE], line 87, in <module>() initial_epoch=initial_epoch) File <*>python36/site-packages/keras/legacy/interfaces.py, line 87, in wrapper(*args, **kwargs) return func(*args, **kwargs) File <*>python36/site-packages/keras/engine/training.py, line 2042, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) class_weight=class_weight) File <*>python36/site-packages/keras/engine/training.py, line 1756, in train_on_batch(self, x, y, sample_weight, class_weight) check_batch_axis=True) File <*>python36/site-packages/keras/engine/training.py, line 1378, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size) exception_prefix='input') File <*>python36/site-packages/keras/engine/training.py, line 58, in _standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) 'expected no data, but got:', data) ValueError: ('Error when checking model input: expected no data, but got:', [array([[[[1.62046947e+01, 0.00000000e+00, 0.00000000e+00, ...",0
"File [FILE], line 3, in <module>() plt.imshow(grid) File <*>python3.6/site-packages/matplotlib/pyplot.py, line 3205, in imshow(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs) **kwargs) File <*>python3.6/site-packages/matplotlib/__init__.py, line 1855, in inner(ax, *args, **kwargs) return func(ax, *args, **kwargs) File <*>python3.6/site-packages/matplotlib/axes/_axes.py, line 5487, in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs) im.set_data(X) File <*>python3.6/site-packages/matplotlib/image.py, line 653, in set_data(self, A) raise TypeError(""Invalid dimensions for image data"") TypeError: Invalid dimensions for image data",0
"File [FILE], line 2, in <module>() grid = torchvision.utils.make_grid(w.permute(0,2,3,1), nrow=5) File <*>python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/utils.py, line 85, in make_grid(tensor, nrow, padding, normalize, range, scale_each, pad_value) .copy_(tensor[k]) RuntimeError: The expanded size of the tensor (3) must match the existing size (640) at non-singleton dimension 0",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1330, in _do_call(self, fn, *args) return fn(*args) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1315, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1423, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) status, run_metadata) File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status)) FailedPreconditionError: Attempting to use uninitialized value W_4 [[Node: W_4/read = Identity[T=DT_FLOAT, _class=[""loc:@W_4""], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](W_4)]]",0
"File [FILE], line 4, in <module>() model = torch.load('checkpoint.pth') File <*>python3.6/site-packages/torch/serialization.py, line 303, in load(f, map_location, pickle_module) return _load(f, map_location, pickle_module) File <*>python3.6/site-packages/torch/serialization.py, line 469, in _load(f, map_location, pickle_module) result = unpickler.load() AttributeError: Can't get attribute 'Network' on <module '__main__'>",0
"File [FILE], line 48, in <module>() labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size) File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1349, in sampled_softmax_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name, seed) seed=seed) File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1128, in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed) true_logits -= math_ops.log(true_expected_count) File <*>python3.6/dist-packages/tensorflow/python/ops/math_ops.py, line 862, in binary_op_wrapper(x, y) return func(x, y, name=name) File <*>python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 8318, in sub(x, y, name) ""Sub"", x=x, y=y, name=name) File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 546, in _apply_op_helper(self, op_type_name, name, **keywords) inferred_from[input_arg.type_attr])) TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type float16 of argument 'x'.",0
"File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1334, in _do_call(self, fn, *args) return fn(*args) File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1319, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata) File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1407, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata) UnimplementedError: File system scheme '[local]' not implemented (file: 'checkpointsBook2Vec5Inputs') [[{{node save/SaveV2}} = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, embeddings, embeddings/Shampoo, embeddings/Shampoo_1, embeddings/Shampoo_2, epochCount, softmax_biases, softmax_weights, softmax_weights/Shampoo, softmax_weights/Shampoo_1, softmax_weights/Shampoo_2)]]",0
"File [FILE], line 50, in <module>() save_path = saver.save(session, ""checkpointsBook2Vec5Inputs/Research2VecCS4.ckpt"") #Save checkpoint File <*>python3.6/dist-packages/tensorflow/python/training/saver.py, line 1441, in save(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs) {self.saver_def.filename_tensor_name: checkpoint_file}) File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 929, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr) File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1152, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata) File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1328, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata) File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1348, in _do_call(self, fn, *args) raise type(e)(node_def, op, message) UnimplementedError: File system scheme '[local]' not implemented (file: 'checkpointsBook2Vec5Inputs') [[node save/SaveV2 (defined at <ipython-input-15-c14caac2081d>:45) = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, embeddings, embeddings/Shampoo, embeddings/Shampoo_1, embeddings/Shampoo_2, epochCount, softmax_biases, softmax_weights, softmax_weights/Shampoo, softmax_weights/Shampoo_1, softmax_weights/Shampoo_2)]]",0
"File [FILE], line 3, in <module>() steps=10) File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 354, in train(self, input_fn, hooks, steps, max_steps, saving_listeners) loss = self._train_model(input_fn, hooks, saving_listeners) File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1207, in _train_model(self, input_fn, hooks, saving_listeners) return self._train_model_default(input_fn, hooks, saving_listeners) File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1237, in _train_model_default(self, input_fn, hooks, saving_listeners) features, labels, model_fn_lib.ModeKeys.TRAIN, self.config) File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1195, in _call_model_fn(self, features, labels, mode, config) model_fn_results = self._model_fn(features=features, **kwargs) File [FILE], line 35, in my_model(features, labels, mode, params) num_classes=vocabulary_size)) File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1248, in nce_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name) name=name) File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1031, in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed) if labels.dtype != dtypes.int64: TypeError: data type not understood",0
"File [FILE], line 8, in <module>() concat = tf.keras.layers.Concatenate()((features['a'], features['b'])) File <*>/base_layer.py, line 753, in __call__(self, inputs, *args, **kwargs) self.build(input_shapes) File <*>/tf_utils.py, line 150, in wrapper(instance, input_shape) input_shape = tuple(tensor_shape.TensorShape(input_shape).as_list()) File <*>/tensor_shape.py, line 690, in __init__(self, dims) self._dims = [as_dimension(d) for d in dims_iter] File <*>/tensor_shape.py, line 632, in as_dimension(value) return Dimension(value) File <*>/tensor_shape.py, line 185, in __init__(self, value) self._value = int(value) TypeError: int() argument must be a string or a number, not 'TensorShapeV1'",0
"File [FILE], line 3, in <module>() epochs = range(epochs) NameError: name 'epochs' is not defined",0
"File [FILE], line 16, in <module>() dataset = dataset.padded_batch(2, padded_shapes=([None],[None]), padding_values=-1) File <*>python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py, line 945, in padded_batch(self, batch_size, padded_shapes, padding_values, drop_remainder) drop_remainder) File <*>python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py, line 2528, in __init__(self, input_dataset, batch_size, padded_shapes, padding_values, drop_remainder) input_dataset.output_types) File <*>python3.6/dist-packages/tensorflow/python/data/util/nest.py, line 467, in map_structure_up_to(shallow_tree, func, *inputs) assert_shallow_structure(shallow_tree, input_tree) File <*>python3.6/dist-packages/tensorflow/python/data/util/nest.py, line 301, in assert_shallow_structure(shallow_tree, input_tree, check_types) ""Input has type: %s."" % type(input_tree)) TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'int'>.",0
"File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 511, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype) File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1175, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 304, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 245, in constant(value, dtype, shape, name) allow_broadcast=True) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast)) File <*>python3.7/site-packages/tensorflow/python/framework/tensor_util.py, line 454, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) raise ValueError(""None values not supported."") ValueError: None values not supported.",0
"File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 525, in _apply_op_helper(self, op_type_name, name, **keywords) values, as_ref=input_arg.is_ref).dtype.name File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1175, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 304, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 245, in constant(value, dtype, shape, name) allow_broadcast=True) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast)) File <*>python3.7/site-packages/tensorflow/python/framework/tensor_util.py, line 454, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) raise ValueError(""None values not supported."") ValueError: None values not supported.",0
"File [FILE], line 5, in <module> hessian = tf.hessians(f, xy) File <*>python3.7/site-packages/tensorflow/python/ops/gradients_impl.py, line 1407, in hessians(ys, xs, name, colocate_gradients_with_ops, gate_gradients, aggregation_method) gradient = array_ops.reshape(gradient, [-1]) File <*>python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py, line 7180, in reshape(tensor, shape, name) ""Reshape"", tensor=tensor, shape=shape, name=name) File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 529, in _apply_op_helper(self, op_type_name, name, **keywords) (input_name, err)) ValueError: Tried to convert 'tensor' to a tensor and failed. Error: None values not supported.",0
"File [FILE], line 1, in () output = model(data) File <*>python3.6/dist-packages/torch/nn/modules/module.py, line [NUM], in call(self, *input, **kwargs) [CODE] File <*>python3.6/dist-packages/torch/nn/functional.py, line 1354, in linear(input, weight, bias) output = input.matmul(weight.t()) RuntimeError: size mismatch, m1: [3584 x 28], m2: [784 x 128] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:940",0
"File [FILE], line 14, in <module>() random_search.fit(X_train, y_train) File <*>python3.6/site-packages/sklearn/model_selection/_search.py, line 677, in fit(self, X, y, groups, **fit_params) base_estimator = clone(self.estimator) File <*>python3.6/site-packages/sklearn/base.py, line 58, in clone(estimator, safe) % (repr(estimator), type(estimator))) TypeError: Cannot clone object '<keras.engine.sequential.Sequential object at 0x7fc268d8abe0>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods.",0
"File [FILE], line 1, in <module> modl(x) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 477, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File [FILE], line 223, in forward(self, x) de2 = torch.cat([en6add,de2_],1) RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 5 and 4 in dimension 2 at /opt/conda/conda-bld/pytorch_1535491974311/work/aten/src/TH/generic/THTensorMath.cpp:3616",0
"File [FILE], line 1, in <module>() tf.enable_eager_execution() AttributeError: module 'tensorflow' has no attribute 'enable_eager_execution'",0
"File [FILE], line 1, in <module>() create_record() File [FILE], line 17, in create_record() ""mfcc"":tf.train.Feature(float_list=tf.train.FloatList(value=mfcc.tolist())) TypeError: [-389.381029172618, -393.08814551655723, -404.7248725876356, -407.1006984237564, -409.22695909850626 has type list, but expected one of: int, long, float",0
"File [FILE], line 6, in <module>() print(char_OneHotEncoding(torch.tensor(x_train, dtype=torch.long).cuda()).shape) File [FILE], line 4, in char_OneHotEncoding(x) coded[:,i] = scatter(x[:,i]) File [FILE], line 9, in scatter(x) return torch.zeros(x.shape[0], 101).scatter_(1, x.view(-1,1), 1) RuntimeError: Expected object of backend CPU but got backend CUDA for argument #3 'index'",0
"File [FILE], line 51, in <module> model.fit([x_img_train, x_transform_train], y_train, batch_size=8) File <*>python3.6/site-packages/keras/engine/training.py, line 1039, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs) validation_steps=validation_steps) File <*>python3.6/site-packages/keras/engine/training_arrays.py, line 199, in fit_loop(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps) outs = f(ins_batch) File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 2715, in __call__(self, inputs) return self._call(inputs) File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 2675, in _call(self, inputs) fetched = self._callable_fn(*array_vals) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1439, in __call__(self, *args, **kwargs) run_metadata_ptr) File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status)) InvalidArgumentError: Incompatible shapes: [8,28,28,32] vs. [8,32] [[{{node training_5/Adam/gradients/affine_transform_18/mul_grad/BroadcastGradientArgs}} = BroadcastGradientArgs[T=DT_INT32, _class=[""loc:@training_5/Adam/gradients/batch_normalization_22/cond/Merge_grad/cond_grad""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](training_5/Adam/gradients/affine_transform_18/mul_grad/Shape, training_5/Adam/gradients/affine_transform_18/mul_grad/Shape_1)]]",0
"File [FILE], line 1, in <module> model.fit(dataset, epochs=10, steps_per_epoch=10) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 791, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1515, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch') File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 257, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) batch_outs = batch_function(*batch_data) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1238, in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics) extract_tensors_from_dataset=True) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 2596, in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset) exception_prefix='input') File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 349, in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) str(data_shape)) ValueError: Error when checking input: expected input_1 to have shape (32,) but got array with shape (1,)",0
"File [FILE], line 32, in <module> loss = loss_func(output, b_y) File <*>python3.5/site-packages/torch/nn/modules/module.py, line 489, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.5/site-packages/torch/nn/modules/loss.py, line 504, in forward(self, input, target) return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction) File <*>python3.5/site-packages/torch/nn/functional.py, line 2027, in binary_cross_entropy(input, target, weight, size_average, reduce, reduction) input, target, weight, reduction_enum) RuntimeError: Expected object of scalar type Float but got scalar type Long for argument #2 'target'",0
"File [FILE], line 23, in <module>() print(model(torch.tensor(X)).size) File [FILE], line 14, in forward(self, x) x = self.layer1(x) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 489, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.6/site-packages/torch/nn/modules/conv.py, line 187, in forward(self, input) self.padding, self.dilation, self.groups) RuntimeError: Expected 3-dimensional input for 3-dimensional weight [20, 7, 5], but got 2-dimensional input of size [10, 7] instead",0
"File <*>python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py, line 612, in __call__(self, inputs, *args, **kwargs) outputs = self.call(inputs, *args, **kwargs) File [FILE], line 8, in call(self, data_input) model = self.input_layer(data_input) File <*>python3.6/site-packages/tensorflow/python/keras/engine/input_layer.py, line 233, in Input(shape, batch_size, name, dtype, sparse, tensor, **kwargs) input_tensor=tensor) File <*>python3.6/site-packages/tensorflow/python/keras/engine/input_layer.py, line 94, in __init__(self, input_shape, batch_size, dtype, input_tensor, sparse, name, **kwargs) batch_input_shape = (batch_size,) + tuple(input_shape) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 449, in __iter__(self) ""Tensor objects are only iterable when eager execution is "" TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.",0
"File [FILE], line 5, in <module>() train_step(x_sample=x_point, y_sample=y_point) File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 418, in __call__(self, *args, **kwds) results = self._stateful_fn(*args, **kwds) File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1287, in __call__(self, *args, **kwargs) graph_function, args, kwargs = self._maybe_define_function(args, kwargs) File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1611, in _maybe_define_function(self, args, kwargs) args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes) File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1512, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value), File <*>python3.6/site-packages/tensorflow/python/framework/func_graph.py, line 694, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs) File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 317, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds) File <*>python3.6/site-packages/tensorflow/python/framework/func_graph.py, line 686, in wrapper(*args, **kwargs) ), args, kwargs) File <*>python3.6/site-packages/tensorflow/python/autograph/impl/api.py, line 392, in converted_call(f, owner, options, args, kwargs) result = converted_f(*effective_args, **kwargs) File <*>/tmpluzodr7d.py, line 4, in tf__train_step(x_sample, y_sample) predictions = ag__.converted_call(nn_regressor, None, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (x_sample,), {}) File <*>python3.6/site-packages/tensorflow/python/autograph/impl/api.py, line 267, in converted_call(f, owner, options, args, kwargs) return _call_unconverted(f, args, kwargs) File <*>python3.6/site-packages/tensorflow/python/autograph/impl/api.py, line 188, in _call_unconverted(f, args, kwargs) return f(*args, **kwargs) File <*>python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py, line 625, in __call__(self, inputs, *args, **kwargs) exception_str + '\n""""""') TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.",0
"File [FILE], line 72, in <module>() validate=True, resume=False, flow=True, use_cuda=cuda) File <*>/train_helper.py, line 109, in train(model, num_epochs, train_set, dev_set, lr, batch_size, start_epoch, log, checkpoint_path, validate, resume, flow, use_cuda) loss = criterion(outputs, labels) File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 489, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.6/dist-packages/torch/nn/modules/loss.py, line 904, in forward(self, input, target) ignore_index=self.ignore_index, reduction=self.reduction) File <*>python3.6/dist-packages/torch/nn/functional.py, line 1970, in cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction) return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction) File <*>python3.6/dist-packages/torch/nn/functional.py, line 1790, in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction) ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index) RuntimeError: Expected object of scalar type Long but got scalar type Byte for argument #2 'target'",0
"File [FILE], line 3, in <module> act([a,b]) File <*>python36/site-packages/keras/engine/base_layer.py, line 431, in __call__(self, inputs, **kwargs) self.build(unpack_singleton(input_shapes)) TypeError: build() takes 1 positional argument but 2 were given",0
"File [FILE], line 17, in <module>() d1, d2 = sess.run((d_fx1, d_fx2)) File <*>/site-packages/tensorflow/python/client/session.py, line 929, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr) File <*>/site-packages/tensorflow/python/client/session.py, line 1137, in _run(self, handle, fetches, feed_dict, options, run_metadata) self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles) File <*>/site-packages/tensorflow/python/client/session.py, line 471, in __init__(self, graph, fetches, feeds, feed_handles) self._fetch_mapper = _FetchMapper.for_fetch(fetches) File <*>/site-packages/tensorflow/python/client/session.py, line 261, in for_fetch(fetch) return _ListFetchMapper(fetch) File <*>/site-packages/tensorflow/python/client/session.py, line 370, in __init__(self, fetches) self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches] File <*>/site-packages/tensorflow/python/client/session.py, line 370, in <listcomp>(.0) self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches] File <*>/site-packages/tensorflow/python/client/session.py, line 258, in for_fetch(fetch) type(fetch))) TypeError: Fetch argument None has invalid type <class 'NoneType'>",0
"File [FILE], line 27, in <module>() grads = sess.run(d_fx) File <*>/site-packages/tensorflow/python/client/session.py, line 929, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr) File <*>/site-packages/tensorflow/python/client/session.py, line 1137, in _run(self, handle, fetches, feed_dict, options, run_metadata) self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles) File <*>/site-packages/tensorflow/python/client/session.py, line 471, in __init__(self, graph, fetches, feeds, feed_handles) self._fetch_mapper = _FetchMapper.for_fetch(fetches) File <*>/site-packages/tensorflow/python/client/session.py, line 258, in for_fetch(fetch) type(fetch))) TypeError: Fetch argument None has invalid type <class 'NoneType'>",0
"File [FILE], line [NUM], in <module> [CODE] File <*>python3.7/site-packages/keras/engine/training.py, line 952, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs) batch_size=batch_size) File <*>python3.7/site-packages/keras/engine/training.py, line 677, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size) self._set_inputs(x) File <*>python3.7/site-packages/keras/engine/training.py, line 589, in _set_inputs(self, inputs, outputs, training) self.build(input_shape=(None,) + inputs.shape[1:]) File <*>python3.7/site-packages/keras/engine/sequential.py, line 221, in build(self, input_shape) x = layer(x) File <*>python3.7/site-packages/keras/engine/base_layer.py, line 457, in __call__(self, inputs, **kwargs) output = self.call(inputs, **kwargs) File <*>python3.7/site-packages/keras/layers/core.py, line 126, in call(self, inputs, training) training=training) File <*>python3.7/site-packages/keras/backend/tensorflow_backend.py, line 3105, in in_train_phase(x, alt, training) training = learning_phase() File <*>python3.7/site-packages/keras/backend/tensorflow_backend.py, line 135, in learning_phase() name='keras_learning_phase') File <*>python3.7/site-packages/tensorflow/python/ops/array_ops.py, line 2093, in placeholder_with_default(input, shape, name) return gen_array_ops.placeholder_with_default(input, shape, name) File <*>python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py, line 5925, in placeholder_with_default(input, shape, name) ""PlaceholderWithDefault"", input=input, shape=shape, name=name) File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 511, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype) File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1175, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 304, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 245, in constant(value, dtype, shape, name) allow_broadcast=True) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast)) File <*>python3.7/site-packages/tensorflow/python/framework/tensor_util.py, line 573, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) append_fn(tensor_proto, proto_values) File <*>/fast_tensor_util.pyxintensorflow.python, line [NUM], in tensorflow.python.framework.fast_tensor_util.AppendBoolArrayToTensorProto() [CODE] File <*>python3.7/site-packages/numpy/lib/type_check.py, line 547, in asscalar(***failed resolving arguments***) return a.item() UnboundLocalError: local variable 'a' referenced before assignment",0
"File [FILE], line 11, in <module>() model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc']) File <*>python3.6/dist-packages/tensorflow/python/training/checkpointable/base.py, line 442, in _method_wrapper(self, *args, **kwargs) method(self, *args, **kwargs) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 449, in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs) output_loss = weighted_loss(y_true, y_pred, sample_weight, mask) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py, line 676, in weighted(y_true, y_pred, weights, mask) score_array = math_ops.div_no_nan(score_array, weights) File <*>python3.6/dist-packages/tensorflow/python/util/dispatch.py, line 180, in wrapper(*args, **kwargs) return target(*args, **kwargs) File <*>python3.6/dist-packages/tensorflow/python/ops/math_ops.py, line 1027, in div_no_nan(x, y, name) return gen_math_ops.div_no_nan(x, y, name=name) File <*>python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 3022, in div_no_nan(x, y, name) ""DivNoNan"", x=x, y=y, name=name) File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 610, in _apply_op_helper(self, op_type_name, name, **keywords) param_name=input_name) File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 60, in _SatisfiesTypeConstraint(dtype, attr_def, param_name) "", "".join(dtypes.as_dtype(x).name for x in allowed_list))) TypeError: Value passed to parameter 'x' has DataType float16 not in list of allowed values: float32, float64",0
"File [FILE], line 9, in <module>() for i in train_iter: File <*>python3.6/site-packages/torchtext/data/iterator.py, line 157, in __iter__(self) yield Batch(minibatch, self.dataset, self.device) File <*>python3.6/site-packages/torchtext/data/batch.py, line 34, in __init__(self, data, dataset, device) setattr(self, name, field.process(batch, device=device)) File <*>python3.6/site-packages/torchtext/data/field.py, line 201, in process(self, batch, device) tensor = self.numericalize(padded, device=device) File <*>python3.6/site-packages/torchtext/data/field.py, line 302, in numericalize(self, arr, device) arr = [self.vocab.stoi[x] for x in arr] File <*>python3.6/site-packages/torchtext/data/field.py, line 302, in <listcomp>(.0) arr = [self.vocab.stoi[x] for x in arr] AttributeError: 'Field' object has no attribute 'vocab'",0
"File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1659, in _create_c_op(graph, node_def, inputs, control_inputs) c_op = c_api.TF_FinishOperation(op_desc) InvalidArgumentError: Dimensions must be equal, but are 1 and 64 for 'loss_1/zero_padding2d_5_loss/MatMul' (op: 'BatchMatMul') with input shapes: [?,64,64,1], [1,64,64,?].",0
"File [FILE], line 42, in <module> autoencoder.compile(optimizer='adadelta', loss=[custom_loss1,custom_loss2]) File <*>python3.6/site-packages/keras/engine/training.py, line 342, in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs) sample_weight, mask) File <*>python3.6/site-packages/keras/engine/training_utils.py, line 404, in weighted(y_true, y_pred, weights, mask) score_array = fn(y_true, y_pred) File [FILE], line 4, in custom_loss1(y_true, y_pred) dcor = -1*distance_correlation(y_true,encoded_layer) File [FILE], line 4, in distance_correlation(y_true, y_pred) pred_d = pred_r - 2*tf.matmul(y_pred,tf.transpose(y_pred))+tf.transpose(pred_r) File <*>python3.6/site-packages/tensorflow/python/ops/math_ops.py, line 2417, in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name) a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name) File <*>python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py, line 1423, in batch_mat_mul(x, y, adj_x, adj_y, name) ""BatchMatMul"", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name) File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 788, in _apply_op_helper(self, op_type_name, name, **keywords) op_def=op_def) File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func(*args, **kwargs) return func(*args, **kwargs) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3300, in create_op(***failed resolving arguments***) op_def=op_def) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1823, in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def) control_input_ops) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1662, in _create_c_op(graph, node_def, inputs, control_inputs) raise ValueError(str(e)) ValueError: Dimensions must be equal, but are 1 and 64 for 'loss_1/zero_padding2d_5_loss/MatMul' (op: 'BatchMatMul') with input shapes: [?,64,64,1], [1,64,64,?].",0
"File [FILE], line 4, in <module> steps=20) File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1185, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors) raise RuntimeError(""Attempting to capture an EagerTensor without "" RuntimeError: Attempting to capture an EagerTensor without building a function.",0
"File [FILE], line 3, in <module> train(n_epochs,net,loaders,optimizer,criterion,'saved_model/dog_model.pt') File [FILE], line 24, in train(n_epochs, model, loader, optimizer, criterion, save_path) loss = criterion(outputs,target) RuntimeError: The size of tensor a (133) must match the size of tensor b (10) at non-singleton dimension 1.",0
"File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 1969, in __setattr__(self, name, value) super(tracking.AutoTrackable, self).__setattr__(name, value) AttributeError: can't set attribute",0
"File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 1974, in __setattr__(self, name, value) 'different name.').format(name)) AttributeError: Can't set the attribute ""name"", likely because it conflicts with an existing read-only @property of the object. Please choose a different name.",0
"File [FILE], line 1, in <module> import tensorflow_probability as tfp ModuleNotFoundError: No module named 'tensorflow_probability'.",0
"File [FILE], line 1, in <module> train_image_ds = train_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE) File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1146, in map(self, map_func, num_parallel_calls) self, map_func, num_parallel_calls, preserve_cardinality=True) File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 3264, in __init__(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function) use_legacy_function=use_legacy_function) File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 2591, in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs) self._function = wrapper_fn._get_concrete_function_internal() File <*>/site-packages/tensorflow/python/eager/function.py, line 1366, in _get_concrete_function_internal(self, *args, **kwargs) *args, **kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 1360, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 1648, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 1541, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value), File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 716, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs) File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 2585, in wrapper_fn(*args) ret = _wrapper_helper(*args) File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 2530, in _wrapper_helper(*args) ret = func(*nested_args) File [FILE], line 3, in load_and_preprocess_image(path) return preprocess_image(image) File [FILE], line 13, in preprocess_image(image) image = tf.image.central_crop(image, hor_scale_factor) File <*>/site-packages/tensorflow/python/ops/image_ops_impl.py, line 643, in central_crop(image, central_fraction) if central_fraction <= 0.0 or central_fraction > 1.0: File <*>/site-packages/tensorflow/python/framework/ops.py, line 698, in __bool__(self) raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. "" TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",0
"File [FILE], line 35, in <module>() output = model(data) File <*>python3.6/dist-packages/torch/nn/modules/conv.py, line 338, in forward(self, input) self.padding, self.dilation, self.groups) RuntimeError: Expected 4-dimensional input for 4-dimensional weight 32 3 3, but got 3-dimensional input of size [3, 224, 224] instead",0
"File [FILE], line 17, in <module>() opt.minimize(lambda: loss_function(intercept,slope,price_batch,size_batch),var_list=[intercept,slope]) File <*>python3.6/dist-packages/tensorflow/python/eager/tape.py, line 59, in watch(tape, tensor) pywrap_tensorflow.TFE_Py_TapeWatch(tape._tape, tensor) # pylint: disable=protected-access SystemError: <built-in function TFE_Py_TapeWatch> returned a result with an error set",0
"File [FILE], line 1, in <module>() process_image('IMG_PATH') File [FILE], line 5, in process_image(img_path) pImg = MobileNetV2.preprocess_input(img_array) AttributeError: 'function' object has no attribute 'preprocess_input'",0
"File [FILE], line 23, in <module> optimizer = nlp.resume_training() TypeError: Model() got multiple values for argument 'nr_class'",0
"File [FILE], line 29, in <module> global_loss_list = global_training(lstm2) File [FILE], line 5, in global_training(optimizee) _, global_loss_1 = learn2(LSTM_Optimizee, training_steps, retain_graph_flag=True, reset_theta=True) File [FILE], line 45, in learn2(optimizee, unroll_train_steps, retain_graph_flag, reset_theta) loss.backward(retain_graph = retain_graph_flag) #The default is False, when the optimized LSTM is set to True File <*>python3.7/site-packages/torch/tensor.py, line 118, in backward(self, gradient, retain_graph, create_graph) torch.autograd.backward(self, gradient, retain_graph, create_graph) File <*>python3.7/site-packages/torch/autograd/__init__.py, line 93, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables) allow_unreachable=True) # allow_unreachable flag RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 10]] is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",0
"File [FILE], line 2, in <module> x.forward(torch.tensor([0,2,5,8]), higgs_bosson=2) TypeError: forward() got an unexpected keyword argument 'higgs_bosson'",0
"File [FILE], line [NUM], in <module> [CODE] File <*>python3.6/site-packages/keras/engine/saving.py, line 458, in load_wrapper(*args, **kwargs) return load_function(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/saving.py, line 550, in load_model(filepath, custom_objects, compile) model = _deserialize_model(h5dict, custom_objects, compile) File <*>python3.6/site-packages/keras/engine/saving.py, line 292, in _deserialize_model(h5dict, custom_objects, compile) reshape=False) File <*>python3.6/site-packages/keras/engine/saving.py, line 811, in convert_nested_model(weights) original_backend=original_backend)) File <*>python3.6/site-packages/keras/engine/saving.py, line 823, in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape) weights = convert_nested_model(weights) File <*>python3.6/site-packages/keras/engine/saving.py, line 799, in convert_nested_model(weights) original_backend=original_backend)) File <*>python3.6/site-packages/keras/engine/saving.py, line 942, in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape) weights[0] = np.transpose(weights[0], (3, 2, 0, 1)) File <*>python3.6/site-packages/numpy/core/fromnumeric.py, line 639, in transpose(a, axes) return _wrapfunc(a, 'transpose', axes) File <*>python3.6/site-packages/numpy/core/fromnumeric.py, line 56, in _wrapfunc(obj, method, *args, **kwds) return getattr(obj, method)(*args, **kwds) ValueError: axes don't match array",0
"File <*>python3.6/site-packages/keras/engine/topology.py, line 425, in assert_input_compatibility(self, inputs) K.is_keras_tensor(x) File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 400, in is_keras_tensor(x) raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. ' ValueError: Unexpectedly found an instance of type `<class 'keras.layers.normalization.BatchNormalization'>`. Expected a symbolic tensor instance.",0
"File [FILE], line 7, in <module>() A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a') File [FILE], line 45, in identity_block(X, f, filters, stage, block) X = Add()([X_shortcut,X]) File <*>python3.6/site-packages/keras/engine/topology.py, line 558, in __call__(self, inputs, **kwargs) self.assert_input_compatibility(inputs) File <*>python3.6/site-packages/keras/engine/topology.py, line 431, in assert_input_compatibility(self, inputs) str(inputs) + '. All inputs to the layer ' ValueError: Layer add_1 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.normalization.BatchNormalization'>. Full input: [<tf.Tensor 'Placeholder:0' shape=(3, 4, 4, 6) dtype=float32>, <keras.layers.normalization.BatchNormalization object at 0x7f169c6d9668>]. All inputs to the layer should be tensors.",0
"File [FILE], line 8, in <module> train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](root='./.data', ngrams=NGRAMS, vocab=None) File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 170, in AG_NEWS(*args, **kwargs) return _setup_datasets(*((""AG_NEWS"",) + args), **kwargs) File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 128, in _setup_datasets(dataset_name, root, ngrams, vocab, include_unk) vocab = build_vocab_from_iterator(_csv_iterator(train_csv_path, ngrams)) File <*>python36/site-packages/torchtext/vocab.py, line 557, in build_vocab_from_iterator(iterator) for tokens in iterator: File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 35, in _csv_iterator(data_path, ngrams, yield_cls) for row in reader: File <*>python36/site-packages/torchtext/utils.py, line 130, in unicode_csv_reader(unicode_csv_data, **kwargs) csv.field_size_limit(sys.maxsize) OverflowError: Python int too large to convert to C long",0
"File [FILE], line 1, in <module> import acgan File <*>/acgan.py, line 3, in <module> from keras.datasets import mnist File <*>python3.6/site-packages/keras/__init__.py, line 3, in <module> from . import utils File <*>python3.6/site-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils File <*>python3.6/site-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K File <*>python3.6/site-packages/keras/backend/__init__.py, line 1, in <module> from .load_backend import epsilon File <*>python3.6/site-packages/keras/backend/load_backend.py, line 90, in <module> from .tensorflow_backend import * File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 54, in <module> get_graph = tf_keras_backend.get_graph File [FILE], line [NUM], in [FUNC] [CODE] AttributeError: module 'tensorflow.python.keras.backend' has no attribute 'get_graph'",0
"File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1356, in _do_call(self, fn, *args) return fn(*args) File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1339, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) self._extend_graph() File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1374, in _extend_graph(self) tf_session.ExtendSession(self._session) InvalidArgumentError: Cannot assign a device for operation MatMul: {{node MatMul}}was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.",0
"File <*>python3.6/dist-packages/pandas/core/indexes/base.py, line 2657, in get_loc(self, key, method, tolerance) return self._engine.get_loc(key) File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE] File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE] KeyError: 'filename'",0
"File [FILE], line 20, in <module> subset='training') File <*>python3.6/dist-packages/keras/preprocessing/image.py, line 594, in flow_from_dataframe(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs) **kwargs File <*>python3.6/dist-packages/keras/preprocessing/image.py, line 235, in __init__(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames) validate_filenames=validate_filenames) File <*>python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py, line 129, in __init__(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames) self._check_params(df, x_col, y_col, weight_col, classes) File <*>python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py, line 181, in _check_params(self, df, x_col, y_col, weight_col, classes) if not all(df[x_col].apply(lambda x: isinstance(x, str))): File <*>python3.6/dist-packages/pandas/core/frame.py, line 2927, in __getitem__(self, key) indexer = self.columns.get_loc(key) File <*>python3.6/dist-packages/pandas/core/indexes/base.py, line 2659, in get_loc(self, key, method, tolerance) return self._engine.get_loc(self._maybe_cast_indexer(key)) File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE] File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE] KeyError: 'filename'",0
"File [FILE], line 4, in <module>() feature_extractor = hub.KerasLayer(_URL, input_shape=(_TARGET_SIZE, _TARGET_SIZE,3)) File <*>python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py, line 167, in _variable_handle_from_shape_and_dtype(shape, dtype, shared_name, name, graph_mode, initial_value) handle_data.shape_and_type.append( AttributeError: 'google.protobuf.pyext._message.RepeatedCompositeCo' object has no attribute 'append'",0
"File [FILE], line 28, in <module> loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) TypeError: forward() got an unexpected keyword argument 'labels'",0
"File [FILE], line 1, in <module> for batch_idx, (data, _) in enumerate(trainDL): File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 346, in __next__(self) data = self._dataset_fetcher.fetch(index) # may raise StopIteration File <*>python3.6/site-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch(self, possibly_batched_index) data = [self.dataset[idx] for idx in possibly_batched_index] File <*>python3.6/site-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp>(.0) data = [self.dataset[idx] for idx in possibly_batched_index] File <*>python3.6/site-packages/pandas/core/frame.py, line 2995, in __getitem__(self, key) indexer = self.columns.get_loc(key) File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 2899, in get_loc(self, key, method, tolerance) return self._engine.get_loc(self._maybe_cast_indexer(key)) File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE] File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE] KeyError: 40592",0
"File [FILE], line 1, in <module> loaded_model.summary() AttributeError: 'NoneType' object has no attribute 'summary'",0
"File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 2, in [FUNC] from tensorboard.summary.writer.record_writer import RecordWriter # noqa F401 ModuleNotFoundError: No module named 'tensorboard.summary'; 'tensorboard' is not a package",0
"File <*>/tensorboard.py, line 1, in [FUNC] from torch.utils.tensorboard import SummaryWriter File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 4, in [FUNC] raise ImportError('TensorBoard logging requires TensorBoard with Python summary writer installed. ' ImportError: TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above.",0
"File [FILE], line 4, in <module>() pred = model(x) File <*>python3.6/sequential.py, line 256, in call(self, inputs, training, mask) return super(Sequential, self).call(inputs, training=training, mask=mask) File <*>python3.6/network.py, line 708, in call(self, inputs, training, mask) convert_kwargs_to_constants=base_layer_utils.call_context().saving) File <*>python3.6/network.py, line 860, in _run_internal_graph(self, inputs, training, mask, convert_kwargs_to_constants) output_tensors = layer(computed_tensors, **kwargs) File <*>python3.6/wrappers.py, line 528, in __call__(self, inputs, initial_state, constants, **kwargs) return super(Bidirectional, self).__call__(inputs, **kwargs) File <*>python3.6/base_layer.py, line 891, in __call__(self, inputs, *args, **kwargs) outputs = self.call(cast_inputs, *args, **kwargs) File <*>python3.6/wrappers.py, line 642, in call(self, inputs, training, mask, initial_state, constants) initial_state=forward_state, **kwargs) File <*>python3.6/recurrent.py, line 623, in __call__(self, inputs, initial_state, constants, **kwargs) return super(RNN, self).__call__(inputs, **kwargs) File <*>python3.6/recurrent_v2.py, line 961, in call(self, inputs, mask, training, initial_state) **cudnn_lstm_kwargs) File <*>python3.6/recurrent_v2.py, line 1174, in cudnn_lstm(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards) rnn_mode='lstm') File <*>python3.6/gen_cudnn_rnn_ops.py, line 109, in cudnn_rnn(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name) ctx=_ctx) File <*>python3.6/gen_cudnn_rnn_ops.py, line 198, in cudnn_rnn_eager_fallback(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx) attrs=_attrs, ctx=_ctx, name=name) File <*>python3.6/execute.py, line 67, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) six.raise_from(core._status_to_exception(e.code, message), None) File <*>python3.6/dist-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE] InvalidArgumentError: Invalid input_h shape: [1,64,1024] [1,54,1024] [Op:CudnnRNN]",0
"File [FILE], line 9, in <module>() train(test_net, train_loader, 10, batch_size, optimiser, clip, criterion) File [FILE], line 59, in train(SNN, dataloader, epochs, batch_size, optimiser, clip, criterion) loss = criterion(output1, output2, labels) File [FILE], line 51, in forward(self, output1, output2, labels) pred, loss = estimate_loss(self.d) File [FILE], line 45, in estimate_loss(forward) distance = dimensional_reduction(self.d) File [FILE], line 38, in dimensional_reduction(forward) self.d = self.linear(self.d) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.6/site-packages/torch/nn/modules/linear.py, line 87, in forward(self, input) return F.linear(input, self.weight, self.bias) File <*>python3.6/site-packages/torch/nn/functional.py, line 1370, in linear(input, weight, bias) ret = torch.addmm(bias, input, weight.t()) RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_addmm",0
"File [FILE], line 1001, in <module>() train_step(group, inp, tar, label) File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializer_map) File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize(self, args, kwds, add_initializers_to) *args, **kwds)) File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs) File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs) File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value), File <*>python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs) File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds) File <*>python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py, line 905, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e) ValueError: in converted code: <ipython-input-1-81054f0385cb>:856 train_step * optimizer.apply_gradients(zip(gradients, transformer.trainable_variables)) /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:427 apply_gradients grads_and_vars = _filter_grads(grads_and_vars) /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:1025 _filter_grads ([v.name for _, v in grads_and_vars],)) ValueError: No gradients provided for any variable: ['transformer_1/encoder_1/embedding_2/embeddings:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_98/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_98/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_99/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_99/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_100/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_100/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_101/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_101/bias:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_102/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_102/bias:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_103/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_103/bias:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_30/gamma:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_30/beta:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_31/gamma:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_31/beta:0', 'transformer_1/encoder_1/encoder_layer_7/multi_head_attention_19/dense_104/kernel:0', 'transformer_1/encoder_1/encoder...",0
"File [FILE], line 10, in <module>() scan_object = ta.Scan(x_train, y_train, params=p, model=iris_model, experiment_name='test', x_val=x_val, y_val=y_val, fraction_limit=0.1) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 1815, in _validate_or_infer_batch_size(self, batch_size, steps, x) x, batch_size)) ValueError: The `batch_size` argument must not be specified for the given input type. Received input: <DatasetV1Adapter shapes: ((512, 4), (512, 3)), types: (tf.float32, tf.float32)>, batch_size: 512",0
"File [FILE], line 48, in <module> prediction = model(X) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 493, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.6/site-packages/torch/nn/parallel/data_parallel.py, line 146, in forward(self, *inputs, **kwargs) ""them on device: {}"".format(self.src_device_obj, t.device)) RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:2",0
"File [FILE], line 3, in <module> epochs=10) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 324, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs) total_epochs=epochs) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 123, in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs) batch_outs = execution_function(iterator) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 86, in execution_function(input_fn) distributed_function(input_fn)) File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializer_map) File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize(self, args, kwds, add_initializers_to) *args, **kwds)) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value), File <*>python3.7/site-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs) File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 73, in distributed_function(input_iterator) per_replica_function, args=(model, x, y, sample_weights)) File <*>python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 760, in experimental_run_v2(self, fn, args, kwargs) return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) File <*>python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 1787, in call_for_each_replica(self, fn, args, kwargs) return self._call_for_each_replica(fn, args, kwargs) File <*>python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 2132, in _call_for_each_replica(self, fn, args, kwargs) return fn(*args, **kwargs) File <*>python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py, line 292, in wrapper(*args, **kwargs) return func(*args, **kwargs) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics) output_loss_metrics=model._output_loss_metrics) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 315, in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics) model, outs, targets, sample_weights=sample_weights, masks=masks) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 74, in _eager_metrics_fn(model, outputs, targets, sample_weights, masks) skip_target_masks=model._prepare_skip_target_masks()) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 2063, in _handle_metrics(self, outputs, targets, skip_target_masks, sample_weights, masks, return_weighted_metrics, return_weighted_and_unweighted_metrics) target, output, output_mask)) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 2014, in _handle_per_output_metrics(self, metrics_dict, y_true, y_pred, mask, weights) metric_fn, y_true, y_pred, weights=weights, mask=mask) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py, line 1067, in call_metric_function(metric_fn, y_true, y_pred, weights, mask) return metric_fn(y_true, y_pred, sample_weight=weights) File <*>python3.7/site-packages/tensorflow_core/python/keras/metrics.py, line 193, in __call__(self, *args, **kwargs) replica_local_fn, *args, **kwargs) File <*>python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py, line 1135, in call_replica_local_fn(fn, *args, **kwargs) return fn(*args, **kwargs) File <*>python3.7/site-packages/tensorflow_core/python/keras/metrics.py, line 176, in replica_local_fn(*args, **kwargs) update_op = self.update_state(*args, **kwargs) # pylint: disable=not-callable File <*>python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py, line 75, in decorated(metric_obj, *args, **kwargs) update_op = update_state_fn(*args, **kwargs) File <*>python3.7/site-packages/tensorflow_core/python/keras/metrics.py, line 883, in update_state(self, y_true, y_pred, sample_weight) sample_weight=sample_weight) File <*>python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py, line 278, in update_confusion_matrix_variables(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight) y_pred.shape.assert_is_compatible_with(y_true.shape) File <*>python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py, line 1115, in assert_is_compatible_with(self, other) raise ValueError(""Shapes %s and %s are incompatible"" % (self, other)) ValueError: Shapes (None, 4) and (None, 1) are incompatible",0
"File [FILE], line 2, in <module> model = make_feed_forward_model() File [FILE], line 20, in make_feed_forward_model() dense_layer_1 = tf.keras.layers.Dense(HPARAMS.num_fc_units, activation='relu')(inputs) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 616, in __call__(self, inputs, *args, **kwargs) self._maybe_build(inputs) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1966, in _maybe_build(self, inputs) self.build(input_shapes) File <*>/site-packages/tensorflow/python/keras/layers/core.py, line 1005, in build(self, input_shape) raise ValueError('The last dimension of the inputs to `Dense` ' ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.",0
"File [FILE], line 8, in <module> es.tell(X, eval_all(X, NPARAMS)) File [FILE], line 16, in _evaluate2(self, X, *args) return [job.get() for job in jobs] File [FILE], line 16, in <listcomp>(.0) return [job.get() for job in jobs] File <*>python3.7/pool.py, line 657, in get(self, timeout) raise self._value File <*>python3.7/pool.py, line 431, in _handle_tasks(taskqueue, put, outqueue, pool, cache) put(task) File <*>python3.7/connection.py, line 206, in send(self, obj) self._send_bytes(_ForkingPickler.dumps(obj)) File <*>python3.7/reduction.py, line 51, in dumps(cls, obj, protocol) cls(buf, protocol).dump(obj) TypeError: can't pickle _thread.lock objects",0
"File [FILE], line 4, in <module> model.fit(train_encoded, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(test_encoded,test_labels)) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 324, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs) total_epochs=epochs) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 123, in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs) batch_outs = execution_function(iterator) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 86, in execution_function(input_fn) distributed_function(input_fn)) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializer_map) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize(self, args, kwds, add_initializers_to) *args, **kwds)) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value), File <*>/site-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 73, in distributed_function(input_iterator) per_replica_function, args=(model, x, y, sample_weights)) File <*>/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 760, in experimental_run_v2(self, fn, args, kwargs) return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) File <*>/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 1787, in call_for_each_replica(self, fn, args, kwargs) return self._call_for_each_replica(fn, args, kwargs) File <*>/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 2132, in _call_for_each_replica(self, fn, args, kwargs) return fn(*args, **kwargs) File <*>/site-packages/tensorflow_core/python/autograph/impl/api.py, line 292, in wrapper(*args, **kwargs) return func(*args, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics) output_loss_metrics=model._output_loss_metrics) File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics) output_loss_metrics=output_loss_metrics)) File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 252, in _process_single_batch(model, inputs, targets, output_loss_metrics, sample_weights, training) training=training)) File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 127, in _model_loss(model, inputs, targets, output_loss_metrics, sample_weights, training) outs = model(inputs, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 847, in __call__(self, inputs, *args, **kwargs) outputs = call_fn(cast_inputs, *args, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/engine/sequential.py, line 270, in call(self, inputs, training, mask) outputs = layer(inputs, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 812, in __call__(self, inputs, *args, **kwargs) self.name) File <*>/site-packages/tensorflow_core/python/keras/engine/input_spec.py, line 213, in assert_input_compatibility(input_spec, inputs, layer_name) ' but received input with shape ' + str(shape)) ValueError: Input 0 of layer dense_3 is incompatible with the layer: expected axis -1 of input shape to have value 6022 but received input with shape [None, 512]",0
"File [FILE], line 3, in <module> cocoBuilder.download_and_prepare() File <*>/site-packages/tensorflow_datasets/core/api_utils.py, line 52, in disallow_positional_args_dec(fn, instance, args, kwargs) return fn(*args, **kwargs) File <*>/site-packages/tensorflow_datasets/core/dataset_builder.py, line 287, in download_and_prepare(self, download_dir, download_config) download_config=download_config) File <*>/site-packages/tensorflow_datasets/core/dataset_builder.py, line 948, in _download_and_prepare(self, dl_manager, download_config) max_examples_per_split=download_config.max_examples_per_split, File <*>/site-packages/tensorflow_datasets/core/dataset_builder.py, line 804, in _download_and_prepare(self, dl_manager, **prepare_split_kwargs) for split_generator in self._split_generators(dl_manager): File <*>/site-packages/tensorflow_datasets/image/coco.py, line 239, in _split_generators(self, dl_manager) key: root_url + url for key, url in urls.items() File <*>/site-packages/tensorflow_datasets/core/download/download_manager.py, line 359, in download_and_extract(self, url_or_urls) return _map_promise(self._download_extract, url_or_urls) File <*>/site-packages/tensorflow_datasets/core/download/download_manager.py, line 395, in _map_promise(map_fn, all_inputs) res = utils.map_nested(_wait_on_promise, all_promises) File <*>/site-packages/tensorflow_datasets/core/utils/py_utils.py, line 129, in map_nested(function, data_struct, dict_only, map_tuple) for k, v in data_struct.items() File <*>/site-packages/tensorflow_datasets/core/utils/py_utils.py, line 129, in <dictcomp>(.0) for k, v in data_struct.items() File <*>/site-packages/tensorflow_datasets/core/utils/py_utils.py, line 143, in map_nested(function, data_struct, dict_only, map_tuple) return function(data_struct) File <*>/site-packages/tensorflow_datasets/core/download/download_manager.py, line 379, in _wait_on_promise(p) return p.get() File <*>/site-packages/promise/promise.py, line 510, in get(self, timeout) return self._target_settled_value(_raise=True) File <*>/site-packages/promise/promise.py, line 514, in _target_settled_value(self, _raise) return self._target()._settled_value(_raise) File <*>/site-packages/promise/promise.py, line 224, in _settled_value(self, _raise) reraise(type(raise_val), raise_val, self._traceback) File <*>/site-packages/six.py, line 696, in reraise(tp, value, tb) raise value File <*>/site-packages/promise/promise.py, line 842, in handle_future_result(future) resolve(future.result()) File <*>/_base.py, line 425, in result(self, timeout) return self.__get_result() File <*>/_base.py, line 384, in __get_result(self) raise self._exception File <*>/thread.py, line 56, in run(self) result = self.fn(*self.args, **self.kwargs) File <*>/site-packages/tensorflow_datasets/core/download/extractor.py, line 94, in _sync_extract(self, from_path, method, to_path) raise ExtractError(msg) ExtractError: Error while extracting C:\Users\%user%\tensorflow_datasets\downloads\images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip to C:\Users\%user%\tensorflow_datasets\downloads\extracted\ZIP.images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip : C:\Users\%user%\tensorflow_datasets\downloads\images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip; Unknown error",0
"File [FILE], line 1, in <module>() addn = tf.add(mul, div) File <*>python3.5/site-packages/tensorflow_core/python/ops/gen_math_ops.py, line 343, in add(x, y, name) _ops.raise_from_not_ok_status(e, name) File <*>python3.5/site-packages/tensorflow_core/python/framework/ops.py, line 6606, in raise_from_not_ok_status(e, name) six.raise_from(core._status_to_exception(e.code, message), None) File <*>python3.5/site-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE] InvalidArgumentError: cannot compute Add as input #1(zero-based) was expected to be a int32 tensor but is a double tensor [Op:Add]",0
"File [FILE], line 19, in <module> transformed_dataset, transform_fn = (raw_dataset | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 863, in expand(self, dataset) dataset | 'AnalyzeDataset' >> AnalyzeDataset(self._preprocessing_fn)) File <*>python3.7/site-packages/apache_beam/transforms/ptransform.py, line 989, in __ror__(self, pvalueish, _unused) return self.transform.__ror__(pvalueish, self.label) File <*>python3.7/site-packages/apache_beam/transforms/ptransform.py, line 549, in __ror__(self, left, label) result = p.apply(self, pvalueish, label) File <*>python3.7/site-packages/apache_beam/pipeline.py, line 536, in apply(self, transform, pvalueish, label) return self.apply(transform, pvalueish) File <*>python3.7/site-packages/apache_beam/pipeline.py, line 577, in apply(self, transform, pvalueish, label) pvalueish_result = self.runner.apply(transform, pvalueish, self._options) File <*>python3.7/site-packages/apache_beam/runners/runner.py, line 195, in apply(self, transform, input, options) return m(transform, input, options) File <*>python3.7/site-packages/apache_beam/runners/runner.py, line 225, in apply_PTransform(self, transform, input, options) return transform.expand(input) File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 810, in expand(self, dataset) None, input_metadata)) File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 683, in expand(self, dataset) output_signature = self._preprocessing_fn(copied_inputs) File [FILE], line 11, in preprocessing_fn(inputs) tf.constant(value, shape=outputs[key].shape), File <*>python3.7/site-packages/tensorflow_core/python/framework/constant_op.py, line 258, in constant(value, dtype, shape, name) allow_broadcast=True) File <*>python3.7/site-packages/tensorflow_core/python/framework/constant_op.py, line 296, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast)) File <*>python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py, line 448, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) if shape is not None and np.prod(shape, dtype=np.int64) == 0: File [FILE], line [NUM], in prod(*args, **kwargs) [CODE] File <*>python3.7/site-packages/numpy/core/fromnumeric.py, line 2962, in prod(a, axis, dtype, out, keepdims, initial, where) keepdims=keepdims, initial=initial, where=where) File <*>python3.7/site-packages/numpy/core/fromnumeric.py, line 90, in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs) return ufunc.reduce(obj, axis, dtype, out, **passkwargs) TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'",0
"File [FILE], line 13, in <module> loss = criterion(output, labels) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 532, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.6/site-packages/torch/nn/modules/loss.py, line 204, in forward(self, input, target) return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction) File <*>python3.6/site-packages/torch/nn/functional.py, line 1838, in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction) ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index) RuntimeError: expected scalar type Long but found Float",0
"File [FILE], line 13, in <module> model = FullyConnectedLayer (512, dist, 0.99, 0.5 ) # 4 LAYERS File [FILE], line 58, in FullyConnectedLayer(denseUnits, seluDistribution, batchMomentum, alphaDropRate) model.add(Activation(gelu(x=seluDistribution))) File <*>/site-packages/tensorflow_core/python/keras/layers/core.py, line 378, in __init__(self, activation, **kwargs) self.activation = activations.get(activation) File <*>/site-packages/tensorflow_core/python/keras/activations.py, line 454, in get(identifier) repr(identifier))) TypeError: Could not interpret activation function identifier: <tf.Tensor: shape=(5, 5, 1, 32), dtype=float32, numpy= array([[[[-1.26586094e-01, -1.02963023e-01, 3.14652212e-02, -1.39087364e-01, 1.13992631e-01, 1.52557418e-01, -1.09972686e-01, -5.12595251e-02, -1.58538278e-02, -1.29528284e-01, 1.63152684e-02, 1.01518132e-01, -4.35875840e-02, 1.46785110e-01, -2.23108958e-02, -2.09968127e-02, -8.54036435e-02, 9.01642349e-03, -4.25574742e-02, 4.80710454e-02]], [[ 9.34263412e-03, 1.06001608e-01, -7.65870064e-02, -8.02185014e-02, 6.67698979e-02, -8.98385793e-02, -6.12295903e-02, 7.36039877e-02, -1.33156419e-01, [[-1.38585389e-01, 1.03538044e-01, 1.76681668e-01, -6.94317510e-03, 6.14152141e-02, -3.92788239e-02, -5.83523549e-02, 6.68111816e-02, 5.49897328e-02, -5.77139147e-02, -7.64194950e-02, -7.55715296e-02, -4.95074578e-02, 7.71198049e-02, 5.40203564e-02, -9.74030495e-02, -1.00650810e-01, 1.23783059e-01, -8.46874043e-02, -1.04908131e-01, -2.63819955e-02, -1.31487399e-01, 1.30674899e-01]], [[ 6.60606772e-02, 1.46065757e-01, 1.59279909e-02, -1.20391339e-01, -7.02986643e-02, -2.74278801e-02, -1.29030854e-01, -7.62277395e-02, -1.19075023e-01, -9.22646299e-02, 7.98776373e-02, 6.54103830e-02, -6.72401339e-02, -4.81364317e-02, -6.03620708e-02, -2.84200851e-02, -9.10447016e-02]], [[-1.23140588e-01, 1.10491589e-01, -9.61843282e-02, -8.91052186e-02, 4.01075035e-01, 1.94666237e-02, -2.61222124e-02, -1.56512097e-01, 9.74281505e-02, -3.66279632e-02, 6.65708026e-03, 9.61058680e-03, -1.21156186e-01, -2.98077669e-02, 1.66137442e-02, -3.38280275e-02, -9.28360224e-02, -7.76154548e-02, -7.96113610e-02, -2.57881228e-02, -1.58247918e-01, [[[-1.13160208e-01, -1.98329911e-02, 1.20878376e-01, -1.13716172e-02, -5.21509871e-02, 7.25255907e-02, -1.12730011e-01, -7.29970336e-02, 6.37045652e-02, -8.64603445e-02, -2.22087242e-02, -2.47925967e-02, -6.44451613e-03, -1.73095725e-02, -6.07393086e-02, -4.96991165e-02, -3.15147117e-02, 2.43039820e-02, -7.35211000e-02, -6.92363605e-02]], [[ 3.96580771e-02, 1.26118317e-01, 1.16271339e-01, -5.80145419e-02, -2.15136074e-03, -9.12490934e-02, -1.27457187e-01, 3.60154063e-02, 9.91806835e-02, -4.64559309e-02, -2.11531147e-02, 4.10205543e-01, -4.43787202e-02, 4.39099297e-02, 3.06370091e-02, -9.87873599e-02, -5.10304309e-02]], [[ 2.13202462e-02, 1.41525701e-01, -4.84775938e-02, -1.43082231e-01, 4.21900637e-02, -1.17563821e-01, -3.71489525e-02, -1.45584494e-01, -1.12884097e-01, -7.87854716e-02, -2.01713406e-02, -3.49416770e-02, -6.53499886e-02, -2.09143162e-02, 2.94101406e-02, -5.27165644e-02, 1.19348057e-02, -4.39126566e-02, -6.26288429e-02, 4.20925207e-02]], [[-8.23830441e-02, 2.23106906e-01, 8.56178179e-02, -5.99831380e-02, -1.71386788e-03, -3.62357125e-02, -1.59021363e-01, -2.17766548e-03, 2.16864720e-01, -5.73305860e-02, -1.80698894e-02, 1.36940643e-01, -1.97473206e-02, 8.14313069e-02, 1.96376622e-01, -6.43103570e-02, -3.85615453e-02]], [[-3.53560485e-02, 4.35038935e-03, -7.06349090e-02, -2.80691660e-03, -6.92954510e-02, 1.11481667e-01, -4.58219610e-02, -2.38394644e-02, -7.87800774e-02, -1.67009607e-02, 6.01479635e-02, 1.56740978e-01, -9.78638828e-02, -4.29860055e-02, 1.38192121e-02, -1.36006713e-01, -1.05418041e-01, -2.51792613e-02, -1.22639257e-02, -1.21888302e-01, -5.46660051e-02, -7.12147309e-03, -6.58531636e-02, -7.14808479e-02, [[[ 6.32937178e-02, 2.72242278e-01, -3.74731459e-02, -2.62564681e-02, -1.54855132e-01, 7.81283434e-03, -8.01301673e-02, 7.47360140e-02, -5.00108190e-02, -7.64894933e-02, 8.45131949e-02, -3.27355303e-02, -3.79370786e-02, -6.93783676e-03, -4.87477183e-02, [[-7.98909813e-02, 2.59152979e-01, 1.75541520e-01, -8.12215135e-02, -9.54297185e-02, 1.99518725e-03, -3.72358635e-02, -1.39946237e-01, -5.76626435e-02, -7.13582858e-02, 5.86171262e-02, -1.39267772e-01, -1.00216493e-01, 2.68728107e-01, 1.63495377e-01, -2.24205833e-02, 1.44553408e-01, -9.67240557e-02, -1.24277532e-01, -1.40620157e-01]], [[-5.69531657e-02, 1.71630532e-01, 2.86230773e-01, -5.93378842e-02, -1.71954520e-02, -3.26295868e-02, -3.98173966e-02, 7.21049905e-02, -6.91456124e-02, -1.23138815e-01, 1.33402884e-01, -1.02245316e-01, -4.69203852e-02, -1.75676849e-02, 1.40360445e-01, -3.40559036e-02, 3.35928686e-02, -1.04908220e-01, [[-7.85556585e-02, -1.18466914e-01, 1.53003752e-01, -4.67218924e-03, -1.16112582e-01, 5.51390201e-02, -1.52055770e-02, 3.54320277e-03, 3.42624858e-02, -1.05386212e-01, 1.98949352e-02, 2.73315758e-02, -7.58572146e-02, 1.03625186e-01, 2.05493998e-03, -1.01805991e-02, 2.19766423e-02]], [[-1.00509115e-02, 2.22494956e-02, -9.08879191e-02, -8.11229870e-02, 9.98405516e-02, -5.72074987e-02, -1.33951874e-02, 3.92576605e-02, 1.16789080e-01, -1.89318452e-02, -1.59033425e-02, 9.48152542e-02, -2.66773477e-02, 1.37753570e-02, 1.79445334e-02, -6.62883669e-02, -9.37851295e-02, 1.94142580e-01, -1.28269400e-02, 1.25869989e-01, 1.50878415e-01, -2.11219154e-02, -1.05045862e-01, -2.73662023e-02, [[[ 1.83003962e-01, -4.02955636e-02, 7.92874582e-03, -1.04859909e-02, 1.41754048e-02, -1.52763631e-02, -9.11424682e-02, 3.24082047e-01, 1.05546042e-02, -1.30687788e-01, -3.98224816e-02, 1.38061410e-02, [[ 2.33758405e-01, -9.26907063e-02, 1.65917858e-01, -1.22203723e-01, -2.83196904e-02, 1.02213569e-01, -5.63387433e-03, -3.08787469e-02, 1.96257643e-02, -7.37890229e-02, -1.93086471e-02, 1.30984381e-01, [[-5.09779751e-02, 6.08728305e-02, -8.07061568e-02, -1.26804784e-01, -1.43676013e-01, -3.28507088e-02, -1.66144117e-03, -7.41888210e-03, 1.42028257e-01, -4.99214791e-02, -1.86899900e-02, -1.09298825e-02, -8.03249031e-02, -1.00237548e-01]], [[-7.80191123e-02, 4.05082256e-02, 7.47731477e-02, -8.76973122e-02, -2.91744564e-02, 1.23694569e-01, -1.49070352e-01, 2.42730626e-03, 3.52480598e-02, -5.62792830e-03, -2.28355639e-02, -1.27415329e-01, -8.48858505e-02, -3.52028869e-02, -7.95315206e-02, -3.92727107e-02, -4.16678861e-02, 2.39140958e-01, -1.44019471e-02, -8.69576260e-03]], [[-1.67441964e-02, -1.43177100e-02, -9.23768803e-02, -2.72830930e-02, 7.51334131e-02, -2.28366554e-02, -5.57800010e-02, -1.31770581e-01, 9.31192283e-03, -1.38517320e-02, -1.41043484e-01, -6.42404705e-02, -4.86476049e-02, -1.12639852e-01, 7.89660513e-02, -1.09081008e-01, -3.03610712e-02]]], [[[-1.40361011e-01, 1.21919084e-02, 4.36685272e-02, -3.61564793e-02, -1.11773185e-01, 2.25092173e-02, -1.02469876e-01, 1.76996499e-01, 4.30173017e-02, -2.26258971e-02, 2.11037025e-01, 9.66922417e-02, -4.83587980e-02, 4.68245940e-04, -1.47096828e-01, -2.91392524e-02, 8.22411999e-02, 2.07852814e-02, -4.12134677e-02, 5.33621386e-02, 9.24792588e-02, [[ 1.66879535e-01, 6.54919222e-02, -3.27483788e-02, -1.43241754e-03, -1.14416316e-01, -2.12962832e-02, -4.46583293e-02, 2.71647628e-02, -5.61558232e-02, -1.24854170e-01, 1.25476092e-01, -7.09585026e-02, -4.40548174e-02, 7.21732453e-02, 7.45785460e-02, -1.17296316e-01, -1.46051958e-01, 1.88378561e-02, [[ 2.60874778e-01, -1.45940065e-01, -9.79427770e-02, -8.68195742e-02, 2.04389215e-01, -2.24198923e-02, -8.38927086e-03, -4.99465019e-02, 4.69646640e-02, -7.15569034e-02, -1.78242605e-02, -8.51068646e-03, -3.08227092e-02, -4.82530929e-02, 8.31630453e-02, -4.16018628e-02, -7.55471215e-02]], [[ 2.24076852e-01, -1.39667824e-01, 7.93220941e-03, -1.78845283e-02, -5.64770252e-02, -7.84719810e-02, -1.81565285e-02, 1.24106847e-01, -6.28474308e-03, -1.72791779e-02, -3.47166769e-02, -4.92920280e-02, -9.12440866e-02, 6.42236844e-02, -1.16013244e-01, -7.96606317e-02, 1.50838092e-01, -4.71229590e-02, -4.02066261e-02, 1.17019311e-01]], [[-3.95799540e-02, -4.35096361e-02, -9.93420109e-02, -6.20126911e-02, 1.93700612e-01, 5.02851121e-02, -9.00325775e-02, 1.32245719e-01, 2.68575907e-01, -8.08344856e-02, -4.56905663e-02, 1.26069590e-01, -6.64912462e-02, 9.61613879e-02, -1.48803489e-02, "", 'Error', 'Error', '', '')",0
"File [FILE], line 7, in <module>() print(x[tensor(0)]) KeyError: tensor(0)",0
"File [FILE], line 11, in <module>() print(x[0]) KeyError: 0",0
"File [FILE], line 8, in <module>() callbacks=[ccall, esd3] File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 813, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) callbacks.on_epoch_end(epoch, epoch_logs) File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 365, in on_epoch_end(self, epoch, logs) callback.on_epoch_end(epoch, logs) File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 1485, in on_epoch_end(self, epoch, logs) self.model.set_weights(self.best_weights) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 1519, in set_weights(self, weights) if expected_num_weights != len(weights): TypeError: object of type 'NoneType' has no len()",0
"File [FILE], line 9, in <module> train_loss, train_acc = train(model, train_iterator, optimizer, criterion) File [FILE], line 8, in train(model, iterator, optimizer, criterion) for batch in iterator: File <*>python3.7/site-packages/torchtext/data/iterator.py, line 142, in __iter__(self) for idx, minibatch in enumerate(self.batches): File <*>python3.7/site-packages/torchtext/data/iterator.py, line 286, in pool(data, batch_size, key, batch_size_fn, random_shuffler, shuffle, sort_within_batch) if sort_within_batch \ TypeError: '<' not supported between instances of 'Example' and 'Example'",0
"File [FILE], line 70, in <module>() loss = torch.nn.MSELoss(out, target) File <*>python3.6/dist-packages/torch/nn/_reduction.py, line 36, in legacy_get_string(size_average, reduce, emit_warning) if size_average and reduce: RuntimeError: bool value of Tensor with more than one value is ambiguous",0
"File [FILE], line 6, in <module> from tensorflow.keras.models import Sequential File <*>/site-packages/tensorflow/keras/__init__.py, line 14, in <module> from . import activations File <*>/site-packages/tensorflow/keras/activations/__init__.py, line 23, in <module> from tensorflow.python.keras.activations import swish ImportError: cannot import name 'swish' from 'tensorflow.python.keras.activations' (C:\Users\FlamePrinz\Anaconda3\lib\site-packages\tensorflow\python\keras\activations.py)",0
"File [FILE], line 16, in <module> model.fit(X_train, y_train, epochs=3) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 819, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 342, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) total_epochs=epochs) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs) batch_outs = execution_function(iterator) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function(input_fn) distributed_function(input_fn)) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 632, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2363, in __call__(self, *args, **kwargs) return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call(self, args, kwargs) self.captured_inputs) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat(self, args, captured_inputs, cancellation_manager) ctx, args, cancellation_manager=cancellation_manager)) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 545, in call(self, ctx, args, cancellation_manager) ctx=ctx) File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) six.raise_from(core._status_to_exception(e.code, message), None) File <*>/site-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE] UnimplementedError: Cast string to int64 is not supported [[node loss/output_1_loss/Cast (defined at <ipython-input-111-1a89f1d94518>:16) ]] [Op:__inference_distributed_function_544280]",0
"File [FILE], line 14, in <module> Y = torch.masked_select(X, (mask == 1)) RuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2",0
"File [FILE], line 5, in <module> verbose = 1) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 872, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) return_dict=True) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1081, in evaluate(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict) tmp_logs = test_function(iterator) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 618, in _call(self, *args, **kwds) results = self._stateful_fn(*args, **kwds) File <*>/site-packages/tensorflow/python/eager/function.py, line 2419, in __call__(self, *args, **kwargs) graph_function, args, kwargs = self._maybe_define_function(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 2774, in _maybe_define_function(self, args, kwargs) return self._define_function_with_shape_relaxation(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 2706, in _define_function_with_shape_relaxation(self, args, kwargs) args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes) File <*>/site-packages/tensorflow/python/eager/function.py, line 2667, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value), File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 981, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 441, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds) File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e) AssertionError: in user code: c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\training.py:941 test_function * outputs = self.distribute_strategy.run( c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:951 run ** return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2290 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2649 _call_for_each_replica return fn(*args, **kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\training.py:909 test_step ** y_pred = self(x, training=False) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:927 __call__ outputs = call_fn(cast_inputs, *args, **kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\ etwork.py:719 call convert_kwargs_to_constants=base_layer_utils.call_context().saving) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\ etwork.py:899 _run_internal_graph assert str(id(x)) in tensor_dict, 'Could not compute output ' + str(x) AssertionError: Could not compute output Tensor(""O1_6/Identity:0"", shape=(None, 2), dtype=float32)",0
"File [FILE], line 58, in <module>() optimizer.step() File <*>python3.6/dist-packages/torch/autograd/grad_mode.py, line 15, in decorate_context(*args, **kwargs) return func(*args, **kwargs) File <*>python3.6/dist-packages/torch/optim/adam.py, line 99, in step(self, closure) exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1) RuntimeError: expected device cpu but got device cuda:0",0
"File [FILE], line 4, in <module>() model = encoder_model(k) File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1113, in op(self) ""Tensor.op is meaningless when eager execution is enabled."") AttributeError: Tensor.op is meaningless when eager execution is enabled.",0
"File [FILE], line 9, in <module>() model.save(outdir+'model.h5') File <*>python3.6/dist-packages/h5py/_hl/group.py, line 373, in __setitem__(self, name, obj) h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl) File <*>/_objects.pyx, line [NUM], in h5py._objects.with_phil.wrapper() [CODE] File <*>/h5o.pyx, line [NUM], in h5py.h5o.link() [CODE] RuntimeError: Unable to create link (name already exists)",0
"File [FILE], line 8, in <module>() ds = ds.filter(filter_fn) File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e) OperatorNotAllowedInGraphError: in user code: <ipython-input-52-52131b5369b6>:5 filter_fn * return features['department'] in ['FERRAMENTAS', 'MERCEARIA', 'MOVEIS'] /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:778 __bool__ self._disallow_bool_casting() /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:545 _disallow_bool_casting ""using a `tf.Tensor` as a Python `bool`"") /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:532 _disallow_when_autograph_enabled "" decorating it directly with @tf.function."".format(task)) OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.",0
"File <*>/site-packages/tensorflow_core/python/client/session.py, line 1365, in _do_call(self, fn, *args) return fn(*args) File <*>/site-packages/tensorflow_core/python/client/session.py, line 1350, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) target_list, run_metadata) File <*>/site-packages/tensorflow_core/python/client/session.py, line 1443, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata) InvalidArgumentError: indices[24,0] = 335 is not in [0, 304) [[{{node user-embedding-mlp_1/GatherV2}}]]",0
"File [FILE], line 1, in <module> history = model.fit([train.id, train.user_id], train.user_like, nb_epoch=3) File <*>/site-packages/keras/engine/training.py, line 1657, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs) validation_steps=validation_steps) File <*>/site-packages/keras/engine/training.py, line 1213, in _fit_loop(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps) outs = f(ins_batch) File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2357, in __call__(self, inputs) **self.session_kwargs) File <*>/site-packages/tensorflow_core/python/client/session.py, line 956, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr) File <*>/site-packages/tensorflow_core/python/client/session.py, line 1180, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata) File <*>/site-packages/tensorflow_core/python/client/session.py, line 1359, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata) File <*>/site-packages/tensorflow_core/python/client/session.py, line 1384, in _do_call(self, fn, *args) session_config.graph_options.rewrite_options.' raise type(e)(node_def, op, message) InvalidArgumentError: indices[24,0] = 335 is not in [0, 304) [[node user-embedding-mlp_1/GatherV2 (defined at E:\My\Ananconda\envs\tensor\lib\site-packages\tensorflow_core\python\framework\ops.py:1748) ]]",0
"File [FILE], line 4, in <module> history = comp_lstm.fit(train, File <*>python3.8/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs) File <*>python3.8/site-packages/tensorflow/python/keras/engine/training.py, line 848, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) tmp_logs = train_function(iterator) File <*>python3.8/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>python3.8/site-packages/tensorflow/python/eager/def_function.py, line 611, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) # pylint: disable=not-callable TypeError: 'NoneType' object is not callable",0
"File [FILE], line 29, in <module> interpreter.allocate_tensors() File <*>/interpreter.py, line 242, in allocate_tensors(self) return self._interpreter.AllocateTensors() File <*>/tensorflow_wrap_interpreter_wrapper.py, line 110, in AllocateTensors(self) return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self) RuntimeError: tensorflow/lite/kernels/reshape.cc:66 num_input_elements != num_output_elements (1536 != 768)Node number 3 (RESHAPE) failed to prepare.",0
"File [FILE], line 1, in <module> output = encoder(src, src_mask) File <*>python3.7/site-packages/torch/nn/modules/transformer.py, line 167, in forward(self, src, mask, src_key_padding_mask) src_key_padding_mask=src_key_padding_mask) File <*>python3.7/site-packages/torch/nn/modules/module.py, line 547, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.7/site-packages/torch/nn/modules/transformer.py, line 266, in forward(self, src, src_mask, src_key_padding_mask) key_padding_mask=src_key_padding_mask)[0] File <*>python3.7/site-packages/torch/nn/modules/activation.py, line 783, in forward(self, query, key, value, key_padding_mask, need_weights, attn_mask) attn_mask=attn_mask) File <*>python3.7/site-packages/torch/nn/functional.py, line 3252, in multi_head_attention_forward(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v) attn_output_weights += attn_mask RuntimeError: The size of tensor a (20) must match the size of tensor b (95) at non-singleton dimension 2",0
"File [FILE], line 3, in <module> validation_data=validation_batches) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 848, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) tmp_logs = train_function(iterator) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 611, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) # pylint: disable=not-callable File <*>/site-packages/tensorflow/python/eager/function.py, line 2420, in __call__(self, *args, **kwargs) return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access File <*>/site-packages/tensorflow/python/eager/function.py, line 1665, in _filtered_call(self, args, kwargs) self.captured_inputs) File <*>/site-packages/tensorflow/python/eager/function.py, line 1746, in _call_flat(self, args, captured_inputs, cancellation_manager) ctx, args, cancellation_manager=cancellation_manager)) File <*>/site-packages/tensorflow/python/eager/function.py, line 598, in call(self, ctx, args, cancellation_manager) ctx=ctx) File <*>/site-packages/tensorflow/python/eager/execute.py, line 60, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) inputs, attrs, num_outputs) InvalidArgumentError: 2 root error(s) found. (0) Invalid argument: Invalid JPEG data or crop window, data size 34228 [[{{node DecodeJpeg}}]] [[IteratorGetNext]] (1) Invalid argument: Invalid JPEG data or crop window, data size 34228 [[{{node DecodeJpeg}}]] [[IteratorGetNext]] [[IteratorGetNext/_4]]",0
"File [FILE], line 11, in <module> validation_steps=nb_val_steps) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs) File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1063, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) steps_per_execution=self._steps_per_execution) File <*>/site-packages/tensorflow/python/keras/engine/data_adapter.py, line 1110, in __init__(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution) model=model) File <*>/site-packages/tensorflow/python/keras/engine/data_adapter.py, line 798, in __init__(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs) output_shapes = nest.map_structure(_get_dynamic_shape, peek) File <*>/site-packages/tensorflow/python/util/est.py, line 635, in map_structure(func, *structure, **kwargs) structure[0], [func(*x) for x in entries], File <*>/site-packages/tensorflow/python/util/est.py, line 635, in <listcomp>(.0) structure[0], [func(*x) for x in entries], File <*>/site-packages/tensorflow/python/keras/engine/data_adapter.py, line 794, in _get_dynamic_shape(t) if shape.rank is None: AttributeError: 'tuple' object has no attribute 'rank'",0
"File [FILE], line 21, in <module>() history = m.fit([X, y, W], y, epochs=10) File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 819, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing) File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 235, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing) File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 593, in _process_training_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing) use_multiprocessing=use_multiprocessing) File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 646, in _process_inputs(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing) x, y, sample_weight=sample_weights) File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 2383, in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset) batch_size=batch_size) File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 2469, in _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size) exception_prefix='target') File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_utils.pyc, line 496, in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) 'expected no data, but got:', data) ValueError: ('Error when checking model target: expected no data, but got:', array([3.39102071e-01, 1.23122638e-01, 7.54209531e-01, 8.10110230e-01,",0
"File [FILE], line 4, in <module>() y_true = np.argmax(testdata, axis=1) File [FILE], line [NUM], in argmax(*args, **kwargs) [CODE] File <*>python3.6/dist-packages/numpy/core/fromnumeric.py, line 47, in _wrapit(obj, method, *args, **kwds) result = getattr(asarray(obj), method)(*args, **kwds) AxisError: axis 1 is out of bounds for array of dimension 1",0
"File [FILE], line 2, in <module> model.save(""network.h5"") File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 1008, in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options) signatures, options) File <*>/site-packages/tensorflow_core/python/keras/saving/save.py, line 99, in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options) (h5py is not None and isinstance(filepath, h5py.File)) or AttributeError: module 'h5py' has no attribute 'File'",0
"File [FILE], line 1, in <module>() load_image('/content/train2017/000000000009.jpg') File [FILE], line 4, in load_image(image_path) img = tf.image.resize(img, (299, 299)) File <*>python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py, line 1517, in resize_images_v2(images, size, method, preserve_aspect_ratio, antialias, name) skip_resize_if_same=False) File <*>python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py, line 1185, in _resize_images_common(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same) if images.get_shape().ndims is None: File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1073, in get_shape(self) return self.shape File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1067, in shape(self) six.raise_from(core._status_to_exception(e.code, e.message), None) File <*>python3.6/dist-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE] UnimplementedError: File system scheme '[local]' not implemented (file: '/content/train2017/000000000009.jpg')",0
"File [FILE], line 1, in <module>() X_prime_class_split = np.array_split(X_prime_class.numpy(), TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",0
"File [FILE], line 22, in [FUNC] train_iter.next() File <*>/site-packages/torch/utils/data/dataloader.py, line 345, in __next__(self) data = self._next_data() File <*>/site-packages/torch/utils/data/dataloader.py, line 385, in _next_data(self) data = self._dataset_fetcher.fetch(index) # may raise StopIteration File <*>/site-packages/torch/utils/data/_utils/fetch.py, line 47, in fetch(self, possibly_batched_index) return self.collate_fn(data) File <*>/site-packages/torch/utils/data/_utils/collate.py, line 79, in default_collate(batch) return [default_collate(samples) for samples in transposed] File <*>/site-packages/torch/utils/data/_utils/collate.py, line 79, in (.0) return [default_collate(samples) for samples in transposed] File <*>/site-packages/torch/utils/data/_utils/collate.py, line 81, in default_collate(batch) raise TypeError(default_collate_err_msg_format.format(elem_type)) TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found",0
"File [FILE], line 27, in <module> loss = criterion(pred, y) File <*>python3.7/site-packages/torch/nn/modules/module.py, line 550, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.7/site-packages/torch/nn/modules/loss.py, line 432, in forward(self, input, target) return F.mse_loss(input, target, reduction=self.reduction) File <*>python3.7/site-packages/torch/nn/functional.py, line 2530, in mse_loss(input, target, size_average, reduce, reduction) if not (target.size() == input.size()): File <*>python3.7/site-packages/torch/nn/modules/module.py, line 594, in __getattr__(self, name) type(self).__name__, name)) AttributeError: 'UNet3D' object has no attribute 'size'",0
"File [FILE], line 30, in <module>() attn_out, attn_states = tf.keras.layers.Attention()([encoder_output, decoder_output]) File <*>python3.6/site-packages/tensorflow_core/python/framework/ops.py, line 548, in __iter__(self) ""Cannot iterate over a tensor with unknown first dimension."") TypeError: Cannot iterate over a tensor with unknown first dimension.",0
"File [FILE], line 1, in <module> writer.add_graph(net, images) File <*>/site-packages/tensorboardX/writer.py, line 793, in add_graph(self, model, input_to_model, verbose) from torch.utils.tensorboard._pytorch_graph import graph File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 4, in <module> raise ImportError('TensorBoard logging requires TensorBoard version 1.15 or above') ImportError: TensorBoard logging requires TensorBoard version 1.15 or above",0
"File [FILE], line 6, in <module> train_step(image_x, image_y) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 823, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializers) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 696, in _initialize(self, args, kwds, add_initializers_to) self._stateful_fn._get_concrete_function_internal_garbage_collected( # pylint: disable=protected-access File <*>/site-packages/tensorflow/python/eager/function.py, line 2855, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 3213, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 3065, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) func_graph_module.func_graph_from_py_func( File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 986, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 600, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds) File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 973, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e) OperatorNotAllowedInGraphError: in user code: <ipython-input-160-538af916a6fd>:28 train_step * total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_losss(real_y, cycled_y) <ipython-input-151-74a790ebcddf>:2 calc_cycle_loss * loss1 = tf.reduce_mean(tf.abs(real_image, cycled_image)) C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\util\dispatch.py:201 wrapper ** return target(*args, **kwargs) C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\ops\math_ops.py:388 abs with ops.name_scope(name, ""Abs"", [x]) as name: C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:6492 __enter__ return self._name_scope.__enter__() c:\users\astro\appdata\local\programs\python\python38\lib\contextlib.py:113 __enter__ return next(self.gen) C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:4176 name_scope if name: C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:877 __bool__ self._disallow_bool_casting() C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:486 _disallow_bool_casting self._disallow_when_autograph_enabled( C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:472 _disallow_when_autograph_enabled raise errors.OperatorNotAllowedInGraphError( OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.",0
"File [FILE], line 16, in <module>() abc = model.predict(img) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py, line 971, in select_data_adapter(x, y) _type_name(x), _type_name(y))) ValueError: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>",0
"File [FILE], line [NUM], in apache_beam.runners.common.DoFnRunner.process() [CODE] File [FILE], line [NUM], in apache_beam.runners.common.PerWindowInvoker.invoke_process() [CODE] File [FILE], line [NUM], in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window() [CODE] File [FILE], line [NUM], in apache_beam.runners.common._OutputProcessor.process_outputs() [CODE] File [FILE], line [NUM], in apache_beam.runners.worker.operations.SingletonConsumerSet.receive() [CODE] File [FILE], line [NUM], in apache_beam.runners.worker.operations.PGBKCVOperation.process() [CODE] File <*>python3.7/site-packages/tensorflow_model_analysis/evaluators/metrics_and_plots_evaluator_v2.py, line 356, in add_input(self, accumulator, element) result = c.add_input(a, get_combiner_input(elements[0], i)) File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/calibration_histogram.py, line 142, in add_input(self, accumulator, element) class_weights=self._class_weights)): File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py, line 284, in to_label_prediction_example_weight(inputs, eval_config, model_name, output_name, sub_key, class_weights, flatten, squeeze, allow_none) label, prediction = select_top_k(sub_key.top_k, label, prediction) File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py, line 622, in select_top_k(top_k, labels, predictions, scores) labels = one_hot(labels, predictions) File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py, line 672, in one_hot(tensor, target) tensor = np.delete(np.eye(target.shape[-1] + 1)[tensor], -1, axis=-1) IndexError: arrays used as indices must be of integer (or boolean) type",0
"File <*>/site-packages/keras/__init__.py, line 3, in <module> from tensorflow.keras.layers.experimental.preprocessing import RandomRotation ModuleNotFoundError: No module named 'tensorflow.keras.layers.experimental.preprocessing'",0
"File [FILE], line 8, in <module> from keras.models import Sequential File <*>/site-packages/keras/__init__.py, line 6, in <module> 'Keras requires TensorFlow 2.2 or higher. ' ImportError: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow",0
"File [FILE], line 5, in <module>() out = vae.generate(model, mean, var) File <*>/vae.py, line 92, in generate(model, mean, var) out = model.decode(z) File <*>/vae.py, line 58, in decode(self, z) out = self.z_develop(z) File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 722, in _call_impl(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.6/dist-packages/torch/nn/modules/linear.py, line 91, in forward(self, input) return F.linear(input, self.weight, self.bias) File <*>python3.6/dist-packages/torch/nn/functional.py, line 1676, in linear(input, weight, bias) output = input.matmul(weight.t()) RuntimeError: mat1 dim 1 must match mat2 dim 0",0
"File [FILE], line 3, in <module>() loss = keras.losses.categorical_crossentropy() File <*>python3.6/dist-packages/tensorflow/python/util/dispatch.py, line 201, in wrapper(*args, **kwargs) return target(*args, **kwargs) TypeError: categorical_crossentropy() missing 2 required positional arguments: 'y_true' and 'y_pred'",0
"File [FILE], line 29, in <module>() model.add(Bidirectional(LSTM(150, return_sequences=True))) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py, line 180, in assert_input_compatibility(input_spec, inputs, layer_name) str(x.shape.as_list())) ValueError: Input 0 of layer bidirectional is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, 1, 1, 80]",0
"File [FILE], line 1, in <module> batch_first[:,1:].view(-1, embedding) # slicing out the first time step RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",0
"File [FILE], line 1, in <module> import deeplabcut as dlc File <*>python3.7/site-packages/deeplabcut/__init__.py, line 38, in <module> from deeplabcut import generate_training_dataset File <*>python3.7/site-packages/deeplabcut/generate_training_dataset/__init__.py, line 18, in <module> from deeplabcut.generate_training_dataset.labeling_toolbox import * File <*>python3.7/site-packages/deeplabcut/generate_training_dataset/labeling_toolbox.py, line 33, in <module> from deeplabcut.utils import auxiliaryfunctions File <*>python3.7/site-packages/deeplabcut/utils/__init__.py, line 6, in <module> from deeplabcut.utils.make_labeled_video import * File <*>python3.7/site-packages/deeplabcut/utils/make_labeled_video.py, line 28, in <module> from matplotlib.animation import FFMpegWriter File <*>python3.7/site-packages/matplotlib/animation.py, line 737, in <module> class ImageMagickWriter(ImageMagickBase, MovieWriter): File <*>python3.7/site-packages/matplotlib/animation.py, line 120, in wrapper(writerClass) if writerClass.isAvailable(): File <*>python3.7/site-packages/matplotlib/animation.py, line 730, in isAvailable(cls) return super().isAvailable() File <*>python3.7/site-packages/matplotlib/animation.py, line 427, in isAvailable(cls) return shutil.which(cls.bin_path()) is not None File <*>python3.7/site-packages/matplotlib/animation.py, line 724, in bin_path(cls) binpath = mpl._get_executable_info('magick').executable File <*>python3.7/site-packages/matplotlib/__init__.py, line 385, in _get_executable_info(name) return impl([path, ""--version""], r""^Version: ImageMagick (\S*)"") File <*>python3.7/site-packages/matplotlib/__init__.py, line 330, in impl(args, regex, min_ver, ignore_exit_code) raise _cpe File <*>python3.7/site-packages/matplotlib/__init__.py, line 325, in impl(args, regex, min_ver, ignore_exit_code) universal_newlines=True, errors=""replace"") File <*>python3.7/subprocess.py, line 411, in check_output(timeout, *popenargs, **kwargs) **kwargs).stdout File <*>python3.7/subprocess.py, line 512, in run(input, capture_output, timeout, check, *popenargs, **kwargs) output=stdout, stderr=stderr) CalledProcessError: Command '['convert', '--version']' returned non-zero exit status 1.",0
"File [FILE], line 1, in <module>() model.fit([images, negatives], positives, epochs=10, batch_size=8, verbose=2) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 1098, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) tmp_logs = train_function(iterator) File <*>python3.6/dist-packages/tensorflow/python/eager/def_function.py, line 780, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>python3.6/dist-packages/tensorflow/python/eager/def_function.py, line 807, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) # pylint: disable=not-callable TypeError: 'NoneType' object is not callable",0
"File [FILE], line 3, in <module> torch.load(cachefile) File <*>python3.8/site-packages/torch/serialization.py, line 584, in load(f, map_location, pickle_module, **pickle_load_args) return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args) File <*>python3.8/site-packages/torch/serialization.py, line 839, in _load(zip_file, map_location, pickle_module, **pickle_load_args) data_file = io.BytesIO(zip_file.get_record('data.pkl')) RuntimeError: [enforce fail at inline_container.cc:209] . file not found: archive/data.pkl",0
"File [FILE], line 3, in <module> shap_values = explainer.shap_values(X_train) File <*>/site-packages/shap/explainers/deep/__init__.py, line 119, in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity) return self.explainer.shap_values(X, ranked_outputs, output_rank_order, check_additivity=check_additivity) File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 304, in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity) sample_phis = self.run(self.phi_symbolic(feature_ind), self.model_inputs, joint_input) File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 361, in run(self, out, model_inputs, X) return self.execute_with_overridden_gradients(anon) File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 397, in execute_with_overridden_gradients(self, f) out = f() File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 357, in anon() final_out = out(inputs) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 823, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializers) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 696, in _initialize(self, args, kwds, add_initializers_to) self._stateful_fn._get_concrete_function_internal_garbage_collected( # pylint: disable=protected-access File <*>/site-packages/tensorflow/python/eager/function.py, line 2855, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 3213, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 3065, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) func_graph_module.func_graph_from_py_func( File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 986, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 600, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds) File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 973, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e) StagingError: in user code: C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\shap\explainers\deep\deep_tf.py:244 grad_graph * x_grad = tape.gradient(out, shap_rAnD) C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\backprop.py:1067 gradient ** flat_grad = imperative_grad.imperative_grad( C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\imperative_grad.py:71 imperative_grad return pywrap_tfe.TFE_Py_TapeGradient( C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\backprop.py:151 _gradient_function grad_fn = ops._gradient_registry.lookup(op_name) # pylint: disable=protected-access C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\framework\registry.py:96 lookup raise LookupError( LookupError: gradient registry has no entry for: shap_TensorListStack",0
"File [FILE], line 1, in <module>() x = build_img_encod() File <*>python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py, line 166, in assert_input_compatibility(input_spec, inputs, layer_name) if x.shape.ndims is None: AttributeError: 'Functional' object has no attribute 'shape'",0
"File [FILE], line 6, in <module>() validation_data=(x_test, y_test), File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 973, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e) ValueError: in user code: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function * return step_function(self, iterator) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function ** outputs = model.distribute_strategy.run(run_step, args=(data,)) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica return fn(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step ** outputs = model.train_step(data) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step y_pred = self(x, training=True) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__ outputs = call_fn(inputs, *args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call inputs, training=training, mask=mask) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph outputs = node.layer(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__ outputs = call_fn(inputs, *args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py:183 call return self._merge_function(inputs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py:522 _merge_function return K.concatenate(inputs, axis=self.axis) /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper return target(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:2881 concatenate return array_ops.concat([to_dense(x) for x in tensors], axis) /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper return target(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1654 concat return gen_array_ops.concat_v2(values=values, axis=axis, name=name) /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:1222 concat_v2 ""ConcatV2"", values=values, axis=axis, name=name) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper attrs=attr_protos, op_def=op_def) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal compute_device) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3485 _create_op_internal op_def=op_def) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1975 __init__ control_input_ops, op_def) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1815 _create_c_op raise ValueError(str(e)) ValueError: Dimension 2 in both shapes must be equal, but are 512 and 511. Shapes are [?,384,512] and [?,384,511]. for '{{node functional_3/decoder_stage3_concat/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](functional_3/decoder_stage3_upsampling/resize/ResizeNearestNeighbor, functional_3/relu0/Relu, functional_3/decoder_stage3_concat/concat/axis)' with input shapes: [?,384,512,64], [?,384,511,64], [] and with computed input tensors: input[2] = <3>.",0
"File <*>python3.6/dist-packages/tensorflow/python/util/nest.py, line 402, in assert_same_structure(nest1, nest2, check_types, expand_composites) % (str(e), str1, str2)) ValueError: The two structures don't have the same nested structure.",0
"File [FILE], line 49, in <module> logps = model(images) #log probabilities File <*>python3.8/site-packages/torch/nn/modules/container.py, line 117, in forward(self, input) input = module(input) File <*>python3.8/site-packages/torch/nn/modules/module.py, line 727, in _call_impl(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.8/site-packages/torch/nn/modules/linear.py, line 93, in forward(self, input) return F.linear(input, self.weight, self.bias) File <*>python3.8/site-packages/torch/nn/functional.py, line 1690, in linear(input, weight, bias) ret = torch.addmm(bias, input, weight.t()) RuntimeError: expected scalar type Float but found Byte",0
"File [FILE], line 7, in <module>() gen.load_state_dict(torch.load(os.path.join(workspace_dir, 'dcgan_g.pth'))) File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 1052, in load_state_dict(self, state_dict, strict) self.__class__.__name__, ""\n\t"".join(error_msgs))) ***RuntimeError: Error(s) in loading state_dict for Generator: Missing key(s) in state_dict***: ""gen.0.0.weight"", ""gen.0.1.weight"", ""gen.0.1.bias"", ""gen.0.1.running_mean"", ""gen.0.1.running_var"", ""gen.1.0.weight"", ""gen.1.1.weight"", ""gen.1.1.bias"", ""gen.1.1.running_mean"", ""gen.1.1.running_var"", ""gen.2.0.weight"", ""gen.2.1.weight"", ""gen.2.1.bias"", ""gen.2.1.running_mean"", ""gen.2.1.running_var"", ""gen.3.0.weight"", ""gen.3.1.weight"", ""gen.3.1.bias"", ""gen.3.1.running_mean"", ""gen.3.1.running_var"", ""gen.4.weight"", ""gen.4.bias"". Unexpected key(s) in state_dict: ""disc.0.weight"", ""disc.0.bias"", ""disc.2.0.weight"", ""disc.2.1.weight"", ""disc.2.1.bias"", ""disc.2.1.running_mean"", ""disc.2.1.running_var"", ""disc.2.1.num_batches_tracked"", ""disc.3.0.weight"", ""disc.3.1.weight"", ""disc.3.1.bias"", ""disc.3.1.running_mean"", ""disc.3.1.running_var"", ""disc.3.1.num_batches_tracked"", ""disc.4.0.weight"", ""disc.4.1.weight"", ""disc.4.1.bias"", ""disc.4.1.running_mean"", ""disc.4.1.running_var"", ""disc.4.1.num_batches_tracked"", ""disc.5.weight"", ""disc.5.bias"".",0
"File [FILE], line 8, in <module> optimization.train(x_train, y_train, x_val, y_val, File [FILE], line 70, in train(self, x_train, y_train, x_val, y_val, batch_size, n_epochs, dropout, do_teacher_forcing) y_pred = self._predict(x_batch, y_batch, seq_len, do_teacher_forcing) File [FILE], line 95, in _predict(self, x_batch, y_batch, seq_len, do_teacher_forcing) y_pred = self.model(x_batch) File [FILE], line 19, in forward(self, input, future, y) h_t, c_t = self.lstm(input_t, (h_t, c_t)) File <*>/site-packages/torch/nn/modules/module.py, line 727, in _call_impl(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>/site-packages/torch/nn/modules/rnn.py, line 965, in forward(self, input, hx) self.check_forward_input(input) File <*>/site-packages/torch/nn/modules/rnn.py, line 791, in check_forward_input(self, input) raise RuntimeError( RuntimeError: input has inconsistent input_size: got 1, expected 3",0
"File [FILE], line 8, in <module> model.save(""temp_model"") File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1979, in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options) signatures, options) File <*>/site-packages/tensorflow/python/keras/saving/save.py, line 134, in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options) signatures, options) File <*>/site-packages/tensorflow/python/keras/saving/saved_model/save.py, line 80, in save(model, filepath, overwrite, include_optimizer, signatures, options) save_lib.save(model, filepath, signatures, options) File <*>/site-packages/tensorflow/python/saved_model/save.py, line 976, in save(obj, export_dir, signatures, options) obj, export_dir, signatures, options, meta_graph_def) File <*>/site-packages/tensorflow/python/saved_model/save.py, line 1061, in _build_meta_graph(obj, export_dir, signatures, options, meta_graph_def) _ = _SaveableView(checkpoint_graph_view) File <*>/site-packages/tensorflow/python/saved_model/save.py, line 178, in __init__(self, checkpoint_view, wrapped_functions) self.checkpoint_view.objects_ids_and_slot_variables()) File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 426, in objects_ids_and_slot_variables(self) object_names[obj] = _object_prefix_from_path(path) File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 64, in _object_prefix_from_path(path_to_root) for trackable in path_to_root)) File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 64, in <genexpr>(.0) for trackable in path_to_root)) File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 57, in _escape_local_name(name) return (name.replace(_ESCAPE_CHAR, _ESCAPE_CHAR + _ESCAPE_CHAR) AttributeError: 'NoneType' object has no attribute 'replace'",0
"File <*>python3.6/dist-packages/optkeras/optkeras.py, line 230, in synch_with_optuna(self) self.best_trial = self.study.best_trial ValueError: No trials are completed yet.",0
"File [FILE], line 16, in <module>() results = p.map(X_power_func, range(8)) File <*>python3.6/pool.py, line 644, in get(self, timeout) raise self._value RuntimeError: CUDA error: initialization error",0
"File [FILE], line 7, in <module>() validation_steps = valid_step , callbacks = [metrics], verbose=2) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 673, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 1433, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch') File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py, line 331, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) callbacks.on_epoch_end(epoch, epoch_logs) File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 311, in on_epoch_end(self, epoch, logs) callback.on_epoch_end(epoch, logs) File [FILE], line 16, in on_epoch_end(self, batch, logs) X_val, y_val = self.validation_data[0], self.validation_data[1] TypeError: 'NoneType' object is not subscriptable",0
"File [FILE], line 7, in <module>() validation_steps = valid_step , callbacks = [metrics], verbose=2) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 673, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 1433, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch') File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py, line 260, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) callbacks._call_batch_hook(mode, 'begin', step, batch_logs) File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 247, in _call_batch_hook(self, mode, hook, batch, logs) batch_hook = getattr(callback, hook_name) AttributeError: 'Metrics' object has no attribute 'on_train_batch_begin'",0
"File [FILE], line 49, in <module>() for images, labels in myTrain_dataloader: File <*>python3.6/dist-packages/torch/utils/data/dataloader.py, line 819, in __next__(self) return self._process_data(data) File <*>python3.6/dist-packages/torch/utils/data/dataloader.py, line 846, in _process_data(self, data) data.reraise() File <*>python3.6/dist-packages/torch/_utils.py, line 385, in reraise(self) raise self.exc_type(msg) RuntimeError: Caught RuntimeError in DataLoader worker process 0.",0
