Templates,label
"File <stdin>, line 1, in <module> [CODE] File <*>python2.7/site-packages/tensorflow/__init__.py, line 4, in <module> from tensorflow.python import * File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 13, in <module> from tensorflow.core.framework.graph_pb2 import * File <*>python2.7/site-packages/tensorflow/core/framework/graph_pb2.py, line 16, in <module> from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2 File <*>python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py, line 16, in <module> from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2 File <*>python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py, line 16, in <module> from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2 File <*>python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py, line 22, in <module> serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto \x12\ntensorflow\""d\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tb\x06proto3') TypeError: __init__() got an unexpected keyword argument 'syntax'",1
"File classify.py, line 14, in <module> import caffe File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver File <*>/pycaffe.py, line 13, in <module> from ._caffe import Net, SGDSolver ImportError: dynamic module does not define module export function (PyInit__caffe)",1
"File <stdin>, line 1, in <module> [CODE] File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import * File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 48, in <module> from tensorflow.python import pywrap_tensorflow File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper() File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description) ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.19' not found (required by /home/anirudh/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so)",1
"File <*>/census.py, line 73, in <module> df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int) File <*>python2.7/dist-packages/pandas/core/series.py, line 2023, in apply mapped = lib.map_infer(values, f, convert=convert_dtype) File inference.pyx, line 920, in pandas.lib.map_infer (pandas/lib.c:44780) File <*>/census.py, line 73, in <lambda> df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int) TypeError: argument of type 'float' is not iterable",1
"File [FILE], line 1, in <module>() writer = tf.train.SummaryWriter('./my_graph', sess.graph) AttributeError: 'module' object has no attribute 'SummaryWriter'",1
"File <stdin>, line 1, in <module> [CODE] AttributeError: 'module' object has no attribute 'FileWriter'",1
"File mnist_test.py, line 19, in <module> cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_, logits=y) TypeError: sigmoid_cross_entropy_with_logits() got an unexpected keyword argument 'labels'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in () from tensorflow.python.pywrap_tensorflow_internal import * File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in () _pywrap_tensorflow_internal = swig_import_helper() File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper() return importlib.import_module('_pywrap_tensorflow_internal' ) File <*>/importlib__init__.py, line 126, in import_module(name, pac kage) return _bootstrap._gcd_import(name[level:], package, level) ImportError: No module named '_pywrap_tensorflow_internal'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in from tensorflow.python.pywrap_tensorflow_internal import * File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in _pywrap_tensorflow_internal = swig_import_helper() File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal') File <*>/importlib__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) ImportError: No module named '_pywrap_tensorflow_internal'",1
"File <*>python2.7/runpy.py, line 174, in _run_module_as_main ""__main__"", fname, loader, pkg_name) File <*>python2.7/runpy.py, line 72, in _run_code exec code in run_globals File <*>python2.7/site-packages/object_detection/train.py, line 49, in <module> from object_detection import trainer File <*>python2.7/site-packages/object_detection/trainer.py, line 27, in <module> from object_detection.builders import preprocessor_builder File <*>python2.7/site-packages/object_detection/builders/preprocessor_builder.py, line 21, in <module> from object_detection.protos import preprocessor_pb2 File <*>python2.7/site-packages/object_detection/protos/preprocessor_pb2.py, line 71, in <module> options=None, file=DESCRIPTOR), TypeError: __new__() got an unexpected keyword argument 'file'",1
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 14, in swig_import_helper return importlib.import_module(mname) File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File <frozen importlib._bootstrap>, line 994, in _gcd_import [CODE] File <frozen importlib._bootstrap>, line 971, in _find_and_load [CODE] File <frozen importlib._bootstrap>, line 955, in _find_and_load_unlocked [CODE] File <frozen importlib._bootstrap>, line 658, in _load_unlocked [CODE] File <frozen importlib._bootstrap>, line 571, in module_from_spec [CODE] File <frozen importlib._bootstrap_external>, line 922, in create_module [CODE] File <frozen importlib._bootstrap>, line 219, in _call_with_frames_removed [CODE] ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.",1
"File <stdin>, line 1, in <module> [CODE] File <*>python3.7/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import File <*>python3.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 114, in [FUNC] [CODE] SyntaxError: invalid syntax",1
"File <input>, line 3, in <module> [CODE] AttributeError: 'Tensor' object has no attribute '_keras_shape'",1
"File <*>/test_callback.py, line 34, in <module> model.evaluate_generator(generator=test_generator, steps=STEP_SIZE_TEST, callbacks=[test_callback]) File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs) TypeError: evaluate_generator() got an unexpected keyword argument 'callbacks'",1
"File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File <*>python3.6/imp.py, line 243, in load_module return load_dynamic(name, filename, file) File <*>python3.6/imp.py, line 343, in load_dynamic return _load(spec) ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory",1
"File <*>/train.py, line 7, in <module> import models as m File <*>/models.py, line 25, in <module> K.set_image_dim_ordering('th') AttributeError: module 'tensorflow.python.keras.api._v2.keras.backend' has no attribute 'set_image_dim_ordering'",1
"File train_initialize.py, line 18, in agent = Agent(""horoscope_domain.yml"", policies = [MemoizationPolicy(), KerasPolicy()]) File <*>/site-packages/rasa_core/policies/keras_policy.py, line 31, in init if KerasPolicy.is_using_tensorflow() and not graph: File <*>/site-packages/rasa_core/policies/keras_policy.py, line 48, in is_using_tensorflow return keras.backend._BACKEND == ""tensorflow"" AttributeError: module 'keras.backend' has no attribute '_BACKEND'",1
"File <stdin>, line 1, in <module> [CODE] File <*>python3.6/site-packages/deepposekit/__init__.py, line 20, in <module> from deepposekit.io import TrainingGenerator, DataGenerator File <*>python3.6/site-packages/deepposekit/io/__init__.py, line 18, in <module> from deepposekit.io.BaseGenerator import BaseGenerator File <*>python3.6/site-packages/deepposekit/io/BaseGenerator.py, line 16, in <module> from tensorflow.keras.utils import Sequence ModuleNotFoundError: No module named 'tensorflow'",1
"File <*>/model_loggingfinal.py, line 35, in <module> callbacks=[logger] File <*>python3.7/site-packages/keras/engine/training.py, line 1239, in fit validation_freq=validation_freq) File <*>python3.7/site-packages/keras/engine/training_arrays.py, line 119, in fit_loop callbacks.set_model(callback_model) File <*>python3.7/site-packages/keras/callbacks/callbacks.py, line 68, in set_model callback.set_model(model) File <*>python3.7/site-packages/keras/callbacks/tensorboard_v2.py, line 116, in set_model super(TensorBoard, self).set_model(model) File <*>python3.7/site-packages/tensorflow_core/python/keras/callbacks.py, line 1532, in set_model self.log_dir, self.model._get_distribution_strategy()) # pylint: disable=protected-access AttributeError: 'Sequential' object has no attribute '_get_distribution_strategy'",1
"File [FILE], line 8, in <module> trainer.trainModel() File <*>python3.6/site-packages/imageai/Detection/Custom/__init__.py, line 274, in trainModel(self) class_scale=self.__train_class_scale, File <*>python3.6/site-packages/imageai/Detection/Custom/__init__.py, line 553, in _create_model(self, nb_class, anchors, max_box_per_image, max_grid, batch_size, warmup_batches, ignore_thresh, multi_gpu, lr, grid_scales, obj_scale, noobj_scale, xywh_scale, class_scale) class_scale=class_scale File <*>python3.6/site-packages/imageai/Detection/Custom/yolo.py, line 294, in create_yolov3_model(nb_class, anchors, max_box_per_image, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scales, obj_scale, noobj_scale, xywh_scale, class_scale) class_scale)([input_image, pred_yolo_1, true_yolo_1, true_boxes]) File <*>python3.6/site-packages/imageai/Detection/Custom/yolo.py, line 24, in __init__(self, anchors, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scale, obj_scale, noobj_scale, xywh_scale, class_scale, **kwargs) cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(max_grid_w), [max_grid_h]), (1, max_grid_h, max_grid_w, 1, 1))) AttributeError: module 'tensorflow' has no attribute 'to_float'",1
"File <*>python3.6/dist-packages/fastai/data_block.py, line 594, in _check_kwargs(ds, tfms, **kwargs) try: x.apply_tfms(tfms, **kwargs) File <*>python3.6/dist-packages/fastai/vision/image.py, line 123, in apply_tfms(self, tfms, do_resolve, xtra, size, resize_method, mult, padding_mode, mode, remove_out) else: x = tfm(x) File <*>python3.6/dist-packages/fastai/vision/image.py, line 524, in __call__(self, x, *args, **kwargs) return self.tfm(x, *args, **{**self.resolved, **kwargs}) if self.do_run else x File <*>python3.6/dist-packages/fastai/vision/image.py, line 470, in __call__(self, p, is_random, use_on_y, *args, **kwargs) if args: return self.calc(*args, **kwargs) File <*>python3.6/dist-packages/fastai/vision/image.py, line 475, in calc(self, x, *args, **kwargs) if self._wrap: return getattr(x, self._wrap)(self.func, *args, **kwargs) File <*>python3.6/dist-packages/fastai/vision/image.py, line 183, in affine(self, func, *args, **kwargs) self.affine_mat = self.affine_mat @ m RuntimeError: Expected object of scalar type Float but got scalar type Double for argument #3 'mat2' in call to _th_addmm_out",1
"File <*>/test.py, line 13, in <module> lstm = Bidirectional(lstm_nobi, name=""layerC"")(embedding_layer) File <*>python3.9/site-packages/tensorflow/python/keras/layers/wrappers.py, line 539, in __call__ return super(Bidirectional, self).__call__(inputs, **kwargs) File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 951, in __call__ return self._functional_construction_call(inputs, args, kwargs, File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1090, in _functional_construction_call outputs = self._keras_tensor_symbolic_call( File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 822, in _keras_tensor_symbolic_call return self._infer_output_signature(inputs, args, kwargs, input_masks) File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 863, in _infer_output_signature outputs = call_fn(inputs, *args, **kwargs) File <*>python3.9/site-packages/tensorflow/python/keras/layers/wrappers.py, line 652, in call y = self.forward_layer(forward_inputs, File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 660, in __call__ return super(RNN, self).__call__(inputs, **kwargs) File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1012, in __call__ outputs = call_fn(inputs, *args, **kwargs) File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py, line 1157, in call inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None) File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 859, in _process_inputs initial_state = self.get_initial_state(inputs) File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 642, in get_initial_state init_state = get_initial_state_fn( File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 2506, in get_initial_state return list(_generate_zero_filled_state_for_cell( File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 2987, in _generate_zero_filled_state_for_cell return _generate_zero_filled_state(batch_size, cell.state_size, dtype) File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 3003, in _generate_zero_filled_state return nest.map_structure(create_zeros, state_size) File <*>python3.9/site-packages/tensorflow/python/util/nest.py, line 659, in map_structure structure[0], [func(*x) for x in entries], File <*>python3.9/site-packages/tensorflow/python/util/nest.py, line 659, in <listcomp> structure[0], [func(*x) for x in entries], File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 3000, in create_zeros return array_ops.zeros(init_state_size, dtype=dtype) File <*>python3.9/site-packages/tensorflow/python/util/dispatch.py, line 201, in wrapper return target(*args, **kwargs) File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2819, in wrapped tensor = fun(*args, **kwargs) File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2868, in zeros output = _constant_if_small(zero, shape, dtype, name) File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2804, in _constant_if_small if np.prod(shape) < 1000: File <__array_function__ internals>, line 5, in prod [CODE] File <*>python3.9/site-packages/numpy/core/fromnumeric.py, line 3030, in prod return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out, File <*>python3.9/site-packages/numpy/core/fromnumeric.py, line 87, in _wrapreduction return ufunc.reduce(obj, axis, dtype, out, **passkwargs) File <*>python3.9/site-packages/tensorflow/python/framework/ops.py, line 852, in __array__ raise NotImplementedError( NotImplementedError: Cannot convert a symbolic Tensor (layerC/forward_layerB/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",1
"File train.py, line 29, in <module> policy = tf.keras.mixed_precision.Policy('mixed_float16') AttributeError: module 'tensorflow.keras.mixed_precision' has no attribute 'Policy'",1
"File <*>/CNN_Image_Denoising.py, line 15, in <module> from keras.optimizers import SGD, Adam ImportError: cannot import name 'SGD' from 'keras.optimizers'",1
"File <*>/script.py, line 654, in <module> prediction_result, (r, t) = cf.to(model_runner.predict(processed_feature_dict, random_seed=seed), ""cpu"") File <*>python3.7/site-packages/alphafold/model/model.py, line 134, in predict result, recycles = self.apply(self.params, jax.random.PRNGKey(random_seed), feat) File <*>python3.7/site-packages/jax/_src/traceback_util.py, line 183, in reraise_with_filtered_traceback return fun(*args, **kwargs) File <*>python3.7/site-packages/jax/_src/api.py, line 402, in cache_miss donated_invars=donated_invars, inline=inline) File <*>python3.7/site-packages/jax/core.py, line 1561, in bind return call_bind(self, fun, *args, **params) File <*>python3.7/site-packages/jax/core.py, line 1552, in call_bind outs = primitive.process(top_trace, fun, tracers, params) File <*>python3.7/site-packages/jax/core.py, line 1564, in process return trace.process_call(self, fun, tracers, params) File <*>python3.7/site-packages/jax/core.py, line 607, in process_call return primitive.impl(f, *tracers, **params) File <*>python3.7/site-packages/jax/interpreters/xla.py, line 608, in _xla_call_impl *unsafe_map(arg_spec, args)) File <*>python3.7/site-packages/jax/, line 262, in memoized_fun ans = call(fun, *args) File <*>python3.7/site-packages/jax/interpreters/xla.py, line 758, in _xla_callable compiled = compile_or_get_cached(backend, built, options) File env/lib/python3.7/site-packages/jax/interpreters/xla.py, line 76, in compile_or_get_cached return backend_compile(backend, computation, compile_options)",1
"File <*>/site-packages/theano/configparser.py, line 327, in __get__ val_str = fetch_val_for_key(self.fullname, File <*>/site-packages/theano/configparser.py, line 172, in fetch_val_for_key raise KeyError(key) KeyError: 'blas.ldflags'",1
"File [FILE], line 3, in <module>() from keras.applications.resnet50 import preprocess_input, ResNet50 ModuleNotFoundError: No module named 'keras.applications.resnet50'",1
"File <*>/ai.py, line 15, in <module> from keras.models import Sequential, load_model File <*>/site-packages/keras/__init__.py, line 24, in <module> from keras import models File <*>/site-packages/keras/models/__init__.py, line 18, in <module> from keras.engine.functional import Functional File <*>/site-packages/keras/engine/functional.py, line 24, in <module> from keras.dtensor import layout_map as layout_map_lib File <*>/site-packages/keras/dtensor/__init__.py, line 22, in <module> from tensorflow.compat.v2.experimental import dtensor as dtensor_api # pylint: disable=g-import-not-at-top ImportError: cannot import name 'dtensor' from 'tensorflow.compat.v2.experimental' (C:\Users\Fynn\AppData\Local\Programs\Python\Python39\lib\site-packages\tensorflow\_api\v2\compat\v2\experimental\__init__.py)",1
"File <*>/output.py, line 13, in <module> import caffe File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver File <*>/pycaffe.py, line 10, in <module> from ._caffe import Net, SGDSolver ImportError: No module named _caffe",0
"File <stdin>, line 1, in <module> [CODE] ImportError: No module named deepdish",0
"File <*>python2.7/site-packages/pip/basecommand.py, line 211, in main status = self.run(options, args) File <*>python2.7/site-packages/pip/commands/install.py, line 311, in run root=options.root_path, File <*>python2.7/site-packages/pip/req/req_set.py, line 640, in install requirement.uninstall(auto_confirm=True) File <*>python2.7/site-packages/pip/req/req_install.py, line 716, in uninstall paths_to_remove.remove(auto_confirm) File <*>python2.7/site-packages/pip/req/req_uninstall.py, line 125, in remove renames(path, new_path) File <*>python2.7/site-packages/pip/utils/__init__.py, line 315, in renames shutil.move(old, new) File <*>python2.7/shutil.py, line 303, in move os.unlink(src) OSError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/site-packages/six-1.9.0.dist-info/DESCRIPTION.rst'",0
"File <*>/translate.py, line 28, in <module> from tensorflow.models.rnn.translate import data_utils ImportError: No module named translate",0
"File <*>/convolutional.py, line 133, in <module> train_accuracy = accuracy.eval(feed_dict = {x: batch[0], y_: batch[1], keep_prob: 1.0}) File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 405, in eval return _eval_using_default_session(self, feed_dict, self.graph, session) File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 2728, in _eval_using_default_session return session.run(tensors, feed_dict) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 345, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 419, in _do_run e.code) tensorflow.python.framework.errors.InvalidArgumentError: Incompatible shapes: [8] vs. [20] [[Node: Equal = Equal[T=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](ArgMax, ArgMax_1)]]",0
"File <*>/convolutional_network_batch_2d2c_clean_64f.py, line 213, in <module> pred = conv_net(x, weights, biases, keep_prob) File <*>/convolutional_network_batch_2d2c_clean_64f.py, line 153, in conv_net conv1 = max_pool(conv1, k=2) # Normally K=2 File <*>/convolutional_network_batch_2d2c_clean_64f.py, line 135, in max_pool return tf.nn.max_pool(img, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME') File <*>python2.7/site-packages/tensorflow/python/ops/nn_ops.py, line 235, in max_pool name=name) File <*>python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 449, in _max_pool strides=strides, padding=padding, name=name) File <*>python2.7/site-packages/tensorflow/python/ops/op_def_library.py, line 430, in apply_op (prefix, dtypes.as_dtype(input_arg.type).name)) TypeError: Input 'input' of 'MaxPool' Op has type float64 that does not match expected type of float32.",0
"File [FILE], line <*>, in [FUNC] [CODE] File <*>/site-packages/nolearn/lasagne/base.py, line 457, in fit self.initialize() File <*>/site-packages/nolearn/lasagne/base.py, line 303, in initialize self.y_tensor_type, File <*>/site-packages/nolearn/lasagne/base.py, line 435, in _create_iter_funcs allow_input_downcast=True, File <*>/site-packages/theano/compile/function.py, line 317, in function output_keys=output_keys) File <*>/site-packages/theano/compile/pfunc.py, line 526, in pfunc output_keys=output_keys) File <*>/site-packages/theano/compile/function_module.py, line 1778, in orig_function defaults) File <*>/site-packages/theano/compile/function_module.py, line 1642, in create input_storage=input_storage_lists, storage_map=storage_map) File <*>/site-packages/theano/gof/link.py, line 690, in make_thunk storage_map=storage_map)[:3] File <*>/site-packages/theano/gof/vm.py, line 1037, in make_all no_recycling)) File <*>/site-packages/theano/gof/op.py, line 932, in make_thunk no_recycling) File <*>/site-packages/theano/gof/op.py, line 850, in make_c_thunk output_storage=node_output_storage) File <*>/site-packages/theano/gof/cc.py, line 1207, in make_thunk keep_lock=keep_lock) File <*>/site-packages/theano/gof/cc.py, line 1152, in __compile__ keep_lock=keep_lock) File <*>/site-packages/theano/gof/cc.py, line 1602, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock) File <*>/site-packages/theano/gof/cmodule.py, line 1174, in module_from_key module = lnk.compile_cmodule(location) File <*>/site-packages/theano/gof/cc.py, line 1513, in compile_cmodule preargs=preargs) File <*>/site-packages/theano/gof/cmodule.py, line 2187, in compile_str (status, compile_stderr.replace('\n', '. '))) Exception: ('The following error happened while compiling the node', CorrMM{valid, (1, 1)}(input.input, Subtensor{::, ::, ::int64, ::int64}.0), '\n', ""Compilation failed (return status=1): C:\\Users\\Michal\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64\\tmpgdh7ov2i\\mod.cpp: In member function 'int {anonymous}::__struct_compiled_op_mf217e5b3a6b61b4ef70844368439f6cb::run()':\r. C:\\Users\\Michal\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64\\tmpgdh7ov2i\\mod.cpp:947:16: warning: converting to non-pointer type 'int' from NULL [-Wconversion-null]\r. kH = NULL;\r. ^\r. C:\\Users\\Michal\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64\\tmpgdh7ov2i\\mod.cpp:958:16: warning: converting to non-pointer type 'int' from NULL [-Wconversion-null]\r. kW = NULL;\r. ^\r. C:\\Users\\Michal\\AppData\\Local\\Temp\\cc67su6o.o: In function `corrMM(tagPyArrayObject*, tagPyArrayObject*, tagPyArrayObject*, int, int, int, int, int)':\r. C:/Users/Michal/AppData/Local/Theano/compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64/tmpgdh7ov2i/mod.cpp:431: undefined reference to `dgemm_'\r. C:/Users/Michal/AppData/Local/Theano/compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64/tmpgdh7ov2i/mod.cpp:528: undefined reference to `dgemm_'\r. C:/Users/Michal/AppData/Local/Theano/compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64/tmpgdh7ov2i/mod.cpp:483: undefined reference to `dgemm_'\r. collect2.exe: error: ld returned 1 exit status\r. "", '[CorrMM{valid, (1, 1)}(input.input, )]')",0
"File cifar10.py, line 54, in <module> """"""Number of images to process in a batch."""""") File <*>python2.7/site-packages/tensorflow/python/platform/default/_flags.py, line 86, in DEFINE_integer _define_helper(flag_name, default_value, docstring, int) File <*>python2.7/site-packages/tensorflow/python/platform/default/_flags.py, line 60, in _define_helper type=flagtype) File <*>python2.7/argparse.py, line 1297, in add_argument return self._add_action(action) File <*>python2.7/argparse.py, line 1671, in _add_action self._optionals._add_action(action) File <*>python2.7/argparse.py, line 1498, in _add_action action = super(_ArgumentGroup, self)._add_action(action) File <*>python2.7/argparse.py, line 1311, in _add_action self._check_conflict(action) File <*>python2.7/argparse.py, line 1449, in _check_conflict conflict_handler(action, confl_optionals) File <*>python2.7/argparse.py, line 1456, in _handle_conflict_error raise ArgumentError(action, message % conflict_string) argparse.ArgumentError: argument --batch_size: conflicting option string(s): --batch_size",0
"File <ipython-input-1-adf2ca85bb77>, line 1, in <module> runfile('/home/kang/Documents/work_code_PC1/py_tensorflow_learning/cifar10CNN_test/cifar10_eval_test.py', wdir='/home/kang/Documents/work_code_PC1/py_tensorflow_learning/cifar10CNN_test') File <*>python3/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 685, in runfile execfile(filename, namespace) File <*>python3/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 85, in execfile exec(compile(open(filename, 'rb').read(), filename, 'exec'), namespace) File <*>/cifar10_eval_test.py, line 107, in <module> tf.app.run() File <*>python3.4/dist-packages/tensorflow/python/platform/default/_app.py, line 30, in run sys.exit(main(sys.argv)) File <*>/cifar10_eval_test.py, line 104, in main evaluate() File <*>/cifar10_eval_test.py, line 94, in evaluate eval_once(saver, summary_writer, top_k_op, summary_op) File <*>/cifar10_eval_test.py, line 72, in eval_once coord.join(threads, stop_grace_period_secs = 10) File <*>python3.4/dist-packages/tensorflow/python/training/coordinator.py, line 264, in join six.reraise(*self._exc_info_to_raise) File <*>python3/dist-packages/six.py, line 659, in reraise raise value File <*>python3.4/dist-packages/tensorflow/python/training/queue_runner.py, line 185, in _run sess.run(enqueue_op) File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 315, in run return self._run(None, fetches, feed_dict) File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 473, in _run raise RuntimeError('Attempted to use a closed Session.') RuntimeError: Attempted to use a closed Session.",0
"File trainer_deepMnist.py, line 109, in <module> x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})) File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 559, in eval return _eval_using_default_session(self, feed_dict, self.graph, session) File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 3648, in _eval_using_default_session return session.run(tensors, feed_dict) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 710, in run run_metadata_ptr) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 908, in _run feed_dict_string, options, run_metadata) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 958, in _do_run target_list, options, run_metadata) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 978, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[10000,32,28,28] [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Reshape, Variable_2/read)]]",0
"File <*>/xxx.py, line 262, in <module> model.add(SimpleRNN(output_dim=vocab_size, input_shape=train_x.shape)) File <*>/site-packages/keras/models.py, line 275, in add layer.create_input_layer(batch_input_shape, input_dtype) File <*>/site-packages/keras/engine/topology.py, line 367, in create_input_layer self(x) File <*>/site-packages/keras/engine/topology.py, line 467, in __call__ self.assert_input_compatibility(x) File <*>/site-packages/keras/engine/topology.py, line 408, in assert_input_compatibility str(K.ndim(x))) Exception: Input 0 is incompatible with layer simplernn_1: expected ndim=3, found ndim=4",0
"File <*>python2.7/site-packages/theano/sandbox/gpuarray/__init__.py, line 20, in <module> import pygpu File <*>/__init__.py, line 7, in <module> from . import gpuarray, elemwise, reduction File <*>/elemwise.py, line 3, in <module> from .dtypes import dtype_to_ctype, get_common_dtype File <*>/dtypes.py, line 6, in <module> from . import gpuarray ImportError: cannot import name gpuarray",0
"File <*>/mlp_.py, line 152, in <module> train_auc = sess.run(auc, feed_dict={X: batch_xs, y: batch_ys, dropout_keep_prob:1.}) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 372, in run run_metadata_ptr) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 636, in _run feed_dict_string, options, run_metadata) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 708, in _do_run target_list, options, run_metadata) File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 728, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value auc/false_positives [[Node: auc/false_positives/read = Identity[T=DT_FLOAT, _class=[""loc:@auc/false_positives""], _device=""/job:localhost/replica:0/task:0/cpu:0""](auc/false_positives)]]",0
"File dummy.py, line 16, in <module> features = tf.pack([col1, col2, col3]) File <*>python2.7/dist-packages/tensorflow/python/ops/array_ops.py, line 487, in pack return gen_array_ops._pack(values, axis=axis, name=name) File <*>python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py, line 1462, in _pack result = _op_def_lib.apply_op(""Pack"", values=values, axis=axis, name=name) File <*>python2.7/dist-packages/tensorflow/python/framework/op_def_library.py, line 437, in apply_op raise TypeError(""%s that don't all match."" % prefix) TypeError: Tensors in list passed to 'values' of 'Pack' Op have types [int32, int32, float32] that don't all match.",0
"File <*>/__init__.py, line 79, in <module> model = baseline_model() File <*>/training_module.py, line 31, in baseline_model model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(3, IMG_WIDTH, IMG_HEIGHT))) File <*>python2.7/site-packages/keras/models.py, line 276, in add layer.create_input_layer(batch_input_shape, input_dtype) File <*>python2.7/site-packages/keras/engine/topology.py, line 370, in create_input_layer self(x) File <*>python2.7/site-packages/keras/engine/topology.py, line 514, in __call__ self.add_inbound_node(inbound_layers, node_indices, tensor_indices) File <*>python2.7/site-packages/keras/engine/topology.py, line 572, in add_inbound_node Node.create_node(self, inbound_layers, node_indices, tensor_indices) File <*>python2.7/site-packages/keras/engine/topology.py, line 149, in create_node output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0])) File <*>python2.7/site-packages/keras/layers/convolutional.py, line 466, in call filter_shape=self.W_shape) File <*>python2.7/site-packages/keras/backend/tensorflow_backend.py, line 1579, in conv2d x = tf.nn.conv2d(x, kernel, strides, padding=padding) File <*>python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 394, in conv2d data_format=data_format, name=name) File <*>python2.7/site-packages/tensorflow/python/framework/op_def_library.py, line 703, in apply_op op_def=op_def) File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 2319, in create_op set_shapes_for_outputs(ret) File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 1711, in set_shapes_for_outputs shapes = shape_func(op) File <*>python2.7/site-packages/tensorflow/python/framework/common_shapes.py, line 246, in conv2d_shape padding) File <*>python2.7/site-packages/tensorflow/python/framework/common_shapes.py, line 184, in get2d_conv_output_size (row_stride, col_stride), padding_type) File <*>python2.7/site-packages/tensorflow/python/framework/common_shapes.py, line 149, in get_conv_output_size ""Filter: %r Input: %r"" % (filter_size, input_size)) ValueError: Filter must not be larger than the input: Filter: (5, 5) Input: (3, 350)",0
"File <*>python2.7/dist-packages/django/core/handlers/base.py, line 149, in get_response response = self.process_exception_by_middleware(e, request) File <*>python2.7/dist-packages/django/core/handlers/base.py, line 147, in get_response response = wrapped_callback(request, *callback_args, **callback_kwargs) File <*>/views.py, line 27, in home output=loaded_model.predict(img_np) File <*>python2.7/dist-packages/keras/models.py, line 671, in predict return self.model.predict(x, batch_size=batch_size, verbose=verbose) File <*>python2.7/dist-packages/keras/engine/training.py, line 1161, in predict check_batch_dim=False) File <*>python2.7/dist-packages/keras/engine/training.py, line 108, in standardize_input_data str(array.shape)) Exception: Error when checking : expected dense_input_1 to have shape (None, 784) but got array with shape (784, 1)",0
"File add_1.py, line 13, in <module> saver = tf.train.Saver([y]) raise TypeError(""Variable to save is not a Variable: %s"" % var) TypeError: Variable to save is not a Variable: Tensor(""add_3:0"", shape=(), dtype=int32, device=/job:local/task:3)",0
"File convolutional.py, line 339, in <module> tf.app.run(main=main, argv=[sys.argv[0]] + unparsed) File <*>python2.7/dist-packages/tensorflow/python/platform/app.py, line 44, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough)) File convolutional.py, line 284, in main with tf.Session() as sess: File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 1187, in __init__ super(Session, self).__init__(target, graph, config=config) File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 552, in __init__ self._session = tf_session.TF_NewDeprecatedSession(opts, status) File <*>python2.7/contextlib.py, line 24, in __exit__ self.gen.next() File <*>python2.7/dist-packages/tensorflow/python/framework/errors_impl.py, line 469, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors_impl.InternalError: Failed to create session.",0
"File board.py, line 3, in <module> mnist = input_data.read_data_sets(r'Z:/downloads/MNIST dataset', one_hot=True) File <*>/input_data.py, line 150, in read_data_sets train_images = extract_images(local_file) File <*>/input_data.py, line 40, in extract_images buf = bytestream.read(rows * cols * num_images) File <*>/gzip.py, line 274, in read return self._buffer.read(size) TypeError: only integer scalar arrays can be converted to a scalar index",0
"File helloWorld.py, line 10, in <module> import matplotlib.pyplot as plt ImportError: No module named 'matplotlib'",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call return fn(*args) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1293, in _run_fn self._extend_graph() File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1354, in _extend_graph self._session, graph_def.SerializeToString(), status) File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.UnavailableError: Trying to connect an http1.x server",0
"File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 62, in _pin_memory_loop batch = pin_memory_batch(batch) File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 123, in pin_memory_batch return [pin_memory_batch(sample) for sample in batch] File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 123, in <listcomp> return [pin_memory_batch(sample) for sample in batch] File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 117, in pin_memory_batch return batch.pin_memory() File <*>python3.6/site-packages/torch/tensor.py, line 82, in pin_memory return type(self)().set_(storage.pin_memory()).view_as(self) File <*>python3.6/site-packages/torch/storage.py, line 83, in pin_memory allocator = torch.cuda._host_allocator() File <*>python3.6/site-packages/torch/cuda/__init__.py, line 220, in _host_allocator _lazy_init() File <*>python3.6/site-packages/torch/cuda/__init__.py, line 84, in _lazy_init _check_driver() File <*>python3.6/site-packages/torch/cuda/__init__.py, line 51, in _check_driver raise AssertionError(""Torch not compiled with CUDA enabled"") AssertionError: Torch not compiled with CUDA enabled",0
"File SAMME_train_all.py, line 47, in <module> ce = K.categorical_crossentropy(label, label_pred) File <*>/tensorflow_backend.py, line 2754, in categorical_c axis=len(output.get_shape()) - 1, AttributeError: 'numpy.ndarray' object has no attribute 'get_shape'",0
"File <*>/main.py, line 89, in <module> _ = sess.run([update_step]) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[500,80] [[Node: decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](decoder/while/BasicDecoderStep/basic_lstm_cell/concat, decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul/Enter)]] [[Node: gradients/Add/_282 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_457_gradients/Add"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](^_cloopdecoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y/_181)]]",0
"File <ipython-input-6-06fadd69ae8f>, line 1, in <module> runfile('C:/Users/1/Desktop/transfer_learning_tutorial-master/MCVE.py', wdir='C:/Users/1/Desktop/transfer_learning_tutorial-master') File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 710, in runfile execfile(filename, namespace) File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 101, in execfile exec(compile(f.read(), filename, 'exec'), namespace) File <*>/MCVE.py, line 77, in <module> tf.app.run(main=main, argv=[sys.argv[0]]) File <*>/site-packages/tensorflow/python/platform/app.py, line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough)) File <*>/MCVE.py, line 68, in main steps=1000) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 302, in train loss = self._train_model(input_fn, hooks, saving_listeners) File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 780, in _train_model log_step_count_steps=self._config.log_step_count_steps) as mon_sess: File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 368, in MonitoredTrainingSession stop_grace_period_secs=stop_grace_period_secs) File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 673, in __init__ stop_grace_period_secs=stop_grace_period_secs) File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 493, in __init__ self._sess = _RecoverableSession(self._coordinated_creator) File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 851, in __init__ _WrappedSession.__init__(self, self._create_session()) File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 856, in _create_session return self._sess_creator.create_session() File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 554, in create_session self.tf_sess = self._session_creator.create_session() File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 428, in create_session init_fn=self._scaffold.init_fn) File <*>/site-packages/tensorflow/python/training/session_manager.py, line 279, in prepare_session sess.run(init_op, feed_dict=init_feed_dict) File <*>/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr) File <*>/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message) InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [900] rhs shape= [1001] [[Node: Assign_1145 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionResnetV2/Logits/Logits/biases""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionResnetV2/Logits/Logits/biases, checkpoint_initializer_1145)]]",0
"File <stdin>, line 1, in <module> [CODE] File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import * File <*>/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 30, in <module> self_check.preload_check() File <*>/site-packages/tensorflow/python/platform/self_check.py, line 82, in preload_check % (build_info.cudart_dll_name, build_info.cuda_version_number)) ImportError: Could not find 'cudart64_80.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 8.0 from this URL: https://developer.nvidia.com/cuda-toolkit",0
"File <*>/hackerearth_project.py, line 90, in <module> model(X_train, X_test, Y_train, Y_test) File <*>/hackerearth_project.py, line 71, in model optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1, beta2=beta2).minimize(cost) File <*>/site-packages/tensorflow/python/training/optimizer.py, line 343, in minimize grad_loss=grad_loss) File <*>/site-packages/tensorflow/python/training/optimizer.py, line 394, in compute_gradients self._assert_valid_dtypes([loss]) File <*>/site-packages/tensorflow/python/training/optimizer.py, line 543, in _assert_valid_dtypes dtype = t.dtype.base_dtype AttributeError: 'NoneType' object has no attribute 'dtype'",0
"File [FILE], line 337, in [FUNC] [CODE] TypeError: 'UnimplementedError' object is not iterable",0
"File processing_2a_1.py, line 125, in <module> history=model.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_val,Y_val), epochs=nr_of_epochs,verbose=2) File <*>/models.py, line 871, in fit [CODE] File <*>/training.py, line 1524, in fit [CODE] File <*>/training.py, line 1382, in _standardize_user_data [CODE] File <*>/training.py, line 132, in _standardize_input_data [CODE] ValueError: Error when checking target: expected dense_2 to have 3 dimensions, but got array with shape (1496000, 1)",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1330, in _do_call return fn(*args) File <*>/site-packages/tensorflow/python/client/session.py, line 1315, in _run_fn options, feed_dict, fetch_list, target_list, run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1423, in _call_tf_sessionrun status, run_metadata) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__ c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,25] vs. shape[1] = [30,100] [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](rnn/while/TensorArrayReadV3, rnn/while/Switch_4:1, rnn/while/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/Const)]]",0
"File <*>/dnn_gragh.py, line 198, in <module> model.train(5000, 0.0001, my_input_fn, training_examples, training_targets, sequenceLenth=trainSequenceL) File <*>/dnn_gragh.py, line 124, in train state2, current_loss, nowAccuracy = sess.run([state, loss, accuracy]) File <*>/site-packages/tensorflow/python/client/session.py, line 908, in run run_metadata_ptr) File <*>/site-packages/tensorflow/python/client/session.py, line 1143, in _run feed_dict_tensor, options, run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1324, in _do_run run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1343, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,25] vs. shape[1] = [30,100] [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](rnn/while/TensorArrayReadV3, rnn/while/Switch_4:1, rnn/while/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/Const)]]",0
"File main.py, line 69, in <module> main(); File main.py, line 66, in main train_model(iris_dataset, model, optimizer); File main.py, line 41, in train_model gradients = gradient_tune(features, label, model); File main.py, line 27, in gradient_tune prediction_loss = prediction_loss_diff(features, targets, model); File main.py, line 23, in prediction_loss_diff return tf.losses.sparse_softmax_cross_entropy(label, predicted_label); File <*>python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py, line 853, in sparse_softmax_cross_entropy name=""xentropy"") File <*>python3.6/site-packages/tensorflow/python/ops/nn_ops.py, line 2050, in sparse_softmax_cross_entropy_with_logits precise_logits, labels, name=name) File <*>python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 7504, in sparse_softmax_cross_entropy_with_logits _six.raise_from(_core._status_to_exception(e.code, message), None) File <string>, line 2, in raise_from [CODE] tensorflow.python.framework.errors_impl.InternalError: Could not find valid device for node name: ""SparseSoftmaxCrossEntropyWithLogits""",0
"File <string>, line 1, in <module> [CODE] File <*>/spawn.py, line 105, in spawn_main exitcode = _main(fd) File <*>/spawn.py, line 114, in _main prepare(preparation_data) File <*>/spawn.py, line 225, in prepare _fixup_main_from_path(data['init_main_from_path']) File <*>/spawn.py, line 277, in _fixup_main_from_path run_name=""__mp_main__"") File <*>/runpy.py, line 263, in run_path pkg_name=pkg_name, script_name=fname) File <*>/runpy.py, line 96, in _run_module_code mod_name, mod_spec, pkg_name, script_name) File <*>/runpy.py, line 85, in _run_code exec(code, run_globals) File <*>/TutorialCIFAR10.py, line 36, in <module> dataiter = iter(trainloader) File <*>/site-packages/torch/utils/data/dataloader.py, line 451, in __iter__ return _DataLoaderIter(self) File <*>/site-packages/torch/utils/data/dataloader.py, line 239, in __init__ w.start() File <*>/process.py, line 105, in start self._popen = self._Popen(self) File <*>/context.py, line 223, in _Popen return _default_context.get_context().Process._Popen(process_obj) File <*>/context.py, line 322, in _Popen return Popen(process_obj) File <*>/popen_spawn_win32.py, line 33, in __init__ prep_data = spawn.get_preparation_data(process_obj._name) File <*>/spawn.py, line 143, in get_preparation_data _check_not_importing_main() File <*>/spawn.py, line 136, in _check_not_importing_main is not going to be frozen to produce an executable.) RuntimeError: An attempt has been made to start a new process before the current process has finished its bootstrapping phase.",0
"File seq2seq_train.py, line 5, in <module> from keras_text_summarization.library.utility.plot_utils import plot_and_save_history ModuleNotFoundError: No module named 'keras_text_summarization'",0
"File generate_tfrecord.py, line 17, in <module> import tensorflow as tf File <*>/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import File <*>/site-packages/tensorflow/python/__init__.py, line 81, in <module> from tensorflow.python import keras File <*>/site-packages/tensorflow/python/keras/__init__.py, line 24, in <module> from tensorflow.python.keras import activations File <*>/site-packages/tensorflow/python/keras/activations/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.activations import elu File <*>/site-packages/tensorflow/python/keras/_impl/keras/__init__.py, line 21, in <module> from tensorflow.python.keras._impl.keras import activations File <*>/site-packages/tensorflow/python/keras/_impl/keras/activations.py, line 23, in <module> from tensorflow.python.keras._impl.keras import backend as K File <*>/site-packages/tensorflow/python/keras/_impl/keras/backend.py, line 38, in <module> from tensorflow.python.layers import base as tf_base_layers File <*>/site-packages/tensorflow/python/layers/base.py, line 25, in <module> from tensorflow.python.keras.engine import base_layer File <*>/site-packages/tensorflow/python/keras/engine/__init__.py, line 21, in <module> from tensorflow.python.keras.engine.base_layer import InputSpec File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 33, in <module> from tensorflow.python.keras import backend File <*>/site-packages/tensorflow/python/keras/backend/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.backend import abs ImportError: cannot import name 'abs'",0
"File test.py, line 13, in <module> layers.Dense(64, activation='sigmoid') NameError: name 'layers' is not defined",0
"File <ipython-input-7-2ef5e6514df7>, line 33, in data_generator [CODE] File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1530, in __exit__ self._default_graph_context_manager.__exit__(exec_type, exec_value, exec_tb) File <*>python3.6/contextlib.py, line 99, in __exit__ self.gen.throw(type, value, traceback) File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 5025, in get_controller context.context().context_switches.pop() File <*>python3.6/dist-packages/tensorflow/python/eager/context.py, line 136, in pop self.stack.pop() IndexError: pop from empty list",0
"File <*>/playground.py, line 22, in <module> print(get_grad(x_cloned, x)) File <*>/playground.py, line 16, in get_grad A.backward() File <*>python3.5/site-packages/torch/tensor.py, line 93, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph) File <*>python3.5/site-packages/torch/autograd/__init__.py, line 84, in backward grad_tensors = _make_grads(tensors, grad_tensors) File <*>python3.5/site-packages/torch/autograd/__init__.py, line 28, in _make_grads raise RuntimeError(""grad can be implicitly created only for scalar outputs"") RuntimeError: grad can be implicitly created only for scalar outputs",0
"File noveou_train_netvlad.py, line 226, in <module> minu = keras.layers.Maximum()( [ minu, K.zeros(nN, nP) ] ) File <*>python2.7/dist-packages/keras/engine/base_layer.py, line 457, in __call__ output = self.call(inputs, **kwargs) File <*>python2.7/dist-packages/keras/layers/merge.py, line 115, in call return self._merge_function(reshaped_inputs) File <*>python2.7/dist-packages/keras/layers/merge.py, line 301, in _merge_function output = K.maximum(output, inputs[i]) File <*>python2.7/dist-packages/keras/backend/tensorflow_backend.py, line 1672, in maximum return tf.maximum(x, y) File <*>python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 4707, in maximum ""Maximum"", x=x, y=y, name=name) File <*>python2.7/dist-packages/tensorflow/python/framework/op_def_library.py, line 546, in _apply_op_helper inferred_from[input_arg.type_attr])) TypeError: Input 'y' of 'Maximum' Op has type string that does not match type float32 of argument 'x'.",0
"File <*>/lesson4-imdb2.py, line 27, in <module> pickle.dump(md, file) TypeError: 'generator' object is not callable",0
"File model.py, line 6, in <module> class_labels = 'conv_labels.txt' File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 586, in convert custom_conversion_functions=custom_conversion_functions) File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 206, in _convert_pb_to_mlmodel raise ValueError('Please provide the shape for the input {} through the argument \'input_name_shape_dict\''.format(input_name)) ValueError: Please provide the shape for the input wav_data:0 through the argument 'input_name_shape_dict'",0
"File <*>/tst1.py, line 110, in <module> classifier.fit(X_train, y_train, batch_size = 10, epochs = 100) File <*>/site-packages/keras/engine/training.py, line 950, in fit batch_size=batch_size) File <*>/site-packages/keras/engine/training.py, line 787, in _standardize_user_data exception_prefix='target') File <*>/site-packages/keras/engine/training_utils.py, line 137, in standardize_input_data str(data_shape)) ValueError: Error when checking target: expected dense_3 to have shape (1,) but got array with shape (6,)",0
"File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 3078, in get_loc return self._engine.get_loc(key) File <*>/index.pyx, line 140, in pandas._libs.index.IndexEngine.get_loc [CODE] File <*>/index.pyx, line 162, in pandas._libs.index.IndexEngine.get_loc [CODE] File <*>/hashtable_class_helper.pxi, line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE] File <*>/hashtable_class_helper.pxi, line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE] KeyError: range(418, 419)",0
"File <stdin>, line 1, in <module> [CODE] File <*>python3.5/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import File <*>python3.5/site-packages/tensorflow/python/__init__.py, line 47, in <module> import numpy as np File <*>python3.5/site-packages/numpy/__init__.py, line 142, in <module> from . import core File <*>python3.5/site-packages/numpy/core/__init__.py, line 57, in <module> from . import numerictypes as nt File <*>python3.5/site-packages/numpy/core/numerictypes.py, line 111, in <module> from ._type_aliases import ( File <*>python3.5/site-packages/numpy/core/_type_aliases.py, line 63, in <module> _concrete_types = {v.type for k, v in _concrete_typeinfo.items()} File <*>python3.5/site-packages/numpy/core/_type_aliases.py, line 63, in <setcomp> _concrete_types = {v.type for k, v in _concrete_typeinfo.items()} AttributeError: 'tuple' object has no attribute 'type'",0
"File test.py, line 141, in <module> max_queue_size=2) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 2177, in fit_generator initial_epoch=initial_epoch) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 147, in fit_generator generator_output = next(output_generator) File <*>python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py, line 831, in get six.reraise(value.__class__, value, value.__traceback__) File <*>python3.6/site-packages/six.py, line 693, in reraise raise value TypeError: 'My_Generator' object is not an iterator",0
"File <frozen importlib._bootstrap>, line 968, in _find_and_load [CODE] SystemError: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set ImportError: numpy.core._multiarray_umath failed to import ImportError: numpy.core.umath failed to import",0
"File pretrain_lm.py, line 7, in <module> import fastai File <*>python3.7/site-packages/fastai/__init__.py, line 1, in <module> from .basic_train import * File <*>python3.7/site-packages/fastai/basic_train.py, line 2, in <module> from .torch_core import * File <*>python3.7/site-packages/fastai/torch_core.py, line 2, in <module> from .imports.torch import * File <*>python3.7/site-packages/fastai/imports/__init__.py, line 2, in <module> from .torch import * File <*>python3.7/site-packages/fastai/imports/torch.py, line 1, in <module> import torch, torch.nn.functional as F File <*>python3.7/site-packages/torch/__init__.py, line 84, in <module> from torch._C import * ImportError: libtorch_python.so: cannot open shared object file: No such file or directory",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1334, in _do_call return fn(*args) File <*>/site-packages/tensorflow/python/client/session.py, line 1319, in _run_fn options, feed_dict, fetch_list, target_list, run_metadata) File <*>/site-packages/tensorflow/python/client/session.py, line 1407, in _call_tf_sessionrun run_metadata) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[51200,2304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[{{node model/h0/attn/c_attn/MatMul}}]]",0
"File <*>/pydevd.py, line 1758, in <module> main() File <*>/pydevd.py, line 1752, in main globals = debugger.run(setup['file'], None, None, is_module) File <*>/pydevd.py, line 1147, in run pydev_imports.execfile(file, globals, locals) # execute the script File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc) File <*>/deep_test_conv1d.py, line 231, in <module> main() File <*>/deep_test_conv1d.py, line 149, in main for i, (images, labels) in enumerate(train_loader): File <*>/site-packages/torch/utils/data/dataloader.py, line 615, in __next__ batch = self.collate_fn([self.dataset[i] for i in indices]) File <*>/site-packages/torch/utils/data/dataloader.py, line 615, in <listcomp> batch = self.collate_fn([self.dataset[i] for i in indices]) File <*>/deep_test_conv1d.py, line 102, in __getitem__ return self.transform(self.features[index]), self.transform(self.classes[index]) File <*>/site-packages/torchvision/transforms/transforms.py, line 60, in __call__ img = t(img) File <*>/site-packages/torchvision/transforms/transforms.py, line 91, in __call__ return F.to_tensor(pic) File <*>/site-packages/torchvision/transforms/functional.py, line 50, in to_tensor raise TypeError('pic should be PIL Image or ndarray. Got {}'.format(type(pic))) TypeError: pic should be PIL Image or ndarray. Got <class 'numpy.ndarray'>",0
"File file.py, line 2, in <module> from torch.utils.data import Dataset, DataLoader ModuleNotFoundError: No module named 'torch'",0
"File test_transform.py, line 87, in <module> for batch_idx, image, mask in enumerate(train_loader): File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 314, in __next__ batch = self.collate_fn([self.dataset[i] for i in indices]) File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 314, in <listcomp> batch = self.collate_fn([self.dataset[i] for i in indices]) File <*>python3.6/site-packages/torch/utils/data/dataset.py, line 103, in __getitem__ return self.dataset[self.indices[idx]] File <*>/data.py, line 164, in __getitem__ img, mask = self.transforms(img, mask) File <*>/augmentations.py, line 17, in __call__ img, mask = a(img, mask) TypeError: __call__() takes 2 positional arguments but 3 were given",0
"File tf_1_day_scikit_dnn.py, line 12, in <module> from sklearn import decomposition File <*>python3.6/site-packages/sklearn/decomposition/__init__.py, line 19, in <module> from ._online_lda import LatentDirichletAllocation ImportError: cannot import name 'LatentDirichletAllocation'",0
"File <*>/N09.py, line 363, in <module> main() File <*>/N09.py, line 343, in main args.save_interval) File <*>/N09.py, line 92, in train_model verbose=self.verbose) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 1297, in fit_generator steps_name='steps_per_epoch') File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py, line 265, in model_iteration batch_outs = batch_function(*batch_data) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 973, in train_on_batch class_weight=class_weight, reset_metrics=reset_metrics) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch output_loss_metrics=model._output_loss_metrics) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch output_loss_metrics=output_loss_metrics)) File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 268, in _process_single_batch grads = tape.gradient(scaled_total_loss, trainable_weights) File <*>python3.7/site-packages/tensorflow_core/python/eager/backprop.py, line 1014, in gradient unconnected_gradients=unconnected_gradients) File <*>python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py, line 76, in imperative_grad compat.as_str(unconnected_gradients.value)) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 911, in _backward_function_wrapper processed_args, remapped_captures) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1224, in _call_flat ctx, args, cancellation_manager=cancellation_manager) File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 511, in call ctx=ctx) File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 75, in quick_execute ""tensors, but found {}"".format(keras_symbolic_tensors)) tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'StridedSliceGrad:0' shape=(16, 64, 64, 3) dtype=float32>]",0
"File <*>/test2.py, line 73, in <module> grads = gradients(model, x, y) File <*>/test2.py, line 58, in gradients print(model.get_layer('minimalrnn').output) File <*>python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 1553, in output raise AttributeError('Layer ' + self.name + ' has no inbound nodes.') AttributeError: Layer minimalrnn has no inbound nodes.",0
"File <*>/unet_trainer.py, line 82, in <module> results = model.fit_generator(train_generator, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, validation_data=val_generator, validation_steps=VALIDATION_STEPS, callbacks=callbacks) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 1297, in fit_generator steps_name='steps_per_epoch') File <*>/site-packages/tensorflow_core/python/keras/engine/training_generator.py, line 265, in model_iteration batch_outs = batch_function(*batch_data) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 973, in train_on_batch class_weight=class_weight, reset_metrics=reset_metrics) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch output_loss_metrics=model._output_loss_metrics) File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch output_loss_metrics=output_loss_metrics)) File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 252, in _process_single_batch training=training)) File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 127, in _model_loss outs = model(inputs, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 891, in __call__ outputs = self.call(cast_inputs, *args, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 708, in call convert_kwargs_to_constants=base_layer_utils.call_context().saving) File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 860, in _run_internal_graph output_tensors = layer(computed_tensors, **kwargs) File <*>/site-packages/tensorflow_core/python/keras/layers/convolutional.py, line 197, in call outputs = self._convolution_op(inputs, self.kernel) File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 1134, in __call__ return self.conv_op(inp, filter) File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 639, in __call__ return self.call(inp, filter) File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 238, in __call__ name=self.name) File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 2010, in conv2d name=name) File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1031, in conv2d data_format=data_format, dilations=dilations, name=name, ctx=_ctx) File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1130, in conv2d_eager_fallback ctx=_ctx, name=name) File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None) File <string>, line 3, in raise_from [CODE] tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,16,1536,1536] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",0
"File <*>/3D_tf_data_generator.py, line 181, in <module> evaluation_ad = model.evaluate(ad_test, ad_test_labels, verbose=0) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 930, in evaluate use_multiprocessing=use_multiprocessing) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 490, in evaluate use_multiprocessing=use_multiprocessing, **kwargs) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 426, in _model_iteration use_multiprocessing=use_multiprocessing) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 646, in _process_inputs x, y, sample_weight=sample_weights) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 2383, in _standardize_user_data batch_size=batch_size) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 2489, in _standardize_tensors y, self._feed_loss_fns, feed_output_shapes) File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py, line 810, in check_loss_and_target_compatibility ' while using as loss `' + loss_name + '`. ' ValueError: A target array with shape (5, 2) was passed for an output of shape (None, 1) while using as loss `binary_crossentropy`. This loss expects targets to have the same shape as the output.",0
"File <*>python3.6/dist-packages/torch/utils/data/_utils/worker.py, line 178, in _worker_loop data = fetcher.fetch(index) File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch data = [self.dataset[idx] for idx in possibly_batched_index] File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp> data = [self.dataset[idx] for idx in possibly_batched_index] File <ipython-input-114-e0ccd94603fd>, line 31, in __getitem__ xs = label_data[:,0:8:2]; IndexError: too many indices for array",0
"File <*>python3.6/dist-packages/optuna/study.py, line 734, in _run_trial result = func(trial) File <*>python3.6/dist-packages/optkeras/optkeras.py, line 130, in fun_tf return fun(trial) File <ipython-input-11-45495c9f2ae9>, line 65, in optima_run self.model.fit(self.train_images, self.train_labels, epochs=10, callbacks = self.ok.callbacks(trial), verbose = self.ok.keras_verbose) File <*>python3.6/dist-packages/optkeras/optkeras.py, line 172, in callbacks self.synch_with_optuna() File <*>python3.6/dist-packages/optkeras/optkeras.py, line 232, in synch_with_optuna self.best_trial = get_trial_default() File <*>python3.6/dist-packages/optkeras/optkeras.py, line 367, in get_trial_default num_fields = optuna.structs.FrozenTrial._field_types.__len__() AttributeError: type object 'FrozenTrial' has no attribute '_field_types'",0
"File <*>python3.6/site-packages/uvicorn/protocols/http/httptools_impl.py, line 385, in run_asgi result = await app(self.scope, self.receive, self.send) File <*>python3.6/site-packages/uvicorn/middleware/proxy_headers.py, line 45, in __call__ return await self.app(scope, receive, send) File <*>python3.6/site-packages/fastapi/applications.py, line 183, in __call__ await super().__call__(scope, receive, send) # pragma: no cover File <*>python3.6/site-packages/starlette/applications.py, line 102, in __call__ await self.middleware_stack(scope, receive, send) File <*>python3.6/site-packages/starlette/middleware/errors.py, line 181, in __call__ raise exc from None File <*>python3.6/site-packages/starlette/middleware/errors.py, line 159, in __call__ await self.app(scope, receive, _send) File <*>python3.6/site-packages/starlette/exceptions.py, line 82, in __call__ raise exc from None File <*>python3.6/site-packages/starlette/exceptions.py, line 71, in __call__ await self.app(scope, receive, sender) File <*>python3.6/site-packages/starlette/routing.py, line 550, in __call__ await route.handle(scope, receive, send) File <*>python3.6/site-packages/starlette/routing.py, line 227, in handle await self.app(scope, receive, send) File <*>python3.6/site-packages/starlette/routing.py, line 41, in app response = await func(request) File <*>python3.6/site-packages/fastapi/routing.py, line 197, in app dependant=dependant, values=values, is_coroutine=is_coroutine File <*>python3.6/site-packages/fastapi/routing.py, line 149, in run_endpoint_function return await run_in_threadpool(dependant.call, **values) File <*>python3.6/site-packages/starlette/concurrency.py, line 34, in run_in_threadpool return await loop.run_in_executor(None, func, *args) File <*>python3.6/thread.py, line 56, in run result = self.fn(*self.args, **self.kwargs) File <*>/main.py, line 155, in API_call raise e File <*>/main.py, line 129, in API_call model = pickle.load(open('models/' + current_model, 'rb')) File <*>python3.6/site-packages/dill/_dill.py, line 270, in load return Unpickler(file, ignore=ignore, **kwds).load() File <*>python3.6/site-packages/dill/_dill.py, line 473, in load obj = StockUnpickler.load(self) File <*>python3.6/site-packages/dill/_dill.py, line 463, in find_class return StockUnpickler.find_class(self, module, name) AttributeError: Can't get attribute 'Model_II_b' on <module '__mp_main__' from '/opt/apps/env/bin/uvicorn'>",0
"File <*>/site-packages/tensorflow/python/data/util/structure.py, line 93, in normalize_element spec = type_spec_from_value(t, use_fallback=False) File <*>/site-packages/tensorflow/python/data/util/structure.py, line 466, in type_spec_from_value (element, type(element).__name__)) TypeError: Could not build a TypeSpec for 0 Tecmo Koei 1 Nippon Ichi Software 2 Ubisoft 3 Activision 4 Atari ... 6594 Kemco 6595 Infogrames 6596 Activision 6597 7G//AMES 6598 Wanadoo Name: Publisher, Length: 6599, dtype: object with type Series",0
"File <*>/site-packages/IPython/core/interactiveshell.py, line 3331, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File <ipython-input-2-d2317d03e1c1>, line 1, in <module> runfile('F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news/bitcoin.py', wdir='F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news') File <*>/pydev_umd.py, line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc) File <*>/bitcoin.py, line 41, in <module> model.fit(x=x_train, y=y_train, batch_size=64, epochs=5, shuffle=True, validation_split=0.1) File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 819, in fit use_multiprocessing=use_multiprocessing) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 342, in fit total_epochs=epochs) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch batch_outs = execution_function(iterator) File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function distributed_function(input_fn)) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__ result = self._call(*args, **kwds) File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 632, in _call return self._stateless_fn(*args, **kwds) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2363, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call self.captured_inputs) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat ctx, args, cancellation_manager=cancellation_manager)) File <*>/site-packages/tensorflow_core/python/eager/function.py, line 545, in call ctx=ctx) File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None) File <string>, line 3, in raise_from [CODE] tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Condition x == y did not hold element-wise:] [x (loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [64 1] [y (loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [64 14] [[node loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news/bitcoin.py:41) ]] [Op:__inference_distributed_function_2970]",0
"File <stdin>, line 1, in <module> [CODE] File <*>/site-packages/tensorflow/__init__.py, line 101, in <module> from tensorflow_core import * File <*>/site-packages/tensorflow_core/__init__.py, line 40, in <module> from tensorflow.python.tools import module_util as _module_util File <frozen importlib._bootstrap>, line 983, in _find_and_load [CODE] File <frozen importlib._bootstrap>, line 959, in _find_and_load_unlocked [CODE] File <*>/site-packages/tensorflow/__init__.py, line 50, in __getattr__ module = self._load() File <*>/site-packages/tensorflow/__init__.py, line 44, in _load module = _importlib.import_module(self.__name__) File <*>/__init__.py, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level) File <*>/site-packages/tensorflow_core/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py, line 15, in swig_import_helper import imp ValueError: source code string cannot contain null bytes",0
"File <*>/site-packages/pytorch_lightning/trainer/trainer.py, line 521, in train self.train_loop.run_training_epoch() File <*>/site-packages/pytorch_lightning/trainer/training_loop.py, line 588, in run_training_epoch self.trainer.run_evaluation(test_mode=False) File <*>/site-packages/pytorch_lightning/trainer/trainer.py, line 613, in run_evaluation self.evaluation_loop.log_evaluation_step_metrics(output, batch_idx) File <*>/site-packages/pytorch_lightning/trainer/evaluation_loop.py, line 346, in log_evaluation_step_metrics self.__log_result_step_metrics(step_log_metrics, step_pbar_metrics, batch_idx) File <*>/site-packages/pytorch_lightning/trainer/evaluation_loop.py, line 350, in __log_result_step_metrics cached_batch_pbar_metrics, cached_batch_log_metrics = cached_results.update_logger_connector() File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 378, in update_logger_connector batch_log_metrics = self.get_latest_batch_log_metrics() File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 418, in get_latest_batch_log_metrics batch_log_metrics = self.run_batch_from_func_name(""get_batch_log_metrics"") File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 414, in run_batch_from_func_name results = [func(include_forked_originals=False) for func in results] File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 414, in <listcomp> results = [func(include_forked_originals=False) for func in results] File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 122, in get_batch_log_metrics return self.run_latest_batch_metrics_with_func_name(""get_batch_log_metrics"", *args, **kwargs) File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 115, in run_latest_batch_metrics_with_func_name for dl_idx in range(self.num_dataloaders) File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 115, in <listcomp> for dl_idx in range(self.num_dataloaders) File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 100, in get_latest_from_func_name results.update(func(*args, add_dataloader_idx=add_dataloader_idx, **kwargs)) File <*>/site-packages/pytorch_lightning/core/step_result.py, line 298, in get_batch_log_metrics result[dl_key] = self[k]._forward_cache.detach() AttributeError: 'NoneType' object has no attribute 'detach'",0
"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 64, in <module> from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.",0
"File <stdin>, line 24, in <module> [CODE] TypeError: expected CPU (got CUDA)",0
"File [FILE], line 5, in <module>() z = x + y File <*>python3.4/site-packages/theano/tensor/var.py, line 128, in __add__(self, other) return theano.tensor.basic.add(self, other) File <*>python3.4/site-packages/theano/gof/op.py, line 525, in __call__(self, *inputs, **kwargs) raise ValueError('Cannot compute test value: input %i (%s) of Op %s missing default value' % (i, ins, node)) ValueError: Cannot compute test value: input 0 (x) of Op Elemwise{add,no_inplace}(x, y) missing default value",0
"File [FILE], line 19, in <module>() rotate_x_axis_theano = theano.function([angle_var],rotate_x_axis_expr(angle_var)) File [FILE], line 14, in rotate_x_axis_expr(angle) R[1][1] = cosa; R[1][2] = -sina TypeError: 'TensorVariable' object does not support item assignment",0
"File [FILE], line 7, in <module>() input_map={'import/pool5':out_pool}) File <*>python3.4/dist-packages/tensorflow/python/framework/importer.py, line 335, in import_graph_def(graph_def, input_map, return_elements, name, op_dict) ops.set_shapes_for_outputs(op) File <*>python3.4/dist-packages/tensorflow/python/framework/ops.py, line 1612, in set_shapes_for_outputs(op) shapes = shape_func(op) File <*>/roi_pooling_op_grad.py, line 15, in _roi_pool_shape(op) dims_rois = op.inputs[1].get_shape().as_list() File <*>python3.4/dist-packages/tensorflow/python/framework/tensor_shape.py, line 747, in as_list(self) return [dim.value for dim in self._dims] TypeError: 'NoneType' object is not iterable",0
"File [FILE], line 1, in <module>() audiocnn(input) File <*>python2.7/site-packages/torch/nn/modules/module.pyc, line 224, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File [FILE], line 17, in forward(self, x) _, (_, _) = self.lstm(x,(h_0,c_0)) # x dim : 2 x 1 x 256 File <*>python2.7/site-packages/torch/nn/modules/rnn.pyc, line 162, in forward(self, input, hx) output, hidden = func(input, self.all_weights, hx) File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 351, in forward(input, *fargs, **fkwargs) return func(input, *fargs, **fkwargs) File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 244, in forward(input, weight, hidden) nexth, output = func(input, hidden, weight) File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 84, in forward(input, hidden, weight) hy, output = inner(input, hidden[l], weight[l]) File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 113, in forward(input, hidden, weight) hidden = inner(input[i], hidden, *weight) File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 31, in LSTMCell(input, hidden, w_ih, w_hh, b_ih, b_hh) gates = F.linear(input, w_ih, b_ih) + F.linear(hx, w_hh, b_hh) File <*>python2.7/site-packages/torch/nn/functional.pyc, line 553, in linear(input, weight, bias) return torch.addmm(bias, input, weight.t()) File <*>python2.7/site-packages/torch/autograd/variable.pyc, line 924, in addmm(cls, *args) return cls._blas(Addmm, args, False) File <*>python2.7/site-packages/torch/autograd/variable.pyc, line 920, in _blas(cls, args, inplace) return cls.apply(*(tensors + (alpha, beta, inplace))) RuntimeError: save_for_backward can only save input or output tensors, but argument 0 doesn't satisfy this condition",0
"File <*>python3.6/dist-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn) input_tensors_as_shapes, status) File <*>python3.6/dist-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status)) InvalidArgumentError: Negative dimension size caused by subtracting 3 from 1 for 'conv1d_26/convolution/Conv2D' (op: 'Conv2D') with input shapes: [?,1,1,256], [1,3,256,256].",0
"File [FILE], line 35, in <module>() mean , variance = tf.nn.moments(X_train, axes = 1, keep_dims = True) File <*>python2.7/nn_impl.pyc, line 666, in moments(x, axes, shift, name, keep_dims) y = math_ops.cast(x, dtypes.float32) if x.dtype == dtypes.float16 else x TypeError: data type not understood",0
"File [FILE], line [NUM], in () [CODE] File [FILE], line [NUM], in [FUNC] [CODE] File <*>python3.6/site-packages/torch/autograd/variable.py, line [NUM], in setitem(self, key, value) [CODE] RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.",0
"File <*>/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call(self, fn, *args) return fn(*args) File <*>/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata) status, run_metadata) File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status)) InvalidArgumentError: You must feed a value for placeholder tensor 'time_distributed_2_target' with dtype float and shape [?,?,?] [[Node: time_distributed_2_target = Placeholder[dtype=DT_FLOAT, shape=[?,?,?], _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1322, in _do_call(self, fn, *args) return fn(*args) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1307, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1409, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata) InvalidArgumentError: slice index 0 of dimension 0 out of bounds. [[Node: lstm_25/strided_slice_13 = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](lstm_25/transpose, loss_11/dense_58_loss/Const_2, lstm_25/strided_slice_9/stack_2, lstm_25/strided_slice_9/stack_2)]]",0
"File [FILE], line 57, in <module>() feed_dict=feed_dict) TypeError: 'NoneType' object is not iterable",0
"File [FILE], line 2, in <module>() steps_per_epoch=1, epochs=15, verbose=2) File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs) File <*>/site-packages/keras/engine/training.py, line 2230, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) class_weight=class_weight) File <*>/site-packages/keras/engine/training.py, line 1877, in train_on_batch(self, x, y, sample_weight, class_weight) class_weight=class_weight) File <*>/site-packages/keras/engine/training.py, line 1480, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size) exception_prefix='target') File <*>/site-packages/keras/engine/training.py, line 76, in _standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data] File <*>/site-packages/keras/engine/training.py, line 76, in <listcomp>(.0) data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data] AttributeError: 'Tensor' object has no attribute 'ndim'",0
"File [FILE], line 2, in <module>() grid = torchvision.utils.make_grid(w.permute(0,2,3,1), nrow=5) File <*>python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/utils.py, line 85, in make_grid(tensor, nrow, padding, normalize, range, scale_each, pad_value) .copy_(tensor[k]) RuntimeError: The expanded size of the tensor (3) must match the existing size (640) at non-singleton dimension 0",0
"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1330, in _do_call(self, fn, *args) return fn(*args) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1315, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata) File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1423, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) status, run_metadata) File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status)) FailedPreconditionError: Attempting to use uninitialized value W_4 [[Node: W_4/read = Identity[T=DT_FLOAT, _class=[""loc:@W_4""], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](W_4)]]",0
"File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1334, in _do_call(self, fn, *args) return fn(*args) File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1319, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata) File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1407, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata) UnimplementedError: File system scheme '[local]' not implemented (file: 'checkpointsBook2Vec5Inputs') [[{{node save/SaveV2}} = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, embeddings, embeddings/Shampoo, embeddings/Shampoo_1, embeddings/Shampoo_2, epochCount, softmax_biases, softmax_weights, softmax_weights/Shampoo, softmax_weights/Shampoo_1, softmax_weights/Shampoo_2)]]",0
"File [FILE], line 50, in <module>() save_path = saver.save(session, ""checkpointsBook2Vec5Inputs/Research2VecCS4.ckpt"") #Save checkpoint File <*>python3.6/dist-packages/tensorflow/python/training/saver.py, line 1441, in save(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs) {self.saver_def.filename_tensor_name: checkpoint_file}) File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 929, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr) File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1152, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata) File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1328, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata) File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1348, in _do_call(self, fn, *args) raise type(e)(node_def, op, message) UnimplementedError: File system scheme '[local]' not implemented (file: 'checkpointsBook2Vec5Inputs') [[node save/SaveV2 (defined at <ipython-input-15-c14caac2081d>:45) = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, embeddings, embeddings/Shampoo, embeddings/Shampoo_1, embeddings/Shampoo_2, epochCount, softmax_biases, softmax_weights, softmax_weights/Shampoo, softmax_weights/Shampoo_1, softmax_weights/Shampoo_2)]]",0
"File [FILE], line 3, in <module>() steps=10) File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 354, in train(self, input_fn, hooks, steps, max_steps, saving_listeners) loss = self._train_model(input_fn, hooks, saving_listeners) File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1207, in _train_model(self, input_fn, hooks, saving_listeners) return self._train_model_default(input_fn, hooks, saving_listeners) File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1237, in _train_model_default(self, input_fn, hooks, saving_listeners) features, labels, model_fn_lib.ModeKeys.TRAIN, self.config) File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1195, in _call_model_fn(self, features, labels, mode, config) model_fn_results = self._model_fn(features=features, **kwargs) File [FILE], line 35, in my_model(features, labels, mode, params) num_classes=vocabulary_size)) File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1248, in nce_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name) name=name) File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1031, in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed) if labels.dtype != dtypes.int64: TypeError: data type not understood",0
"File [FILE], line 3, in <module>() epochs = range(epochs) NameError: name 'epochs' is not defined",0
"File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 511, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype) File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1175, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 304, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 245, in constant(value, dtype, shape, name) allow_broadcast=True) File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast)) File <*>python3.7/site-packages/tensorflow/python/framework/tensor_util.py, line 454, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) raise ValueError(""None values not supported."") ValueError: None values not supported.",0
"File [FILE], line 1, in () output = model(data) File <*>python3.6/dist-packages/torch/nn/modules/module.py, line [NUM], in call(self, *input, **kwargs) [CODE] File <*>python3.6/dist-packages/torch/nn/functional.py, line 1354, in linear(input, weight, bias) output = input.matmul(weight.t()) RuntimeError: size mismatch, m1: [3584 x 28], m2: [784 x 128] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:940",0
"File [FILE], line 6, in <module>() print(char_OneHotEncoding(torch.tensor(x_train, dtype=torch.long).cuda()).shape) File [FILE], line 4, in char_OneHotEncoding(x) coded[:,i] = scatter(x[:,i]) File [FILE], line 9, in scatter(x) return torch.zeros(x.shape[0], 101).scatter_(1, x.view(-1,1), 1) RuntimeError: Expected object of backend CPU but got backend CUDA for argument #3 'index'",0
"File [FILE], line 1, in <module> model.fit(dataset, epochs=10, steps_per_epoch=10) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 791, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1515, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch') File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 257, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) batch_outs = batch_function(*batch_data) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1238, in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics) extract_tensors_from_dataset=True) File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 2596, in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset) exception_prefix='input') File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 349, in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) str(data_shape)) ValueError: Error when checking input: expected input_1 to have shape (32,) but got array with shape (1,)",0
"File [FILE], line 32, in <module> loss = loss_func(output, b_y) File <*>python3.5/site-packages/torch/nn/modules/module.py, line 489, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.5/site-packages/torch/nn/modules/loss.py, line 504, in forward(self, input, target) return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction) File <*>python3.5/site-packages/torch/nn/functional.py, line 2027, in binary_cross_entropy(input, target, weight, size_average, reduce, reduction) input, target, weight, reduction_enum) RuntimeError: Expected object of scalar type Float but got scalar type Long for argument #2 'target'",0
"File [FILE], line 27, in <module>() grads = sess.run(d_fx) File <*>/site-packages/tensorflow/python/client/session.py, line 929, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr) File <*>/site-packages/tensorflow/python/client/session.py, line 1137, in _run(self, handle, fetches, feed_dict, options, run_metadata) self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles) File <*>/site-packages/tensorflow/python/client/session.py, line 471, in __init__(self, graph, fetches, feeds, feed_handles) self._fetch_mapper = _FetchMapper.for_fetch(fetches) File <*>/site-packages/tensorflow/python/client/session.py, line 258, in for_fetch(fetch) type(fetch))) TypeError: Fetch argument None has invalid type <class 'NoneType'>",0
"File [FILE], line 42, in <module> autoencoder.compile(optimizer='adadelta', loss=[custom_loss1,custom_loss2]) File <*>python3.6/site-packages/keras/engine/training.py, line 342, in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs) sample_weight, mask) File <*>python3.6/site-packages/keras/engine/training_utils.py, line 404, in weighted(y_true, y_pred, weights, mask) score_array = fn(y_true, y_pred) File [FILE], line 4, in custom_loss1(y_true, y_pred) dcor = -1*distance_correlation(y_true,encoded_layer) File [FILE], line 4, in distance_correlation(y_true, y_pred) pred_d = pred_r - 2*tf.matmul(y_pred,tf.transpose(y_pred))+tf.transpose(pred_r) File <*>python3.6/site-packages/tensorflow/python/ops/math_ops.py, line 2417, in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name) a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name) File <*>python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py, line 1423, in batch_mat_mul(x, y, adj_x, adj_y, name) ""BatchMatMul"", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name) File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 788, in _apply_op_helper(self, op_type_name, name, **keywords) op_def=op_def) File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func(*args, **kwargs) return func(*args, **kwargs) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3300, in create_op(***failed resolving arguments***) op_def=op_def) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1823, in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def) control_input_ops) File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1662, in _create_c_op(graph, node_def, inputs, control_inputs) raise ValueError(str(e)) ValueError: Dimensions must be equal, but are 1 and 64 for 'loss_1/zero_padding2d_5_loss/MatMul' (op: 'BatchMatMul') with input shapes: [?,64,64,1], [1,64,64,?].",0
"File [FILE], line 23, in <module> optimizer = nlp.resume_training() TypeError: Model() got multiple values for argument 'nr_class'",0
"File [FILE], line 29, in <module> global_loss_list = global_training(lstm2) File [FILE], line 5, in global_training(optimizee) _, global_loss_1 = learn2(LSTM_Optimizee, training_steps, retain_graph_flag=True, reset_theta=True) File [FILE], line 45, in learn2(optimizee, unroll_train_steps, retain_graph_flag, reset_theta) loss.backward(retain_graph = retain_graph_flag) #The default is False, when the optimized LSTM is set to True File <*>python3.7/site-packages/torch/tensor.py, line 118, in backward(self, gradient, retain_graph, create_graph) torch.autograd.backward(self, gradient, retain_graph, create_graph) File <*>python3.7/site-packages/torch/autograd/__init__.py, line 93, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables) allow_unreachable=True) # allow_unreachable flag RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 10]] is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",0
"File [FILE], line [NUM], in <module> [CODE] File <*>python3.6/site-packages/keras/engine/saving.py, line 458, in load_wrapper(*args, **kwargs) return load_function(*args, **kwargs) File <*>python3.6/site-packages/keras/engine/saving.py, line 550, in load_model(filepath, custom_objects, compile) model = _deserialize_model(h5dict, custom_objects, compile) File <*>python3.6/site-packages/keras/engine/saving.py, line 292, in _deserialize_model(h5dict, custom_objects, compile) reshape=False) File <*>python3.6/site-packages/keras/engine/saving.py, line 811, in convert_nested_model(weights) original_backend=original_backend)) File <*>python3.6/site-packages/keras/engine/saving.py, line 823, in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape) weights = convert_nested_model(weights) File <*>python3.6/site-packages/keras/engine/saving.py, line 799, in convert_nested_model(weights) original_backend=original_backend)) File <*>python3.6/site-packages/keras/engine/saving.py, line 942, in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape) weights[0] = np.transpose(weights[0], (3, 2, 0, 1)) File <*>python3.6/site-packages/numpy/core/fromnumeric.py, line 639, in transpose(a, axes) return _wrapfunc(a, 'transpose', axes) File <*>python3.6/site-packages/numpy/core/fromnumeric.py, line 56, in _wrapfunc(obj, method, *args, **kwds) return getattr(obj, method)(*args, **kwds) ValueError: axes don't match array",0
"File [FILE], line 8, in <module> train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](root='./.data', ngrams=NGRAMS, vocab=None) File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 170, in AG_NEWS(*args, **kwargs) return _setup_datasets(*((""AG_NEWS"",) + args), **kwargs) File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 128, in _setup_datasets(dataset_name, root, ngrams, vocab, include_unk) vocab = build_vocab_from_iterator(_csv_iterator(train_csv_path, ngrams)) File <*>python36/site-packages/torchtext/vocab.py, line 557, in build_vocab_from_iterator(iterator) for tokens in iterator: File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 35, in _csv_iterator(data_path, ngrams, yield_cls) for row in reader: File <*>python36/site-packages/torchtext/utils.py, line 130, in unicode_csv_reader(unicode_csv_data, **kwargs) csv.field_size_limit(sys.maxsize) OverflowError: Python int too large to convert to C long",0
"File <*>python3.6/dist-packages/pandas/core/indexes/base.py, line 2657, in get_loc(self, key, method, tolerance) return self._engine.get_loc(key) File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE] File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE] KeyError: 'filename'",0
"File [FILE], line 20, in <module> subset='training') File <*>python3.6/dist-packages/keras/preprocessing/image.py, line 594, in flow_from_dataframe(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs) **kwargs File <*>python3.6/dist-packages/keras/preprocessing/image.py, line 235, in __init__(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames) validate_filenames=validate_filenames) File <*>python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py, line 129, in __init__(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames) self._check_params(df, x_col, y_col, weight_col, classes) File <*>python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py, line 181, in _check_params(self, df, x_col, y_col, weight_col, classes) if not all(df[x_col].apply(lambda x: isinstance(x, str))): File <*>python3.6/dist-packages/pandas/core/frame.py, line 2927, in __getitem__(self, key) indexer = self.columns.get_loc(key) File <*>python3.6/dist-packages/pandas/core/indexes/base.py, line 2659, in get_loc(self, key, method, tolerance) return self._engine.get_loc(self._maybe_cast_indexer(key)) File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE] File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE] KeyError: 'filename'",0
"File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 2, in [FUNC] from tensorboard.summary.writer.record_writer import RecordWriter # noqa F401 ModuleNotFoundError: No module named 'tensorboard.summary'; 'tensorboard' is not a package",0
"File [FILE], line 9, in <module>() train(test_net, train_loader, 10, batch_size, optimiser, clip, criterion) File [FILE], line 59, in train(SNN, dataloader, epochs, batch_size, optimiser, clip, criterion) loss = criterion(output1, output2, labels) File [FILE], line 51, in forward(self, output1, output2, labels) pred, loss = estimate_loss(self.d) File [FILE], line 45, in estimate_loss(forward) distance = dimensional_reduction(self.d) File [FILE], line 38, in dimensional_reduction(forward) self.d = self.linear(self.d) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.6/site-packages/torch/nn/modules/linear.py, line 87, in forward(self, input) return F.linear(input, self.weight, self.bias) File <*>python3.6/site-packages/torch/nn/functional.py, line 1370, in linear(input, weight, bias) ret = torch.addmm(bias, input, weight.t()) RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_addmm",0
"File [FILE], line 1001, in <module>() train_step(group, inp, tar, label) File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializer_map) File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize(self, args, kwds, add_initializers_to) *args, **kwds)) File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs) File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs) File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value), File <*>python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs) File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds) File <*>python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py, line 905, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e) ValueError: in converted code: <ipython-input-1-81054f0385cb>:856 train_step * optimizer.apply_gradients(zip(gradients, transformer.trainable_variables)) /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:427 apply_gradients grads_and_vars = _filter_grads(grads_and_vars) /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:1025 _filter_grads ([v.name for _, v in grads_and_vars],)) ValueError: No gradients provided for any variable: ['transformer_1/encoder_1/embedding_2/embeddings:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_98/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_98/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_99/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_99/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_100/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_100/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_101/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_101/bias:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_102/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_102/bias:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_103/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_103/bias:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_30/gamma:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_30/beta:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_31/gamma:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_31/beta:0', 'transformer_1/encoder_1/encoder_layer_7/multi_head_attention_19/dense_104/kernel:0', 'transformer_1/encoder_1/encoder...",0
"File [FILE], line 2, in <module> model = make_feed_forward_model() File [FILE], line 20, in make_feed_forward_model() dense_layer_1 = tf.keras.layers.Dense(HPARAMS.num_fc_units, activation='relu')(inputs) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 616, in __call__(self, inputs, *args, **kwargs) self._maybe_build(inputs) File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1966, in _maybe_build(self, inputs) self.build(input_shapes) File <*>/site-packages/tensorflow/python/keras/layers/core.py, line 1005, in build(self, input_shape) raise ValueError('The last dimension of the inputs to `Dense` ' ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.",0
"File [FILE], line 19, in <module> transformed_dataset, transform_fn = (raw_dataset | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 863, in expand(self, dataset) dataset | 'AnalyzeDataset' >> AnalyzeDataset(self._preprocessing_fn)) File <*>python3.7/site-packages/apache_beam/transforms/ptransform.py, line 989, in __ror__(self, pvalueish, _unused) return self.transform.__ror__(pvalueish, self.label) File <*>python3.7/site-packages/apache_beam/transforms/ptransform.py, line 549, in __ror__(self, left, label) result = p.apply(self, pvalueish, label) File <*>python3.7/site-packages/apache_beam/pipeline.py, line 536, in apply(self, transform, pvalueish, label) return self.apply(transform, pvalueish) File <*>python3.7/site-packages/apache_beam/pipeline.py, line 577, in apply(self, transform, pvalueish, label) pvalueish_result = self.runner.apply(transform, pvalueish, self._options) File <*>python3.7/site-packages/apache_beam/runners/runner.py, line 195, in apply(self, transform, input, options) return m(transform, input, options) File <*>python3.7/site-packages/apache_beam/runners/runner.py, line 225, in apply_PTransform(self, transform, input, options) return transform.expand(input) File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 810, in expand(self, dataset) None, input_metadata)) File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 683, in expand(self, dataset) output_signature = self._preprocessing_fn(copied_inputs) File [FILE], line 11, in preprocessing_fn(inputs) tf.constant(value, shape=outputs[key].shape), File <*>python3.7/site-packages/tensorflow_core/python/framework/constant_op.py, line 258, in constant(value, dtype, shape, name) allow_broadcast=True) File <*>python3.7/site-packages/tensorflow_core/python/framework/constant_op.py, line 296, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast)) File <*>python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py, line 448, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) if shape is not None and np.prod(shape, dtype=np.int64) == 0: File [FILE], line [NUM], in prod(*args, **kwargs) [CODE] File <*>python3.7/site-packages/numpy/core/fromnumeric.py, line 2962, in prod(a, axis, dtype, out, keepdims, initial, where) keepdims=keepdims, initial=initial, where=where) File <*>python3.7/site-packages/numpy/core/fromnumeric.py, line 90, in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs) return ufunc.reduce(obj, axis, dtype, out, **passkwargs) TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'",0
"File [FILE], line 13, in <module> loss = criterion(output, labels) File <*>python3.6/site-packages/torch/nn/modules/module.py, line 532, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.6/site-packages/torch/nn/modules/loss.py, line 204, in forward(self, input, target) return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction) File <*>python3.6/site-packages/torch/nn/functional.py, line 1838, in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction) ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index) RuntimeError: expected scalar type Long but found Float",0
"File [FILE], line 7, in <module>() print(x[tensor(0)]) KeyError: tensor(0)",0
"File [FILE], line 8, in <module>() callbacks=[ccall, esd3] File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 813, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) callbacks.on_epoch_end(epoch, epoch_logs) File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 365, in on_epoch_end(self, epoch, logs) callback.on_epoch_end(epoch, logs) File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 1485, in on_epoch_end(self, epoch, logs) self.model.set_weights(self.best_weights) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 1519, in set_weights(self, weights) if expected_num_weights != len(weights): TypeError: object of type 'NoneType' has no len()",0
"File [FILE], line 58, in <module>() optimizer.step() File <*>python3.6/dist-packages/torch/autograd/grad_mode.py, line 15, in decorate_context(*args, **kwargs) return func(*args, **kwargs) File <*>python3.6/dist-packages/torch/optim/adam.py, line 99, in step(self, closure) exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1) RuntimeError: expected device cpu but got device cuda:0",0
"File [FILE], line 4, in <module>() model = encoder_model(k) File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1113, in op(self) ""Tensor.op is meaningless when eager execution is enabled."") AttributeError: Tensor.op is meaningless when eager execution is enabled.",0
"File <*>/site-packages/tensorflow_core/python/client/session.py, line 1365, in _do_call(self, fn, *args) return fn(*args) File <*>/site-packages/tensorflow_core/python/client/session.py, line 1350, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) target_list, run_metadata) File <*>/site-packages/tensorflow_core/python/client/session.py, line 1443, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata) InvalidArgumentError: indices[24,0] = 335 is not in [0, 304) [[{{node user-embedding-mlp_1/GatherV2}}]]",0
"File [FILE], line 29, in <module> interpreter.allocate_tensors() File <*>/interpreter.py, line 242, in allocate_tensors(self) return self._interpreter.AllocateTensors() File <*>/tensorflow_wrap_interpreter_wrapper.py, line 110, in AllocateTensors(self) return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self) RuntimeError: tensorflow/lite/kernels/reshape.cc:66 num_input_elements != num_output_elements (1536 != 768)Node number 3 (RESHAPE) failed to prepare.",0
"File [FILE], line 1, in <module> output = encoder(src, src_mask) File <*>python3.7/site-packages/torch/nn/modules/transformer.py, line 167, in forward(self, src, mask, src_key_padding_mask) src_key_padding_mask=src_key_padding_mask) File <*>python3.7/site-packages/torch/nn/modules/module.py, line 547, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.7/site-packages/torch/nn/modules/transformer.py, line 266, in forward(self, src, src_mask, src_key_padding_mask) key_padding_mask=src_key_padding_mask)[0] File <*>python3.7/site-packages/torch/nn/modules/activation.py, line 783, in forward(self, query, key, value, key_padding_mask, need_weights, attn_mask) attn_mask=attn_mask) File <*>python3.7/site-packages/torch/nn/functional.py, line 3252, in multi_head_attention_forward(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v) attn_output_weights += attn_mask RuntimeError: The size of tensor a (20) must match the size of tensor b (95) at non-singleton dimension 2",0
"File [FILE], line 21, in <module>() history = m.fit([X, y, W], y, epochs=10) File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 819, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing) File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 235, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing) File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 593, in _process_training_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing) use_multiprocessing=use_multiprocessing) File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 646, in _process_inputs(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing) x, y, sample_weight=sample_weights) File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 2383, in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset) batch_size=batch_size) File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 2469, in _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size) exception_prefix='target') File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_utils.pyc, line 496, in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) 'expected no data, but got:', data) ValueError: ('Error when checking model target: expected no data, but got:', array([3.39102071e-01, 1.23122638e-01, 7.54209531e-01, 8.10110230e-01,",0
"File [FILE], line 4, in <module>() y_true = np.argmax(testdata, axis=1) File [FILE], line [NUM], in argmax(*args, **kwargs) [CODE] File <*>python3.6/dist-packages/numpy/core/fromnumeric.py, line 47, in _wrapit(obj, method, *args, **kwds) result = getattr(asarray(obj), method)(*args, **kwds) AxisError: axis 1 is out of bounds for array of dimension 1",0
"File [FILE], line 2, in <module> model.save(""network.h5"") File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 1008, in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options) signatures, options) File <*>/site-packages/tensorflow_core/python/keras/saving/save.py, line 99, in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options) (h5py is not None and isinstance(filepath, h5py.File)) or AttributeError: module 'h5py' has no attribute 'File'",0
"File [FILE], line 22, in [FUNC] train_iter.next() File <*>/site-packages/torch/utils/data/dataloader.py, line 345, in __next__(self) data = self._next_data() File <*>/site-packages/torch/utils/data/dataloader.py, line 385, in _next_data(self) data = self._dataset_fetcher.fetch(index) # may raise StopIteration File <*>/site-packages/torch/utils/data/_utils/fetch.py, line 47, in fetch(self, possibly_batched_index) return self.collate_fn(data) File <*>/site-packages/torch/utils/data/_utils/collate.py, line 79, in default_collate(batch) return [default_collate(samples) for samples in transposed] File <*>/site-packages/torch/utils/data/_utils/collate.py, line 79, in (.0) return [default_collate(samples) for samples in transposed] File <*>/site-packages/torch/utils/data/_utils/collate.py, line 81, in default_collate(batch) raise TypeError(default_collate_err_msg_format.format(elem_type)) TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found",0
"File [FILE], line 27, in <module> loss = criterion(pred, y) File <*>python3.7/site-packages/torch/nn/modules/module.py, line 550, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>python3.7/site-packages/torch/nn/modules/loss.py, line 432, in forward(self, input, target) return F.mse_loss(input, target, reduction=self.reduction) File <*>python3.7/site-packages/torch/nn/functional.py, line 2530, in mse_loss(input, target, size_average, reduce, reduction) if not (target.size() == input.size()): File <*>python3.7/site-packages/torch/nn/modules/module.py, line 594, in __getattr__(self, name) type(self).__name__, name)) AttributeError: 'UNet3D' object has no attribute 'size'",0
"File [FILE], line 1, in <module> writer.add_graph(net, images) File <*>/site-packages/tensorboardX/writer.py, line 793, in add_graph(self, model, input_to_model, verbose) from torch.utils.tensorboard._pytorch_graph import graph File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 4, in <module> raise ImportError('TensorBoard logging requires TensorBoard version 1.15 or above') ImportError: TensorBoard logging requires TensorBoard version 1.15 or above",0
"File [FILE], line 3, in <module> shap_values = explainer.shap_values(X_train) File <*>/site-packages/shap/explainers/deep/__init__.py, line 119, in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity) return self.explainer.shap_values(X, ranked_outputs, output_rank_order, check_additivity=check_additivity) File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 304, in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity) sample_phis = self.run(self.phi_symbolic(feature_ind), self.model_inputs, joint_input) File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 361, in run(self, out, model_inputs, X) return self.execute_with_overridden_gradients(anon) File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 397, in execute_with_overridden_gradients(self, f) out = f() File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 357, in anon() final_out = out(inputs) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__(self, *args, **kwds) result = self._call(*args, **kwds) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 823, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializers) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 696, in _initialize(self, args, kwds, add_initializers_to) self._stateful_fn._get_concrete_function_internal_garbage_collected( # pylint: disable=protected-access File <*>/site-packages/tensorflow/python/eager/function.py, line 2855, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 3213, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs) File <*>/site-packages/tensorflow/python/eager/function.py, line 3065, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) func_graph_module.func_graph_from_py_func( File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 986, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs) File <*>/site-packages/tensorflow/python/eager/def_function.py, line 600, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds) File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 973, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e) StagingError: in user code: C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\shap\explainers\deep\deep_tf.py:244 grad_graph * x_grad = tape.gradient(out, shap_rAnD) C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\backprop.py:1067 gradient ** flat_grad = imperative_grad.imperative_grad( C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\imperative_grad.py:71 imperative_grad return pywrap_tfe.TFE_Py_TapeGradient( C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\backprop.py:151 _gradient_function grad_fn = ops._gradient_registry.lookup(op_name) # pylint: disable=protected-access C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\framework\registry.py:96 lookup raise LookupError( LookupError: gradient registry has no entry for: shap_TensorListStack",0
"File [FILE], line 8, in <module> optimization.train(x_train, y_train, x_val, y_val, File [FILE], line 70, in train(self, x_train, y_train, x_val, y_val, batch_size, n_epochs, dropout, do_teacher_forcing) y_pred = self._predict(x_batch, y_batch, seq_len, do_teacher_forcing) File [FILE], line 95, in _predict(self, x_batch, y_batch, seq_len, do_teacher_forcing) y_pred = self.model(x_batch) File [FILE], line 19, in forward(self, input, future, y) h_t, c_t = self.lstm(input_t, (h_t, c_t)) File <*>/site-packages/torch/nn/modules/module.py, line 727, in _call_impl(self, *input, **kwargs) result = self.forward(*input, **kwargs) File <*>/site-packages/torch/nn/modules/rnn.py, line 965, in forward(self, input, hx) self.check_forward_input(input) File <*>/site-packages/torch/nn/modules/rnn.py, line 791, in check_forward_input(self, input) raise RuntimeError( RuntimeError: input has inconsistent input_size: got 1, expected 3",0
"File [FILE], line 16, in <module>() results = p.map(X_power_func, range(8)) File <*>python3.6/pool.py, line 644, in get(self, timeout) raise self._value RuntimeError: CUDA error: initialization error",0
"File [FILE], line 7, in <module>() validation_steps = valid_step , callbacks = [metrics], verbose=2) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 673, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch) File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 1433, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch') File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py, line 331, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) callbacks.on_epoch_end(epoch, epoch_logs) File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 311, in on_epoch_end(self, epoch, logs) callback.on_epoch_end(epoch, logs) File [FILE], line 16, in on_epoch_end(self, batch, logs) X_val, y_val = self.validation_data[0], self.validation_data[1] TypeError: 'NoneType' object is not subscriptable",0
