eventId,post_id,label,Pattern,type,Unnamed: 5,Templates,,
0,16848650,1,1,CORE-TPL,,"File <pyshell#146>, line 1, in <module> that[~(that>=5).nonzero()].max().eval()[SEP]AttributeError: 'TensorVariable' object has no attribute 'nonzero'",,
1,33622842,1,1,TPL-LLL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 4, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 13, in <module> from tensorflow.core.framework.graph_pb2 import *[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/graph_pb2.py, line 16, in <module> from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py, line 16, in <module> from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py, line 16, in <module> from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py, line 22, in <module> serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto \x12\ntensorflow\""d\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tb\x06proto3')[SEP]TypeError: __init__() got an unexpected keyword argument 'syntax'",,
3,33656551,1,2,TPL-TPL,,"File [FILE], line 1, in <module>() import tensorflow[SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 4, in <module>() from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 13, in <module>() from tensorflow.core.framework.graph_pb2 import *[SEP]File <*>python2.7/site-packages/tensorflow/core/framework/graph_pb2.py, line 8, in <module>() from google.protobuf import reflection as _reflection[SEP]File <*>python2.7/site-packages/google/protobuf/reflection.py, line 58, in <module>() from google.protobuf.internal import python_message as message_impl[SEP]File <*>python2.7/site-packages/google/protobuf/internal/python_message.py, line 59, in <module>() import six.moves.copyreg as copyreg[SEP]ImportError: No module named copyreg",,
4,33671372,1,1,TPL-LLL,,"File multiply.py, line 2, in <module> import tensorflow as tf[SEP]File <*>python2.7.10/site-packages/tensorflow/__init__.py, line 4, in <module> from tensorflow.python import *[SEP]File <*>python2.7.10/site-packages/tensorflow/python/__init__.py, line 22, in <module> from tensorflow.python.client.client_lib import *[SEP]File <*>python2.7.10/site-packages/tensorflow/python/client/client_lib.py, line 35, in <module> from tensorflow.python.client.session import InteractiveSession[SEP]File <*>python2.7.10/site-packages/tensorflow/python/client/session.py, line 11, in <module> from tensorflow.python import pywrap_tensorflow as tf_session[SEP]File <*>python2.7.10/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7.10/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory",,
5,34295136,1,1,TPL-python,,"File classify.py, line 14, in <module> import caffe[SEP]File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver[SEP]File <*>/pycaffe.py, line 13, in <module> from ._caffe import Net, SGDSolver[SEP]ImportError: dynamic module does not define module export function (PyInit__caffe)",,
6,35596795,1,1,TPL-hardware,,"File <*>python3.5/site-packages/theano/gof/opt.py, line 1772, in process_node replacements = lopt.transform(node)[SEP]File <*>python3.5/site-packages/theano/sandbox/gpuarray/opt.py, line 140, in local_opt new_op = maker(node, context_name)[SEP]File <*>python3.5/site-packages/theano/sandbox/gpuarray/opt.py, line 732, in local_gpua_hgemm if nvcc_compiler.nvcc_version < '7.5':[SEP]TypeError: unorderable types: NoneType() < str()",,
7,35735162,1,1,TPL-LLL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow import contrib[SEP]File <*>python2.7/site-packages/tensorflow/contrib/__init__.py, line 23, in <module> from tensorflow.contrib import layers[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/__init__.py, line 68, in <module> from tensorflow.contrib.layers.python.layers import *[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/__init__.py, line 22, in <module> from tensorflow.contrib.layers.python.layers.initializers import *[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/initializers.py, line 24, in <module> from tensorflow.python.ops import random_ops[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/random_ops.py, line 23, in <module> from tensorflow.python.framework import ops[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 39, in <module> from tensorflow.python.framework import versions[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/versions.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory",,
8,35905264,1,1,CORE-TPL,,"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: No module named data_utils",,
10,36490849,1,1,TPL-TPL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/prettytensor-0.6.0-py2.7.egg/prettytensor/__init__.py, line 25, in <module> from prettytensor import funcs[SEP]File <*>python2.7/site-packages/prettytensor-0.6.0-py2.7.egg/prettytensor/funcs.py, line 25, in <module> from prettytensor.pretty_tensor_image_methods import *[SEP]File <*>python2.7/site-packages/prettytensor-0.6.0-py2.7.egg/prettytensor/pretty_tensor_image_methods.py, line 20, in <module> from prettytensor import layers[SEP]ImportError: cannot import name layers",,
11,37002134,1,1,CORE-TPL,,"File <*>/fully_connected_feed.py, line 27, in [FUNC] [CODE][SEP]File <*>/input_data.py, line 29, in [FUNC] [CODE][SEP]ImportError: No module named contrib.learn.python.learn.datasets.mnist",,
12,37686139,1,1,TPL-TPL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tflearn/__init__.py, line 22, in <module> from . import activations[SEP]File <*>python2.7/site-packages/tflearn/activations.py, line 7, in <module> from . import initializations[SEP]File <*>python2.7/site-packages/tflearn/initializations.py, line 5, in <module> from tensorflow.contrib.layers.python.layers.initializers import \[SEP]ImportError: cannot import name variance_scaling_initializer",,
13,38446771,1,1,TPL-TPL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/dist-packages/theano/__init__.py, line 74, in <module> from theano.printing import pprint, pp[SEP]File <*>python2.7/dist-packages/theano/printing.py, line 35, in <module> if pd.find_graphviz():[SEP]AttributeError: 'module' object has no attribute 'find_graphviz'",,
14,38716584,1,1,TPL-DEV,,"File <*>/worker.py, line 98, in main command = pickleSer._read_with_length(infile)[SEP]File <*>/serializers.py, line 164, in _read_with_length return self.loads(obj)[SEP]File <*>/serializers.py, line 422, in loads return pickle.loads(obj)[SEP]File <*>python2.7/site-packages/six.py, line 118, in __getattr__ _module = self._resolve()[SEP]File <*>python2.7/site-packages/six.py, line 115, in _resolve return _import_module(self.mod)[SEP]RuntimeError: maximum recursion depth exceeded",,
15,38790852,1,1,TPL-LLL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 48, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.19' not found (required by /home/anirudh/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so)",,
16,39238057,1,1,CORE-TPL,,"File <*>/census.py, line 73, in <module> df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)[SEP]File <*>python2.7/dist-packages/pandas/core/series.py, line 2023, in apply mapped = lib.map_infer(values, f, convert=convert_dtype)[SEP]File inference.pyx, line 920, in pandas.lib.map_infer (pandas/lib.c:44780)[SEP]File <*>/census.py, line 73, in <lambda> df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)[SEP]TypeError: argument of type 'float' is not iterable",,
17,39646921,1,1,CORE-TPL,,"File <pyshell#0>, line 1, in <module> from keras.layers import Dense[SEP]ImportError: cannot import name 'Dense'",,
18,40467893,1,1,CORE-TPL,,"File mnist_softmax.py, line 78, in <module> tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)[SEP]TypeError: run() got an unexpected keyword argument 'argv'",,
19,40511562,1,2,CORE-TPL,,"File [FILE], line 4, in `<module>`() tf.global_variables_initializer().run()[SEP]AttributeError: 'module' object has no attribute 'global_variables_initializer'",,
20,40538920,1,2,TPL-TPL,,"File <*>python3.5/site-packages/keras/backend/tensorflow_backend.py, line 5, in <module>() from tensorflow.python.ops import ctc_ops as ctc[SEP]ImportError: cannot import name 'ctc_ops'",,
21,40538920,1,2,TPL-TPL,,"File [FILE], line 1, in <module>() import keras[SEP]File <*>python3.5/site-packages/keras/__init__.py, line 2, in <module>() from . import backend[SEP]File <*>python3.5/site-packages/keras/backend/__init__.py, line 69, in <module>() from .tensorflow_backend import *[SEP]File <*>python3.5/site-packages/keras/backend/tensorflow_backend.py, line 7, in <module>() import tensorflow.contrib.ctc as ctc[SEP]ImportError: No module named 'tensorflow.contrib.ctc'",,
22,41372375,1,1,CORE-TPL,,"File <*>/test3.py, line 5, in [FUNC] [CODE][SEP]AttributeError: module 'tensorflow.contrib.learn' has no attribute 'TensorFlowDNNClassifier'",,
23,41482913,1,2,CORE-TPL,,"File [FILE], line 1, in <module>() writer = tf.train.SummaryWriter('./my_graph', sess.graph)[SEP]AttributeError: 'module' object has no attribute 'SummaryWriter'",,
24,41482913,1,2,CORE-TPL,,"File [FILE], line 1, in <module>() writer = tf.train.FileWriter('./my_graph', sess.graph)[SEP]AttributeError: 'module' object has no attribute 'FileWriter'",,
25,41482913,1,1,CORE-TPL,,"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: 'module' object has no attribute 'FileWriter'",,
26,41813665,1,1,CORE-TPL,,"File DA_test_pred.py, line 24, in <module> logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False)[SEP]File <*>/inception_v1.py, line 290, in inception_v1 net, end_points = inception_v1_base(inputs, scope=scope)[SEP]File <*>/inception_v1.py, line 96, in inception_v1_base net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])[SEP]File <*>python2.7/dist-packages/tensorflow/python/ops/array_ops.py, line 1053, in concat dtype=dtypes.int32).get_shape([SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 651, in convert_to_tensor as_ref=False)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 716, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/constant_op.py, line 176, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/constant_op.py, line 165, in constant tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/tensor_util.py, line 367, in make_tensor_proto _AssertCompatible(values, dtype)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/tensor_util.py, line 302, in _AssertCompatible (dtype.name, repr(mismatch), type(mismatch).__name__))[SEP]TypeError: Expected int32, got list containing Tensors of type '_Message' instead.",,
27,41875915,1,1,TPL-TPL,,"File <*>python2.7/dist-packages/pip/basecommand.py, line 122, in main status = self.run(options, args)[SEP]File <*>python2.7/dist-packages/pip/commands/install.py, line 278, in run requirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle)[SEP]File /usr/lib/python2.7/dist-packages/pip/req.py, line 1178, in prepare_files url = finder.find_requirement(req_to_install, upgrade=self.upgrade)",,
28,42094377,1,1,CORE-TPL,,"File ptb_word_lm.py, line 374, in <module> tf.app.run()[SEP]File <*>python3.6/site-packages/tensorflow/python/platform/app.py, line 43, in run sys.exit(main(sys.argv[:1] + flags_passthrough))[SEP]File ptb_word_lm.py, line 334, in main train_input = PTBInput(config=config, data=train_data, name=""TrainInput"")[SEP]File ptb_word_lm.py, line 94, in __init__ data, batch_size, num_steps, name=name)[SEP]File <*>/reader.py, line 117, in ptb_producer [batch_size, (i + 1) * num_steps])[SEP]TypeError: strided_slice() missing 1 required positional argument: 'strides'",,
29,42481938,1,1,CORE-TPL,,"File fully_connected_feed.py, line 229, in <module> tf.app.run()[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 44, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough))[SEP]File fully_connected_feed.py, line 225, in main run_training()[SEP]File fully_connected_feed.py, line 154, in run_training summary_op = tf.merge_all_summaries()[SEP]AttributeError: 'module' object has no attribute 'merge_all_summaries'",,
30,42675391,1,1,CORE-TPL,,"File mnist_test.py, line 19, in <module> cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_, logits=y)[SEP]TypeError: sigmoid_cross_entropy_with_logits() got an unexpected keyword argument 'labels'",,
31,42729958,1,1,TPL-DEV,,"File <*>python3.6/site-packages/theano/gof/opt.py, line 1772, in process_node replacements = lopt.transform(node)[SEP]File <*>python3.6/site-packages/theano/tensor/opt.py, line 5825, in constant_folding no_recycling=[])[SEP]File <*>python3.6/site-packages/theano/gof/op.py, line 970, in make_thunk no_recycling)[SEP]File <*>python3.6/site-packages/theano/gof/op.py, line 879, in make_c_thunk output_storage=node_output_storage)[SEP]File <*>python3.6/site-packages/theano/gof/cc.py, line 1200, in make_thunk keep_lock=keep_lock)[SEP]File <*>python3.6/site-packages/theano/gof/cc.py, line 1143, in __compile__ keep_lock=keep_lock)[SEP]File <*>python3.6/site-packages/theano/gof/cc.py, line 1595, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock)[SEP]File <*>python3.6/site-packages/theano/gof/cmodule.py, line 1142, in module_from_key module = lnk.compile_cmodule(location)[SEP]File <*>python3.6/site-packages/theano/gof/cc.py, line 1506, in compile_cmodule preargs=preargs)[SEP]File <*>python3.6/site-packages/theano/gof/cmodule.py, line 2213, in compile_str return dlimport(lib_filename)[SEP]File <*>python3.6/site-packages/theano/gof/cmodule.py, line 299, in dlimport rval = __import__(module_name, {}, {}, [module_name])[SEP]ImportError: /home/puck/.theano/compiledir_Linux-4.4--MANJARO-x86_64-with-glibc2.2.5--3.6.0-64/tmpre6vph8g/mdb219947724f79219f7dbd36f0f52c77.so: undefined symbol: _ZdlPvm",,
32,42756503,1,1,TPL-os,,"File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 61, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: dlopen(/Users/smahesh/src/tensorflow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.8.0.dylib",,
33,42822486,1,1,CORE-TPL,,"File cnn.py, line 258, in <module> models = run_cross_validation_create_models(num_folds)[SEP]File cnn.py, line 205, in run_cross_validation_create_models validation_data=(X_valid, Y_valid))[SEP]TypeError: fit_generator() takes at least 4 arguments (5 given)",,
34,42823627,1,1,CORE-TPL,,"File <*>/test_model.py, line 2, in <module> from models import NN_with_EntityEmbedding[SEP]File <*>/models.py, line 8, in <module> from keras.layers.core import Dense, Dropout, Activation, Merge, Reshape[SEP]ImportError: cannot import name Merge",,
35,42947295,1,1,CORE-TPL,,"File convnet.py, line 6, in <module> model.add(Conv2D(32, (3, 3), input_shape=(3, 150, 150)))[SEP]TypeError: __init__() missing 1 required positional argument: 'nb_col'",,
36,42998355,1,1,TPL-TPL,,"File <*>/CNNTest-one.py, line 7, in <module> import lasagne[SEP]File <*>/site-packages/lasagne/__init__.py, line 19, in <module> from . import layers[SEP]File <*>/site-packages/lasagne/layers/__init__.py, line 7, in <module> from .pool import *[SEP]File <*>/site-packages/lasagne/layers/pool.py, line 6, in <module> from theano.tensor.signal import downsample[SEP]ImportError: cannot import name 'downsample'",,
37,43577923,1,2,TPL-LLL,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper() return importlib.import_module(mname)[SEP]File <*>/importlib__init__.py, line 126, in import_module(name, package) return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <*>/importlib_bootstrap.py, line [NUM], in _gcd_import(name, package, level) [CODE][SEP]File <*>/importlib_bootstrap.py, line [NUM], in _find_and_load(name, import_) [CODE][SEP]File <*>/importlib_bootstrap.py, line [NUM], in _find_and_load_unlocked(name, import_) [CODE][SEP]File <*>/importlib_bootstrap.py, line [NUM], in _load_unlocked(spec) [CODE][SEP]File <*>/importlib_bootstrap.py, line [NUM], in module_from_spec(spec ) [CODE][SEP]File <*>/importlib_bootstrap_external.py, line [NUM], in create_module(self, spec) [CODE][SEP]File <*>/importlib_bootstrap.py, line [NUM], in _call_with_frames_removed(f, *args, **kwds) [CODE][SEP]ImportError: DLL load failed: The specified module could not be found.",,
38,43577923,1,2,TPL-LLL,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in () from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in () _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper() return importlib.import_module('_pywrap_tensorflow_internal' )[SEP]File <*>/importlib__init__.py, line 126, in import_module(name, pac kage) return _bootstrap._gcd_import(name[level:], package, level)[SEP]ImportError: No module named '_pywrap_tensorflow_internal'",,
39,43577923,1,1,TPL-LLL,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper return importlib.import_module(mname)[SEP]File <*>/importlib__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File [FILE], line 126, in [FUNC] [CODE][SEP]ImportError: DLL load failed: The specified module could not be found.",,
40,43577923,1,1,TPL-LLL,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal')[SEP]File <*>/importlib__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]ImportError: No module named '_pywrap_tensorflow_internal'",,
41,43786994,1,2,CORE-TPL,,"File <*>python3.5/site-packages/tensorflow/python/framework/op_def_library.py, line 491, in apply_op(self, op_type_name, name, **keywords) preferred_dtype=default_dtype)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 704, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 577, in _TensorTensorConversionFunction(t, dtype, name, as_ref) % (dtype.name, t.dtype.name, str(t)))[SEP]ValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(""nce_loss/Reshape_1:0"", shape=(?, 1, ?), dtype=float32)'",,
42,43786994,1,2,CORE-TPL,,"File [FILE], line 44, in <module>() num_sampled, vocabulary_size))[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/nn_impl.py, line 1166, in nce_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name) name=name)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/nn_impl.py, line 1001, in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name) array_ops.reshape(true_w, new_true_w_shape))[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/math_ops.py, line 278, in multiply(x, y, name) return gen_math_ops._mul(x, y, name)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py, line 1434, in _mul(x, y, name) result = _op_def_lib.apply_op(""Mul"", x=x, y=y, name=name)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/op_def_library.py, line 527, in apply_op(self, op_type_name, name, **keywords) inferred_from[input_arg.type_attr]))[SEP]TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int32 of argument 'x'.",,
43,44080677,1,1,TPL-LLL,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal')[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]ImportError: No module named '_pywrap_tensorflow_internal'",,
44,44080677,1,1,TPL-LLL,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper return importlib.import_module(mname)[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <frozen importlib._bootstrap>, line 986, in _gcd_import [CODE][SEP]File <frozen importlib._bootstrap>, line 969, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 958, in _find_and_load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 666, in _load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 577, in module_from_spec [CODE][SEP]File <frozen importlib._bootstrap_external>, line 906, in create_module [CODE][SEP]File <frozen importlib._bootstrap>, line 222, in _call_with_frames_removed [CODE][SEP]ImportError: DLL load failed: The specified module could not be found.",,
45,44503603,1,1,TPL-LLL,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper return importlib.import_module(mname)[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <frozen importlib._bootstrap>, line 986, in _gcd_import [CODE][SEP]File <frozen importlib._bootstrap>, line 969, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 958, in _find_and_load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 666, in _load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 577, in module_from_spec [CODE][SEP]File <frozen importlib._bootstrap_external>, line 919, in create_module [CODE][SEP]File <frozen importlib._bootstrap>, line 222, in _call_with_frames_removed [CODE][SEP]ImportError: DLL load failed: The specified module could not be found.",,
47,44679439,1,1,CORE-TPL ,,"File <*>/tensorboard, line 7, in <module> from tensorflow.tensorboard.tensorboard import main[SEP]ModuleNotFoundError: No module named 'tensorflow.tensorboard.tensorboard'",,
48,44993098,1,1,TPL-LLL,,"File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]ImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory Failed to load the native TensorFlow runtime.",,
49,45084467,1,1,CORE-TPL,,"File <*>/running_template.py, line 65, in <module> cytoplasm_predictions = run_models_on_directory(data_location,cyto_channel_names, cyto_location, model_fn = cyto_fn,list_of_weights = list_of_cyto_weights, image_size_x = image_size_x, image_size_y = image_size_y,win_x = win_cyto, win_y = win_cyto, std = False, split = False)[SEP]File <*>/cnn_functions.py, line 1491, in run_models_on_directory model = model_fn(batch_input_shape = batch_input_shape, n_features = n_features, weights_path = list_of_weights[0])[SEP]File <*>/model_zoo.py, line 528, in sparse_bn_feature_net_61x61 model.add(sparse_Convolution2D(64, 3, 3, d = d, init = init, batch_input_shape = batch_input_shape, border_mode='valid', W_regularizer = l2(reg)))[SEP]File <*>python2.7/site-packages/keras/models.py, line 436, in add layer(x)[SEP]File <*>python2.7/site-packages/keras/engine/topology.py, line 569, in __call__ self.build(input_shapes[0])[SEP]File <*>/cnn_functions.py, line 1012, in build self.W = self.init(self.W_shape, name='{}_W'.format(self.name))[SEP]TypeError: __call__() got an unexpected keyword argument 'name'",,
50,47485847,1,1,TPL-os,,"File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.6/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.6/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: dlopen(/Users/joson/tensorflow/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 10): Library not loaded: @rpath/libcublas.8.0.dylib",,
52,48054531,1,1,TPL-TPL,,"File <string>, line 1, in <module> [CODE][SEP]File <*>python3.4/site-packages/pandas/__init__.py, line 35, in <module> ""the C extensions first."".format(module))[SEP]ImportError: C extension: numpy.core.multiarray failed to import not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.",,
53,48477909,1,1,TPL-LLL,,"File <*>/site-packages/tensorflow/python/platform/self_check.py, line 75, in preload_check ctypes.WinDLL(build_info.cudart_dll_name)[SEP]File <*>/__init__.py, line 347, in __init__ self._handle = _dlopen(self._name, mode)[SEP]OSError: [WinError 126] The specified module could not be found",,
54,48477909,1,1,TPL-LLL,,"File <pyshell#6>, line 1, in <module> import tensorflow as tf[SEP]File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import *[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 30, in <module> self_check.preload_check()[SEP]File <*>/site-packages/tensorflow/python/platform/self_check.py, line 82, in preload_check % (build_info.cudart_dll_name, build_info.cuda_version_number))[SEP]ImportError: Could not find 'cudart64_90.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 9.0 from this URL: https://developer.nvidia.com/cuda-toolkit",,
55,48546508,1,1,TPL-LLL,,"File <*>python2.7/runpy.py, line 174, in _run_module_as_main ""__main__"", fname, loader, pkg_name)[SEP]File <*>python2.7/runpy.py, line 72, in _run_code exec code in run_globals[SEP]File <*>python2.7/site-packages/object_detection/train.py, line 49, in <module> from object_detection import trainer[SEP]File <*>python2.7/site-packages/object_detection/trainer.py, line 27, in <module> from object_detection.builders import preprocessor_builder[SEP]File <*>python2.7/site-packages/object_detection/builders/preprocessor_builder.py, line 21, in <module> from object_detection.protos import preprocessor_pb2[SEP]File <*>python2.7/site-packages/object_detection/protos/preprocessor_pb2.py, line 71, in <module> options=None, file=DESCRIPTOR),[SEP]TypeError: __new__() got an unexpected keyword argument 'file'",,
56,49113497,1,1,TPL-hardware,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 21, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal')[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'",,
57,49113497,1,1,TPL-hardware,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 18, in swig_import_helper return importlib.import_module(mname)[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <frozen importlib._bootstrap>, line 994, in _gcd_import [CODE][SEP]File <frozen importlib._bootstrap>, line 971, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 955, in _find_and_load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 658, in _load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 571, in module_from_spec [CODE][SEP]File <frozen importlib._bootstrap_external>, line 922, in create_module [CODE][SEP]File <frozen importlib._bootstrap>, line 219, in _call_with_frames_removed [CODE][SEP]ImportError: DLL load failed with error code -1073741795",,
58,49913335,1,1,TPL-TPL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer[SEP]File <*>/pycaffe.py, line 15, in <module> import caffe.io[SEP]File <*>/io.py, line 2, in <module> import skimage.io[SEP]File <*>python3.6/site-packages/skimage/io/__init__.py, line 15, in <module> reset_plugins()[SEP]File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 93, in reset_plugins _load_preferred_plugins()[SEP]File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 73, in _load_preferred_plugins _set_plugin(p_type, preferred_plugins['all'])[SEP]File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 85, in _set_plugin use_plugin(plugin, kind=plugin_type)[SEP]File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 255, in use_plugin _load(name)[SEP]File <*>python3.6/site-packages/skimage/io/manage_plugins.py, line 299, in _load fromlist=[modname])[SEP]File <*>python3.6/site-packages/skimage/io/_plugins/matplotlib_plugin.py, line 3, in <module> import matplotlib.pyplot as plt[SEP]File <*>python3.6/site-packages/matplotlib/pyplot.py, line 40, in <module> from matplotlib.figure import Figure, figaspect[SEP]File <*>python3.6/site-packages/matplotlib/figure.py, line 39, in <module> from matplotlib.axes import Axes, SubplotBase, subplot_class_factory[SEP]File <*>python3.6/site-packages/matplotlib/axes/__init__.py, line 4, in <module> from ._subplots import *[SEP]File <*>python3.6/site-packages/matplotlib/axes/_subplots.py, line 10, in <module> from matplotlib.axes._axes import Axes[SEP]File <*>python3.6/site-packages/matplotlib/axes/_axes.py, line 23, in <module> import matplotlib.dates as _ # <-registers a date unit converter[SEP]File <*>python3.6/site-packages/matplotlib/dates.py, line 148, in <module> from dateutil.rrule import (rrule, MO, TU, WE, TH, FR, SA, SU, YEARLY,[SEP]File <*>python3.6/site-packages/dateutil/rrule.py, line 55, in [FUNC] [CODE][SEP]SyntaxError: invalid syntax",,
59,50354158,1,2,CORE-TPL,,"File [FILE], line 9, in <module>() features, label = iter(train_dataset).next()[SEP]TypeError: 'BatchDataset' object is not iterable",,
60,50430086,1,1,TPL-hardware,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 14, in swig_import_helper return importlib.import_module(mname)[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <frozen importlib._bootstrap>, line 994, in _gcd_import [CODE][SEP]File <frozen importlib._bootstrap>, line 971, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 955, in _find_and_load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 658, in _load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 571, in module_from_spec [CODE][SEP]File <frozen importlib._bootstrap_external>, line 922, in create_module [CODE][SEP]File <frozen importlib._bootstrap>, line 219, in _call_with_frames_removed [CODE][SEP]ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.",,
61,50430086,1,1,TPL-hardware,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 17, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 16, in swig_import_helper return importlib.import_module('_pywrap_tensorflow_internal')[SEP]File <*>/__init__.py, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'",,
62,50542683,1,1,CORE-python,,"File kerasbottleneck.py, line 103, in <module> save_bottlebeck_features()[SEP]File kerasbottleneck.py, line 69, in save_bottlebeck_features np.save(open('bottleneck_features_train.npy', 'w'),bottleneck_features_train)[SEP]File <*>python3.6/site-packages/numpy/lib/npyio.py, line 511, in save pickle_kwargs=pickle_kwargs)[SEP]File <*>python3.6/site-packages/numpy/lib/format.py, line 565, in write_array version)[SEP]File <*>python3.6/site-packages/numpy/lib/format.py, line 335, in _write_array_header fp.write(header_prefix)[SEP]TypeError: write() argument must be str, not bytes",,
63,50542683,1,1,CORE-python,,"File kerasbottleneck.py, line 104, in <module> train_top_model()[SEP]File kerasbottleneck.py, line 82, in train_top_model train_data = np.load(open('bottleneck_features_train.npy'))[SEP]File <*>python3.6/site-packages/numpy/lib/npyio.py, line 404, in load magic = fid.read(N)[SEP]File <*>python3.6/codecs.py, line 321, in decode (result, consumed) = self._buffer_decode(data, self.errors, final)[SEP]UnicodeDecodeError: 'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte",,
64,50830736,1,1,CORE-TPL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/keras/models.py, line 243, in load_model model = model_from_config(model_config, custom_objects=custom_objects)[SEP]File <*>python3.6/site-packages/keras/models.py, line 317, in model_from_config return layer_module.deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.6/site-packages/keras/layers/__init__.py, line 55, in deserialize printable_module_name='layer')[SEP]File <*>python3.6/site-packages/keras/utils/generic_utils.py, line 143, in deserialize_keras_object list(custom_objects.items())))[SEP]File <*>python3.6/site-packages/keras/models.py, line 1352, in from_config layer = layer_module.deserialize(conf, custom_objects=custom_objects)[SEP]File <*>python3.6/site-packages/keras/utils/generic_utils.py, line 145, in deserialize_keras_object return cls.from_config(config['config'])[SEP]File <*>python3.6/site-packages/keras/engine/topology.py, line 1269, in from_config return cls(**config)[SEP]File <*>python3.6/site-packages/keras/layers/core.py, line 483, in __init__ super(Flatten, self).__init__(**kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/topology.py, line 292, in __init__ raise TypeError('Keyword argument not understood:', kwarg)[SEP]TypeError: ('Keyword argument not understood:', 'data_format')",,
65,51337939,1,1,TPL-python,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.7/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>python3.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 114, in [FUNC] [CODE][SEP]SyntaxError: invalid syntax",,
66,51675235,1,1,CORE-TPL,,"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: module 'tensorflow.python.keras.datasets.fashion_mnist' has no attribute 'load_data'",,
67,51821537,1,1,TPL-TPL,,"File <*>/train_network.py, line 109, in <module> model = LeNet.build(width=100, height=100, depth=3, classes=5)[SEP]File <*>/lenet.py, line 39, in build output = model(pretrainedOutput)[SEP]File <*>python3.6/dist-packages/keras/engine/base_layer.py, line 443, in __call__ previous_mask = _collect_previous_mask(inputs)[SEP]File <*>python3.6/dist-packages/keras/engine/base_layer.py, line 1311, in _collect_previous_mask mask = node.output_masks[tensor_index][SEP]AttributeError: 'Node' object has no attribute 'output_masks'",,
68,51848122,1,1,TPL-os,,"File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.6/imp.py, line 243, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.6/imp.py, line 343, in load_dynamic return _load(spec)[SEP]ImportError: dlopen(/Users/me/tensorflow/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation",,
69,52542275,1,2,CORE-TPL,,"File [FILE], line 1, in <module>() from keras.layers import Merge[SEP]ImportError: cannot import name 'Merge'",,
70,53285424,1,1,TPL-TPL,,"File tSNE-images.py, line 95, in <module> run_tsne(images_path, output_path, tsne_dimensions, tsne_perplexity, tsne_learning_rate)[SEP]File tSNE-images.py, line 75, in run_tsne images, pca_features = analyze_images(images_path)[SEP]File tSNE-images.py, line 50, in analyze_images feat_extractor = Model(inputs=model.input, outputs=model.get_layer(""fc2"").output)[SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 91, in __init__ self._init_graph_network(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 251, in _init_graph_network input_shapes=[x._keras_shape for x in self.inputs],[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 251, in <listcomp> input_shapes=[x._keras_shape for x in self.inputs],[SEP]AttributeError: 'Tensor' object has no attribute '_keras_shape'",,
71,54307268,1,2,CORE-TPL,,"File [FILE], line 2, in <module>() from keras.utils import model_to_dot[SEP]ImportError: cannot import name 'model_to_dot'",,
72,54613474,1,1,TPL-TPL,,"File <input>, line 3, in <module> [CODE][SEP]AttributeError: 'Tensor' object has no attribute '_keras_shape'",,
73,54650423,1,1,CORE-TPL,,"File serialize_model.py, line 60, in <module> traced_script_module.save(""model.pt"")[SEP]AttributeError: 'function' object has no attribute 'save'",,
74,54668364,1,1,CORE-TPL,,"File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in make_tensor_proto str_values = [compat.as_bytes(x) for x in proto_values][SEP]File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in <listcomp> str_values = [compat.as_bytes(x) for x in proto_values][SEP]File <*>python3.6/site-packages/tensorflow/python/util/compat.py, line 61, in as_bytes (bytes_or_text,))[SEP]TypeError: Expected binary or unicode string, got {'DispositionSoldAmount': <tf.Tensor 'random_shuffle_queue_DequeueMany:4' shape=(128,) dtype=float64>}",,
75,54668364,1,1,CORE-TPL,,"File tuto.py, line 85, in <module> estimator.train(input_fn=get_input_fn(num_epochs=None,n_batch = 128,shuffle=True),steps=1000)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 354, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 1207, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 1237, in _train_model_default features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 1195, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/, line 537, in _model_fn sparse_combiner=sparse_combiner)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/, line 215, in _linear_model_fn logits=logits)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 239, in create_estimator_spec regularization_losses))[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 1482, in _create_tpu_estimator_spec features=features, mode=mode, logits=logits, labels=labels)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 1381, in create_loss expected_labels_dimension=self._logits_dimension)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/head.py, line 305, in _check_dense_labels_match_logits_and_reshape labels = sparse_tensor.convert_to_tensor_or_sparse_tensor(labels)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/sparse_tensor.py, line 279, in convert_to_tensor_or_sparse_tensor value, dtype=dtype, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1146, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 229, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 208, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 531, in make_tensor_proto ""supported type."" % (type(values), values))[SEP]TypeError: Failed to convert object of type <class 'dict'> to Tensor. Contents: {'DispositionSoldAmount': <tf.Tensor 'random_shuffle_queue_DequeueMany:4' shape=(128,) dtype=float64>}. Consider casting elements to a supported type.",,
76,54958312,1,1,CORE-TPL,,"File <*>/test_callback.py, line 34, in <module> model.evaluate_generator(generator=test_generator, steps=STEP_SIZE_TEST, callbacks=[test_callback])[SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]TypeError: evaluate_generator() got an unexpected keyword argument 'callbacks'",,
77,54958312,1,1,CORE-TPL,,"File <*>python3.6/threading.py, line 916, in _bootstrap_inner self.run()[SEP]File <*>python3.6/threading.py, line 864, in run self._target(*self._args, **self._kwargs)[SEP]File <*>python3.6/site-packages/keras/utils/data_utils.py, line 671, in _run executor.apply_async(next_sample, (self.uid,)), block=True)[SEP]File <*>python3.6/queue.py, line 127, in put if self.maxsize > 0:[SEP]TypeError: '>' not supported between instances of 'list' and 'int'",,
78,55112713,1,2,TPL-TPL,,"File [FILE], line 19, in <module>() history = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=0, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_split=0.25)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 880, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs) validation_steps=validation_steps)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py, line 325, in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs) callbacks._call_batch_hook(mode, 'begin', batch_index, batch_logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 196, in _call_batch_hook(self, mode, hook, batch, logs) batch_hook = getattr(callback, hook_name)[SEP]AttributeError: 'EarlyStopping' object has no attribute 'on_train_batch_begin'",,
79,55142951,1,1,CORE-TPL,,"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: module 'tensorflow' has no attribute 'Session'",,
80,55224016,1,1,TPL-LLL,,"File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.6/imp.py, line 243, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.6/imp.py, line 343, in load_dynamic return _load(spec)[SEP]ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory",,
81,55236063,1,2,TPL-TPL,,"File [FILE], line 2, in () model = InceptionV3(include_top=True,weights='imagenet')[SEP]File <*>python3.6/site-packages/keras/applications/__init__.py, line 28, in wrapper(*args, **kwargs) return base_fun(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/applications/inception_v3.py, line 11, in InceptionV3(*args, **kwargs) return inception_v3.InceptionV3(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras_applications/inception_v3.py, line 157, in InceptionV3(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs) img_input = layers.Input(shape=input_shape)[SEP]File <*>python3.6/site-packages/keras/engine/input_layer.py, line 178, in Input(shape, batch_shape, name, dtype, sparse, tensor) input_tensor=tensor)[SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/input_layer.py, line 39, in __init__(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name) name = prefix + '_' + str(K.get_uid(prefix))[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 74, in get_uid(prefix) graph = tf.get_default_graph()[SEP]AttributeError: module 'tensorflow' has no attribute 'get_default_graph'",,
84,56093768,1,1,TPL-hardware,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.",,
85,56851895,1,1,TPL-TPL,,"File <*>/train.py, line 326, in <module> batch_size=params.batch_size, is_binary=params.is_b_binary)[SEP]File <*>/models.py, line 378, in g_unet i = Input(shape=(in_ch, 512, 512))[SEP]File <*>/site-packages/keras/engine/input_layer.py, line 178, in Input input_tensor=tensor)[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/engine/input_layer.py, line 39, in __init__ name = prefix + '_' + str(K.get_uid(prefix))[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 74, in get_uid graph = tf.get_default_graph()[SEP]AttributeError: module 'tensorflow' has no attribute 'get_default_graph'",,
86,56851895,1,1,TPL-TPL,,"File <*>/train.py, line 7, in <module> import models as m[SEP]File <*>/models.py, line 25, in <module> K.set_image_dim_ordering('th')[SEP]AttributeError: module 'tensorflow.python.keras.api._v2.keras.backend' has no attribute 'set_image_dim_ordering'",,
87,56951853,1,1,TPL-TPL,,"File model_main.py, line 26, in <module> from object_detection import model_lib[SEP]File <*>/site-packages/object_detection-0.1-py3.7.egg/object_detection/model_lib.py, line 28, in <module> from object_detection import eval_util[SEP]File <*>/site-packages/object_detection-0.1-py3.7.egg/object_detection/eval_util.py, line 35, in <module> slim = tf.contrib.slim[SEP]File <*>/site-packages/tensorflow/python/util/lazy_loader.py, line 62, in __getattr__ module = self._load()[SEP]File <*>/site-packages/tensorflow/python/util/lazy_loader.py, line 45, in _load module = importlib.import_module(self.__name__)[SEP]File <*>/__init__.py, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <*>/site-packages/tensorflow/contrib/__init__.py, line 33, in <module> from tensorflow.contrib import compiler[SEP]File <*>/site-packages/tensorflow/contrib/compiler/__init__.py, line 22, in <module> from tensorflow.contrib.compiler import xla[SEP]File <*>/site-packages/tensorflow/contrib/compiler/xla.py, line 22, in <module> from tensorflow.python.estimator import model_fn as model_fn_lib[SEP]File <*>/site-packages/tensorflow/python/estimator/__init__.py, line 26, in <module> from tensorflow_estimator.python import estimator[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/__init__.py, line 25, in <module> import tensorflow_estimator.python.estimator.estimator_lib[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator_lib.py, line 69, in <module> from tensorflow_estimator.python.estimator.tpu.tpu_estimator import TPUEstimator[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py, line 83, in <module> from tensorflow_estimator.python.estimator import estimator as estimator_lib[SEP]File <*>/site-packages/tensorflow_estimator/__init__.py, line 8, in <module> from tensorflow_estimator._api.v1 import estimator[SEP]File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py, line 11, in <module> from tensorflow_estimator._api.v1.estimator import tpu[SEP]File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/tpu/__init__.py, line 8, in <module> from tensorflow_estimator._api.v1.estimator.tpu import experimental[SEP]File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/tpu/experimental/__init__.py, line 8, in <module> from tensorflow_estimator.python.estimator.tpu._tpu_estimator_embedding import EmbeddingConfigSpec[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/tpu/_tpu_estimator_embedding.py, line 32, in <module> from tensorflow.python.tpu import feature_column_v2 as tpu_fc_v2[SEP]ImportError: cannot import name 'feature_column_v2' from 'tensorflow.python.tpu' (C:\Users\Rodolfo\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\tpu\__init__.py)",,
88,56961839,1,1,TPL-TPL,,"File <*>/image.py, line 7, in <module> detector = ObjectDetection()[SEP]File <*>python3.5/site-packages/imageai/Detection/__init__.py, line 88, in __init__ self.sess = K.get_session()[SEP]File <*>python3.5/site-packages/keras/backend/tensorflow_backend.py, line 174, in get_session default_session = tf.get_default_session()[SEP]AttributeError: module 'tensorflow' has no attribute 'get_default_session'",,
89,57122907,1,2,TPL-TPL,,"File [FILE], line 28, in () callbacks=callbacks_list[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 247, in _call_batch_hook(self, mode, hook, batch, logs) batch_hook = getattr(callback, hook_name)[SEP]AttributeError: 'ModelCheckpoint' object has no attribute 'on_train_batch_begin'",,
90,57390631,1,2,TPL-TPL,,"File [FILE], line 3, in <module> model.add(Embedding(vocabulary_size, embedding_size, input_length=MAXLEN))[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/layers/embeddings.py, line 90, in __init__(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, activity_regularizer, embeddings_constraint, mask_zero, input_length, **kwargs) super(Embedding, self).__init__(**kwargs)[SEP]File <*>/site-packages/keras/engine/base_layer.py, line 132, in __init__(self, **kwargs) name = _to_snake_case(prefix) + '_' + str(K.get_uid(prefix))[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 74, in get_uid(prefix) graph = tf.get_default_graph()[SEP]AttributeError: module 'tensorflow' has no attribute 'get_default_graph'",,
91,57677160,1,2,CORE-TPL,,"File [FILE], line 1, in <module> from tensorflow.python.util.tf_export import keras_export[SEP]ImportError: cannot import name 'keras_export' from 'tensorflow.python.util.tf_export' (C:\Users\DILAW\Anaconda3\lib\site-packages\tensorflow\python\util\tf_export.py)",,
92,57681910,1,2,TPL-TPL,,"File [FILE], line 1, in <module>() plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)[SEP]File <*>python3.6/dist-packages/keras/utils/vis_utils.py, line 132, in plot_model(model, to_file, show_shapes, show_layer_names, rankdir) dot = model_to_dot(model, show_shapes, show_layer_names, rankdir)[SEP]File <*>python3.6/dist-packages/keras/utils/vis_utils.py, line 109, in model_to_dot(model, show_shapes, show_layer_names, rankdir) for inbound_layer in node.inbound_layers:[SEP]TypeError: 'InputLayer' object is not iterable",,
93,57718512,1,1,TPL-TPL,,"File <*>/Testing.py, line 82, in <module> model.fit(x_train, y_train, batch_size=50, epochs = 3, callbacks= [tensorboard])[SEP]File <*>/site-packages/keras/engine/training.py, line 1178, in fit validation_freq=validation_freq)[SEP]File <*>/site-packages/keras/engine/training_arrays.py, line 125, in fit_loop callbacks.set_model(callback_model)[SEP]File <*>/site-packages/keras/callbacks.py, line 68, in set_model callback.set_model(model)[SEP]File <*>/site-packages/tensorflow/python/keras/callbacks.py, line 1509, in set_model if not model.run_eagerly:[SEP]AttributeError: 'Sequential' object has no attribute 'run_eagerly'",,
94,57725839,1,1,TPL-TPL,,"File <*>/script.py, line 150, in <module> callbacks=[cb_checkpointer, cb_early_stopper][SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1418, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/keras/engine/training_generator.py, line 264, in fit_generator callbacks.on_train_end()[SEP]File <*>python3.6/site-packages/keras/callbacks.py, line 142, in on_train_end callback.on_train_end(logs)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/callbacks.py, line 940, in on_train_end if self.model._ckpt_saved_epoch is not None:[SEP]AttributeError: 'Sequential' object has no attribute '_ckpt_saved_epoch'",,
95,57754497,1,2,TPL-TPL,,"File [FILE], line 4, in <module>() model =load_model('Leavesnet Model.h5')[SEP]File <*>python3.6/dist-packages/keras/backend/tensorflow_backend.py, line 541, in placeholder(shape, ndim, dtype, sparse, name) x = tf.placeholder(dtype, shape=shape, name=name)[SEP]AttributeError: module 'tensorflow' has no attribute 'placeholder'",,
96,58638701,1,2,CORE-TPL,,"File [FILE], line 9, in <module> from tensorflow import set_random_seed[SEP]ImportError: cannot import name 'set_random_seed' from 'tensorflow' (C:\Users\polon\Anaconda3\lib\site-packages\tensorflow\__init__.py)",,
97,58770347,1,1,TPL-LLL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/dist-packages/torch/cuda/__init__.py, line 386, in current_device _lazy_init()[SEP]File <*>python3.6/dist-packages/torch/cuda/__init__.py, line 192, in _lazy_init _check_driver()[SEP]File <*>python3.6/dist-packages/torch/cuda/__init__.py, line 111, in _check_driver of the CUDA driver."""""".format(str(torch._C._cuda_getDriverVersion())))[SEP]AssertionError: The NVIDIA driver on your system is too old (found version 10000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",,
98,58827917,1,1,TPL-TPL,,"File train_initialize.py, line 18, in agent = Agent(""horoscope_domain.yml"", policies = [MemoizationPolicy(), KerasPolicy()])[SEP]File <*>/site-packages/rasa_core/policies/keras_policy.py, line 31, in init if KerasPolicy.is_using_tensorflow() and not graph:[SEP]File <*>/site-packages/rasa_core/policies/keras_policy.py, line 48, in is_using_tensorflow return keras.backend._BACKEND == ""tensorflow""[SEP]AttributeError: module 'keras.backend' has no attribute '_BACKEND'",,
99,58833945,1,2,TPL-TPL,,"File [FILE], line 6, in <module> output = tensorflow.keras.layers.Dropout(dropout_rate, name=""dropout_out"")(vgg_output)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 663, in __call__(self, inputs, *args, **kwargs) inputs, outputs, args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1708, in _set_connectivity_metadata_(self, inputs, outputs, args, kwargs) input_tensors=inputs, output_tensors=outputs, arguments=kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1795, in _add_inbound_node(self, input_tensors, output_tensors, arguments) input_tensors)[SEP]File <*>/site-packages/tensorflow/python/util/nest.py, line 515, in map_structure(func, *structure, **kwargs) structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/util/nest.py, line 515, in <listcomp>(.0) structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1794, in <lambda>(t) inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,[SEP]AttributeError: 'tuple' object has no attribute 'layer'",,
100,58833945,1,2,TPL-TPL,,"File [FILE], line 3, in <module> model.add(tensorflow.keras.layers.GlobalMaxPooling2D(name=""gap""))[SEP]File <*>/site-packages/keras/engine/sequential.py, line 133, in add(self, layer) 'Found: ' + str(layer))[SEP]TypeError: The added layer must be an instance of class Layer. Found: <tensorflow.python.keras.layers.core.Flatten object at 0x00000000B74364A8>",,
101,58878421,1,1,TPL-TPL,,"File <*>/keras-script.py, line 18, in <module> model = load_model(MODEL_PATH)[SEP]File <*>python3.7/dist-packages/keras/engine/saving.py, line 492, in load_wrapper return load_function(*args, **kwargs)[SEP]File <*>python3.7/dist-packages/keras/engine/saving.py, line 584, in load_model model = _deserialize_model(h5dict, custom_objects, compile)[SEP]File <*>python3.7/dist-packages/keras/engine/saving.py, line 274, in _deserialize_model model = model_from_config(model_config, custom_objects=custom_objects)[SEP]File <*>python3.7/dist-packages/keras/engine/saving.py, line 627, in model_from_config return deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.7/dist-packages/keras/layers/__init__.py, line 168, in deserialize printable_module_name='layer')[SEP]File <*>python3.7/dist-packages/keras/utils/generic_utils.py, line 147, in deserialize_keras_object list(custom_objects.items())))[SEP]File <*>python3.7/dist-packages/keras/engine/sequential.py, line 301, in from_config custom_objects=custom_objects)[SEP]File <*>python3.7/dist-packages/keras/engine/network.py, line 1056, in from_config process_layer(layer_data)[SEP]File <*>python3.7/dist-packages/keras/engine/network.py, line 1042, in process_layer custom_objects=custom_objects)[SEP]File <*>python3.7/dist-packages/keras/utils/generic_utils.py, line 149, in deserialize_keras_object return cls.from_config(config['config'])[SEP]File <*>python3.7/dist-packages/keras/engine/base_layer.py, line 1179, in from_config return cls(**config)[SEP]File <*>python3.7/dist-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]TypeError: __init__() got an unexpected keyword argument 'ragged'",,
102,58963553,1,1,TPL-TPL,,"File <ipython-input-3-0715decb6662>, line 1, in <module> runfile('G:/Traffic Violation Detection/object_detection.py', wdir='G:/Traffic Violation Detection')[SEP]File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 710, in runfile execfile(filename, namespace)[SEP]File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 101, in execfile exec(compile(f.read(), filename, 'exec'), namespace)[SEP]File <*>/object_detection.py, line 6, in <module> from keras.layers.merge import add, concatenate[SEP]File <*>/site-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>/site-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils[SEP]File <*>/site-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K[SEP]File <*>/site-packages/keras/backend/__init__.py, line 1, in <module> from .load_backend import epsilon[SEP]File <*>/site-packages/keras/backend/load_backend.py, line 90, in <module> from .tensorflow_backend import *[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 54, in <module> get_graph = tf_keras_backend.get_graph[SEP]AttributeError: module 'tensorflow.python.keras.backend' has no attribute 'get_graph'",,
103,59226533,1,2,CORE-TPL,,"File [FILE], line 1, in <module> var_init_1 = tf.get_variable(""var_init_1"", [1, 2], dtype=tf.int32, initializer=tf.zeros_initializer)[SEP]AttributeError: module 'tensorflow' has no attribute 'get_variable'",,
104,59232286,1,1,TPL-TPL,,"File <stdin>, line 1, in <module> [CODE][SEP]ModuleNotFoundError: No module named 'tensorflow'",,
105,59232286,1,1,TPL-TPL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/deepposekit/__init__.py, line 20, in <module> from deepposekit.io import TrainingGenerator, DataGenerator[SEP]File <*>python3.6/site-packages/deepposekit/io/__init__.py, line 18, in <module> from deepposekit.io.BaseGenerator import BaseGenerator[SEP]File <*>python3.6/site-packages/deepposekit/io/BaseGenerator.py, line 16, in <module> from tensorflow.keras.utils import Sequence[SEP]ModuleNotFoundError: No module named 'tensorflow'",,
106,59493606,1,1,TPL-TPL,,"File <*>python3.6/dist-packages/numpy/core/function_base.py, line 117, in linspace num = operator.index(num)[SEP]TypeError: 'numpy.float64' object cannot be interpreted as an integer",,
107,59493606,1,1,TPL-TPL,,"File <*>/tv-training-code.py, line 166, in <module> main()[SEP]File <*>/tv-training-code.py, line 161, in main evaluate(model, data_loader_test, device=device)[SEP]File <*>python3.6/dist-packages/torch/autograd/grad_mode.py, line 49, in decorate_no_grad return func(*args, **kwargs)[SEP]File <*>/engine.py, line 80, in evaluate coco_evaluator = CocoEvaluator(coco, iou_types)[SEP]File <*>/coco_eval.py, line 28, in __init__ self.coco_eval[iou_type] = COCOeval(coco_gt, iouType=iou_type)[SEP]File <*>/cocoeval.py, line 75, in __init__ self.params = Params(iouType=iouType) # parameters[SEP]File <*>/cocoeval.py, line 527, in __init__ self.setDetParams()[SEP]File <*>/cocoeval.py, line 506, in setDetParams self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)[SEP]File <__array_function__ internals>, line 6, in linspace [CODE][SEP]File <*>python3.6/dist-packages/numpy/core/function_base.py, line 121, in linspace .format(type(num)))[SEP]TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.",,
108,59622277,1,1,CORE-TPL,,"File <*>/train.py, line 165, in <module> main()[SEP]File <*>/train.py, line 65, in main tf.set_random_seed(args.random_seed)[SEP]AttributeError: 'module' object has no attribute 'set_random_seed'",,
109,59644859,1,2,CORE-TPL,,"File [FILE], line 3, in <module> images_flat = tf.contrib.layers.flatten(x)[SEP]AttributeError: module 'tensorflow_core.compat.v1' has no attribute 'contrib'",,
110,59765784,1,1,TPL-TPL,,"File <*>/model_loggingfinal.py, line 35, in <module> callbacks=[logger][SEP]File <*>python3.7/site-packages/keras/engine/training.py, line 1239, in fit validation_freq=validation_freq)[SEP]File <*>python3.7/site-packages/keras/engine/training_arrays.py, line 119, in fit_loop callbacks.set_model(callback_model)[SEP]File <*>python3.7/site-packages/keras/callbacks/callbacks.py, line 68, in set_model callback.set_model(model)[SEP]File <*>python3.7/site-packages/keras/callbacks/tensorboard_v2.py, line 116, in set_model super(TensorBoard, self).set_model(model)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/callbacks.py, line 1532, in set_model self.log_dir, self.model._get_distribution_strategy()) # pylint: disable=protected-access[SEP]AttributeError: 'Sequential' object has no attribute '_get_distribution_strategy'",,
111,59894720,1,1,TPL-TPL,,"File <*>/NN_Training.py, line 128, in <module> history = model.fit(X, Y, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[tensorboard]) # Feed in the trainset for X and y and run the model!!![SEP]File <*>/site-packages/keras/engine/training.py, line 1239, in fit validation_freq=validation_freq)[SEP]File <*>/site-packages/keras/engine/training_arrays.py, line 119, in fit_loop callbacks.set_model(callback_model)[SEP]File <*>/site-packages/keras/callbacks/callbacks.py, line 68, in set_model callback.set_model(model)[SEP]File <*>/site-packages/keras/callbacks/tensorboard_v2.py, line 116, in set_model super(TensorBoard, self).set_model(model)[SEP]File <*>/site-packages/tensorflow_core/python/keras/callbacks.py, line 1532, in set_model self.log_dir, self.model._get_distribution_strategy()) # pylint: disable=protected-access[SEP]AttributeError: 'Sequential' object has no attribute '_get_distribution_strategy'",,
112,59953127,1,1,CORE-TPL,,"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: module 'tensorflow' has no attribute 'random_normal'",,
113,61205905,1,2,TPL-TPL,,"File [FILE], line 8, in <module> trainer.trainModel()[SEP]File <*>python3.6/site-packages/imageai/Detection/Custom/__init__.py, line 274, in trainModel(self) class_scale=self.__train_class_scale,[SEP]File <*>python3.6/site-packages/imageai/Detection/Custom/__init__.py, line 553, in _create_model(self, nb_class, anchors, max_box_per_image, max_grid, batch_size, warmup_batches, ignore_thresh, multi_gpu, lr, grid_scales, obj_scale, noobj_scale, xywh_scale, class_scale) class_scale=class_scale[SEP]File <*>python3.6/site-packages/imageai/Detection/Custom/yolo.py, line 294, in create_yolov3_model(nb_class, anchors, max_box_per_image, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scales, obj_scale, noobj_scale, xywh_scale, class_scale) class_scale)([input_image, pred_yolo_1, true_yolo_1, true_boxes])[SEP]File <*>python3.6/site-packages/imageai/Detection/Custom/yolo.py, line 24, in __init__(self, anchors, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scale, obj_scale, noobj_scale, xywh_scale, class_scale, **kwargs) cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(max_grid_w), [max_grid_h]), (1, max_grid_h, max_grid_w, 1, 1)))[SEP]AttributeError: module 'tensorflow' has no attribute 'to_float'",,
114,61250311,1,2,TPL-TPL,,"File [FILE], line 2, in () from bert import run_classifier_with_tfhub # run_classifier[SEP]File <*>python3.6/dist-packages/bert/optimization.py, line [NUM], in [FUNC] [CODE][SEP]File [FILE], line 87, in () class AdamWeightDecayOptimizer(tf.train.Optimizer):[SEP]AttributeError: module 'tensorflow._api.v2.train' has no attribute 'Optimizer'",,
115,61503339,1,2,TPL-TPL,,"File <*>python3.6/dist-packages/fastai/data_block.py, line 594, in _check_kwargs(ds, tfms, **kwargs) try: x.apply_tfms(tfms, **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 123, in apply_tfms(self, tfms, do_resolve, xtra, size, resize_method, mult, padding_mode, mode, remove_out) else: x = tfm(x)[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 524, in __call__(self, x, *args, **kwargs) return self.tfm(x, *args, **{**self.resolved, **kwargs}) if self.do_run else x[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 470, in __call__(self, p, is_random, use_on_y, *args, **kwargs) if args: return self.calc(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 475, in calc(self, x, *args, **kwargs) if self._wrap: return getattr(x, self._wrap)(self.func, *args, **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/vision/image.py, line 183, in affine(self, func, *args, **kwargs) self.affine_mat = self.affine_mat @ m[SEP]RuntimeError: Expected object of scalar type Float but got scalar type Double for argument #3 'mat2' in call to _th_addmm_out",,
116,61503339,1,2,TPL-TPL,,"File [FILE], line 8, in <module>() data= (src.transform(tfms,size=sz) #Data augmentation[SEP]File <*>python3.6/dist-packages/fastai/data_block.py, line 505, in transform(self, tfms, **kwargs) self.train.transform(tfms[0], **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/data_block.py, line 724, in transform(self, tfms, tfm_y, **kwargs) _check_kwargs(self.x, tfms, **kwargs)[SEP]File <*>python3.6/dist-packages/fastai/data_block.py, line 596, in _check_kwargs(ds, tfms, **kwargs) raise Exception(f""It's not possible to apply those transforms to your dataset:\n {e}"")[SEP]Exception: It's not possible to apply those transforms to your dataset: Expected object of scalar type Float but got scalar type Double for argument #3 'mat2' in call to _th_addmm_out",,
117,61922334,1,2,TPL-LLL,,"File [FILE], line 2, in <module> from object_detection.utils import label_map_util[SEP]File <*>/site-packages/object_detection/utils/label_map_util.py, line 27, in <module> from object_detection.protos import string_int_label_map_pb2[SEP]File <*>/site-packages/object_detection/protos/string_int_label_map_pb2.py, line 21, in <module> create_key=_descriptor._internal_create_key,[SEP]AttributeError: module 'google.protobuf.descriptor' has no attribute '_internal_create_key'",,
118,62324422,1,1,TPL-LLL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.7/site-packages/torch/__init__.py, line 81, in <module> from torch._C import *[SEP]ImportError: /lib/arm-linux-gnueabihf/libc.so.6: version `GLIBC_2.28' not found (required by /usr/local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)",,
119,62622704,1,1,TPL-TPL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/tensorflow/__init__.py, line 101, in <module> from tensorflow_core import *[SEP]File <*>/site-packages/tensorflow_core/__init__.py, line 46, in <module> from . _api.v2 import compat[SEP]File <*>/site-packages/tensorflow_core/_api/v2/compat/__init__.py, line 39, in <module> from . import v1[SEP]File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/__init__.py, line 32, in <module> from . import compat[SEP]File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/compat/__init__.py, line 39, in <module> from . import v1[SEP]File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/compat/v1/__init__.py, line 29, in <module> from tensorflow._api.v2.compat.v1 import app[SEP]File <*>/site-packages/tensorflow_core/_api/v2/compat/v1/compat/v1/__init__.py, line 667, in <module> from tensorflow_estimator.python.estimator.api._v1 import estimator[SEP]File <*>/site-packages/tensorflow_estimator/__init__.py, line 10, in <module> from tensorflow_estimator._api.v1 import estimator[SEP]File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py, line 10, in <module> from tensorflow_estimator._api.v1.estimator import experimental[SEP]File <*>/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py, line 10, in <module> from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py, line 33, in <module> from tensorflow_estimator.python.estimator import estimator[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 53, in <module> from tensorflow_estimator.python.estimator import util as estimator_util[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/util.py, line 75, in <module> class _DatasetInitializerHook(tf.compat.v1.train.SessionRunHook):[SEP]AttributeError: module 'tensorflow' has no attribute 'compat'",,
120,62743492,1,1,TPL-TPL,,"File PATH, line 1, in <module> import tensorflow_probability[SEP]File PATH, line 75, in <module> from tensorflow_probability.python import * # pylint: disable=wildcard-import[SEP]File PATH, line 24, in <module> from tensorflow_probability.python import edward2[SEP]File PATH, line 32, in <module> from tensorflow_probability.python.experimental.edward2.generated_random_variables import *[SEP]File PATH, line 34, in <module> from tensorflow_probability.python.experimental import auto_batching[SEP]File PATH, line 24, in <module> from tensorflow_probability.python.experimental.auto_batching import frontend[SEP]File PATH, line 46, in <module> from tensorflow.python.autograph.pyct import compiler[SEP]ImportError: cannot import name 'compiler' from 'tensorflow.python.autograph.pyct' (PATH)",,
121,63308383,1,1,TPL-TPL,,"File test.py, line 2, in <module> model = load_model(filepath = 'saved_model/model2.h5',custom_objects=None,compile=True, )[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/saving/save.py, line 184, in load_model return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py, line 177, in load_model_from_hdf5 model = model_config_lib.model_from_config(model_config,[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/saving/model_config.py, line 55, in model_from_config return deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/layers/serialization.py, line 105, in deserialize return deserialize_keras_object([SEP]File <*>python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 369, in deserialize_keras_object return cls.from_config([SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/sequential.py, line 397, in from_config layer = layer_module.deserialize(layer_config,[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 375, in deserialize_keras_object return cls.from_config(cls_config)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py, line 655, in from_config return cls(**config)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py, line 582, in __init__ super(Conv2D, self).__init__([SEP]File <*>python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py, line 121, in __init__ super(Conv, self).__init__([SEP]File <*>python3.8/site-packages/tensorflow/python/training/tracking/base.py, line 456, in _method_wrapper result = method(self, *args, **kwargs)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py, line 294, in __init__ generic_utils.validate_kwargs(kwargs, allowed_kwargs)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 792, in validate_kwargs raise TypeError(error_message, kwarg)[SEP]TypeError: ('Keyword argument not understood:', 'groups')",,
122,64333065,1,1,CORE-TPL,,"File <*>/site-packages/keras/models.py, line 1211, in from_config if 'class_name' not in config[0] or config[0]['class_name'] == 'Merge':[SEP]KeyError: 0",,
123,65383964,1,1,TPL-TPL,,"File <*>/coco.py, line 456, in <module> model_dir=args.logs)[SEP]File <*>/site-packages/mrcnn/model.py, line 1832, in __init__ self.keras_model = self.build(mode=mode, config=config)[SEP]File <*>/site-packages/mrcnn/model.py, line 1871, in build x, K.shape(input_image)[1:3]))(input_gt_boxes)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 952, in __call__ input_list)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1091, in _functional_construction_call inputs, input_masks, args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 822, in _keras_tensor_symbolic_call return self._infer_output_signature(inputs, args, kwargs, input_masks)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 869, in _infer_output_signature keras_tensor.keras_tensor_from_tensor, outputs)[SEP]File <*>/site-packages/tensorflow/python/util/nest.py, line 659, in map_structure structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/util/nest.py, line 659, in <listcomp> structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/keras/engine/keras_tensor.py, line 606, in keras_tensor_from_tensor out = keras_tensor_cls.from_tensor(tensor)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/keras_tensor.py, line 205, in from_tensor type_spec = type_spec_module.type_spec_from_value(tensor)[SEP]File <*>/site-packages/tensorflow/python/framework/type_spec.py, line 554, in type_spec_from_value (value, type(value).__name__))[SEP]TypeError: Could not build a TypeSpec for <KerasTensor: shape=(None, None, 4) dtype=float32 (created by layer 'tf.math.truediv')> with type KerasTensor",,
124,65397061,1,2,CORE-TPL,,"File [FILE], line 1, in <module>() tokenizer = tfds.features.text.VocabTokenizer()[SEP]AttributeError: module 'tensorflow_datasets.core.features' has no attribute 'text'",,
125,65501905,1,1,CORE-TPL,,"File object_detection_test.py, line 15, in <module> from utils import label_map_util[SEP]File <*>/label_map_util.py, line 27, in <module> import tensorflow.compat.v1 as tf[SEP]ModuleNotFoundError: No module named 'tensorflow.compat.v1'",,
126,65569050,1,1,CORE-TPL,,"File file.py, line 537, in <Module> params,tuner = search_model(X_train,y_train,trials=t,executions=e)[SEP]File file.py, line 503, in search_model verbose = 0[SEP]File <*>python3.6/dist-packages/kerastuner/engine/base_tuner.py, line 131, in search self.run_trial(trial, *fit_args, **fit_kwargs)[SEP]File file.py, line 476, in run_trial super(MyTuner, self).run_trial(trial, *args, **kwargs)[SEP]File <*>python3.6/dist-packages/kerastuner/engine/multi_execution_tuner.py, line 78, in [FUNC] [CODE][SEP]File <*>python3.6/dist-packages/kerastuner/engine/tuner.py, line 317, in _get_checkp if (isinstance(self.distribution_strategy, tf.distribute.TPUStrategy) and[SEP]AttributeError: module 'tensorflow._api.v2.distribute' has no attribute 'TPUStrategy'",,
127,66141547,1,1,TPL-python,,"File <*>/test.py, line 13, in <module> lstm = Bidirectional(lstm_nobi, name=""layerC"")(embedding_layer)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/wrappers.py, line 539, in __call__ return super(Bidirectional, self).__call__(inputs, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 951, in __call__ return self._functional_construction_call(inputs, args, kwargs,[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1090, in _functional_construction_call outputs = self._keras_tensor_symbolic_call([SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 822, in _keras_tensor_symbolic_call return self._infer_output_signature(inputs, args, kwargs, input_masks)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 863, in _infer_output_signature outputs = call_fn(inputs, *args, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/wrappers.py, line 652, in call y = self.forward_layer(forward_inputs,[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 660, in __call__ return super(RNN, self).__call__(inputs, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1012, in __call__ outputs = call_fn(inputs, *args, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py, line 1157, in call inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 859, in _process_inputs initial_state = self.get_initial_state(inputs)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 642, in get_initial_state init_state = get_initial_state_fn([SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 2506, in get_initial_state return list(_generate_zero_filled_state_for_cell([SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 2987, in _generate_zero_filled_state_for_cell return _generate_zero_filled_state(batch_size, cell.state_size, dtype)[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 3003, in _generate_zero_filled_state return nest.map_structure(create_zeros, state_size)[SEP]File <*>python3.9/site-packages/tensorflow/python/util/nest.py, line 659, in map_structure structure[0], [func(*x) for x in entries],[SEP]File <*>python3.9/site-packages/tensorflow/python/util/nest.py, line 659, in <listcomp> structure[0], [func(*x) for x in entries],[SEP]File <*>python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py, line 3000, in create_zeros return array_ops.zeros(init_state_size, dtype=dtype)[SEP]File <*>python3.9/site-packages/tensorflow/python/util/dispatch.py, line 201, in wrapper return target(*args, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2819, in wrapped tensor = fun(*args, **kwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2868, in zeros output = _constant_if_small(zero, shape, dtype, name)[SEP]File <*>python3.9/site-packages/tensorflow/python/ops/array_ops.py, line 2804, in _constant_if_small if np.prod(shape) < 1000:[SEP]File <__array_function__ internals>, line 5, in prod [CODE][SEP]File <*>python3.9/site-packages/numpy/core/fromnumeric.py, line 3030, in prod return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,[SEP]File <*>python3.9/site-packages/numpy/core/fromnumeric.py, line 87, in _wrapreduction return ufunc.reduce(obj, axis, dtype, out, **passkwargs)[SEP]File <*>python3.9/site-packages/tensorflow/python/framework/ops.py, line 852, in __array__ raise NotImplementedError([SEP]NotImplementedError: Cannot convert a symbolic Tensor (layerC/forward_layerB/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",,
128,66516388,1,1,CORE-TPL,,"File main.py, line 60, in <module> main()[SEP]File main.py, line 50, in main train_iters, dev_iters, test_iters, vocab = load_dataset(config)[SEP]File <*>/data.py, line 23, in load_dataset TEXT = data.Field(batch_first=True, eos_token='<eos>')[SEP]AttributeError: module 'torchtext.data' has no attribute 'Field'",,
129,66524542,1,2,CORE-TPL,,"File [FILE], line 1, in <module> last_hidden_state.shape[SEP]AttributeError: 'str' object has no attribute 'shape'",,
130,66600362,1,1,TPL-LLL,,"File <*>/main.py, line 217, in Processing y_predict = model(x) # [batch size, fc3 output][SEP]File <*>/site-packages/torch/nn/modules/module.py, line 722, in _call_impl result = self.forward(*input, **kwargs)[SEP]File <*>/cnn.py, line 104, in forward x = self.fc1(x)[SEP]File <*>/site-packages/torch/nn/modules/, line 91, in forward return F.linear(input, self.weight, self.bias)[SEP]File <*>/site-packages/torch/nn/functional.py, line 1674, in linear ret = torch.addmm(bias, input, weight.t())[SEP]RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",,
131,66964492,1,2,TPL-TPL,,"File [FILE], line 9, in <module>() from keras.preprocessing import image[SEP]File <*>python3.7/dist-packages/keras/backend.py, line 37, in <module>() from tensorflow.python.eager.context import get_config[SEP]ImportError: cannot import name 'get_config' from 'tensorflow.python.eager.context' (/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/context.py)",,
132,66992585,1,1,TPL-LLL,,"File <*>/main_dist_maml_l2l.py, line 1423, in <module> main()[SEP]File <*>/main_dist_maml_l2l.py, line 1365, in main train(args=args)[SEP]File <*>/main_dist_maml_l2l.py, line 1385, in train args.opt = move_opt_to_cherry_opt_and_sync_params(args) if is_running_parallel(args.rank) else args.opt[SEP]File <*>/distributed.py, line 456, in move_opt_to_cherry_opt_and_sync_params args.opt = cherry.optim.Distributed(args.model.parameters(), opt=args.opt, sync=syn)[SEP]File <*>python3.9/site-packages/cherry/optim.py, line 62, in __init__ self.sync_parameters()[SEP]File <*>python3.9/site-packages/cherry/optim.py, line 78, in sync_parameters dist.broadcast(p.data, src=root)[SEP]File <*>python3.9/site-packages/torch/distributed/distributed_c10d.py, line 1090, in broadcast work = default_pg.broadcast([tensor], opts)[SEP]RuntimeError: NCCL error in: ../torch/lib/c10d/ProcessGroupNCCL.cpp:911, unhandled system error, NCCL version 2.7.8",,
133,67037067,1,1,CORE-TPL,,"File train.py, line 28, in <module> tf.keras.mixed_precision.set_global_policy('mixed_float16')[SEP]AttributeError: module 'tensorflow.keras.mixed_precision' has no attribute 'set_global_policy'",,
134,67037067,1,1,CORE-TPL,,"File train.py, line 29, in <module> policy = tf.keras.mixed_precision.Policy('mixed_float16')[SEP]AttributeError: module 'tensorflow.keras.mixed_precision' has no attribute 'Policy'",,
135,67604780,1,1,CORE-TPL,,"File <*>/CNN_Image_Denoising.py, line 15, in <module> from keras.optimizers import SGD, Adam[SEP]ImportError: cannot import name 'SGD' from 'keras.optimizers'",,
136,67695451,1,2,CORE-TPL,,"File [FILE], line 1, in <module>() from keras.utils import to_categorical[SEP]ImportError: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",,
137,68902851,1,1,TPL-hardware,,"File <*>/script.py, line 654, in <module> prediction_result, (r, t) = cf.to(model_runner.predict(processed_feature_dict, random_seed=seed), ""cpu"")[SEP]File <*>python3.7/site-packages/alphafold/model/model.py, line 134, in predict result, recycles = self.apply(self.params, jax.random.PRNGKey(random_seed), feat)[SEP]File <*>python3.7/site-packages/jax/_src/traceback_util.py, line 183, in reraise_with_filtered_traceback return fun(*args, **kwargs)[SEP]File <*>python3.7/site-packages/jax/_src/api.py, line 402, in cache_miss donated_invars=donated_invars, inline=inline)[SEP]File <*>python3.7/site-packages/jax/core.py, line 1561, in bind return call_bind(self, fun, *args, **params)[SEP]File <*>python3.7/site-packages/jax/core.py, line 1552, in call_bind outs = primitive.process(top_trace, fun, tracers, params)[SEP]File <*>python3.7/site-packages/jax/core.py, line 1564, in process return trace.process_call(self, fun, tracers, params)[SEP]File <*>python3.7/site-packages/jax/core.py, line 607, in process_call return primitive.impl(f, *tracers, **params)[SEP]File <*>python3.7/site-packages/jax/interpreters/xla.py, line 608, in _xla_call_impl *unsafe_map(arg_spec, args))[SEP]File <*>python3.7/site-packages/jax/, line 262, in memoized_fun ans = call(fun, *args)[SEP]File <*>python3.7/site-packages/jax/interpreters/xla.py, line 758, in _xla_callable compiled = compile_or_get_cached(backend, built, options)[SEP]File env/lib/python3.7/site-packages/jax/interpreters/xla.py, line 76, in compile_or_get_cached return backend_compile(backend, computation, compile_options)",,
138,68902851,1,1,TPL-hardware,,"File <*>/script.py, line 654, in <module> prediction_result, (r, t) = cf.to(model_runner.predict(processed_feature_dict, random_seed=seed), ""cpu"")[SEP]File <*>python3.7/site-packages/alphafold/model/model.py, line 134, in predict result, recycles = self.apply(self.params, jax.random.PRNGKey(random_seed), feat)[SEP]File <*>python3.7/site-packages/jax/interpreters/xla.py, line 373, in backend_compile return backend.compile(built_c, compile_options=options)[SEP]RuntimeError: Resource exhausted: Out of memory while trying to allocate 4649385984 bytes.",,
139,68962427,1,2,CORE-TPL,,"File [FILE], line 41, in <module>() from theano.tensor import shared_randomstreams[SEP]File <*>python3.7/dist-packages/theano/gof/cmodule.py, line 37, in <module>() from theano.configdefaults import gcc_version_str, local_bitwidth[SEP]ImportError: cannot import name 'local_bitwidth' from 'theano.configdefaults' (/usr/local/lib/python3.7/dist-packages/theano/configdefaults.py)",,
140,69471749,1,1,CORE-TPL,,"File <*>/train_model.py, line 10, in <module> from cancernet.cancernet import CancerNet[SEP]File <*>/cancernet.py, line 2, in <module> from keras.layers.normalization import BatchNormalization[SEP]ImportError: cannot import name 'BatchNormalization' from 'keras.layers.normalization' (C:\Users\Catalin\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\layers\normalization\__init__.py)",,
141,70537488,1,1,TPL-TPL,,"File <*>/model_main_tf2.py, line 32, in <module> from object_detection import model_lib_v2[SEP]File <*>python3.7/dist-packages/object_detection/model_lib_v2.py, line 29, in <module> from object_detection import eval_util[SEP]File <*>python3.7/dist-packages/object_detection/eval_util.py, line 36, in <module> from object_detection.metrics import lvis_evaluation[SEP]File <*>python3.7/dist-packages/object_detection/metrics/lvis_evaluation.py, line 23, in <module> from lvis import results as lvis_results[SEP]File <*>python3.7/dist-packages/lvis/__init__.py, line 5, in <module> from lvis.vis import LVISVis[SEP]File <*>python3.7/dist-packages/lvis/vis.py, line 1, in <module> import cv2[SEP]File <*>python3.7/dist-packages/cv2/__init__.py, line 9, in <module> from .cv2 import _registerMatType[SEP]ImportError: cannot import name '_registerMatType' from 'cv2.cv2' (/usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so)",,
142,70839312,1,1,TPL-TPL,,"File <*>/site-packages/theano/configparser.py, line 168, in fetch_val_for_key return theano_cfg.get(section, option)[SEP]File <*>/configparser.py, line 781, in get d = self._unify_values(section, vars)[SEP]File <*>/configparser.py, line 1149, in _unify_values raise NoSectionError(section) from None[SEP]configparser.NoSectionError: No section: 'blas'",,
143,70839312,1,1,TPL-TPL,,"File <*>/site-packages/theano/configparser.py, line 327, in __get__ val_str = fetch_val_for_key(self.fullname,[SEP]File <*>/site-packages/theano/configparser.py, line 172, in fetch_val_for_key raise KeyError(key)[SEP]KeyError: 'blas.ldflags'",,
144,70839312,1,1,TPL-TPL,,"File <*>/test.py, line 156, in <module> import network3[SEP]File <*>/network3.py, line 37, in <module> import theano[SEP]File <*>/site-packages/theano/__init__.py, line 124, in <module> from theano.scan_module import (scan, map, reduce, foldl, foldr, clone,[SEP]File <*>/site-packages/theano/scan_module/__init__.py, line 41, in <module> from theano.scan_module import scan_opt[SEP]File <*>/site-packages/theano/scan_module/scan_opt.py, line 60, in <module> from theano import tensor, scalar[SEP]File <*>/site-packages/theano/tensor/__init__.py, line 17, in <module> from theano.tensor import blas[SEP]File <*>/site-packages/theano/tensor/blas.py, line 155, in <module> from theano.tensor.blas_headers import blas_header_text[SEP]File <*>/site-packages/theano/tensor/blas_headers.py, line 987, in <module> if not config.blas.ldflags:[SEP]File <*>/site-packages/theano/configparser.py, line 332, in __get__ val_str = self.default()[SEP]File <*>/site-packages/theano/configdefaults.py, line 1284, in default_blas_ldflags blas_info = np.distutils.__config__.blas_opt_info[SEP]AttributeError: module 'numpy.distutils.__config__' has no attribute 'blas_opt_info'",,
145,71111005,1,2,CORE-TPL,,"File [FILE], line 3, in <module>() from keras.applications.resnet50 import preprocess_input, ResNet50[SEP]ModuleNotFoundError: No module named 'keras.applications.resnet50'",,
146,72255562,1,1,TPL-TPL,,"File <*>/ai.py, line 15, in <module> from keras.models import Sequential, load_model[SEP]File <*>/site-packages/keras/__init__.py, line 24, in <module> from keras import models[SEP]File <*>/site-packages/keras/models/__init__.py, line 18, in <module> from keras.engine.functional import Functional[SEP]File <*>/site-packages/keras/engine/functional.py, line 24, in <module> from keras.dtensor import layout_map as layout_map_lib[SEP]File <*>/site-packages/keras/dtensor/__init__.py, line 22, in <module> from tensorflow.compat.v2.experimental import dtensor as dtensor_api # pylint: disable=g-import-not-at-top[SEP]ImportError: cannot import name 'dtensor' from 'tensorflow.compat.v2.experimental' (C:\Users\Fynn\AppData\Local\Programs\Python\Python39\lib\site-packages\tensorflow\_api\v2\compat\v2\experimental\__init__.py)",,
147,21342931,0,1,, ,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/__init__.py, line 55, in <module> from theano.compile import \[SEP]File <*>/__init__.py, line 6, in <module> from theano.compile.function_module import *[SEP]File <*>/function_module.py, line 18, in <module> import theano.compile.mode[SEP]File <*>/mode.py, line 11, in <module> import theano.gof.vm[SEP]File <*>/vm.py, line 516, in <module> import lazylinker_c[SEP]File <*>/lazylinker_c.py, line 86, in <module> preargs=args)[SEP]File <*>/cmodule.py, line 1975, in compile_str (status, compile_stderr.replace('\n', '. ')))[SEP]Exception: Compilation failed (return status=1): /usr/bin/ld: /home/minh.lengoc/.local/lib/libpython2.7.a(abstract.o): relocation R_X86_64_32 against `.rodata.str1.8' can not be used when making a shared object; recompile with -fPIC. /home/minh.lengoc/.local/lib/libpython2.7.a: could not read symbols: Bad value. collect2: ld returned 1 exit status.",,
148,23744826,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 540, in runfile execfile(filename, namespace)[SEP]File <*>/untitled4.py, line 603, in <module> params = test_mlp()[SEP]File <*>/untitled4.py, line 553, in test_mlp minibatch_avg_cost = train_model(minibatch_index)[SEP]File <*>/site-packages/theano-0.6.0-py2.7.egg/theano/compile/function_module.py, line 588, in __call__ self.fn.thunks[self.fn.position_of_error])[SEP]File <*>/site-packages/theano-0.6.0-py2.7.egg/theano/compile/function_module.py, line 579, in __call__ outputs = self.fn()[SEP]ValueError: y_i value out of bounds Apply node that caused the error: CrossentropySoftmaxArgmax1HotWithBias(Dot22.0, b, Elemwise{Cast{int32}}.0) Inputs shapes: [(10L, 1L), (1L,), (10L,)] Inputs strides: [(8L, 8L), (8L,), (4L,)] Inputs types: [TensorType(float64, matrix), TensorType(float64, vector), TensorType(int32, vector)] Use the Theano flag 'exception_verbosity=high' for a debugprint of this apply node.",,
149,27396664,0,1,,,"File <string>, line 1, in <module> [CODE][SEP]ImportError: No module named caffe",,
150,27396664,0,1,,,"File <*>python2.7/dist-packages/apport_python_hook.py, line 66, in apport_excepthook from apport.fileutils import likely_packaged, get_recent_crashes[SEP]File <*>python2.7/dist-packages/apport/__init__.py, line 1, in <module> from apport.report import Report[SEP]File <*>python2.7/dist-packages/apport/report.py, line 18, in <module> import problem_report[SEP]File <*>python2.7/dist-packages/problem_report.py, line 14, in <module> import zlib, base64, time, sys, gzip, struct, os[SEP]File <*>python2.7/gzip.py, line 10, in <module> import io[SEP]File <*>/io.py, line 2, in <module> import skimage.io[SEP]File <*>python2.7/dist-packages/skimage/io/__init__.py, line 11, in <module> from ._io import *[SEP]File <*>python2.7/dist-packages/skimage/io/_io.py, line 1, in <module> from io import BytesIO[SEP]ImportError: cannot import name BytesIO",,
151,27396664,0,1,,,"File <*>/io.py, line 2, in <module> import skimage.io[SEP]File <*>python2.7/dist-packages/skimage/io/__init__.py, line 11, in <module> from ._io import *[SEP]File <*>python2.7/dist-packages/skimage/io/_io.py, line 1, in <module> from io import BytesIO[SEP]ImportError: cannot import name BytesIO",,
152,28177298,0,1,,,"File <*>/output.py, line 13, in <module> import caffe[SEP]File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver[SEP]File <*>/pycaffe.py, line 10, in <module> from ._caffe import Net, SGDSolver[SEP]ImportError: No module named _caffe",,
153,28692209,0,1,,,"File <*>/classify.py, line 130, in <module> main(sys.argv)[SEP]File <*>/classify.py, line 103, in main channel_swap=channel_swap)[SEP]TypeError: __init__() got an unexpected keyword argument 'gpu'",,
154,29707174,0,1,,,"File las_mnist.py, line 39, in <module> net1.fit(X[i], y[i])[SEP]File <*>python2.7/dist-packages/nolearn/lasagne.py, line 266, in fit self.train_loop(X, y)[SEP]File <*>python2.7/dist-packages/nolearn/lasagne.py, line 273, in train_loop X, y, self.eval_size)[SEP]File <*>python2.7/dist-packages/nolearn/lasagne.py, line 377, in train_test_split kf = KFold(y.shape[0], round(1. / eval_size))[SEP]IndexError: tuple index out of range",,
155,29995397,0,1,,,"File <*>/site-packages/IPython/core/interactiveshell.py, line 3032, in run_code =============================== C:\Users\aleja_000\AppData\Local\Theano\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.9-64\lazylinker_ext\mod.cpp:1:0: sorry, unimplemented: 64-bit mode not compiled in #include <Python.h> ^ exec(code_obj, self.user_global_ns, self.user_ns)[SEP]File <ipython-input-2-1e86b04c8a9c>, line 6, in <module> from lasagne.layers import DenseLayer[SEP]File <*>/pydev_import_hook.py, line 21, in do_import module = self._system_import(name, *args, **kwargs)[SEP]File <*>/__init__.py, line 5, in <module> from . import nonlinearities[SEP]File <*>/non, line 6, in <module> from theano.tensor.nnet import sigmoid[SEP]File <*>/site-packages/theano/__init__.py, line 55, in <module> from theano.compile import ([SEP]File <*>/site-packages/theano/compile/__init__.py, line 9, in <module> from theano.compile.function_module import *[SEP]File <*>/site-packages/theano/compile/function_module.py, line 17, in <module> import theano.compile.mode[SEP]File <*>/site-packages/theano/compile/mode.py, line 11, in <module> import theano.gof.vm[SEP]File <*>/site-packages/theano/gof/vm.py, line 654, in <module> import lazylinker_c[SEP]File <*>/site-packages/theano/gof/lazylinker_c.py, line 125, in <module> preargs=args)[SEP]File <*>/site-packages/theano/gof/cmodule.py, line 2042, in compile_str (status, compile_stderr.replace('\n', '. ')))[SEP]Exception: Compilation failed (return status=1): C:\Users\aleja_000\AppData\Local\Theano\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.9-64\lazylinker_ext\mod.cpp:1:0: sorry, unimplemented: 64-bit mode not compiled in . #include <Python.h> . ^",,
156,30769048,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: No module named lmdb",,
157,30769048,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: No module named deepdish",,
158,30808735,0,1,,,"File cnn_age_gender_demo.py, line 25, in [FUNC] [CODE][SEP]File <*>/classifier.py, line 34, in init self.transformer.set_mean(in_, mean)[SEP]File <*>/io.py, line 255, in set_mean raise ValueError('Mean shape incompatible with input shape.')[SEP]ValueError: Mean shape incompatible with input shape.",,
159,31361377,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: 'TensorVariable' object has no attribute 'get_value'",,
160,33619190,0,1,,,"File <*>python2.7/site-packages/pip/basecommand.py, line 211, in main status = self.run(options, args)[SEP]File <*>python2.7/site-packages/pip/commands/install.py, line 311, in run root=options.root_path,[SEP]File <*>python2.7/site-packages/pip/req/req_set.py, line 640, in install requirement.uninstall(auto_confirm=True)[SEP]File <*>python2.7/site-packages/pip/req/req_install.py, line 716, in uninstall paths_to_remove.remove(auto_confirm)[SEP]File <*>python2.7/site-packages/pip/req/req_uninstall.py, line 125, in remove renames(path, new_path)[SEP]File <*>python2.7/site-packages/pip/utils/__init__.py, line 315, in renames shutil.move(old, new)[SEP]File <*>python2.7/shutil.py, line 303, in move os.unlink(src)[SEP]OSError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/site-packages/six-1.9.0.dist-info/DESCRIPTION.rst'",,
161,33624048,0,1,,,"File word2vec_basic.py, line 171, in <module> _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 345, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 419, in _do_run e.code)[SEP]tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'GradientDescent/update_Variable_2/ScatterSub': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/GPU:0' [[Node: GradientDescent/update_Variable_2/ScatterSub = ScatterSub[T=DT_FLOAT, Tindices=DT_INT64, use_locking=false](Variable_2, gradients/concat_1, GradientDescent/update_Variable_2/mul)]]",,
162,33625824,0,1,,,"File <*>/convolutional.py, line 13, in <module> import tensorflow.python.platform[SEP]File <*>/__init__.py, line 4, in <module> from tensorflow.python import *[SEP]File <*>/__init__.py, line 13, in <module> from tensorflow.core.framework.graph_pb2 import *[SEP]ImportError: No module named core.framework.graph_pb2",,
163,33663980,0,1,,,"File <*>/translate.py, line 28, in <module> from tensorflow.models.rnn.translate import data_utils[SEP]ImportError: No module named translate",,
164,33743944,0,1,,,"File run_deep_trainer.py, line 404, in <module> main()[SEP]File run_deep_trainer.py, line 400, in main layer_trainers[-1].main_loop()[SEP]File <*>/train.py, line 141, in main_loop self.setup()[SEP]File <*>/train.py, line 121, in setup self.algorithm.setup(model=self.model, dataset=self.dataset)[SEP]File <*>/sgd.py, line 243, in setup inf_params = [param for param in model.get_params()[SEP]File <*>/model.py, line 503, in get_params return list(self._params)[SEP]AttributeError: 'Softmax' object has no attribute '_params'",,
165,33762831,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/py1053173el, line 12, in <module> [CODE][SEP]File <*>python2.7/dist-packages/tensorflow/models/rnn/seq2seq.py, line 82, in basic_rnn_seq2seq _, enc_states = rnn.rnn(cell, encoder_inputs, dtype=dtype)[SEP]File <*>python2.7/dist-packages/tensorflow/models/rnn/rnn.py, line 85, in rnn output_state = cell(input_, state)[SEP]File <*>python2.7/dist-packages/tensorflow/models/rnn/rnn_cell.py, line 161, in __call__ concat = linear.linear([inputs, h], 4 * self._num_units, True)[SEP]File <*>python2.7/dist-packages/tensorflow/models/rnn/, line 32, in linear raise ValueError(""Linear is expecting 2D arguments: %s"" % str(shapes))[SEP]ValueError: Linear is expecting 2D arguments: [[None], [None, 512]]",,
166,33921398,0,1,,,"File ae.py, line 330, in <module> main()[SEP]File ae.py, line 305, in main ae.train(n_epochs=n_epochs, mini_batch_size=100, learning_rate=0.002, train_data= train_sentence_embeddings, test_data= test_sentence_embeddings)[SEP]File ae.py, line 87, in train givens={x:self.X[index:index+mini_batch_size,:]})[SEP]File <*>python2.7/dist-packages/theano/compile/function.py, line 266, in function profile=profile)[SEP]File <*>python2.7/dist-packages/theano/compile/pfunc.py, line 489, in pfunc no_default_updates=no_default_updates)[SEP]File <*>python2.7/dist-packages/theano/compile/pfunc.py, line 194, in rebuild_collect_shared store_into)[SEP]TypeError: ('update target must be a SharedVariable', Subtensor{::, int64}.0)",,
167,33929368,0,1,,,"File test_theano.py, line 9, in <module> for iter in range(n_iters):[SEP]TypeError: range() integer end argument expected, got TensorVariable.",,
168,33980109,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 8, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 34, in <module> from tensorflow.python.client.client_lib import *[SEP]File <*>python2.7/site-packages/tensorflow/python/client/client_lib.py, line 39, in <module> from tensorflow.python.client.session import InteractiveSession[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 16, in <module> from tensorflow.python import pywrap_tensorflow as tf_session[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 26, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 22, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: /home/zjuese/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: clock_gettime",,
169,34193649,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/models.py, line 602, in compile [CODE][SEP]File <*>/advanced_activations.py, line 149, in get_output [CODE][SEP]File <*>/core.py, line 117, in get_input [CODE][SEP]File <*>/core.py, line 1334, in get_output [CODE][SEP]File <*>/core.py, line 1282, in get_output_sum [CODE][SEP]File <*>/core.py, line 1266, in get_output_at [CODE][SEP]File <*>/core.py, line 730, in get_output [CODE][SEP]File <*>/core.py, line 1340, in get_output [CODE][SEP]File <*>/core.py, line 1312, in get_output_dot [CODE][SEP]File <*>python2.7/site-packages/theano/tensor/var.py, line 360, in dimshuffle pattern)[SEP]File <*>python2.7/site-packages/theano/tensor/elemwise.py, line 164, in __init__ (input_broadcastable, new_order))[SEP]ValueError: ('You cannot drop a non-broadcastable dimension.', ((False, False, False, False), (0, 'x')))",,
170,34223315,0,1,,,"File <*>/convolutional.py, line 133, in <module> train_accuracy = accuracy.eval(feed_dict = {x: batch[0], y_: batch[1], keep_prob: 1.0})[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 405, in eval return _eval_using_default_session(self, feed_dict, self.graph, session)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 2728, in _eval_using_default_session return session.run(tensors, feed_dict)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 345, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 419, in _do_run e.code)[SEP]tensorflow.python.framework.errors.InvalidArgumentError: Incompatible shapes: [8] vs. [20] [[Node: Equal = Equal[T=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](ArgMax, ArgMax_1)]]",,
171,34331448,0,1,,,"File <string>, line 1, in <module> [CODE][SEP]AttributeError: 'module' object has no attribute 'getsitepackages'",,
172,34354126,0,1,,,"File <*>/convolutional_network_batch_2d2c_clean_64f.py, line 213, in <module> pred = conv_net(x, weights, biases, keep_prob)[SEP]File <*>/convolutional_network_batch_2d2c_clean_64f.py, line 153, in conv_net conv1 = max_pool(conv1, k=2) # Normally K=2[SEP]File <*>/convolutional_network_batch_2d2c_clean_64f.py, line 135, in max_pool return tf.nn.max_pool(img, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/nn_ops.py, line 235, in max_pool name=name)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 449, in _max_pool strides=strides, padding=padding, name=name)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/op_def_library.py, line 430, in apply_op (prefix, dtypes.as_dtype(input_arg.type).name))[SEP]TypeError: Input 'input' of 'MaxPool' Op has type float64 that does not match expected type of float32.",,
173,34567454,0,1,,,"File <*>/Layer.py, line 113, in <module> train_model(i)[SEP]File <*>python2.7/site-packages/theano/compile/function_module.py, line 595, in __call__ outputs = self.fn()[SEP]File <*>python2.7/site-packages/theano/gof/link.py, line 485, in streamline_default_f raise_with_op(node, thunk)[SEP]File <*>python2.7/site-packages/theano/gof/link.py, line 481, in streamline_default_f thunk()[SEP]File <*>python2.7/site-packages/theano/gof/op.py, line 768, in rval r = p(n, [x[0] for x in i], o)[SEP]File <*>python2.7/site-packages/theano/tensor/nnet/nnet.py, line 896, in perform nll[i] = -row[y_idx[i]] + m + numpy.log(sum_j)[SEP]IndexError: index 1 is out of bounds for axis 0 with size 1",,
174,34572414,0,1,,,"File [FILE], line <*>, in [FUNC] [CODE][SEP]File <*>/site-packages/nolearn/lasagne/base.py, line 457, in fit self.initialize()[SEP]File <*>/site-packages/nolearn/lasagne/base.py, line 303, in initialize self.y_tensor_type,[SEP]File <*>/site-packages/nolearn/lasagne/base.py, line 435, in _create_iter_funcs allow_input_downcast=True,[SEP]File <*>/site-packages/theano/compile/function.py, line 317, in function output_keys=output_keys)[SEP]File <*>/site-packages/theano/compile/pfunc.py, line 526, in pfunc output_keys=output_keys)[SEP]File <*>/site-packages/theano/compile/function_module.py, line 1778, in orig_function defaults)[SEP]File <*>/site-packages/theano/compile/function_module.py, line 1642, in create input_storage=input_storage_lists, storage_map=storage_map)[SEP]File <*>/site-packages/theano/gof/link.py, line 690, in make_thunk storage_map=storage_map)[:3][SEP]File <*>/site-packages/theano/gof/vm.py, line 1037, in make_all no_recycling))[SEP]File <*>/site-packages/theano/gof/op.py, line 932, in make_thunk no_recycling)[SEP]File <*>/site-packages/theano/gof/op.py, line 850, in make_c_thunk output_storage=node_output_storage)[SEP]File <*>/site-packages/theano/gof/cc.py, line 1207, in make_thunk keep_lock=keep_lock)[SEP]File <*>/site-packages/theano/gof/cc.py, line 1152, in __compile__ keep_lock=keep_lock)[SEP]File <*>/site-packages/theano/gof/cc.py, line 1602, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock)[SEP]File <*>/site-packages/theano/gof/cmodule.py, line 1174, in module_from_key module = lnk.compile_cmodule(location)[SEP]File <*>/site-packages/theano/gof/cc.py, line 1513, in compile_cmodule preargs=preargs)[SEP]File <*>/site-packages/theano/gof/cmodule.py, line 2187, in compile_str (status, compile_stderr.replace('\n', '. ')))[SEP]Exception: ('The following error happened while compiling the node', CorrMM{valid, (1, 1)}(input.input, Subtensor{::, ::, ::int64, ::int64}.0), '\n', ""Compilation failed (return status=1): C:\\Users\\Michal\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64\\tmpgdh7ov2i\\mod.cpp: In member function 'int {anonymous}::__struct_compiled_op_mf217e5b3a6b61b4ef70844368439f6cb::run()':\r. C:\\Users\\Michal\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64\\tmpgdh7ov2i\\mod.cpp:947:16: warning: converting to non-pointer type 'int' from NULL [-Wconversion-null]\r. kH = NULL;\r. ^\r. C:\\Users\\Michal\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64\\tmpgdh7ov2i\\mod.cpp:958:16: warning: converting to non-pointer type 'int' from NULL [-Wconversion-null]\r. kW = NULL;\r. ^\r. C:\\Users\\Michal\\AppData\\Local\\Temp\\cc67su6o.o: In function `corrMM(tagPyArrayObject*, tagPyArrayObject*, tagPyArrayObject*, int, int, int, int, int)':\r. C:/Users/Michal/AppData/Local/Theano/compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64/tmpgdh7ov2i/mod.cpp:431: undefined reference to `dgemm_'\r. C:/Users/Michal/AppData/Local/Theano/compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64/tmpgdh7ov2i/mod.cpp:528: undefined reference to `dgemm_'\r. C:/Users/Michal/AppData/Local/Theano/compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.3-64/tmpgdh7ov2i/mod.cpp:483: undefined reference to `dgemm_'\r. collect2.exe: error: ld returned 1 exit status\r. "", '[CorrMM{valid, (1, 1)}(input.input, )]')",,
175,34734054,0,1,,,"File cifar10.py, line 54, in <module> """"""Number of images to process in a batch."""""")[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/default/_flags.py, line 86, in DEFINE_integer _define_helper(flag_name, default_value, docstring, int)[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/default/_flags.py, line 60, in _define_helper type=flagtype)[SEP]File <*>python2.7/argparse.py, line 1297, in add_argument return self._add_action(action)[SEP]File <*>python2.7/argparse.py, line 1671, in _add_action self._optionals._add_action(action)[SEP]File <*>python2.7/argparse.py, line 1498, in _add_action action = super(_ArgumentGroup, self)._add_action(action)[SEP]File <*>python2.7/argparse.py, line 1311, in _add_action self._check_conflict(action)[SEP]File <*>python2.7/argparse.py, line 1449, in _check_conflict conflict_handler(action, confl_optionals)[SEP]File <*>python2.7/argparse.py, line 1456, in _handle_conflict_error raise ArgumentError(action, message % conflict_string)[SEP]argparse.ArgumentError: argument --batch_size: conflicting option string(s): --batch_size",,
176,34898247,0,1,,,"File mnist_mlp.py, line 13, in <module> from keras.models import Sequential[SEP]File <*>python3.5/site-packages/Keras-0.3.1-py3.5.egg/keras/models.py, line 15, in <module> [CODE][SEP]File <*>python3.5/site-packages/Keras-0.3.1-py3.5.egg/keras/backend/__init__.py, line 46, in <module> [CODE][SEP]File <*>python3.5/site-packages/Keras-0.3.1-py3.5.egg/keras/backend/theano_backend.py, line 4, in <module> [CODE][SEP]File <*>python3.5/site-packages/Theano-0.8.0.dev0-py3.5.egg/theano/tensor/signal/downsample.py, line 2, in <module> import pool[SEP]ImportError: No module named 'pool'",,
177,34967312,0,1,,,"File <*>/lstmNetwork.py, line 54, in <module> model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=3, validation_data=(X_test, Y_test), show_accuracy=True)[SEP]File <*>python2.7/dist-packages/keras/models.py, line 581, in fit shuffle=shuffle, metrics=metrics)[SEP]File <*>python2.7/dist-packages/keras/models.py, line 239, in _fit outs = f(ins_batch)[SEP]File <*>python2.7/dist-packages/keras/backend/theano_backend.py, line 365, in __call__ return self.function(*inputs)[SEP]File <*>/function_module.py, line 786, in __call__ allow_downcast=s.allow_downcast)[SEP]File <*>/type.py, line 177, in filter data.shape))[SEP]TypeError: ('Bad input argument to theano function with name ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py:362"" at index 1(0-based)', 'Wrong number of dimensions: expected 3, got 2 with shape (5, 10).')",,
178,34982492,0,1,,,"File tensor_restore.py, line 14, in <module> saver.restore(sess, ""/tmp/model.ckpt"")[SEP]File <*>python2.7/site-packages/tensorflow/python/training/saver.py, line 891, in restore sess.run([self._restore_op_name], {self._filename_tensor_name: save_path})[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 368, in run results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 444, in _do_run e.code)[SEP]tensorflow.python.framework.errors.NotFoundError: Tensor name ""v2"" not found in checkpoint files /tmp/model.ckpt [[Node: save/restore_slice_1 = RestoreSlice[dt=DT_INT32, preferred_shard=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_1/tensor_name, save/restore_slice_1/shape_and_slice)]]",,
179,35170791,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: No module named sklearn.linear_model",,
180,35658519,0,1,,,"File <*>/teste2.py, line 1479, in Pred model.fit(X=predictor_train, y=target_train, nb_epoch=2, batch_size=90,show_accuracy=True)[SEP]File <*>/site-packages/keras/models.py, line 581, in fit shuffle=shuffle, metrics=metrics)[SEP]File <*>/site-packages/keras/models.py, line 239, in _fit outs = f(ins_batch)[SEP]File <*>/site-packages/keras/backend/theano_backend.py, line 365, in __call__ return self.function(*inputs)[SEP]File <*>/site-packages/theano/compile/function_module.py, line 595, in __call__ outputs = self.fn()[SEP]File <*>/site-packages/theano/gof/vm.py, line 233, in __call__ link.raise_with_op(node, thunk)[SEP]File <*>/site-packages/theano/gof/vm.py, line 229, in __call__ thunk()[SEP]File <*>/site-packages/theano/gof/op.py, line 768, in rval r = p(n, [x[0] for x in i], o)[SEP]File <*>/site-packages/theano/tensor/elemwise.py, line 808, in perform raise ValueError(base_exc_str)[SEP]ValueError: Dimension mismatch; shapes are (98, 10), (98, 1)",,
181,36099918,0,1,,,"File kaggle_otto_nn.py, line 28, in <module> from keras.models import Sequential[SEP]File <*>/models.py, line 15, in <module> [CODE][SEP]File <*>/__init__.py, line 46, in <module> [CODE][SEP]File <*>/theano_backend.py, line 1, in <module> [CODE][SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/__init__.py, line 111, in <module> theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1()[SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/sandbox/cuda/tests/test_driver.py, line 38, in test_nvidia_driver1 if not numpy.allclose(f(), a.sum()):[SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.py, line 871, in __call__ storage_map=getattr(self.fn, 'storage_map', None))[SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/link.py, line 314, in raise_with_op reraise(exc_type, exc_value, exc_trace)[SEP]File <*>python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.py, line 859, in __call__ outputs = self.fn()[SEP]RuntimeError: Cuda error: kernel_reduce_ccontig_node_97496c4d3cf9a06dc4082cc141f918d2_0: out of memory. (grid: 1 x 1; block: 256 x 1 x 1)",,
182,36226872,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: No module named tensorflow",,
183,36248056,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/theano/__init__.py, line 111, in <module> theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1()[SEP]File <*>/site-packages/theano/sandbox/cuda/tests/test_driver.py, line 31, in test_nvidia_driver1 profile=False)[SEP]File <*>/site-packages/theano/compile/function.py, line 320, in function output_keys=output_keys)[SEP]File <*>/site-packages/theano/compile/pfunc.py, line 479, in pfunc output_keys=output_keys)[SEP]File <*>/site-packages/theano/compile/function_module.py, line 1776, in orig_function output_keys=output_keys).create([SEP]File <*>/site-packages/theano/compile/function_module.py, line 1456, in __init__ optimizer_profile = optimizer(fgraph)[SEP]File <*>/site-packages/theano/gof/opt.py, line 101, in __call__ return self.optimize(fgraph)[SEP]File <*>/site-packages/theano/gof/opt.py, line 89, in optimize ret = self.apply(fgraph, *args, **kwargs)[SEP]File <*>/site-packages/theano/gof/opt.py, line 230, in apply sub_prof = optimizer.optimize(fgraph)[SEP]File <*>/site-packages/theano/sandbox/cuda/dnn.py, line 2508, in apply dnn_available.msg)[SEP]AssertionError: cuDNN optimization was enabled, but Theano was not able to use it. We got this error: Theano can not compile with cuDNN.",,
184,36615004,0,1,,,"File <*>/tensorboard, line 4, in <module> import tensorflow.tensorboard.tensorboard[SEP]ImportError: No module named 'tensorflow.tensorboard.tensorboard'",,
185,36886711,0,1,,,"File <ipython-input-1-65016ddab3cd>, line 1, in <module> from keras.utils.visualize_util import plot[SEP]File <*>/site-packages/keras/utils/visualize_util.py, line 8, in <module> raise RuntimeError('Failed to import pydot. You must install pydot'[SEP]RuntimeError: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",,
186,37383812,0,1,,,"File <*>/tensorflow.py, line 2, in <module> import tensorflow as tf[SEP]File <*>/tensorflow.py, line 53, in <module> tf_in = tf.placeholder(""float"", [None, A]) # Features[SEP]AttributeError: 'module' object has no attribute 'placeholder'",,
187,37454932,0,1,,,"File detectGoNo.py, line 95, in <module> sess.run(train_step, feed_dict={x: image_batch, y_: label_batch})[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 340, in run run_metadata_ptr)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 545, in _run raise TypeError('The value of a feed cannot be a tf.Tensor object. '[SEP]TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, or numpy ndarrays.",,
188,37568980,0,1,,,"File <ipython-input-1-adf2ca85bb77>, line 1, in <module> runfile('/home/kang/Documents/work_code_PC1/py_tensorflow_learning/cifar10CNN_test/cifar10_eval_test.py', wdir='/home/kang/Documents/work_code_PC1/py_tensorflow_learning/cifar10CNN_test')[SEP]File <*>python3/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 685, in runfile execfile(filename, namespace)[SEP]File <*>python3/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py, line 85, in execfile exec(compile(open(filename, 'rb').read(), filename, 'exec'), namespace)[SEP]File <*>/cifar10_eval_test.py, line 107, in <module> tf.app.run()[SEP]File <*>python3.4/dist-packages/tensorflow/python/platform/default/_app.py, line 30, in run sys.exit(main(sys.argv))[SEP]File <*>/cifar10_eval_test.py, line 104, in main evaluate()[SEP]File <*>/cifar10_eval_test.py, line 94, in evaluate eval_once(saver, summary_writer, top_k_op, summary_op)[SEP]File <*>/cifar10_eval_test.py, line 72, in eval_once coord.join(threads, stop_grace_period_secs = 10)[SEP]File <*>python3.4/dist-packages/tensorflow/python/training/coordinator.py, line 264, in join six.reraise(*self._exc_info_to_raise)[SEP]File <*>python3/dist-packages/six.py, line 659, in reraise raise value[SEP]File <*>python3.4/dist-packages/tensorflow/python/training/queue_runner.py, line 185, in _run sess.run(enqueue_op)[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 315, in run return self._run(None, fetches, feed_dict)[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 473, in _run raise RuntimeError('Attempted to use a closed Session.')[SEP]RuntimeError: Attempted to use a closed Session.",,
189,37623259,0,1,,,"File <*>python2.7/dist-packages/pip/basecommand.py, line 122, in main status = self.run(options, args)[SEP]File <*>python2.7/dist-packages/pip/commands/install.py, line 278, in run requirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle)[SEP]File <*>python2.7/dist-packages/pip/req.py, line 1091, in prepare_files req_to_install.check_if_exists()[SEP]File <*>python2.7/dist-packages/pip/req.py, line 811, in check_if_exists self.satisfied_by = pkg_resources.get_distribution(self.req)[SEP]File <*>python2.7/dist-packages/pkg_resources/__init__.py, line 535, in get_distribution dist = get_provider(dist)[SEP]File <*>python2.7/dist-packages/pkg_resources/__init__.py, line 415, in get_provider return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0][SEP]IndexError: list index out of range",,
191,37980078,0,1,,,"File <*>/audiornn.py, line 56, in <module> tf.with_dependencies([expected_output], input_tensor)[SEP]AttributeError: module 'tensorflow' has no attribute 'with_dependencies'",,
192,38020817,0,1,,,"File <ipython-input-29-4e06de0b7af3>, line 1, in <module> sess.run(edit_distances, feed_dict=feed_dict)[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 372, in run run_metadata_ptr)[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 597, in _run for subfeed, subfeed_val in _feed_fn(feed, feed_val):[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 558, in _feed_fn return feed_fn(feed, feed_val)[SEP]File <*>python3.4/dist-packages/tensorflow/python/client/session.py, line 268, in <lambda> [feed.indices, feed.values, feed.shape], feed_val)),[SEP]TypeError: zip argument #2 must support iteration",,
193,38167388,0,1,,,"File main.py, line 6, in <module> connection.start_socket(8089, callback=handler.message_processor)[SEP]File <*>/python_socket_server.py, line 13, in start_socket process_message(connection, callback=callback)[SEP]File <*>/python_socket_server.py, line 38, in process_message result = callback(general_proto)[SEP]File <*>/proto_handler.py, line 39, in message_processor return train_shape(general_proto.template)[SEP]File <*>/proto_handler.py, line 23, in train_shape rec.add_training_data(recognition_template.interpretation.label, recognition_template.shape)[SEP]File <*>/recognition_manager.py, line 98, in add_training_data self.recognizers[label].train(label, points)[SEP]File <*>/recognizer.py, line 78, in train self.classifier.fit(x=reshaped_tensor, y=target, steps=1)[SEP]File <*>python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py, line 173, in fit input_fn, feed_fn = _get_input_fn(x, y, batch_size)[SEP]File <*>python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py, line 67, in _get_input_fn x, y, n_classes=None, batch_size=batch_size)[SEP]File <*>python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py, line 117, in setup_train_data_feeder X, y, n_classes, batch_size, shuffle=shuffle, epochs=epochs)[SEP]File <*>python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py, line 239, in __init__ self.X.shape, None if self.y is None else self.y.shape, n_classes,[SEP]AttributeError: 'Tensor' object has no attribute 'shape'",,
194,38321879,0,1,,,"File <*>/pool.py, line 119, in worker result = (True, func(*args, **kwds))[SEP]TypeError: func1() got multiple values for argument 'func'",,
195,38321879,0,1,,,"File <*>/theano_multiprocess_debug.py, line 36, in <module> Y = MPjob(xlist)[SEP]File <*>/theano_multiprocess_debug.py, line 29, in MPjob for y in Results:[SEP]File <*>/pool.py, line 695, in next raise value[SEP]TypeError: func1() got multiple values for argument 'func'",,
196,38616620,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File caffepb.py, line 28, in <module> type=None),[SEP]File <*>python2.7/site-packages/google/protobuf/descriptor.py, line 652, in __new__ _message.Message._CheckCalledFromGeneratedFile()[SEP]TypeError: Descriptors should not be created directly, but only retrieved from their parent.",,
197,38710339,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.4/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import *[SEP]File <*>python3.4/site-packages/tensorflow/python/__init__.py, line 48, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python3.4/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python3.4/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]File <*>python3.4/imp.py, line 243, in load_module return load_dynamic(name, filename, file)[SEP]ImportError: dlopen(/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.7.5.dylib",,
198,38809686,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: cannot import name Nadam",,
199,38833934,0,1,,,"File custom_op.py, line 19, in <module> grad = tf.gradients(my_op(a), [a])[0][SEP]File <*>python3.5/site-packages/tensorflow/python/framework/function.py, line 528, in __call__ return call_function(self._definition, *args, **kwargs)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/function.py, line 267, in call_function compute_shapes=False)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 2285, in create_op raise TypeError(""Input #%d is not a tensor: %s"" % (idx, a))[SEP]TypeError: Input #0 is not a tensor: <tensorflow.python.ops.variables.Variable object at 0x1080d2710>",,
200,39076388,0,1,,,"File trainer_deepMnist.py, line 109, in <module> x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 559, in eval return _eval_using_default_session(self, feed_dict, self.graph, session)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 3648, in _eval_using_default_session return session.run(tensors, feed_dict)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 710, in run run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 908, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 958, in _do_run target_list, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 978, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[10000,32,28,28] [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Reshape, Variable_2/read)]]",,
201,39114832,0,1,,,"File <*>/model.py, line 109, in <module> output_actual: batch[1][SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 698, in run run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 838, in _run fetch_handler = _FetchHandler(self._graph, fetches)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 355, in __init__ self._fetch_mapper = _FetchMapper.for_fetch(fetches)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 181, in for_fetch return _ListFetchMapper(fetch)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 288, in __init__ self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches][SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 178, in for_fetch (fetch, type(fetch)))[SEP]TypeError: Fetch argument None has invalid type <type 'NoneType'>",,
202,39171170,0,1,,,"File <*>/xxx.py, line 262, in <module> model.add(SimpleRNN(output_dim=vocab_size, input_shape=train_x.shape))[SEP]File <*>/site-packages/keras/models.py, line 275, in add layer.create_input_layer(batch_input_shape, input_dtype)[SEP]File <*>/site-packages/keras/engine/topology.py, line 367, in create_input_layer self(x)[SEP]File <*>/site-packages/keras/engine/topology.py, line 467, in __call__ self.assert_input_compatibility(x)[SEP]File <*>/site-packages/keras/engine/topology.py, line 408, in assert_input_compatibility str(K.ndim(x)))[SEP]Exception: Input 0 is incompatible with layer simplernn_1: expected ndim=3, found ndim=4",,
203,39297995,0,1,,,"File <*>python2.7/site-packages/theano/sandbox/gpuarray/__init__.py, line 20, in <module> import pygpu[SEP]File <*>/__init__.py, line 7, in <module> from . import gpuarray, elemwise, reduction[SEP]File <*>/elemwise.py, line 3, in <module> from .dtypes import dtype_to_ctype, get_common_dtype[SEP]File <*>/dtypes.py, line 6, in <module> from . import gpuarray[SEP]ImportError: cannot import name gpuarray",,
204,39309367,0,1,,,"File train_lstm.py, line 66, in <module> model.embedding_placeholder: data.glove_vec})[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 382, in run run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 655, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 723, in _do_run target_list, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 743, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors.OutOfRangeError: PaddingFIFOQueue '_0_batching/padding_fifo_queue' is closed and has insufficient elements (requested 50, current size 0) [[Node: batching = QueueDequeueMany[_class=[""loc:@batching/padding_fifo_queue""], component_types=[DT_INT32, DT_INT32], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](batching/padding_fifo_queue, batching/n)]] [[Node: batching/_9 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_1191_batching"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]",,
205,39376169,0,1,,,"File test_classifier.py, line 48, in <module> score = model.evaluate(x, y, batch_size=16)[SEP]File <*>/site-packages/keras/models.py, line 655, in evaluate sample_weight=sample_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1131, in evaluate batch_size=batch_size)[SEP]File <*>/site-packages/keras/engine/training.py, line 959, in _standardize_user_data exception_prefix='model input')[SEP]File <*>/site-packages/keras/engine/training.py, line 108, in standardize_input_data str(array.shape))[SEP]Exception: Error when checking model input: expected convolution2d_input_1 to have shape (None, 3, 150, 150) but got array with shape (1, 3, 150, 198)`",,
206,39414060,0,1,,,"File <*>/main, line 132, in <module> apply_weights_OP = tf.matmul(activation_OP, Weights, name=""apply_weights"")[SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/math_ops.py, line 1346, in matmul name=name)[SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 1271, in _mat_mul transpose_b=transpose_b, name=name)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/op_def_library.py, line 703, in apply_op op_def=op_def)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 2312, in create_op set_shapes_for_outputs(ret)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 1704, in set_shapes_for_outputs shapes = shape_func(op)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/common_shapes.py, line 94, in matmul_shape inner_a.assert_is_compatible_with(inner_b)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 108, in assert_is_compatible_with % (self, other))[SEP]ValueError: Dimensions 3 and 4 are not compatible",,
207,39435341,0,1,,,"File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 715, in _do_call return fn(*args)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 697, in _run_fn status, run_metadata)[SEP]File <*>python3.5/contextlib.py, line 66, in __exit__ next(self.gen)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/errors.py, line 450, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value auc/false_positives [[Node: auc/false_positives/read = Identity[T=DT_FLOAT, _class=[""loc:@auc/false_positives""], _device=""/job:localhost/replica:0/task:0/cpu:0""](auc/false_positives)]]",,
208,39435341,0,1,,,"File <*>/mlp_.py, line 152, in <module> train_auc = sess.run(auc, feed_dict={X: batch_xs, y: batch_ys, dropout_keep_prob:1.})[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 372, in run run_metadata_ptr)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 636, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 708, in _do_run target_list, options, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 728, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value auc/false_positives [[Node: auc/false_positives/read = Identity[T=DT_FLOAT, _class=[""loc:@auc/false_positives""], _device=""/job:localhost/replica:0/task:0/cpu:0""](auc/false_positives)]]",,
209,39462343,0,1,,,"File dummy.py, line 16, in <module> features = tf.pack([col1, col2, col3])[SEP]File <*>python2.7/dist-packages/tensorflow/python/ops/array_ops.py, line 487, in pack return gen_array_ops._pack(values, axis=axis, name=name)[SEP]File <*>python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py, line 1462, in _pack result = _op_def_lib.apply_op(""Pack"", values=values, axis=axis, name=name)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/op_def_library.py, line 437, in apply_op raise TypeError(""%s that don't all match."" % prefix)[SEP]TypeError: Tensors in list passed to 'values' of 'Pack' Op have types [int32, int32, float32] that don't all match.",,
210,39467496,0,1,,,"File <*>/gridsearch.py, line 43, in <module> model.fit(x,y)[SEP]File <*>/site-packages/keras/wrappers/scikit_learn.py, line 135, in fit **self.filter_sk_params(self.build_fn.__call__))[SEP]TypeError: __call__() missing 1 required positional argument: 'x'",,
211,39553981,0,1,,,"File <*>/main.py, line 13, in <module> autoencoder1.train()[SEP]File <*>/AutoEncoder.py, line 74, in train _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})[SEP]TypeError: unhashable type: 'numpy.ndarray'",,
212,39848466,0,1,,,"File <*>/__init__.py, line 79, in <module> model = baseline_model()[SEP]File <*>/training_module.py, line 31, in baseline_model model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(3, IMG_WIDTH, IMG_HEIGHT)))[SEP]File <*>python2.7/site-packages/keras/models.py, line 276, in add layer.create_input_layer(batch_input_shape, input_dtype)[SEP]File <*>python2.7/site-packages/keras/engine/topology.py, line 370, in create_input_layer self(x)[SEP]File <*>python2.7/site-packages/keras/engine/topology.py, line 514, in __call__ self.add_inbound_node(inbound_layers, node_indices, tensor_indices)[SEP]File <*>python2.7/site-packages/keras/engine/topology.py, line 572, in add_inbound_node Node.create_node(self, inbound_layers, node_indices, tensor_indices)[SEP]File <*>python2.7/site-packages/keras/engine/topology.py, line 149, in create_node output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))[SEP]File <*>python2.7/site-packages/keras/layers/convolutional.py, line 466, in call filter_shape=self.W_shape)[SEP]File <*>python2.7/site-packages/keras/backend/tensorflow_backend.py, line 1579, in conv2d x = tf.nn.conv2d(x, kernel, strides, padding=padding)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 394, in conv2d data_format=data_format, name=name)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/op_def_library.py, line 703, in apply_op op_def=op_def)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 2319, in create_op set_shapes_for_outputs(ret)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 1711, in set_shapes_for_outputs shapes = shape_func(op)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/common_shapes.py, line 246, in conv2d_shape padding)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/common_shapes.py, line 184, in get2d_conv_output_size (row_stride, col_stride), padding_type)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/common_shapes.py, line 149, in get_conv_output_size ""Filter: %r Input: %r"" % (filter_size, input_size))[SEP]ValueError: Filter must not be larger than the input: Filter: (5, 5) Input: (3, 350)",,
213,39945037,0,1,,,"File single_model_conv.py, line 108, in <module> gan = GAN(num_latent, 28, 'single')[SEP]File single_model_conv.py, line 23, in __init__ self.adversary(self.gen_image)[SEP]File single_model_conv.py, line 93, in adversary h2_flattened = tf.reshape(h2, [-1, num_units])[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py, line 1977, in reshape name=name)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/op_def_library.py, line 490, in apply_op preferred_dtype=default_dtype)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 657, in convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/constant_op.py, line 180, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/constant_op.py, line 163, in constant tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/tensor_util.py, line 422, in make_tensor_proto tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])[SEP]File <*>python2.7/site-packages/tensorflow/python/util/compat.py, line 64, in as_bytes (bytes_or_text,))[SEP]TypeError: Expected binary or unicode string, got -1",,
214,39950311,0,1,,,"File <*>python2.7/dist-packages/django/core/handlers/base.py, line 149, in get_response response = self.process_exception_by_middleware(e, request)[SEP]File <*>python2.7/dist-packages/django/core/handlers/base.py, line 147, in get_response response = wrapped_callback(request, *callback_args, **callback_kwargs)[SEP]File <*>/views.py, line 27, in home output=loaded_model.predict(img_np)[SEP]File <*>python2.7/dist-packages/keras/models.py, line 671, in predict return self.model.predict(x, batch_size=batch_size, verbose=verbose)[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 1161, in predict check_batch_dim=False)[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 108, in standardize_input_data str(array.shape))[SEP]Exception: Error when checking : expected dense_input_1 to have shape (None, 784) but got array with shape (784, 1)",,
215,40275774,0,1,,,"File <*>python3.5/dist-packages/tensorflow/python/framework/common_shapes.py, line 594, in call_cpp_shape_fn status)[SEP]File <*>python3.5/contextlib.py, line 66, in exit next(self.gen)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/errors.py, line 463, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors.InvalidArgumentError: Shape must be rank 0 but is rank 1",,
216,40275774,0,1,,,"File my_test.py, line 51, in [FUNC] [CODE][SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/parsing_ops.py, line 640, in parse_single_sequence_example feature_list_dense_defaults, example_name, name)[SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/parsing_ops.py, line 837, in _parse_single_sequence_example_raw name=name)[SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/gen_parsing_ops.py, line 285, in _parse_single_sequence_example name=name)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/op_def_library.py, line 749, in apply_op op_def=op_def)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 2382, in create_op set_shapes_for_outputs(ret)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 1783, in set_shapes_for_outputs shapes = shape_func(op)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/common_shapes.py, line 596, in call_cpp_shape_fn raise ValueError(err.message)[SEP]ValueError: Shape must be rank 0 but is rank 1",,
217,40423766,0,1,,,"File <string>, line 1, in <module> [CODE][SEP]File <*>/setup.py, line 339, in <module> cmdclass=cmdclass,[SEP]File <*>python3.5/core.py, line 148, in setup dist.run_commands()[SEP]File <*>python3.5/dist.py, line 955, in run_commands self.run_command(cmd)[SEP]File <*>python3.5/dist.py, line 974, in run_command cmd_obj.run()[SEP]File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/egg_info.py, line 279, in run [CODE][SEP]File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/egg_info.py, line 306, in find_sources [CODE][SEP]File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/egg_info.py, line 533, in run [CODE][SEP]File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/egg_info.py, line 562, in add_defaults [CODE][SEP]File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/py36compat.py, line 36, in add_defaults [CODE][SEP]File <*>python3.5/site-packages/setuptools-28.7.1-py3.5.egg/setuptools/command/py36compat.py, line 119, in _add_defaults_ext [CODE][SEP]File <*>python3.5/cmd.py, line 299, in get_finalized_command cmd_obj.ensure_finalized()[SEP]File <*>python3.5/cmd.py, line 107, in ensure_finalized self.finalize_options()[SEP]File <*>python3.5/site-packages/Cython/Distutils/build_ext.py, line 19, in finalize_options self.distribution.ext_modules)[SEP]File <*>python3.5/site-packages/Cython/Build/Dependencies.py, line 809, in cythonize aliases=aliases)[SEP]File <*>python3.5/site-packages/Cython/Build/Dependencies.py, line 752, in create_extension_list **kwds))[SEP]TypeError: __init__() missing 3 required positional arguments: 'feature_name', 'feature_description', and 'feature_check'",,
218,40690203,0,1,,,"File test.py, line 45, in <module> (x_train, _), (x_test, _) = data[SEP]ValueError: too many values to unpack (expected 2)",,
219,40955223,0,1,,,"File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 972, in _do_call return fn(*args)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 954, in _run_fn status, run_metadata)[SEP]File <*>python3/contextlib.py, line 66, in __exit__ next(self.gen)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/errors.py, line 463, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors.InvalidArgumentError: Input to reshape is a tensor with 313600 values, but the requested shape requires a multiple of 4608 [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](dropout/mul, Reshape_1/shape)]]",,
220,40955223,0,1,,,"File mnist_tensorflow.py, line 60, in <module> x: batch[0], y_: batch[1], keep_prob1: 1.0, keep_prob2: 1.0})[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 559, in eval return _eval_using_default_session(self, feed_dict, self.graph, session)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 3761, in _eval_using_default_session return session.run(tensors, feed_dict)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 717, in run run_metadata_ptr)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 915, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 965, in _do_run target_list, options, run_metadata)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 985, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors.InvalidArgumentError: Input to reshape is a tensor with 313600 values, but the requested shape requires a multiple of 4608 [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](dropout/mul, Reshape_1/shape)]]",,
221,41008524,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 21, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 20, in swig_import_helper return importlib.import_module('_pywrap_tensorflow')[SEP]File <*>python2.7/__init__.py, line 37, in import_module __import__(name)[SEP]ImportError: No module named _pywrap_tensorflow",,
222,41032108,0,1,,,"File <*>python3.4/site-packages/pip/basecommand.py, line 215, in main status = self.run(options, args)[SEP]File <*>python3.4/site-packages/pip/commands/install.py, line 342, in run prefix=options.prefix_path,[SEP]File <*>python3.4/site-packages/pip/req/req_set.py, line 784, in install **kwargs[SEP]File <*>python3.4/site-packages/pip/req/req_install.py, line 851, in install self.move_wheel_files(self.source_dir, root=root, prefix=prefix)[SEP]File <*>python3.4/site-packages/pip/req/req_install.py, line 1064, in move_wheel_files isolated=self.isolated,[SEP]File <*>python3.4/site-packages/pip/wheel.py, line 345, in move_wheel_files clobber(source, lib_dir, True)[SEP]File <*>python3.4/site-packages/pip/wheel.py, line 329, in clobber os.utime(destfile, (st.st_atime, st.st_mtime))[SEP]PermissionError: [Errno 1] Operation not permitted",,
223,41109376,0,1,,,"File <*>/demo.py, line 18, in <module> from fast_rcnn.test import im_detect[SEP]File <*>/test.py, line 16, in <module> import caffe[SEP]File <*>/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver[SEP]File <*>/pycaffe.py, line 13, in <module> from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \[SEP]ImportError: No module named _caffe",,
224,41117740,0,1,,,"File <*>/site-packages/tensorflow/python/client/session.py, line 1021, in _do_call return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1003, in _run_fn status, run_metadata)[SEP]File <*>/contextlib.py, line 66, in __exit__ next(self.gen)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 469, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(100, 784), b.shape=(784, 256), m=100, n=256, k=784 [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_Placeholder_0/_7, Variable/read)]] [[Node: Mean/_15 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_35_Mean"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]",,
225,41414867,0,1,,,"File <*>python35/site-packages/tensorflow/python/client/session.py, line 972, in _do_call return fn(*args)[SEP]File <*>python35/site-packages/tensorflow/python/client/session.py, line 954, in _run_fn status, run_metadata)[SEP]File <*>python35/contextlib.py, line 66, in __exit__ next(self.gen)[SEP]File <*>python35/site-packages/tensorflow/python/framework/errors.py, line 463, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype float [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]",,
226,41414867,0,1,,,"File neural_network.py, line 48, in <module> print(sess.run(loss), feed_dict={xs:x_data, ys:y_data})[SEP]File <*>python35/site-packages/tensorflow/python/client/session.py, line 717, in run run_metadata_ptr)[SEP]File <*>python35/site-packages/tensorflow/python/client/session.py, line 915, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python35/site-packages/tensorflow/python/client/session.py, line 965, in _do_run target_list, options, run_metadata)[SEP]File <*>python35/site-packages/tensorflow/python/client/session.py, line 985, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype float [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]",,
227,41498883,0,1,,,"File add_1.py, line 13, in <module> saver = tf.train.Saver([y]) raise TypeError(""Variable to save is not a Variable: %s"" % var)[SEP]TypeError: Variable to save is not a Variable: Tensor(""add_3:0"", shape=(), dtype=int32, device=/job:local/task:3)",,
228,41576944,0,1,,,"File <*>/testing.py, line 31, in [FUNC] [CODE][SEP]File <*>python3.5/site-packages/tensorflow/python/ops/functional_ops.py, line 390, in map_fn swap_memory=swap_memory)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py, line 2636, in while_loop result = context.BuildLoop(cond, body, loop_vars, shape_invariants)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py, line 2469, in BuildLoop pred, body, original_loop_vars, loop_vars, shape_invariants)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py, line 2419, in _BuildLoop body_result = body(*packed_vars_for_body)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/functional_ops.py, line 380, in compute packed_fn_values = fn(packed_values)[SEP]TypeError: () missing 1 required positional argument: 'crop'",,
229,41587689,0,1,,,"File <*>/test_counter.py, line 61, in <module> saver = tf.train.Saver({'w':temp})[SEP]File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 1043, in __init__ self.build()[SEP]File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 1073, in build restore_sequentially=self._restore_sequentially)[SEP]File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 649, in build saveables = self._ValidateAndSliceInputs(names_to_saveables)[SEP]File <*>python2.7/dist-packages/tensorflow/python/training/saver.py, line 578, in _ValidateAndSliceInputs variable)[SEP]TypeError: names_to_saveables must be a dict mapping string names to Tensors/Variables. Not a variable: Tensor(""TransformFeatureToIndex:0"", shape=(100,), dtype=string)",,
230,41630022,0,1,,,"File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 451, in __init__ dims_iter = iter(dims)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 510, in __iter__ raise TypeError(""'Tensor' object is not iterable."")[SEP]TypeError: 'Tensor' object is not iterable.",,
231,41630022,0,1,,,"File <*>/test_placeholder.py, line 5, in <module> input = tf.placeholder(tf.int32, [batchSize, 5])[SEP]File <*>/site-packages/tensorflow/python/ops/array_ops.py, line 1579, in placeholder shape = tensor_shape.as_shape(shape)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 821, in as_shape return TensorShape(shape)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 457, in __init__ self._dims = [as_dimension(d) for d in dims_iter][SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 457, in <listcomp> self._dims = [as_dimension(d) for d in dims_iter][SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 378, in as_dimension return Dimension(value)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 33, in __init__ self._value = int(value)[SEP]TypeError: int() argument must be a string, a bytes-like object or a number, not 'Tensor'",,
232,41630022,0,1,,,"File <*>/test_placeholder.py, line 5, in <module> input = tf.placeholder(tf.int32, tf.pack([batchSize, 5]))[SEP]File <*>/site-packages/tensorflow/python/ops/array_ops.py, line 1579, in placeholder shape = tensor_shape.as_shape(shape)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 821, in as_shape return TensorShape(shape)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 454, in __init__ self._dims = [as_dimension(dims)][SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 378, in as_dimension return Dimension(value)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_shape.py, line 33, in __init__ self._value = int(value)[SEP]TypeError: int() argument must be a string, a bytes-like object or a number, not 'Tensor'",,
233,41651628,0,1,,,"File mnist.py, line 154, in <module> input_shape=(1, img_rows, img_cols)))[SEP]File <*>python2.7/dist-packages/keras/models.py, line 276, in add layer.create_input_layer(batch_input_shape, input_dtype)[SEP]File <*>python2.7/dist-packages/keras/engine/topology.py, line 370, in create_input_layer self(x)[SEP]File <*>python2.7/dist-packages/keras/engine/topology.py, line 514, in __call__ self.add_inbound_node(inbound_layers, node_indices, tensor_indices)[SEP]File <*>python2.7/dist-packages/keras/engine/topology.py, line 572, in add_inbound_node Node.create_node(self, inbound_layers, node_indices, tensor_indices)[SEP]File <*>python2.7/dist-packages/keras/engine/topology.py, line 149, in create_node output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))[SEP]File <*>python2.7/dist-packages/keras/layers/convolutional.py, line 466, in call filter_shape=self.W_shape)[SEP]File <*>python2.7/dist-packages/keras/backend/tensorflow_backend.py, line 1579, in conv2d x = tf.nn.conv2d(x, kernel, strides, padding=padding)[SEP]File <*>python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py, line 396, in conv2d data_format=data_format, name=name)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/op_def_library.py, line 759, in apply_op op_def=op_def)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 2242, in create_op set_shapes_for_outputs(ret)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 1617, in set_shapes_for_outputs shapes = shape_func(op)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/ops.py, line 1568, in call_with_requiring return call_cpp_shape_fn(op, require_shape_fn=True)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/common_shapes.py, line 610, in call_cpp_shape_fn debug_python_shape_fn, require_shape_fn)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/common_shapes.py, line 675, in _call_cpp_shape_fn_impl raise ValueError(err.message)[SEP]ValueError: Negative dimension size caused by subtracting 3 from 1 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,1,28,28], [3,3,28,32].",,
234,41746576,0,1,,,"File <*>python2.7/dist-packages/tensorflow/python/__init__.py, line 61, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory",,
235,41771965,0,1,,,"File test_keras.py, line 52, in <module> model.fit(x_train, y_train, validation_data=(x_test, y_test), nb_epoch=epochs, batch_size=32)[SEP]File <*>python2.7/dist-packages/keras/models.py, line 664, in fit sample_weight=sample_weight)[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 1068, in fit batch_size=batch_size)[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 981, in _standardize_user_data exception_prefix='model input')[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 113, in standardize_input_data str(array.shape))[SEP]ValueError: Error when checking model input: expected convolution2d_input_1 to have shape (None, 3, 32, 32) but got array with shape (50000, 32, 32, 3)",,
236,41796618,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/sklearn/model_selection/_validation.py, line 140, in cross_val_score for train, test in cv_iter)[SEP]File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 758, in __call__ while self.dispatch_one_batch(iterator):[SEP]File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 603, in dispatch_one_batch tasks = BatchedCalls(itertools.islice(iterator, batch_size))[SEP]File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 127, in __init__ self.items = list(iterator_slice)[SEP]File <*>/site-packages/sklearn/model_selection/_validation.py, line 140, in <genexpr> for train, test in cv_iter)[SEP]File <*>/site-packages/sklearn/base.py, line 67, in clone new_object_params = estimator.get_params(deep=False)[SEP]TypeError: get_params() got an unexpected keyword argument 'deep'",,
237,41883800,0,1,,,"File <*>/fine-tune-v3-new-classes.py, line 75, in <module> nb_val_samples=nb_validation_samples) #1020[SEP]File <*>python2.7/site-packages/keras/engine/training.py, line 1508, in fit_generator class_weight=class_weight)[SEP]File <*>python2.7/site-packages/keras/engine/training.py, line 1261, in train_on_batch check_batch_dim=True)[SEP]File <*>python2.7/site-packages/keras/engine/training.py, line 985, in _standardize_user_data exception_prefix='model target')[SEP]File <*>python2.7/site-packages/keras/engine/training.py, line 113, in standardize_input_data str(array.shape))[SEP]ValueError: Error when checking model target: expected dense_2 to have shape (None, 200) but got array with shape (16, 2)",,
238,41883800,0,1,,,"File <*>python2.7/threading.py, line 810, in __bootstrap_inner self.run()[SEP]File <*>python2.7/threading.py, line 763, in run self.__target(*self.__args, **self.__kwargs)[SEP]File <*>python2.7/site-packages/keras/engine/training.py, line 409, in data_generator_task generator_output = next(generator)[SEP]File <*>python2.7/site-packages/keras/preprocessing/image.py, line 691, in next target_size=self.target_size)[SEP]File <*>python2.7/site-packages/keras/preprocessing/image.py, line 191, in load_img img = img.convert('RGB')[SEP]File <*>python2.7/site-packages/PIL/Image.py, line 844, in convert self.load()[SEP]File <*>python2.7/site-packages/PIL/ImageFile.py, line 248, in load return Image.Image.load(self)[SEP]AttributeError: 'NoneType' object has no attribute 'Image'",,
239,41937915,0,1,,,"File <string>, line 1, in <module> [CODE][SEP]IOError: [Errno 2] No such file or directory: '/private/var/folders/1p/7km73m0s2cvdfb1js3ct8_mh0000gn/T/pip-JMMIRP-build/setup.py'",,
240,41965187,0,1,,,"File convolutional.py, line 339, in <module> tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)[SEP]File <*>python2.7/dist-packages/tensorflow/python/platform/app.py, line 44, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough))[SEP]File convolutional.py, line 284, in main with tf.Session() as sess:[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 1187, in __init__ super(Session, self).__init__(target, graph, config=config)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 552, in __init__ self._session = tf_session.TF_NewDeprecatedSession(opts, status)[SEP]File <*>python2.7/contextlib.py, line 24, in __exit__ self.gen.next()[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/errors_impl.py, line 469, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors_impl.InternalError: Failed to create session.",,
241,42059487,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import *[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 63, in <module> from tensorflow.core.framework.graph_pb2 import *[SEP]File <*>/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in <module> from google.protobuf import descriptor as _descriptor[SEP]ImportError: No module named 'google'",,
242,42102174,0,1,,,"File <*>/site-packages/tensorflow/python/client/session.py, line 10, in [FUNC] [CODE][SEP]File <*>/contextlib.py, line 66, in __exit__ next(self.gen)[SEP]File <*>/contextlib.py, line 66, in [FUNC] [CODE][SEP]n_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [10000,10] vs. [10000] [[Node: sub = Sub[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](Add, _recv_Placeholder_1_0/_7)]]",,
243,42102174,0,1,,,"File test1.py, line 43, in <module> c = sess.run(cost, feed_dict={X: train_X, Y: train_Y})[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 76, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 96, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 10, in [FUNC] [CODE][SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [10000,10] vs. [10000] [[Node: sub = Sub[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](Add, _recv_Placeholder_1_0/_7)]]",,
244,42128830,0,1,,,"File board.py, line 3, in <module> mnist = input_data.read_data_sets(r'Z:/downloads/MNIST dataset', one_hot=True)[SEP]File <*>/input_data.py, line 150, in read_data_sets train_images = extract_images(local_file)[SEP]File <*>/input_data.py, line 40, in extract_images buf = bytestream.read(rows * cols * num_images)[SEP]File <*>/gzip.py, line 274, in read return self._buffer.read(size)[SEP]TypeError: only integer scalar arrays can be converted to a scalar index",,
245,42284528,0,1,,,"File <*>python2.7/dist-packages/tensorflow/python/__init__.py, line 61, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory Failed to load the native TensorFlow runtime.",,
246,42315289,0,1,,,"File train.py, line 6, in <module> vgg19.fit(nb_epoch=1)[SEP]File <*>/vgg19.py, line 84, in fit nb_val_samples=8[SEP]File <*>python2.7/dist-packages/keras/models.py, line 907, in fit_generator pickle_safe=pickle_safe)[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 1378, in fit_generator callbacks._set_model(callback_model)[SEP]File <*>python2.7/dist-packages/keras/callbacks.py, line 32, in _set_model callback._set_model(model)[SEP]File <*>python2.7/dist-packages/keras/callbacks.py, line 493, in _set_model self.sess = KTF.get_session()[SEP]File <*>python2.7/dist-packages/keras/backend/tensorflow_backend.py, line 111, in get_session _initialize_variables()[SEP]File <*>python2.7/dist-packages/keras/backend/tensorflow_backend.py, line 200, in _initialize_variables sess.run(tf.variables_initializer(uninitialized_variables))[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 766, in run run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 964, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 1014, in _do_run target_list, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.py, line 1034, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[4096] [[Node: Variable_43/Assign = Assign[T=DT_FLOAT, _class=[""loc:@Variable_43""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Variable_43, Const_59)]]",,
247,42356396,0,1,,,"File helloWorld.py, line 10, in <module> import matplotlib.pyplot as plt[SEP]ImportError: No module named 'matplotlib'",,
248,42379138,0,1,,,"File pymask.py, line 303, in <module> main(sys.argv)[SEP]File pymask.py, line 285, in main keras.callbacks.ProgbarLogger()[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1557, in fit_generator class_weight=class_weight)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1314, in train_on_batch check_batch_axis=True)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1029, in _standardize_user_data exception_prefix='model input')[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 52, in standardize_input_data str(names))[SEP]ValueError: No data provided for ""input_1"". Need data for each key in: ['input_1']",,
249,42438170,0,1,,,"File <*>python2.7/threading.py, line 801, in __bootstrap_inner self.run()[SEP]File <*>python2.7/threading.py, line 754, in run self.__target(*self.__args, **self.__kwargs)[SEP]File <*>python2.7/dist-packages/keras/engine/training.py, line 409, in data_generator_task generator_output = next(generator)[SEP]File <*>/load_gluc_data.py, line 198, in generate yield self.next_batch()[SEP]File <*>/load_gluc_data.py, line 192, in next_batch X, y, l = self.process_image(json_im, X, y, l)[SEP]File <*>/load_gluc_data.py, line 131, in process_image im.augment_with_tf(self.tf_sess)[SEP]File <*>/load_gluc_data.py, line 85, in augment_with_tf self.im = sess.run(saturation, {im_placeholder: np.asarray(self.im)})[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 766, in run run_metadata_ptr)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 921, in _run + e.args[0])[SEP]TypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(""Placeholder:0"", shape=(96, 96, 3), dtype=float32) is not an element of this graph.",,
250,42464109,0,1,,,"File <*>/tfclass.py, line 36, in <module> summary_writer = tf.summary.FileWriter('/home/sergo/work/logs',graph_def = sess.graph_def)[SEP]File <*>python3.6/site-packages/tensorflow/python/summary/writer/writer.py, line 308, in __init__ event_writer = EventFileWriter(logdir, max_queue, flush_secs)[SEP]File <*>python3.6/site-packages/tensorflow/python/summary/writer/event_file_writer.py, line 69, in __init__ gfile.MakeDirs(self._logdir)[SEP]File <*>python3.6/site-packages/tensorflow/python/lib/io/file_io.py, line 301, in recursive_create_dir pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status)[SEP]File <*>python3.6/contextlib.py, line 89, in __exit__ next(self.gen)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 469, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors_impl.UnimplementedError: /home/sergo",,
251,42495930,0,1,,,"File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1022, in _do_call return fn(*args)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1004, in _run_fn status, run_metadata)[SEP]File <*>python3.5/contextlib.py, line 66, in __exit__ next(self.gen)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/errors_impl.py, line 469, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status))[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[14525,14000] [[Node: rnn/basic_lstm_cell/weights/Initializer/random_uniform = Add[T=DT_FLOAT, _class=[""loc:@rnn/basic_lstm_cell/weights""], _device=""/job:localhost/replica:0/task:0/gpu:0""](rnn/basic_lstm_cell/weights/Initializer/random_uniform/mul, rnn/basic_lstm_cell/weights/Initializer/random_uniform/min)]]",,
252,42495930,0,1,,,"File Netzwerk_v0.5.1_gamma.py, line 171, in <module> session.run(tf.global_variables_initializer())[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 767, in run run_metadata_ptr)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 965, in _run feed_dict_string, options, run_metadata)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1015, in _do_run target_list, options, run_metadata)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 1035, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[14525,14000] [[Node: rnn/basic_lstm_cell/weights/Initializer/random_uniform = Add[T=DT_FLOAT, _class=[""loc:@rnn/basic_lstm_cell/weights""], _device=""/job:localhost/replica:0/task:0/gpu:0""](rnn/basic_lstm_cell/weights/Initializer/random_uniform/mul, rnn/basic_lstm_cell/weights/Initializer/random_uniform/min)]]",,
253,47143043,0,1,,,"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call return fn(*args)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1293, in _run_fn self._extend_graph()[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1354, in _extend_graph self._session, graph_def.SerializeToString(), status)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.UnavailableError: Trying to connect an http1.x server",,
254,47143043,0,1,,,"File <*>/pydevd.py, line 1599, in <module> globals = debugger.run(setup['file'], None, None, is_module)[SEP]File <*>/pydevd.py, line 1026, in run pydev_imports.execfile(file, globals, locals) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File worker.py, line 426, in <module> main()[SEP]File worker.py, line 418, in main run(args, server)[SEP]File worker.py, line 174, in run sess.run(trainer.sync)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.UnavailableError: Trying to connect an http1.x server",,
255,47241010,0,1,,,"File <*>/rock_detector.py, line 155, in <module> main()[SEP]File <*>/rock_detector.py, line 117, in main est_vgg16.train(input_fn=dataset_input_fn, steps=10)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 302, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 711, in _train_model features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 694, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py, line 145, in model_fn labels)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py, line 92, in _clone_and_build_model keras_model, features)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/_impl/keras/estimator.py, line 58, in _create_ordered_io for key in estimator_io_dict:[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 505, in __iter__ raise TypeError(""'Tensor' object is not iterable."")[SEP]TypeError: 'Tensor' object is not iterable.",,
256,47258882,0,1,,,"File <*>python3.5/dist-packages/Theano-1.0.0rc1-py3.5.egg/theano/gpuarray/__init__.py, line 220, in <module> use(config.device)[SEP]File <*>python3.5/dist-packages/Theano-1.0.0rc1-py3.5.egg/theano/gpuarray/__init__.py, line 207, in use init_dev(device, preallocate=preallocate)[SEP]File <*>python3.5/dist-packages/Theano-1.0.0rc1-py3.5.egg/theano/gpuarray/__init__.py, line 152, in init_dev pygpu.blas.gemm(0, tmp, tmp, 0, tmp, overwrite_c=True)[SEP]File <*>/blas.pyx, line 149, in pygpu.blas.gemm [CODE][SEP]File <*>/blas.pyx, line 47, in pygpu.blas.pygpu_blas_rgemm [CODE][SEP]pygpu.gpuarray.GpuArrayException: (b'cuLinkCreate: CUDA_ERROR_JIT_COMPILER_NOT_FOUND: PTX JIT compiler library not found', 3)",,
257,47262955,0,1,,,"File <ipython-input-6-b5da44e251a5>, line 1, in <module> from keras.layers import Input, Dense[SEP]ModuleNotFoundError: No module named 'keras'",,
258,47312396,0,1,,,"File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 62, in _pin_memory_loop batch = pin_memory_batch(batch)[SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 123, in pin_memory_batch return [pin_memory_batch(sample) for sample in batch][SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 123, in <listcomp> return [pin_memory_batch(sample) for sample in batch][SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 117, in pin_memory_batch return batch.pin_memory()[SEP]File <*>python3.6/site-packages/torch/tensor.py, line 82, in pin_memory return type(self)().set_(storage.pin_memory()).view_as(self)[SEP]File <*>python3.6/site-packages/torch/storage.py, line 83, in pin_memory allocator = torch.cuda._host_allocator()[SEP]File <*>python3.6/site-packages/torch/cuda/__init__.py, line 220, in _host_allocator _lazy_init()[SEP]File <*>python3.6/site-packages/torch/cuda/__init__.py, line 84, in _lazy_init _check_driver()[SEP]File <*>python3.6/site-packages/torch/cuda/__init__.py, line 51, in _check_driver raise AssertionError(""Torch not compiled with CUDA enabled"")[SEP]AssertionError: Torch not compiled with CUDA enabled",,
259,47555568,0,1,,,"File SAMME_train_all.py, line 47, in <module> ce = K.categorical_crossentropy(label, label_pred)[SEP]File <*>/tensorflow_backend.py, line 2754, in categorical_c axis=len(output.get_shape()) - 1,[SEP]AttributeError: 'numpy.ndarray' object has no attribute 'get_shape'",,
260,47585698,0,1,,,"File modeltrain.py, line 180, in <module> model.fit_generator(next_batch(X_train_r, y_train_r, batch_size), steps_per_epoch=(X_train_r.shape[0]/batch_size), validation_data=(X_val_r, y_val_r), epochs=100, callbacks=[csv_logger, model_check])[SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 87, in wrapper return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1978, in fit_generator val_x, val_y, val_sample_weight)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1382, in _standardize_user_data exception_prefix='target')[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 111, in _standardize_input_data 'Found: array with shape ' + str(data.shape))[SEP]ValueError: The model expects 9 target arrays, but only received one array. Found: array with shape (70, 512, 512, 1)",,
261,47723527,0,1,,,"File test_python.py, line 1, in [FUNC] [CODE][SEP]ModuleNotFoundError: No module named 'numpy'",,
262,47724077,0,1,,,"File main.py, line 36, in <module> model.fit(X,Y, epochs=50, batch_size=100)[SEP]File <*>/site-packages/keras/models.py, line 960, in fit validation_steps=validation_steps)[SEP]File <*>/site-packages/keras/engine/training.py, line 1574, in fit batch_size=batch_size)[SEP]File <*>/site-packages/keras/engine/training.py, line 1407, in _standardize_user_data exception_prefix='input')[SEP]File <*>/site-packages/keras/engine/training.py, line 128, in _standardize_input_data arrays[i] = array[SEP]ValueError: could not broadcast input array from shape (14,1) into shape (14)",,
263,47743936,0,1,,,"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call return fn(*args)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn status, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[500,80] [[Node: decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](decoder/while/BasicDecoderStep/basic_lstm_cell/concat, decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul/Enter)]] [[Node: gradients/Add/_282 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_457_gradients/Add"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](^_cloopdecoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y/_181)]]",,
264,47743936,0,1,,,"File <*>/main.py, line 89, in <module> _ = sess.run([update_step])[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[500,80] [[Node: decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](decoder/while/BasicDecoderStep/basic_lstm_cell/concat, decoder/while/BasicDecoderStep/basic_lstm_cell/MatMul/Enter)]] [[Node: gradients/Add/_282 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_457_gradients/Add"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](^_cloopdecoder/while/BasicDecoderStep/TrainingHelperNextInputs/add/y/_181)]]",,
265,47867748,0,1,,,"File <ipython-input-6-06fadd69ae8f>, line 1, in <module> runfile('C:/Users/1/Desktop/transfer_learning_tutorial-master/MCVE.py', wdir='C:/Users/1/Desktop/transfer_learning_tutorial-master')[SEP]File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 710, in runfile execfile(filename, namespace)[SEP]File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 101, in execfile exec(compile(f.read(), filename, 'exec'), namespace)[SEP]File <*>/MCVE.py, line 77, in <module> tf.app.run(main=main, argv=[sys.argv[0]])[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough))[SEP]File <*>/MCVE.py, line 68, in main steps=1000)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 302, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 780, in _train_model log_step_count_steps=self._config.log_step_count_steps) as mon_sess:[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 368, in MonitoredTrainingSession stop_grace_period_secs=stop_grace_period_secs)[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 673, in __init__ stop_grace_period_secs=stop_grace_period_secs)[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 493, in __init__ self._sess = _RecoverableSession(self._coordinated_creator)[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 851, in __init__ _WrappedSession.__init__(self, self._create_session())[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 856, in _create_session return self._sess_creator.create_session()[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 554, in create_session self.tf_sess = self._session_creator.create_session()[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 428, in create_session init_fn=self._scaffold.init_fn)[SEP]File <*>/site-packages/tensorflow/python/training/session_manager.py, line 279, in prepare_session sess.run(init_op, feed_dict=init_feed_dict)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message)[SEP]InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [900] rhs shape= [1001] [[Node: Assign_1145 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionResnetV2/Logits/Logits/biases""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionResnetV2/Logits/Logits/biases, checkpoint_initializer_1145)]]",,
266,47870003,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]RuntimeError: invalid argument 2: dimension 1 out of range of 1D tensor at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensor.c:24",,
267,47870003,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]RuntimeError: t() expects a 2D tensor, but self is 1D",,
268,47870003,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]RuntimeError: matrices expected, got 1D, 2D tensors at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensorMath.c:1288",,
269,47877858,0,1,,,"File <*>/LSTM-RNN.py, line 42, in <module> states_series, current_state = tf.contrib.rnn.static_rnn(cell, inputs_series, init_state)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/rnn.py, line 1181, in static_rnn input_shape = first_input.get_shape().with_rank_at_least(2)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/tensor_shape.py, line 670, in with_rank_at_least raise ValueError(""Shape %s must have rank at least %d"" % (self, rank))[SEP]ValueError: Shape () must have rank at least 2",,
270,48060769,0,1,,,"File <*>/site-packages/tensorflow/python/platform/self_check.py, line 75, in preload_check ctypes.WinDLL(build_info.cudart_dll_name)[SEP]File <*>/__init__.py, line 351, in __init__ self._handle = _dlopen(self._name, mode)[SEP]OSError: [WinError 126] This specified module could not be found",,
271,48060769,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import *[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 30, in <module> self_check.preload_check()[SEP]File <*>/site-packages/tensorflow/python/platform/self_check.py, line 82, in preload_check % (build_info.cudart_dll_name, build_info.cuda_version_number))[SEP]ImportError: Could not find 'cudart64_80.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 8.0 from this URL: https://developer.nvidia.com/cuda-toolkit",,
272,48149954,0,1,,,"File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 468, in make_tensor_proto str_values = [compat.as_bytes(x) for x in proto_values][SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 468, in <listcomp> str_values = [compat.as_bytes(x) for x in proto_values][SEP]File <*>/site-packages/tensorflow/python/util/compat.py, line 65, in as_bytes (bytes_or_text,))[SEP]TypeError: Expected binary or unicode string, got {'weights': <tf.Variable 'Variable:0' shape=(784, 600) dtype=float32_ref>, 'biases': <tf.Variable 'Variable_1:0' shape=(600,) dtype=float32_ref>}",,
273,48149954,0,1,,,"File <*>/neuralnetworktest.py, line 45, in <module> train(x)[SEP]File <*>/neuralnetworktest.py, line 29, in train prediction = neuralNetwork(inputdata)[SEP]File <*>/neuralnetworktest.py, line 22, in neuralNetwork FinalH2 = tf.add(tf.matmul(H1, H2[""weights""]), H2[""biases""])[SEP]File <*>/site-packages/tensorflow/python/ops/math_ops.py, line 1844, in matmul a = ops.convert_to_tensor(a, name=""a"")[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 836, in convert_to_tensor as_ref=False)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 926, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 229, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 208, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 472, in make_tensor_proto ""supported type."" % (type(values), values))[SEP]TypeError: Failed to convert object of type <class 'dict'> to Tensor.",,
274,48215159,0,1,,,"File <*>/site-packages/google/protobuf/internal/python_message.py, line 545, in _GetFieldByName return message_descriptor.fields_by_name[field_name][SEP]KeyError: 'layout_optimizer'",,
275,48215159,0,1,,,"File export_inference_graph.py, line 119, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough))[SEP]File export_inference_graph.py, line 115, in main FLAGS.output_directory, input_shape)[SEP]File <*>/site-packages/object_detection-0.1-py3.5.egg/object_detection/exporter.py, line 427, in export_inference_graph input_shape, optimize_graph, output_collection_name)[SEP]File <*>/site-packages/object_detection-0.1-py3.5.egg/object_detection/exporter.py, line 391, in _export_inference_graph initializer_nodes='')[SEP]File <*>/site-packages/object_detection-0.1-py3.5.egg/object_detection/exporter.py, line 72, in freeze_graph_with_def_protos layout_optimizer=rewriter_config_pb2.RewriterConfig.ON)[SEP]File <*>/site-packages/google/protobuf/internal/python_message.py, line 484, in init field = _GetFieldByName(message_descriptor, field_name)[SEP]File <*>/site-packages/google/protobuf/internal/python_message.py, line 548, in _GetFieldByName (message_descriptor.name, field_name))[SEP]ValueError: Protocol message RewriterConfig has no ""layout_optimizer"" field.",,
276,48276192,0,1,,,"File RF_2.py, line 312, in <module> main()[SEP]File RF_2.py, line 298, in main train_eval(x_train, y_train, x_validation, y_validation, x_test, y_test, num_tree)[SEP]File RF_2.py, line 221, in train_eval prob0 = results[0][eval_metrics.INFERENCE_PROB_NAME][SEP]KeyError: 'probabilities'",,
277,48303166,0,1,,,"File <ipython-input-7-e80e82960eb9>, line 1, in <module> cross = cross_val_score(estimator=classfier, X=Xtrain, y=Ytrain, cv=10 , n_jobs=-1)[SEP]File <*>/site-packages/sklearn/model_selection/_validation.py, line 342, in cross_val_score pre_dispatch=pre_dispatch)[SEP]File <*>/site-packages/sklearn/model_selection/_validation.py, line 206, in cross_validate for train, test in cv.split(X, y, groups))[SEP]File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 779, in __call__ while self.dispatch_one_batch(iterator):[SEP]File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 620, in dispatch_one_batch tasks = BatchedCalls(itertools.islice(iterator, batch_size))[SEP]File <*>/site-packages/sklearn/externals/joblib/parallel.py, line 127, in __init__ self.items = list(iterator_slice)[SEP]File <*>/site-packages/sklearn/model_selection/_validation.py, line 206, in <genexpr> for train, test in cv.split(X, y, groups))[SEP]File <*>/site-packages/sklearn/base.py, line 62, in clone new_object_params[name] = clone(param, safe=False)[SEP]File <*>/site-packages/sklearn/base.py, line 53, in clone return copy.deepcopy(estimator)[SEP]File <*>/copy.py, line 180, in deepcopy y = _reconstruct(x, memo, *rv)[SEP]File <*>/copy.py, line 280, in _reconstruct state = deepcopy(state, memo)[SEP]File <*>/copy.py, line 150, in deepcopy y = copier(x, memo)[SEP]File <*>/copy.py, line 240, in _deepcopy_dict y[deepcopy(key, memo)] = deepcopy(value, memo)[SEP]File <*>/copy.py, line 215, in _deepcopy_list append(deepcopy(a, memo))[SEP]File <*>/copy.py, line 169, in deepcopy rv = reductor(4)[SEP]TypeError: can't pickle _thread.lock objects",,
278,48309322,0,1,,,"File testJan17.py, line 13, in <module> sample_model()[SEP]File testJan17.py, line 8, in sample_model att_mull = Multiply([dense_all, dense_att]) #merge([dense_all, dense_att], output_shape=10, mode='mul')[SEP]TypeError: __init__() takes exactly 1 argument (2 given)",,
279,48343420,0,1,,,"File generate_tfrecord.py, line 192, in <module> tf.app.run()[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough))[SEP]File generate_tfrecord.py, line 184, in main tf_example = create_tf_example(group, path)[SEP]File generate_tfrecord.py, line 173, in create_tf_example 'image/object/class/label': dataset_util.int64_list_feature(classes),[SEP]File <*>/dataset_util.py, line 26, in int64_list_feature return tf.train.Feature(int64_list=tf.train.Int64List(value=value))[SEP]TypeError: None has type NoneType, but expected one of: int, long",,
280,48343857,0,1,,,"File predict.py, line 34, in <module> preds = learn.predict_array(im[None])[SEP]File <*>/learner.py, line 266, in predict_array def predict_array(self, arr): return to_np(self.model(V(T(arr).cuda())))[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 325, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/container.py, line 67, in forward input = module(input)[SEP]File <*>python3.6/site-packages/torch/nn/modules/batchnorm.py, line 37, in forward self.training, self.momentum, self.eps)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1011, in batch_norm raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size))[SEP]ValueError: Expected more than 1 value per channel when training, got input size [1, 1024]",,
281,48347728,0,1,,,"File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call return fn(*args)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn status, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: cnn()conv2 : Tensor had Inf values [[Node: tower_7/conv2/CheckNumerics_3 = CheckNumerics[T=DT_FLOAT, message=""NaN: cnn()conv2"", _device=""/job:localhost/replica:0/task:0/device:GPU:7""](tower_7/conv2/conv2)]]",,
282,48347728,0,1,,,"File cnn_base.py, line 1703, in <module> training()[SEP]File cnn_base.py, line 1314, in training _, loss_value = sess.run([train_op, loss])[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: cnn()conv2 : Tensor had Inf values [[Node: tower_7/conv2/CheckNumerics_3 = CheckNumerics[T=DT_FLOAT, message=""NaN: cnn()conv2"", _device=""/job:localhost/replica:0/task:0/device:GPU:7""](tower_7/conv2/conv2)]]",,
283,48347728,0,1,,,"File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call return fn(*args)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn status, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: average_gradients(expanded_g) : Tensor had Inf and NaN values [[Node: CheckNumerics_30 = CheckNumerics[T=DT_FLOAT, message=""NaN: average_gradients(expanded_g)"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](ExpandDims_30)]] [[Node: tower_6/total_loss/_2216 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:6"", send_device_incarnation=1, tensor_name=""edge_4923_tower_6/total_loss"", _device=""/job:localhost/replica:0/task:0/device:GPU:6""](tower_6/total_loss)]]",,
284,48347728,0,1,,,"File cnn_base.py, line 1704, in <module> training()[SEP]File cnn_base.py, line 1312, in training nan_debug, _, loss_value = sess.run([check_op, train_op, loss])[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 889, in run run_metadata_ptr)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1120, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1317, in _do_run options, run_metadata)[SEP]File <*>python3.4/site-packages/tensorflow/python/client/session.py, line 1336, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: NaN: average_gradients(expanded_g) : Tensor had Inf and NaN values [[Node: CheckNumerics_30 = CheckNumerics[T=DT_FLOAT, message=""NaN: average_gradients(expanded_g)"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](ExpandDims_30)]] [[Node: tower_6/total_loss/_2216 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:6"", send_device_incarnation=1, tensor_name=""edge_4923_tower_6/total_loss"", _device=""/job:localhost/replica:0/task:0/device:GPU:6""](tower_6/total_loss)]]",,
285,48428415,0,1,,,"File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.5/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.5/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.5/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory",,
286,48428415,0,1,,,"File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.5/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.5/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory",,
287,48553812,0,1,,,"File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.5/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.5/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow9ConcatCPUINS_8bfloat16EEEvPNS_10DeviceBaseERKSt6vectorISt10unique_ptrINS_6TTypesIT_Li2EiE11ConstMatrixESt14default_deleteIS9_EESaISC_EEPNS8_6MatrixE",,
288,48555290,0,1,,,"File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory",,
289,48600538,0,1,,,"File <*>/hackerearth_project.py, line 90, in <module> model(X_train, X_test, Y_train, Y_test)[SEP]File <*>/hackerearth_project.py, line 71, in model optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1, beta2=beta2).minimize(cost)[SEP]File <*>/site-packages/tensorflow/python/training/optimizer.py, line 343, in minimize grad_loss=grad_loss)[SEP]File <*>/site-packages/tensorflow/python/training/optimizer.py, line 394, in compute_gradients self._assert_valid_dtypes([loss])[SEP]File <*>/site-packages/tensorflow/python/training/optimizer.py, line 543, in _assert_valid_dtypes dtype = t.dtype.base_dtype[SEP]AttributeError: 'NoneType' object has no attribute 'dtype'",,
290,48824381,0,1,,,"File <*>/cli.py, line 797, in Execute resources = calliope_command.Run(cli=self, args=args)[SEP]File <*>/backend.py, line 757, in Run resources = command_instance.Run(args)[SEP]File <*>/predict.py, line 65, in Run args.text_instances)[SEP]File <*>/local_utils.py, line 89, in RunPredict raise LocalPredictRuntimeError(err)[SEP]LocalPredictRuntimeError: RuntimeError: Bad magic number in .pyc file ERROR: (gcloud.ml-engine.local.predict) RuntimeError: Bad magic number in .pyc file",,
291,48848853,0,1,,,"File <*>/site-packages/cx_Freeze/initscripts/__startup__.py, line 14, in run module.run()[SEP]File <*>/site-packages/cx_Freeze/initscripts/Console.py, line 26, in run exec(code, m.__dict__)[SEP]File app.py, line 2, in <module> [CODE][SEP]File <*>/retrain.py, line 16, in <module> import tensorflow as tf[SEP]File <*>/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import *[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 52, in <module> from tensorflow.core.framework.graph_pb2 import *[SEP]File <*>/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in <module> from google.protobuf import descriptor as _descriptor[SEP]ImportError: No module named 'google'",,
292,48972752,0,1,,,"File <*>/new_main.py, line 35, in <module> b = sess.run(correct_prediction, feed_dict={a: a1, b: b1, y: y1})[SEP]TypeError: unhashable type: 'numpy.ndarray'",,
293,49033008,0,1,,,"File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1350, in _do_call return fn(*args)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1329, in _run_fn status, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,32,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[Node: FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Preprocessor/sub, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read)]]",,
294,49033008,0,1,,,"File eval.py, line 146, in <module> tf.app.run()[SEP]File <*>python3.5/dist-packages/tensorflow/python/platform/app.py, line 124, in run _sys.exit(main(argv))[SEP]File eval.py, line 142, in main FLAGS.checkpoint_dir, FLAGS.eval_dir)[SEP]File <*>/evaluator.py, line 240, in evaluate save_graph_dir=(eval_dir if eval_config.save_graph else ''))[SEP]File <*>/eval_util.py, line 407, in repeated_checkpoint_run save_graph_dir)[SEP]File <*>/eval_util.py, line 286, in _run_checkpoint_once result_dict = batch_processor(tensor_dict, sess, batch, counters)[SEP]File <*>/evaluator.py, line 183, in _process_batch result_dict = sess.run(tensor_dict)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 895, in run run_metadata_ptr)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1128, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1344, in _do_run options, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1363, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,32,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[Node: FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Preprocessor/sub, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read)]]",,
295,49048734,0,1,,,"File <*>python3.6/configparser.py, line 1138, in _unify_values sectiondict = self._sections[section][SEP]KeyError: 'blas'",,
296,49083984,0,1,,,"File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl input_tensors_as_shapes, status)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[1], expected a dimension of 1, got 3 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [100,3].",,
297,49083984,0,1,,,"File <*>/cnn_mnist.py, line 214, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 124, in run _sys.exit(main(argv))[SEP]File <*>/cnn_mnist.py, line 203, in main hooks=[logging_hook])[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 314, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 743, in _train_model features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 725, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs)[SEP]File <*>/cnn_mnist.py, line 67, in cnn_model_fn loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)[SEP]File <*>/site-packages/tensorflow/python/ops/losses/losses_impl.py, line 790, in sparse_softmax_cross_entropy labels, logits, weights, expected_rank_diff=1)[SEP]File <*>/site-packages/tensorflow/python/ops/losses/losses_impl.py, line 720, in _remove_squeezable_dimensions labels, predictions, expected_rank_diff=expected_rank_diff)[SEP]File <*>/site-packages/tensorflow/python/ops/confusion_matrix.py, line 76, in remove_squeezable_dimensions labels = array_ops.squeeze(labels, [-1])[SEP]File <*>/site-packages/tensorflow/python/ops/array_ops.py, line 2490, in squeeze return gen_array_ops._squeeze(input, axis, name)[SEP]File <*>/site-packages/tensorflow/python/ops/gen_array_ops.py, line 7049, in _squeeze ""Squeeze"", input=input, squeeze_dims=axis, name=name)[SEP]File <*>/site-packages/tensorflow/python/framework/op_def_library.py, line 787, in _apply_op_helper op_def=op_def)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 3162, in create_op compute_device=compute_device)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 3208, in _create_op_helper set_shapes_for_outputs(op)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 2427, in set_shapes_for_outputs return _set_shapes_for_outputs(op)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 2400, in _set_shapes_for_outputs shapes = shape_func(op)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 2330, in call_with_requiring return call_cpp_shape_fn(op, require_shape_fn=True)[SEP]File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 627, in call_cpp_shape_fn require_shape_fn)[SEP]File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 691, in _call_cpp_shape_fn_impl raise ValueError(err.message)[SEP]ValueError: Can not squeeze dim[1], expected a dimension of 1, got 3 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [100,3].",,
298,49140164,0,1,,,"File <*>python3.6/inspect.py, line 1119, in getfullargspec sigcls=Signature)[SEP]File <*>python3.6/inspect.py, line 2186, in _signature_from_callable raise TypeError('{!r} is not a callable object'.format(obj))[SEP]TypeError: (<tf.Tensor 'IteratorGetNext:0' shape=(?, 40, 40, ?) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=int32>) is not a callable object",,
299,49177169,0,1,,,"File <*>/task2_new.py, line 78, in <module> loss = compute_loss(h_fc2, margin)[SEP]File <*>/task2_new.py, line 37, in compute_loss Ltriplet = np.maximum(0, 1 - tf.square(diff_neg)/(tf.square(diff_pos) + margin))[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 614, in __bool__ raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""[SEP]TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",,
300,49206550,0,1,,,"File lec5.py, line 97, in <module> train(epoch)[SEP]File lec5.py, line 74, in train loss = criterion(y_pred, labels)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 357, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/loss.py, line 679, in forward self.ignore_index, self.reduce)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1161, in cross_entropy return nll_loss(log_softmax(input, 1), target, weight, size_average, ignore_index, reduce)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1052, in nll_loss return torch._C._nn.nll_loss(input, target, weight, size_average, ignore_index, reduce)[SEP]RuntimeError: multi-target not supported at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/THNN/generic/ClassNLLCriterion.c:22",,
301,49209810,0,1,,,"File <*>/try2.py, line 45, in <module> classifier.train(input_fn=lambda: my_input_fn(is_shuffle=True, repeat_count=100))[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 352, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 812, in _train_model features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/estimator.py, line 793, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py, line 354, in _model_fn config=config)[SEP]File <*>python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py, line 161, in _dnn_model_fn 'Given type: {}'.format(type(features)))[SEP]ValueError: features should be a dictionary of `Tensor`s. Given type: <class 'tensorflow.python.framework.ops.Tensor'>",,
302,49210844,0,1,,,"File <*>/generate_tfrecord.py, line 99, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File <*>/generate_tfrecord.py, line 85, in main writer = tf.python_io.TFRecordWriter(FLAGS.output_path)[SEP]File <*>/site-packages/tensorflow/python/lib/io/tf_record.py, line 111, in __init__ compat.as_bytes(path), compat.as_bytes(compression_type), status)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a NewWriteableFile: : The system cannot find the path specified.",,
303,49265723,0,1,,,"File <*>/main.py, line 6, in <module> watcher = Watcher('res/vid/planet_earth_s01e01/video.mp4', 'res/vid/planet_earth_s01e01/english.srt')[SEP]File <*>/watch.py, line 9, in __init__ self.detector = Detector()[SEP]File <*>/detect.py, line 6, in __init__ self.tfnet = TFNet(self.options)[SEP]File <*>python3.6/site-packages/darkflow/net/build.py, line 75, in __init__ self.build_forward()[SEP]File <*>python3.6/site-packages/darkflow/net/build.py, line 105, in build_forward self.inp = tf.placeholder(tf.float32, inp_size, 'input')[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/array_ops.py, line 1677, in placeholder raise RuntimeError(""tf.placeholder() is not compatible with ""[SEP]RuntimeError: tf.placeholder() is not compatible with eager execution.",,
304,49524396,0,1,,,"File <*>/lstm.py, line 128, in <module> main()[SEP]File <*>/lstm.py, line 108, in main model.fit_generator(generator=training_sequence)[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/models.py, line 1253, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>/site-packages/keras/engine/training.py, line 2244, in fit_generator class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1884, in train_on_batch class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1487, in _standardize_user_data exception_prefix='target')[SEP]File <*>/site-packages/keras/engine/training.py, line 113, in _standardize_input_data 'with shape ' + str(data_shape))[SEP]ValueError: Error when checking target: expected dense_1 to have 5 dimensions, but got array with shape (1, 1939, 9)",,
305,49524396,0,1,,,"File <*>/lstm.py, line 131, in <module> main()[SEP]File <*>/lstm.py, line 111, in main model.fit_generator(generator=training_sequence)[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/models.py, line 1253, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>/site-packages/keras/engine/training.py, line 2244, in fit_generator class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1884, in train_on_batch class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1487, in _standardize_user_data exception_prefix='target')[SEP]File <*>/site-packages/keras/engine/training.py, line 113, in _standardize_input_data 'with shape ' + str(data_shape))[SEP]ValueError: Error when checking target: expected dense_1 to have 2 dimensions, but got array with shape (1, 1034, 9)",,
306,49688535,0,1,,,"File train.py, line 167, in <module> tf.app.run()[SEP]File <*>python3.5/app.py, line 126, in run _sys.exit(main(argv))[SEP]File train.py, line 163, in main worker_job_name, is_chief, FLAGS.train_dir)[SEP]File <*>python3.5/dist-packages/object_detection-0.1-py3.5.egg/object_detection/trainer.py, line 211, in train detection_model = create_model_fn()[SEP]File <*>python3.5/dist-packages/object_detection-0.1-py3.5.egg/object_detection/builders/model_builder.py, line 96, in build add_summaries)[SEP]File <*>python3.5/dist-packages/object_detection-0.1-py3.5.egg/object_detection/builders/model_builder.py, line 272, in _build_faster_rcnn_model frcnn_config.inplace_batchnorm_update)[SEP]AttributeError: 'FasterRcnn' object has no attribute 'inplace_batchnorm_update'",,
307,49688680,0,1,,,"File <*>/freeze_graph鈥? line 11, in <module> sys.exit(main())[SEP]TypeError: main() missing 1 required positional argument: 鈥榰nused_args鈥?
308,49760781,0,1,,,File [FILE]", line 337," in [FUNC] [CODE][SEP]TypeError: 'UnimplementedError' object is not iterable"""
309,49809177,0,1,,,"File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 579, in merge_with new_dims.append(dim.merge_with(other[i]))[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 138, in merge_with self.assert_is_compatible_with(other)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 111, in assert_is_compatible_with other))[SEP]ValueError: Dimensions 5 and 4 are not compatible",,
310,49809177,0,1,,,"File <*>python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py, line 602, in gradients in_grad.set_shape(t_in.get_shape())[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/ops.py, line 407, in set_shape self._shape = self._shape.merge_with(shape)[SEP]File <*>python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py, line 582, in merge_with raise ValueError(""Shapes %s and %s are not compatible"" % (self, other))[SEP]ValueError: Shapes (?, 5, 15, 1) and (?, 4, 15, 1) are not compatible",,
311,49809177,0,1,,,"File experiment.py, line 65, in <module> batches_per_lot=batches_per_lot, sigma=dp_sigma, dp=dp)[SEP]File <*>/model.py, line 247, in GAN_solvers G_solver = tf.train.AdamOptimizer().minimize(G_loss_mean_over_batch, var_list=generator_vars)[SEP]File <*>python3.5/dist-packages/tensorflow/python/training/optimizer.py, line 343, in minimize grad_loss=grad_loss)[SEP]File <*>python3.5/dist-packages/tensorflow/python/training/optimizer.py, line 414, in compute_gradients colocate_gradients_with_ops=colocate_gradients_with_ops)[SEP]File <*>python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py, line 609, in gradients % (op.name, i, t_in.shape, in_grad.shape))[SEP]ValueError: Incompatible shapes between op input and calculated input gradient. Forward operation: generator/conv2d_transpose_1. Input index: 2. Original input shape: (?, 4, 15, 1). Calculated input gradient shape: (?, 5, 15, 1)",,
312,49824872,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/k_means.py, line 10, in prepare_dataset dataset = tf.data.Dataset.from_tensor_slices(dm_data)[SEP]File <*>python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 222, in from_tensor_slices return TensorSliceDataset(tensors)[SEP]File <*>python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1017, in __init__ for i, t in enumerate(nest.flatten(tensors))[SEP]File <*>python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1017, in <listcomp> for i, t in enumerate(nest.flatten(tensors))[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 950, in convert_to_tensor as_ref=False)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1040, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 235, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 185, in constant t = convert_to_eager_tensor(value, ctx, dtype)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 131, in convert_to_eager_tensor return ops.EagerTensor(value, context=handle, device=device, dtype=dtype)[SEP]ValueError: Can't convert Python sequence with mixed types to Tensor.",,
313,49840968,0,1,,,"File processing_2a_1.py, line 96, in <module> model.add(Conv1D(60,32, strides=1, activation='relu',padding='causal',input_shape=(None,64,1)))[SEP]File <*>/models.py, line 442, in add [CODE][SEP]File <*>/topology.py, line 558, in __call__ [CODE][SEP]File <*>/topology.py, line 457, in assert_input_compatibility [CODE][SEP]ValueError: Input 0 is incompatible with layer conv1d_1: expected ndim=3, found ndim=4",,
314,49840968,0,1,,,"File processing_2a_1.py, line 125, in <module> history=model.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_val,Y_val), epochs=nr_of_epochs,verbose=2)[SEP]File <*>/models.py, line 871, in fit [CODE][SEP]File <*>/training.py, line 1524, in fit [CODE][SEP]File <*>/training.py, line 1382, in _standardize_user_data [CODE][SEP]File <*>/training.py, line 132, in _standardize_input_data [CODE][SEP]ValueError: Error when checking target: expected dense_2 to have 3 dimensions, but got array with shape (1496000, 1)",,
315,49846106,0,1,,,"File [FILE], line <*>, in [FUNC] [CODE][SEP]AttributeError: module 'tensorflow' has no attribute 'Session'",,
316,49880939,0,1,,,"File <*>/train.py, line 167, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File <*>/train.py, line 92, in main FLAGS.pipeline_config_path)[SEP]File <*>/config_util.py, line 93, in get_configs_from_pipeline_file text_format.Merge(proto_str, pipeline_config)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 533, in Merge descriptor_pool=descriptor_pool)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 587, in MergeLines return parser.MergeLines(lines, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 620, in MergeLines self._ParseOrMerge(lines, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 635, in _ParseOrMerge self._MergeField(tokenizer, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 735, in _MergeField merger(tokenizer, message, field)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 823, in _MergeMessageField self._MergeField(tokenizer, sub_message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 703, in _MergeField (message_descriptor.full_name, name))[SEP]google.protobuf.text_format.ParseError: 108:7 : Message type ""object_detection.protos.SsdFeatureExtractor"" has no field named ""batch_norm_trainable"".",,
317,49890823,0,1,,,"File train.py, line 167, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File train.py, line 92, in main FLAGS.pipeline_config_path)[SEP]File <*>/config_util.py, line 93, in get_configs_from_pipeline_file text_format.Merge(proto_str, pipeline_config)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 533, in Merge descriptor_pool=descriptor_pool)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 587, in MergeLines return parser.MergeLines(lines, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 620, in MergeLines self._ParseOrMerge(lines, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 635, in _ParseOrMerge self._MergeField(tokenizer, message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 735, in _MergeField merger(tokenizer, message, field)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 823, in _MergeMessageField self._MergeField(tokenizer, sub_message)[SEP]File <*>/site-packages/google/protobuf/text_format.py, line 703, in _MergeField (message_descriptor.full_name, name))[SEP]google.protobuf.text_format.ParseError: 108:7 : Message type ""object_detection.protos.SsdFeatureExtractor"" has no field named ""batch_norm_trainable"".",,
318,49890823,0,1,,,"File train.py, line 167, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File train.py, line 163, in main worker_job_name, is_chief, FLAGS.train_dir)[SEP]File <*>/trainer.py, line 275, in train clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])[SEP]File <*>/model_deploy.py, line 193, in create_clones outputs = model_fn(*args, **kwargs)[SEP]File <*>/trainer.py, line 198, in _create_losses prediction_dict = detection_model.predict(images, true_image_shapes)[SEP]File <*>/ssd_meta_arch.py, line 384, in predict preprocessed_inputs)[SEP]File <*>/ssd_mobilenet_v2_feature_extractor.py, line 123, in extract_features scope=scope)[SEP]File <*>/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py, line 183, in func_with_args return func(*args, **current_args)[SEP]File <*>/mobilenet_v2.py, line 162, in mobilenet_base base_only=True, **kwargs)[SEP]File <*>/mobilenet_v2.py, line 154, in mobilenet **kwargs)[SEP]File <*>/mobilenet.py, line 325, in mobilenet net, end_points = mobilenet_base(inputs, scope=scope, **mobilenet_args)[SEP]File <*>/mobilenet.py, line 244, in mobilenet_base net = opdef.op(net, **params)[SEP]File <*>/site-packages/tensorflow/contrib/layers/python/layers/layers.py, line 1058, in convolution outputs = normalizer_fn(outputs, **normalizer_params)[SEP]File <*>/site-packages/tensorflow/contrib/layers/python/layers/layers.py, line 650, in batch_norm outputs = layer.apply(inputs, training=is_training)[SEP]File <*>/site-packages/tensorflow/python/layers/base.py, line 825, in apply return self.__call__(inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/layers/base.py, line 714, in __call__ outputs = self.call(inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/layers/normalization.py, line 549, in call training_value = utils.constant_value(training)[SEP]File <*>/site-packages/tensorflow/python/layers/utils.py, line 232, in constant_value return smart_module.smart_constant_value(pred)[SEP]File <*>/site-packages/tensorflow/python/framework/smart_cond.py, line 93, in smart_constant_value ""Found instead: %s"" % pred)[SEP]TypeError: `pred` must be a Tensor, or a Python bool, or 1 or 0. Found instead: None",,
319,49951822,0,1,,,"File <*>/site-packages/tensorflow/python/client/session.py, line 1330, in _do_call return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1315, in _run_fn options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1423, in _call_tf_sessionrun status, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,25] vs. shape[1] = [30,100] [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](rnn/while/TensorArrayReadV3, rnn/while/Switch_4:1, rnn/while/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/Const)]]",,
320,49951822,0,1,,,"File <*>/dnn_gragh.py, line 198, in <module> model.train(5000, 0.0001, my_input_fn, training_examples, training_targets, sequenceLenth=trainSequenceL)[SEP]File <*>/dnn_gragh.py, line 124, in train state2, current_loss, nowAccuracy = sess.run([state, loss, accuracy])[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 908, in run run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1143, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1324, in _do_run run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1343, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,25] vs. shape[1] = [30,100] [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](rnn/while/TensorArrayReadV3, rnn/while/Switch_4:1, rnn/while/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/Const)]]",,
321,50121477,0,1,,,"File <*>/mnist_test.py, line 24, in <module> from official.mnist import mnist[SEP]ModuleNotFoundError: No module named 'official'",,
322,50184145,0,1,,,"File main.py, line 69, in <module> main();[SEP]File main.py, line 66, in main train_model(iris_dataset, model, optimizer);[SEP]File main.py, line 41, in train_model gradients = gradient_tune(features, label, model);[SEP]File main.py, line 27, in gradient_tune prediction_loss = prediction_loss_diff(features, targets, model);[SEP]File main.py, line 23, in prediction_loss_diff return tf.losses.sparse_softmax_cross_entropy(label, predicted_label);[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py, line 853, in sparse_softmax_cross_entropy name=""xentropy"")[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/nn_ops.py, line 2050, in sparse_softmax_cross_entropy_with_logits precise_logits, labels, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 7504, in sparse_softmax_cross_entropy_with_logits _six.raise_from(_core._status_to_exception(e.code, message), None)[SEP]File <string>, line 2, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.InternalError: Could not find valid device for node name: ""SparseSoftmaxCrossEntropyWithLogits""",,
323,50199224,0,1,,,"File <*>/scratch_4.py, line 11, in <module> assert type(elem) == tf.python.framework.ops.EagerTensor[SEP]AttributeError: module 'tensorflow' has no attribute 'python'",,
324,50203766,0,1,,,"File train.py, line 167, in <module> tf.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File train.py, line 163, in main worker_job_name, is_chief, FLAGS.train_dir)[SEP]File <*>/trainer.py, line 284, in train train_config.optimizer)[SEP]File <*>/optimizer_builder.py, line 50, in build learning_rate = _create_learning_rate(config.learning_rate)[SEP]File <*>/optimizer_builder.py, line 109, in _create_learning_rate learning_rate_sequence, config.warmup)[SEP]File <*>/learning_schedules.py, line 156, in manual_stepping raise ValueError('First step cannot be zero.')[SEP]ValueError: First step cannot be zero.",,
325,50329855,0,1,,,"File <*>python2.7/site-packages/tensorflow/python/ops/script_ops.py, line 147, in __call__ ret = func(*args)[SEP]File <*>python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 378, in generator_py_func nest.flatten_up_to(output_types, values), flattened_types)[SEP]AttributeError: 'numpy.dtype' object has no attribute 'as_numpy_dtype'",,
326,50329855,0,1,,,"File pipe, line 320, in <module> tf.app.run()[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File pipe, line 316, in main train(FLAGS.num_training_iterations, FLAGS.report_interval, FLAGS.report_interval_verbose)[SEP]File pipe, line 120, in train print(sess.run(next_element))[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 905, in run run_metadata_ptr)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1140, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1321, in _do_run run_metadata)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1340, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.UnknownError: exceptions.AttributeError: 'numpy.dtype' object has no attribute 'as_numpy_dtype'",,
327,50480689,0,1,,,"File <string>, line 1, in <module> [CODE][SEP]File <*>/spawn.py, line 105, in spawn_main exitcode = _main(fd)[SEP]File <*>/spawn.py, line 114, in _main prepare(preparation_data)[SEP]File <*>/spawn.py, line 225, in prepare _fixup_main_from_path(data['init_main_from_path'])[SEP]File <*>/spawn.py, line 277, in _fixup_main_from_path run_name=""__mp_main__"")[SEP]File <*>/runpy.py, line 263, in run_path pkg_name=pkg_name, script_name=fname)[SEP]File <*>/runpy.py, line 96, in _run_module_code mod_name, mod_spec, pkg_name, script_name)[SEP]File <*>/runpy.py, line 85, in _run_code exec(code, run_globals)[SEP]File <*>/TutorialCIFAR10.py, line 36, in <module> dataiter = iter(trainloader)[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 451, in __iter__ return _DataLoaderIter(self)[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 239, in __init__ w.start()[SEP]File <*>/process.py, line 105, in start self._popen = self._Popen(self)[SEP]File <*>/context.py, line 223, in _Popen return _default_context.get_context().Process._Popen(process_obj)[SEP]File <*>/context.py, line 322, in _Popen return Popen(process_obj)[SEP]File <*>/popen_spawn_win32.py, line 33, in __init__ prep_data = spawn.get_preparation_data(process_obj._name)[SEP]File <*>/spawn.py, line 143, in get_preparation_data _check_not_importing_main()[SEP]File <*>/spawn.py, line 136, in _check_not_importing_main is not going to be frozen to produce an executable.)[SEP]RuntimeError: An attempt has been made to start a new process before the current process has finished its bootstrapping phase.",,
328,50480689,0,1,,,"File <*>/TutorialCIFAR10.py, line 36, in <module> dataiter = iter(trainloader)[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 451, in __iter__ return _DataLoaderIter(self)[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 239, in __init__ w.start()[SEP]File <*>/process.py, line 105, in start self._popen = self._Popen(self)[SEP]File <*>/context.py, line 223, in _Popen return _default_context.get_context().Process._Popen(process_obj)[SEP]File <*>/context.py, line 322, in _Popen return Popen(process_obj)[SEP]File <*>/popen_spawn_win32.py, line 65, in __init__ reduction.dump(process_obj, to_child)[SEP]File <*>/reduction.py, line 60, in dump ForkingPickler(file, protocol).dump(obj)[SEP]BrokenPipeError: [Errno 32] Broken pipe",,
329,50628954,0,1,,,"File test.py, line 7, in [FUNC] [CODE][SEP]TypeError: Parameter to MergeFrom() must be instance of same class: expected tensorflow.BytesList got tensorflow.Int64List.",,
330,50665144,0,1,,,"File <*>/label_map_util.py, line 135, in load_labelmap text_format.Merge(label_map_string, label_map)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 525, in Merge descriptor_pool=descriptor_pool)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 579, in MergeLines return parser.MergeLines(lines, message)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 612, in MergeLines self._ParseOrMerge(lines, message)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 627, in _ParseOrMerge self._MergeField(tokenizer, message)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 727, in _MergeField merger(tokenizer, message, field)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 815, in _MergeMessageField self._MergeField(tokenizer, sub_message)[SEP]File <*>python3.6/site-packages/google/protobuf/text_format.py, line 695, in _MergeField (message_descriptor.full_name, name))[SEP]google.protobuf.text_format.ParseError: 23:20 : Message type ""object_detection.protos.StringIntLabelMapItem"" has no field named ""s"".",,
331,50665144,0,1,,,"File train.py, line 184, in <module> tf.app.run()[SEP]File <*>python3.6/site-packages/tensorflow/python/platform/app.py, line 126, in run _sys.exit(main(argv))[SEP]File train.py, line 180, in main graph_hook_fn=graph_rewriter_fn)[SEP]File <*>/trainer.py, line 264, in train train_config.prefetch_queue_capacity, data_augmentation_options)[SEP]File <*>/trainer.py, line 59, in create_input_queue tensor_dict = create_tensor_dict_fn()[SEP]File train.py, line 121, in get_next dataset_builder.build(config)).get_next()[SEP]File <*>/dataset_builder.py, line 155, in build label_map_proto_file=label_map_proto_file)[SEP]File <*>/tf_example_decoder.py, line 245, in init use_display_name)[SEP]File <*>/label_map_util.py, line 152, in get_label_map_dict label_map = load_labelmap(label_map_path)[SEP]File <*>/label_map_util.py, line 137, in load_labelmap label_map.ParseFromString(label_map_string)[SEP]TypeError: a bytes-like object is required, not 'str'",,
332,50793797,0,1,,,"File <*>/site-packages/theano/gof/lazylinker_c.py, line 81, in <module> actual_version, force_compile, _need_reload))[SEP]ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True",,
333,50793797,0,1,,,"File <*>/site-packages/theano/gof/lazylinker_c.py, line 105, in <module> actual_version, force_compile, _need_reload))[SEP]ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True",,
334,50812838,0,1,,,"File <string>, line 1, in <module> [CODE][SEP]File <*>/setup.py, line 11, in <module> raise RuntimeError(README)[SEP]RuntimeError: PyTorch does not currently provide packages for PyPI (see status at https://github.com/pytorch/pytorch/issues/566).",,
335,51069945,0,1,,,"File <ipython-input-11-9a561e7b074b>, line 1, in <module> runfile('C:/Users/emile/Desktop/tensorflow.py', wdir='C:/Users/emile/Desktop')[SEP]File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 705, in runfile execfile(filename, namespace)[SEP]File <*>/site-packages/spyder/utils/site/sitecustomize.py, line 102, in execfile exec(compile(f.read(), filename, 'exec'), namespace)[SEP]File <*>/tensorflow.py, line 6, in <module> import tensorflow as tf[SEP]File <*>/tensorflow.py, line 7, in <module> import tensorflow.contrib.eager as tfe[SEP]ModuleNotFoundError: No module named 'tensorflow.contrib'; 'tensorflow' is not a package",,
336,51118565,0,1,,,"File <ipython-input-17-412a606c772f>, line 1, in <module> dataset = tf.data.Dataset.from_tensor_slices((one_hot_dataset))[SEP]File <*>python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 235, in from_tensor_slices return TensorSliceDataset(tensors)[SEP]File <*>python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1030, in __init__ for i, t in enumerate(nest.flatten(tensors))[SEP]File <*>python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1030, in <listcomp> for i, t in enumerate(nest.flatten(tensors))[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 1014, in convert_to_tensor as_ref=False)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/ops.py, line 1104, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/constant_op.py, line 235, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/constant_op.py, line 214, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>python3.5/site-packages/tensorflow/python/framework/tensor_util.py, line 496, in make_tensor_proto [CODE][SEP]""Cannot create a tensor proto whose content is larger than 2GB."") ValueError: Cannot create a tensor proto whose content is larger than 2GB.",,
337,51157258,0,1,,,"File seq2seq_train.py, line 5, in <module> from keras_text_summarization.library.utility.plot_utils import plot_and_save_history[SEP]ModuleNotFoundError: No module named 'keras_text_summarization'",,
338,51253644,0,1,,,"File model.py, line 91, in <module> model = Model(inputs=[x1, x2], outputs=[out])[SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 91, in __init__ self._init_graph_network(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 183, in _init_graph_network 'The tensor that caused the issue was: ' +[SEP]AttributeError: 'Model' object has no attribute 'name'",,
339,51299194,0,1,,,"File generate_tfrecord.py, line 17, in <module> import tensorflow as tf[SEP]File <*>/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 81, in <module> from tensorflow.python import keras[SEP]File <*>/site-packages/tensorflow/python/keras/__init__.py, line 24, in <module> from tensorflow.python.keras import activations[SEP]File <*>/site-packages/tensorflow/python/keras/activations/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.activations import elu[SEP]File <*>/site-packages/tensorflow/python/keras/_impl/keras/__init__.py, line 21, in <module> from tensorflow.python.keras._impl.keras import activations[SEP]File <*>/site-packages/tensorflow/python/keras/_impl/keras/activations.py, line 23, in <module> from tensorflow.python.keras._impl.keras import backend as K[SEP]File <*>/site-packages/tensorflow/python/keras/_impl/keras/backend.py, line 38, in <module> from tensorflow.python.layers import base as tf_base_layers[SEP]File <*>/site-packages/tensorflow/python/layers/base.py, line 25, in <module> from tensorflow.python.keras.engine import base_layer[SEP]File <*>/site-packages/tensorflow/python/keras/engine/__init__.py, line 21, in <module> from tensorflow.python.keras.engine.base_layer import InputSpec[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 33, in <module> from tensorflow.python.keras import backend[SEP]File <*>/site-packages/tensorflow/python/keras/backend/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.backend import abs[SEP]ImportError: cannot import name 'abs'",,
340,51348085,0,1,,,"File test.py, line 13, in <module> layers.Dense(64, activation='sigmoid')[SEP]NameError: name 'layers' is not defined",,
341,51491307,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.5/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>python3.5/site-packages/tensorflow/python/__init__.py, line 52, in <module> from tensorflow.core.framework.graph_pb2 import *[SEP]ImportError: No module named 'tensorflow.core'",,
342,51585095,0,1,,,"File <ipython-input-2-25b92e4d5dec>, line 2, in <module> hello = tf.constant('Hello, TensorFlow!')[SEP]AttributeError: module 'tensorflow' has no attribute 'constant'",,
343,51654346,0,1,,,"File model_builder_test.py, line 21, in <module> from object_detection.builders import model_builder[SEP]File <*>/model_builder.py, line 17, in <module> from object_detection.builders import anchor_generator_builder[SEP]File <*>/anchor_generator_builder.py, line 18, in <module> from object_detection.anchor_generators import grid_anchor_generator[SEP]File <*>/grid_anchor_generator.py, line 27, in <module> from object_detection.utils import ops[SEP]File <*>/ops.py, line 282, in <module> dtype=tf.float32):[SEP]AttributeError: module 'tensorflow' has no attribute 'float32'",,
344,51664192,0,1,,,"File train_v2.py, line 110, in <module> main()[SEP]File train_v2.py, line 81, in main model.update(batch)[SEP]File <*>/model.py, line 131, in update loss_adv = self.adversarial_loss(batch, loss, self.network.lexicon_encoder.embedding.weight, y)[SEP]File <*>/model.py, line 94, in adversarial_loss adv_embedding = torch.LongTensor(adv_embedding)[SEP]TypeError: expected torch.LongTensor (got torch.cuda.FloatTensor)",,
345,51691563,0,1,,,"File main.py, line 109, in <module> train(loader_train, model, criterion, optimizer)[SEP]File main.py, line 54, in train optimizer.step()[SEP]File <*>python3.6/site-packages/torch/optim/sgd.py, line 93, in step d_p.add_(weight_decay, p.data)[SEP]RuntimeError: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/THC/generated/../generic/THCTensorMathPointwise.cu:265",,
346,51818225,0,1,,,"File deparser.py, line 402, in <module> d.train()[SEP]File deparser.py, line 331, in train total, correct, avgloss = self.train_util()[SEP]File deparser.py, line 362, in train_util loss = self.step(X_train, Y_train, correct, total)[SEP]File deparser.py, line 214, in step loss = nn.CrossEntropyLoss()(out.long(), y)[SEP]File <*>python3.5/site-packages/torch/nn/modules/module.py, line 477, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>python3.5/site-packages/torch/nn/modules/loss.py, line 862, in forward ignore_index=self.ignore_index, reduction=self.reduction)[SEP]File <*>python3.5/site-packages/torch/nn/functional.py, line 1550, in cross_entropy return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)[SEP]File <*>python3.5/site-packages/torch/nn/functional.py, line 975, in log_softmax return input.log_softmax(dim)[SEP]RuntimeError: ""host_softmax"" not implemented for 'torch.cuda.LongTensor'",,
347,51858067,0,1,,,"File pytorch.py, line 14, in <module> test_tensor = torch.tensor(test)[SEP]ValueError: could not determine the shape of object type 'DataFrame'",,
348,51881295,0,1,,,"File [FILE], line <*>, in [FUNC] [CODE][SEP]File <*>/setup.py, line 108, in [FUNC] [CODE][SEP]ImportError: No module named tools.setup_helpers.env",,
349,52026652,0,1,,,"File hello-world.py, line 1, in <module> from keras.models import Sequential[SEP]File <*>python3.6/site-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>python3.6/site-packages/keras/utils/__init__.py, line 2, in <module> from . import np_utils[SEP]File <*>python3.6/site-packages/keras/utils/np_utils.py, line 6, in <module> import numpy as np[SEP]File <*>python3.6/site-packages/numpy/__init__.py, line 142, in <module> from . import add_newdocs[SEP]File <*>python3.6/site-packages/numpy/add_newdocs.py, line 13, in <module> from numpy.lib import add_newdoc[SEP]File <*>python3.6/site-packages/numpy/lib/__init__.py, line 8, in <module> from .type_check import *[SEP]File <*>python3.6/site-packages/numpy/lib/type_check.py, line 11, in <module> import numpy.core.numeric as _nx[SEP]File <*>python3.6/site-packages/numpy/core/__init__.py, line 16, in <module> from . import multiarray[SEP]SystemError: initialization of multiarray raised unreported exception",,
350,52303130,0,1,,,"File <ipython-input-7-2ef5e6514df7>, line 33, in data_generator [CODE][SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1530, in __exit__ self._default_graph_context_manager.__exit__(exec_type, exec_value, exec_tb)[SEP]File <*>python3.6/contextlib.py, line 99, in __exit__ self.gen.throw(type, value, traceback)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 5025, in get_controller context.context().context_switches.pop()[SEP]File <*>python3.6/dist-packages/tensorflow/python/eager/context.py, line 136, in pop self.stack.pop()[SEP]IndexError: pop from empty list",,
351,52317407,0,1,,,"File <*>/predict.py, line 74, in <module> print(get_grad(x_cloned, x))[SEP]File <*>/predict.py, line 68, in get_grad A.backward()[SEP]File <*>python3.5/site-packages/torch/tensor.py, line 93, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>python3.5/site-packages/torch/autograd/__init__.py, line 90, in backward allow_unreachable=True) # allow_unreachable flag[SEP]RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn",,
352,52317407,0,1,,,"File <*>/playground.py, line 22, in <module> print(get_grad(x_cloned, x))[SEP]File <*>/playground.py, line 16, in get_grad A.backward()[SEP]File <*>python3.5/site-packages/torch/tensor.py, line 93, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>python3.5/site-packages/torch/autograd/__init__.py, line 84, in backward grad_tensors = _make_grads(tensors, grad_tensors)[SEP]File <*>python3.5/site-packages/torch/autograd/__init__.py, line 28, in _make_grads raise RuntimeError(""grad can be implicitly created only for scalar outputs"")[SEP]RuntimeError: grad can be implicitly created only for scalar outputs",,
353,52346254,0,1,,,"File <*>/all_good.py, line 15, in <module> import matplotlib.pyplot as plt[SEP]File <*>/site-packages/matplotlib/pyplot.py, line 115, in <module> _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()[SEP]File <*>/site-packages/matplotlib/backends/__init__.py, line 62, in pylab_setup [backend_name], 0)[SEP]File <*>/site-packages/matplotlib/backends/backend_qt5agg.py, line 15, in <module> from .backend_qt5 import ([SEP]File <*>/site-packages/matplotlib/backends/backend_qt5.py, line 19, in <module> import matplotlib.backends.qt_editor.figureoptions as figureoptions[SEP]File <*>/site-packages/matplotlib/backends/qt_editor/figureoptions.py, line 20, in <module> import matplotlib.backends.qt_editor.formlayout as formlayout[SEP]File <*>/site-packages/matplotlib/backends/qt_editor/formlayout.py, line 54, in <module> from matplotlib.backends.qt_compat import QtGui, QtWidgets, QtCore[SEP]File <*>/site-packages/matplotlib/backends/qt_compat.py, line 158, in <module> raise ImportError(""Failed to import any qt binding"")[SEP]ImportError: Failed to import any qt binding",,
354,52358784,0,1,,,"File <string>, line 1, in <module> [CODE][SEP]ImportError: No module named numpy",,
355,52365491,0,1,,,"File <*>/testing.py, line 10, in <module> model = Model(inputs=model_in, outputs=output)[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/engine/network.py, line 93, in __init__ self._init_graph_network(*args, **kwargs)[SEP]File <*>/site-packages/keras/engine/network.py, line 237, in _init_graph_network self.inputs, self.outputs)[SEP]File <*>/site-packages/keras/engine/network.py, line 1353, in _map_graph_network tensor_index=tensor_index)[SEP]File <*>/site-packages/keras/engine/network.py, line 1340, in build_map node_index, tensor_index)[SEP]File <*>/site-packages/keras/engine/network.py, line 1312, in build_map node = layer._inbound_nodes[node_index][SEP]AttributeError: 'NoneType' object has no attribute '_inbound_nodes'",,
356,52388831,0,1,,,"File lstm_test.py, line 152, in <module> model.fit(samples_train, labels_train, epochs=1, batch_size=1)[SEP]File <*>/site-packages/keras/models.py, line 1002, in fit validation_steps=validation_steps)[SEP]File <*>/site-packages/keras/engine/training.py, line 1630, in fit batch_size=batch_size)[SEP]File <*>/site-packages/keras/engine/training.py, line 1476, in _standardize_user_data exception_prefix='input')[SEP]File <*>/site-packages/keras/engine/training.py, line 113, in _standardize_input_data 'with shape ' + str(data_shape))[SEP]ValueError: Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (134, 1)",,
357,52490951,0,1,,,"File run.py, line 64, in <module> model.fit(images, labels, epochs=1, steps_per_epoch=2)[SEP]File <*>python2.7/site-packages/tensorflow/python/keras/engine/training.py, line 1363, in fit validation_steps=validation_steps)[SEP]File <*>python2.7/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 205, in fit_loop outs = f(ins)[SEP]File <*>python2.7/site-packages/tensorflow/python/keras/backend.py, line 2914, in __call__ fetched = self._callable_fn(*array_vals)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.py, line 1382, in __call__ run_metadata_ptr)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/errors_impl.py, line 519, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Matrix size-incompatible: In[0]: [10000,1], In[1]: [3,1] [[Node: rgb_to_grayscale/Tensordot/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](rgb_to_grayscale/Tensordot/Reshape, rgb_to_grayscale/Tensordot/Reshape_1)]] [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,100,100,1], [?,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](OneShotIterator)]]",,
358,52582563,0,1,,,"File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2869, in _dep_map return self.__dep_map[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2663, in __getattr__ raise AttributeError(attr)[SEP]AttributeError: _DistInfoDistribution__dep_map",,
359,52582563,0,1,,,"File <*>python3.6/site-packages/pip/_vendor/packaging/requirements.py, line 93, in __init__ req = REQUIREMENT.parseString(requirement_string)[SEP]File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 1632, in parseString raise exc[SEP]File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 1622, in parseString loc, tokens = self._parse( instring, 0 )[SEP]File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 1379, in _parseNoCache loc,tokens = self.parseImpl( instring, preloc, doActions )[SEP]File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 3395, in parseImpl loc, exprtokens = e._parse( instring, loc, doActions )[SEP]File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 1383, in _parseNoCache loc,tokens = self.parseImpl( instring, preloc, doActions )[SEP]File <*>python3.6/site-packages/pip/_vendor/pyparsing.py, line 3183, in parseImpl raise ParseException(instring, loc, self.errmsg, self)[SEP]pip._vendor.pyparsing.ParseException: Expected stringEnd (at char 33), (line:1, col:34)",,
361,52582563,0,1,,,"File <*>python3.6/site-packages/pip/_internal/basecommand.py, line 141, in main status = self.run(options, args)[SEP]File <*>python3.6/site-packages/pip/_internal/commands/install.py, line 330, in run self._warn_about_conflicts(to_install)[SEP]File <*>python3.6/site-packages/pip/_internal/commands/install.py, line 456, in _warn_about_conflicts package_set, _dep_info = check_install_conflicts(to_install)[SEP]File <*>python3.6/site-packages/pip/_internal/operations/check.py, line 98, in check_install_conflicts package_set = create_package_set_from_installed()[SEP]File <*>python3.6/site-packages/pip/_internal/operations/check.py, line 41, in create_package_set_from_installed package_set[name] = PackageDetails(dist.version, dist.requires())[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2607, in requires dm = self._dep_map[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2871, in _dep_map self.__dep_map = self._compute_dependencies()[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2881, in _compute_dependencies reqs.extend(parse_requirements(req))[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2942, in parse_requirements yield Requirement(line)[SEP]File <*>python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py, line 2951, in __init__ raise RequirementParseError(str(e))[SEP]pip._vendor.pkg_resources.RequirementParseError: Invalid requirement, parse error at ""'; extra '""",,
362,52661518,0,1,,,"File noveou_train_netvlad.py, line 226, in <module> minu = keras.layers.Maximum()( [ minu, K.zeros(nN, nP) ] )[SEP]File <*>python2.7/dist-packages/keras/engine/base_layer.py, line 457, in __call__ output = self.call(inputs, **kwargs)[SEP]File <*>python2.7/dist-packages/keras/layers/merge.py, line 115, in call return self._merge_function(reshaped_inputs)[SEP]File <*>python2.7/dist-packages/keras/layers/merge.py, line 301, in _merge_function output = K.maximum(output, inputs[i])[SEP]File <*>python2.7/dist-packages/keras/backend/tensorflow_backend.py, line 1672, in maximum return tf.maximum(x, y)[SEP]File <*>python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 4707, in maximum ""Maximum"", x=x, y=y, name=name)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/op_def_library.py, line 546, in _apply_op_helper inferred_from[input_arg.type_attr]))[SEP]TypeError: Input 'y' of 'Maximum' Op has type string that does not match type float32 of argument 'x'.",,
363,52920222,0,1,,,"File <string>, line 1, in <module> [CODE][SEP]File <*>/setup.py, line 25, in <module> cythonize(ext_modules)[SEP]File <*>/site-packages/Cython/Build/Dependencies.py, line 956, in cythonize aliases=aliases)[SEP]File <*>/site-packages/Cython/Build/Dependencies.py, line 801, in create_extension_list for file in nonempty(sorted(extended_iglob(filepattern)), ""'%s' doesn't match any files"" % filepattern):[SEP]File <*>/site-packages/Cython/Build/Dependencies.py, line 111, in nonempty raise ValueError(error_msg)[SEP]ValueError: 'pycocotools/_mask.pyx' doesn't match any files",,
364,53032586,0,1,,,"File <*>/QuestionStackoverflow.py, line 26, in <module> q_vals_v = net(state_v.view(1, state_v.shape[0], state_v.shape[1]))[SEP]File <*>python3.5/site-packages/torch/nn/modules/module.py, line 477, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>/QuestionStackoverflow.py, line 15, in forward out = self.hidden2tag(out)[SEP]File <*>python3.5/site-packages/torch/nn/modules/, line 55, in forward return F.linear(input, self.weight, self.bias)[SEP]File <*>python3.5/site-packages/torch/nn/functional.py, line 1022, in linear if input.dim() == 2 and bias is not None:[SEP]AttributeError: 'tuple' object has no attribute 'dim'",,
365,53201921,0,1,,,"File <*>/tensor01.py, line 4, in <module> x = torch.Tensor([[.5, .3, 2.1]], requires_grad=False)[SEP]TypeError: new() received an invalid combination of arguments - got (list, requires_grad=bool), but expected one of: * (torch.device device) * (torch.Storage storage) * (Tensor other) * (tuple of ints size, torch.device device) didn't match because some of the keywords were incorrect: requires_grad * (object data, torch.device device) didn't match because some of the keywords were incorrect: requires_grad",,
366,53217596,0,1,,,"File convolutional_network_raw.py, line 137, in <module> writer.add_summary(summary=summary, global_step=step)[SEP]File <*>python3.6/site-packages/tensorflow/python/summary/writer/writer.py, line 126, in add_summary for value in summary.value:[SEP]AttributeError: 'numpy.float32' object has no attribute 'value'",,
367,53259434,0,1,,,"File binary_classification.py, line 59, in <module> history=model.fit(X, y,batch_size=10, epochs=25,validation_split=0.7)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1039, in fit validation_steps=validation_steps)[SEP]File <*>python3.6/site-packages/keras/engine/training_arrays.py, line 217, in fit_loop callbacks.on_epoch_end(epoch, epoch_logs)[SEP]File <*>python3.6/site-packages/keras/callbacks.py, line 79, in on_epoch_end callback.on_epoch_end(epoch, logs)[SEP]File <*>python3.6/site-packages/keras/callbacks.py, line 338, in on_epoch_end self.progbar.update(self.seen, self.log_values)[SEP]AttributeError: 'ProgbarLogger' object has no attribute 'log_values'",,
368,53277465,0,1,,,"File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 712, in __del__ [CODE][SEP]File <*>python3.5/site-packages/tensorflow/python/framework/c_api_util.py, line 31, in __init__ [CODE][SEP]TypeError: 'NoneType' object is not callable",,
369,53416833,0,1,,,"File test_loocv.py, line 245, in <module> output = model_ft(test_data)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 477, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/resnet.py, line 139, in forward [CODE][SEP]File <*>python3.6/site-packages/torch/nn/modules/conv.py, line 301, in forward self.padding, self.dilation, self.groups)[SEP]RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[3, 1, 224, 224] to have 3 channels, but got 1 channels instead",,
370,53421999,0,1,,,"File <*>/lesson4-imdb2.py, line 27, in <module> pickle.dump(md, file)[SEP]TypeError: 'generator' object is not callable",,
371,53496948,0,1,,,"File app.py, line 16, in <module> from modules.xvision import Xvision[SEP]File <*>/xvision.py, line 84, in <module> tf.import_graph_def(net['graph_def'], name='vgg')[SEP]TypeError: 'Model' object has no attribute '__getitem__'",,
372,53626504,0,1,,,"File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 204, in _convert_pb_to_mlmodel shape_list = shape.as_list()[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/tensor_shape.py, line 900, in as_list raise ValueError(""as_list() is not defined on an unknown TensorShape."")[SEP]ValueError: as_list() is not defined on an unknown TensorShape.",,
373,53626504,0,1,,,"File model.py, line 6, in <module> class_labels = 'conv_labels.txt'[SEP]File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 586, in convert custom_conversion_functions=custom_conversion_functions)[SEP]File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 206, in _convert_pb_to_mlmodel raise ValueError('Please provide the shape for the input {} through the argument \'input_name_shape_dict\''.format(input_name))[SEP]ValueError: Please provide the shape for the input wav_data:0 through the argument 'input_name_shape_dict'",,
374,53626504,0,1,,,"File model.py, line 7, in <module> class_labels = 'conv_labels.txt'[SEP]File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 586, in convert custom_conversion_functions=custom_conversion_functions)[SEP]File <*>python3.6/site-packages/tfcoreml/_tf_coreml_converter.py, line 153, in _convert_pb_to_mlmodel tf.import_graph_def(gdef, name='')[SEP]File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 316, in new_func return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/importer.py, line 541, in import_graph_def raise ValueError('No op named %s in defined operations.' % node.op)[SEP]ValueError: No op named DecodeWav in defined operations.",,
375,53697858,0,1,,,"File <*>/tst1.py, line 110, in <module> classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)[SEP]File <*>/site-packages/keras/engine/training.py, line 950, in fit batch_size=batch_size)[SEP]File <*>/site-packages/keras/engine/training.py, line 787, in _standardize_user_data exception_prefix='target')[SEP]File <*>/site-packages/keras/engine/training_utils.py, line 137, in standardize_input_data str(data_shape))[SEP]ValueError: Error when checking target: expected dense_3 to have shape (1,) but got array with shape (6,)",,
376,53763021,0,1,,,"File <*>/site-packages/keras/engine/topology.py, line 442, in assert_input_compatibility K.is_keras_tensor(x)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 468, in is_keras_tensor raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '[SEP]ValueError: Unexpectedly found an instance of type `<class 'keras.layers.core.Masking'>`. Expected a symbolic tensor instance.",,
377,53763021,0,1,,,"File <*>/testcompile.py, line 46, in <module> model = network_structure(32, 44, 125)[SEP]File <*>/testcompile.py, line 12, in network_structure lstm_h1 = keras.layers.LSTM(lstm_neurons)(masking)[SEP]File <*>/site-packages/keras/layers/recurrent.py, line 499, in __call__ return super(RNN, self).__call__(inputs, **kwargs)[SEP]File <*>/site-packages/keras/engine/topology.py, line 575, in __call__ self.assert_input_compatibility(inputs)[SEP]File <*>/site-packages/keras/engine/topology.py, line 448, in assert_input_compatibility str(inputs) + '. All inputs to the layer '[SEP]ValueError: Layer lstm_1 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.core.Masking'>. Full input: [<keras.layers.core.Masking object at 0x000002224683A780>]. All inputs to the layer should be tensors.",,
378,53844629,0,1,,,"File <*>/auto_LSTM_try3.py, line 398, in <module> run_experiments(config, search_alg=algo, scheduler=hyperband)[SEP]File <*>python3.6/site-packages/ray/tune/tune.py, line 108, in run_experiments runner.step()[SEP]File <*>python3.6/site-packages/ray/tune/trial_runner.py, line 114, in step next_trial = self._get_next_trial()[SEP]File <*>python3.6/site-packages/ray/tune/trial_runner.py, line 254, in _get_next_trial self._update_trial_queue(blocking=wait_for_trial)[SEP]File <*>python3.6/site-packages/ray/tune/trial_runner.py, line 330, in _update_trial_queue trials = self._search_alg.next_trials()[SEP]File <*>python3.6/site-packages/ray/tune/suggest/suggestion.py, line 67, in next_trials for trial in self._trial_generator:[SEP]File <*>python3.6/site-packages/ray/tune/suggest/suggestion.py, line 88, in _generate_trials suggested_config = self._suggest(trial_id)[SEP]File <*>python3.6/site-packages/ray/tune/suggest/hyperopt.py, line 81, in _suggest self.rstate.randint(2**31 - 1))[SEP]File <*>python3.6/site-packages/hyperopt/tpe.py, line 835, in suggest = tpe_transform(domain, prior_weight, gamma)[SEP]File <*>python3.6/site-packages/hyperopt/tpe.py, line 816, in tpe_transform s_prior_weight[SEP]File <*>python3.6/site-packages/hyperopt/tpe.py, line 690, in build_posterior b_post = fn(*b_args, **dict(named_args))[SEP]TypeError: ap_uniform_sampler() missing 1 required positional argument: 'high'",,
379,53869616,0,1,,,"File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 3078, in get_loc return self._engine.get_loc(key)[SEP]File <*>/index.pyx, line 140, in pandas._libs.index.IndexEngine.get_loc [CODE][SEP]File <*>/index.pyx, line 162, in pandas._libs.index.IndexEngine.get_loc [CODE][SEP]File <*>/hashtable_class_helper.pxi, line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE][SEP]File <*>/hashtable_class_helper.pxi, line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE][SEP]KeyError: range(418, 419)",,
380,53869616,0,1,,,"File <*>/main.py, line 94, in <module> data_menu()[SEP]File <*>/main.py, line 42, in data_menu data_menu()[SEP]File <*>/main.py, line 56, in data_menu nn_menu()[SEP]File <*>/main.py, line 76, in nn_menu nn.nn_gen(pre_processed_data)[SEP]File <*>/nn.py, line 33, in nn_gen x, y = train[0][SEP]File <*>python3.6/site-packages/keras_preprocessing/sequence.py, line 378, in __getitem__ samples[j] = self.data[indices][SEP]File <*>python3.6/site-packages/pandas/core/frame.py, line 2688, in __getitem__ return self._getitem_column(key)[SEP]File <*>python3.6/site-packages/pandas/core/frame.py, line 2695, in _getitem_column return self._get_item_cache(key)[SEP]File <*>python3.6/site-packages/pandas/core/generic.py, line 2489, in _get_item_cache values = self._data.get(item)[SEP]File <*>python3.6/site-packages/pandas/core/internals.py, line 4115, in get loc = self.items.get_loc(item)[SEP]File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 3080, in get_loc return self._engine.get_loc(self._maybe_cast_indexer(key))[SEP]File <*>/index.pyx, line 140, in pandas._libs.index.IndexEngine.get_loc [CODE][SEP]File <*>/index.pyx, line 162, in pandas._libs.index.IndexEngine.get_loc [CODE][SEP]File <*>/hashtable_class_helper.pxi, line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE][SEP]File <*>/hashtable_class_helper.pxi, line 1500, in pandas._libs.hashtable.PyObjectHashTable.get_item [CODE][SEP]KeyError: range(418, 419)",,
381,53874115,0,1,,,"File <*>/site-packages/flask/app.py, line 1813, in full_dispatch_request rv = self.dispatch_request()[SEP]File <*>/site-packages/flask/app.py, line 1799, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args)[SEP]File <*>/site-packages/flask_restful/__init__.py, line 458, in wrapper resp = resource(*args, **kwargs)[SEP]File <*>/site-packages/flask/views.py, line 88, in view return self.dispatch_request(*args, **kwargs)[SEP]File <*>/site-packages/flask_restful/__init__.py, line 573, in dispatch_request resp = meth(*args, **kwargs)[SEP]File app.py, line 41, in get print(ann.predict(x_test))[SEP]File <*>/site-packages/keras/engine/training.py, line 1164, in predict self._make_predict_function()[SEP]File <*>/site-packages/keras/engine/training.py, line 554, in _make_predict_function **kwargs)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2744, in function return Function(inputs, outputs, updates=updates, **kwargs)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2546, in __init__ with tf.control_dependencies(self.outputs):[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 5004, in control_dependencies return get_default_graph().control_dependencies(control_inputs)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 4543, in control_dependencies c = self.as_graph_element(c)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 3490, in as_graph_element return self._as_graph_element_locked(obj, allow_tensor, allow_operation)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 3569, in _as_graph_element_locked raise ValueError(""Tensor %s is not an element of this graph."" % obj)[SEP]ValueError: Tensor Tensor(""dense_3/Sigmoid:0"", shape=(?, 1), dtype=float32) is not an element of this graph.",,
382,53879727,0,1,,,"File <ipython-input-286-e49b6fac918b>, line 1, in <module> output=model(input_)[SEP]File <*>/site-packages/torch/nn/modules/module.py, line 489, in __call__ result = self.forward(*input, **kwargs)[SEP]TypeError: forward() missing 1 required positional argument: 'p'",,
383,53916594,0,1,,,"File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 138, in _worker_loop samples = collate_fn([dataset[i] for i in batch_indices])[SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 138, in <listcomp> samples = collate_fn([dataset[i] for i in batch_indices])[SEP]File <*>python3.6/site-packages/torch/utils/data/dataset.py, line 103, in __getitem__ return self.dataset[self.indices[idx]][SEP]File <ipython-input-27-107e03bc3c6a>, line 12, in __getitem__ x = torch.tensor(self.x_data.iloc[index].values, dtype=torch.float)[SEP]File <*>python3.6/site-packages/pandas/core/indexing.py, line 1478, in __getitem__ return self._getitem_axis(maybe_callable, axis=axis)[SEP]File <*>python3.6/site-packages/pandas/core/indexing.py, line 2091, in _getitem_axis return self._get_list_axis(key, axis=axis)[SEP]File <*>python3.6/site-packages/pandas/core/indexing.py, line 2070, in _get_list_axis return self.obj._take(key, axis=axis)[SEP]File <*>python3.6/site-packages/pandas/core/generic.py, line 2789, in _take verify=True)[SEP]File <*>python3.6/site-packages/pandas/core/internals.py, line 4537, in take new_labels = self.axes[axis].take(indexer)[SEP]File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 2195, in take return self._shallow_copy(taken)[SEP]File <*>python3.6/site-packages/pandas/core/indexes/range.py, line 267, in _shallow_copy return self._int64index._shallow_copy(values, **kwargs)[SEP]File <*>python3.6/site-packages/pandas/core/indexes/numeric.py, line 68, in _shallow_copy return self._shallow_copy_with_infer(values=values, **kwargs)[SEP]File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 538, in _shallow_copy_with_infer if not len(values) and 'dtype' not in kwargs:[SEP]TypeError: object of type 'numpy.int64' has no len()",,
384,53966020,0,1,,,"File <*>/tensorboard-script.py, line 6, in <module> from tensorboard.main import run_main[SEP]File <*>/site-packages/tensorboard/main.py, line 40, in <module> from tensorboard import default[SEP]File <*>/site-packages/tensorboard/default.py, line 38, in <module> from tensorboard.plugins.beholder import beholder_plugin[SEP]File <*>/site-packages/tensorboard/plugins/beholder/__init__.py, line 15, in <module> from tensorboard.plugins.beholder.beholder import Beholder[SEP]File <*>/site-packages/tensorboard/plugins/beholder/beholder.py, line 25, in <module> from tensorboard.plugins.beholder import im_util[SEP]File <*>/site-packages/tensorboard/plugins/beholder/im_util.py, line 89, in <module> class PNGDecoder(util.PersistentOpEvaluator):[SEP]AttributeError: module 'tensorboard.util' has no attribute 'PersistentOpEvaluator'",,
385,53993348,0,1,,,"File test.py, line 4, in <module> model = load_model(""test.h5"")[SEP]File <*>python3.7/site-packages/keras/engine/saving.py, line 419, in load_model model = _deserialize_model(f, custom_objects, compile)[SEP]File <*>python3.7/site-packages/keras/engine/saving.py, line 258, in _deserialize_model .format(len(layer_names), len(filtered_layers))[SEP]ValueError: You are trying to load a weight file containing 6 layers into a model with 0 layers",,
386,53993348,0,1,,,"File test.py, line 7, in <module> print(model.summary())[SEP]AttributeError: 'NoneType' object has no attribute 'summary'",,
387,54200850,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.5/site-packages/tensorflow/__init__.py, line 24, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>python3.5/site-packages/tensorflow/python/__init__.py, line 47, in <module> import numpy as np[SEP]File <*>python3.5/site-packages/numpy/__init__.py, line 142, in <module> from . import core[SEP]File <*>python3.5/site-packages/numpy/core/__init__.py, line 57, in <module> from . import numerictypes as nt[SEP]File <*>python3.5/site-packages/numpy/core/numerictypes.py, line 111, in <module> from ._type_aliases import ([SEP]File <*>python3.5/site-packages/numpy/core/_type_aliases.py, line 63, in <module> _concrete_types = {v.type for k, v in _concrete_typeinfo.items()}[SEP]File <*>python3.5/site-packages/numpy/core/_type_aliases.py, line 63, in <setcomp> _concrete_types = {v.type for k, v in _concrete_typeinfo.items()}[SEP]AttributeError: 'tuple' object has no attribute 'type'",,
388,54478702,0,1,,,"File <*>/SVM_Stock.py, line 71, in <module> estimator.fit(x,y)[SEP]File <*>/site-packages/keras/wrappers/scikit_learn.py, line 210, in fit return super(KerasClassifier, self).fit(x, y, **kwargs)[SEP]File <*>/site-packages/keras/wrappers/scikit_learn.py, line 139, in fit **self.filter_sk_params(self.build_fn.__call__))[SEP]TypeError: __call__() missing 1 required positional argument: 'inputs'",,
389,54590826,0,1,,,"File test.py, line 141, in <module> max_queue_size=2)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 2177, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 147, in fit_generator generator_output = next(output_generator)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py, line 831, in get six.reraise(value.__class__, value, value.__traceback__)[SEP]File <*>python3.6/site-packages/six.py, line 693, in reraise raise value[SEP]TypeError: 'My_Generator' object is not an iterator",,
390,54603645,0,1,,,"File 6_reconstruct_alphabet_image.py, line 17, in <module> import caffe[SEP]File <*>python3/dist-packages/caffe/__init__.py, line 1, in <module> from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer[SEP]File <*>python3/dist-packages/caffe/pycaffe.py, line 15, in <module> import caffe.io[SEP]File <*>python3/dist-packages/caffe/io.py, line 2, in <module> import skimage.io[SEP]File <*>python3/dist-packages/skimage/__init__.py, line 158, in <module> from .util.dtype import *[SEP]File <*>python3/dist-packages/skimage/util/__init__.py, line 7, in <module> from .arraycrop import crop[SEP]File <*>python3/dist-packages/skimage/util/arraycrop.py, line 8, in <module> from numpy.lib.arraypad import _validate_lengths[SEP]ImportError: cannot import name '_validate_lengths'",,
391,54721703,0,1,,,"File <frozen importlib._bootstrap>, line 980, in _find_and_load [CODE][SEP]SystemError: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set ImportError: numpy.core._multiarray_umath failed to import ImportError: numpy.core.umath failed to import",,
392,54884984,0,1,,,"File [FILE], line <*>, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow_<em>init</em>_.py, line 24, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow/python_<em>init</em>_.py, line 59, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in [FUNC] [CODE][SEP]File <*>/site-packages/google/protobuf/descriptor.py, line 47, in [FUNC] [CODE][SEP]ImportError: DLL load failed: The specified procedure could not be found.",,
393,54928638,0,1,,,"File <*>/WorkOut.py, line 416, in <module> main()[SEP]File <*>/WorkOut.py, line 412, in main train(args, model, device, train_loader, optimizer, epoch)[SEP]File <*>/WorkOut.py, line 324, in train loss = F.nll_loss(output, target)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1788, in nll_loss .format(input.size(0), target.size(0)))[SEP]ValueError: Expected input batch_size (4) to match target batch_size (64).",,
394,54953856,0,1,,,"File <frozen importlib._bootstrap>, line 968, in _find_and_load [CODE][SEP]SystemError: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set ImportError: numpy.core._multiarray_umath failed to import ImportError: numpy.core.umath failed to import",,
395,54967216,0,1,,,"File <*>python3.6/site-packages/theano/compile/function_module.py, line 884, in __call__ self.fn() if output_subset is None else\[SEP]ValueError: Input dimension mis-match. (input[0].shape[1] = 50, input[1].shape[1] = 100)",,
396,54967216,0,1,,,"File <*>/textClassfierHATT2D.py, line 187, in <module> nb_epoch=10, batch_size=50,verbose=2)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1631, in fit validation_steps=validation_steps)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1213, in _fit_loop outs = f(ins_batch)[SEP]File <*>python3.6/site-packages/keras/backend/theano_backend.py, line 1223, in __call__ return self.function(*inputs)[SEP]File <*>python3.6/site-packages/theano/compile/function_module.py, line 898, in __call__ storage_map=getattr(self.fn, 'storage_map', None))[SEP]File <*>python3.6/site-packages/theano/gof/link.py, line 325, in raise_with_op reraise(exc_type, exc_value, exc_trace)[SEP]File <*>python3.6/site-packages/six.py, line 692, in reraise raise value.with_traceback(tb)[SEP]File <*>python3.6/site-packages/theano/compile/function_module.py, line 884, in __call__ self.fn() if output_subset is None else\[SEP]ValueError: Input dimension mis-match. (input[0].shape[1] = 50, input[1].shape[1] = 100)",,
397,55193860,0,1,,,"File <*>/pydevd.py, line 1741, in <module> main()[SEP]File <*>/pydevd.py, line 1735, in main globals = debugger.run(setup['file'], None, None, is_module)[SEP]File <*>/pydevd.py, line 1135, in run pydev_imports.execfile(file, globals, locals) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/MnistTrainer.py, line 100, in <module> main()[SEP]File <*>/MnistTrainer.py, line 92, in main mnist_trainer.train(train_steps=100, log_interval=1, save_interval=1)[SEP]File <*>/MnistTrainer.py, line 56, in train self.save_models(output_folder_path, i + 1)[SEP]File <*>/MnistTrainer.py, line 69, in save_models os.path.join(output_folder_path, 'discriminator_model_{0}.h5'.format(iteration_no)))[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 1090, in save save_model(self, filepath, overwrite, include_optimizer)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 382, in save_model _serialize_model(model, f, include_optimizer)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 83, in _serialize_model model_config['config'] = model.get_config()[SEP]File <*>python3.6/site-packages/keras/engine/sequential.py, line 278, in get_config 'config': layer.get_config()[SEP]File <*>python3.6/site-packages/keras/layers/convolutional.py, line 493, in get_config config = super(Conv2D, self).get_config()[SEP]File <*>python3.6/site-packages/keras/layers/convolutional.py, line 226, in get_config 'activation': activations.serialize(self.activation),[SEP]File <*>python3.6/site-packages/keras/activations.py, line 176, in serialize return activation.__name__[SEP]AttributeError: 'LeakyReLU' object has no attribute '__name__'",,
398,55280201,0,1,,,"File <*>/train.py, line 107, in <module> callbacks=[Saver(save_every), Evaluation(evaluate_every)])[SEP]File <*>/site-packages/keras/engine/training.py, line 1039, in fit validation_steps=validation_steps)[SEP]File <*>/site-packages/keras/engine/training_arrays.py, line 204, in fit_loop callbacks.on_batch_end(batch_index, batch_logs)[SEP]File <*>/site-packages/keras/callbacks.py, line 115, in on_batch_end callback.on_batch_end(batch, logs)[SEP]File <*>/train.py, line 83, in on_batch_end self.model.save(name)[SEP]File <*>/site-packages/keras/engine/network.py, line 1090, in save save_model(self, filepath, overwrite, include_optimizer)[SEP]File <*>/site-packages/keras/engine/saving.py, line 382, in save_model _serialize_model(model, f, include_optimizer)[SEP]File <*>/site-packages/keras/engine/saving.py, line 83, in _serialize_model model_config['config'] = model.get_config()[SEP]File <*>/site-packages/keras/engine/network.py, line 931, in get_config return copy.deepcopy(config)[SEP]File <*>/copy.py, line 150, in deepcopy y = copier(x, memo)[SEP]File <*>/copy.py, line 240, in _deepcopy_dict y[deepcopy(key, memo)] = deepcopy(value, memo)[SEP]File <*>/copy.py, line 215, in _deepcopy_list append(deepcopy(a, memo))[SEP]File <*>/copy.py, line 220, in _deepcopy_tuple y = [deepcopy(a, memo) for a in x][SEP]File <*>/copy.py, line 220, in <listcomp> y = [deepcopy(a, memo) for a in x][SEP]File <*>/copy.py, line 180, in deepcopy y = _reconstruct(x, memo, *rv)[SEP]File <*>/copy.py, line 280, in _reconstruct state = deepcopy(state, memo)[SEP]File <*>/copy.py, line 169, in deepcopy rv = reductor(4)[SEP]TypeError: can't pickle _thread.RLock objects",,
399,55307368,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]RuntimeError: Could not infer dtype of generator",,
400,55375416,0,1,,,"File <*>/min_working_example.py, line 37, in <module> model.fit(data_generator)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 880, in fit validation_steps=validation_steps)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 310, in model_iteration ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]][SEP]File <*>python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 526, in slice_arrays return [None if x is None else x[start] for x in arrays][SEP]File <*>python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 526, in <listcomp> return [None if x is None else x[start] for x in arrays][SEP]File <*>python3.6/site-packages/tensorflow/python/ops/array_ops.py, line 654, in _slice_helper name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/array_ops.py, line 820, in strided_slice shrink_axis_mask=shrink_axis_mask)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py, line 9334, in strided_slice _six.raise_from(_core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Attr shrink_axis_mask has value 4294967295 out of range for an int32 [Op:StridedSlice] name: strided_slice/",,
401,55375416,0,1,,,"File <*>/min_working_example.py, line 37, in <module> model.fit(data_generator)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 873, in fit steps_name='steps_per_epoch')[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 352, in model_iteration batch_outs = f(ins_batch)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/backend.py, line 3217, in __call__ outputs = self._graph_fn(*converted_inputs)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 558, in __call__ return self._call_flat(args)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 627, in _call_flat outputs = self._inference_function.call(ctx, args)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 397, in call (len(args), len(list(self.signature.input_arg))))[SEP]ValueError: Arguments and signature arguments do not match: 21 23",,
402,55375416,0,1,,,"File <*>/min_working_example.py, line 37, in <module> model.fit_generator(data_generator)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1426, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 115, in model_iteration shuffle=shuffle)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 377, in convert_to_generator_like num_samples = int(nest.flatten(data)[0].shape[0])[SEP]TypeError: __int__ returned non-int (type NoneType)",,
403,55375416,0,1,,,"File <*>/min_working_example.py, line 37, in <module> model.fit_generator(data_generator)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 1515, in fit_generator steps_name='steps_per_epoch')[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py, line 140, in model_iteration shuffle=shuffle)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py, line 477, in convert_to_generator_like raise ValueError('You must specify `batch_size`')[SEP]ValueError: You must specify `batch_size`",,
404,55459087,0,1,,,"File <*>/testo.py, line 18, in <module> optim.minimize(loss, var_list=network.weights)[SEP]AttributeError: 'Adam' object has no attribute 'minimize'",,
405,55476131,0,1,,,"File pretrain_lm.py, line 7, in <module> import fastai[SEP]File <*>python3.7/site-packages/fastai/__init__.py, line 1, in <module> from .basic_train import *[SEP]File <*>python3.7/site-packages/fastai/basic_train.py, line 2, in <module> from .torch_core import *[SEP]File <*>python3.7/site-packages/fastai/torch_core.py, line 2, in <module> from .imports.torch import *[SEP]File <*>python3.7/site-packages/fastai/imports/__init__.py, line 2, in <module> from .torch import *[SEP]File <*>python3.7/site-packages/fastai/imports/torch.py, line 1, in <module> import torch, torch.nn.functional as F[SEP]File <*>python3.7/site-packages/torch/__init__.py, line 84, in <module> from torch._C import *[SEP]ImportError: libtorch_python.so: cannot open shared object file: No such file or directory",,
406,55481140,0,1,,,"File <*>/train.py, line 184, in <module> tf.app.run()[SEP]File <*>python3.6/site-packages/tensorflow/python/platform/app.py, line 125, in run _sys.exit(main(argv))[SEP]File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 324, in new_func return func(*args, **kwargs)[SEP]File <*>/train.py, line 180, in main graph_hook_fn=graph_rewriter_fn)[SEP]File <*>/trainer.py, line 416, in train saver=saver)[SEP]File <*>python3.6/site-packages/tensorflow/contrib/slim/python/slim/learning.py, line 785, in train ignore_live_threads=ignore_live_threads)[SEP]File <*>python3.6/site-packages/tensorflow/python/training/supervisor.py, line 832, in stop ignore_live_threads=ignore_live_threads)[SEP]File <*>python3.6/site-packages/tensorflow/python/training/coordinator.py, line 389, in join six.reraise(*self._exc_info_to_raise)[SEP]File <*>python3.6/site-packages/six.py, line 693, in reraise raise value[SEP]File <*>python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py, line 257, in _run enqueue_callable()[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1257, in _single_operation_run self._call_tf_sessionrun(None, {}, [], target_list, None)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1407, in _call_tf_sessionrun run_metadata)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[15,1,1755,2777,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [[{{node batch}}]]",,
407,55574929,0,1,,,"File <*>/main.py, line 182, in <module> batch_size=128, epochs=1)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 880, in fit validation_steps=validation_steps)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 329, in model_iteration batch_outs = f(ins_batch)[SEP]File <*>/site-packages/tensorflow/python/keras/backend.py, line 3076, in __call__ run_metadata=self.run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1439, in __call__ run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [10,2] vs. [10] [[{{node metrics/acc/Equal}}]] [[{{node loss/mul}}]]",,
408,55718980,0,1,,,"File <*>/vis.py, line 28, in <module> from deeplab import common[SEP]ModuleNotFoundError: No module named 'deeplab'",,
409,55762759,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]AttributeError: module 'tensorflow' has no attribute 'estimator'",,
410,55762759,0,1,,,"File <*>python3.7/site-packages/conda/exceptions.py, line 819, in __call__ return func(*args, **kwargs)[SEP]File <*>python3.7/site-packages/conda/cli/main.py, line 78, in _main exit_code = do_call(args, p)[SEP]File <*>python3.7/site-packages/conda/cli/conda_argparse.py, line 77, in do_call exit_code = getattr(module, func_name)(args, parser)[SEP]File <*>python3.7/site-packages/conda/cli/main_update.py, line 14, in execute install(args, parser, 'update')[SEP]File <*>python3.7/site-packages/conda/cli/install.py, line 253, in install handle_txn(unlink_link_transaction, prefix, args, newenv)[SEP]File <*>python3.7/site-packages/conda/cli/install.py, line 282, in handle_txn unlink_link_transaction.execute()[SEP]File <*>python3.7/site-packages/conda/core/link.py, line 223, in execute self.verify()[SEP]File <*>python3.7/site-packages/conda/common/io.py, line 46, in decorated return f(*args, **kwds)[SEP]File <*>python3.7/site-packages/conda/core/link.py, line 200, in verify self.prepare()[SEP]File <*>python3.7/site-packages/conda/core/link.py, line 192, in prepare stp.remove_specs, stp.update_specs)[SEP]File <*>python3.7/site-packages/conda/core/link.py, line 282, in _prepare mkdir_p(transaction_context['temp_dir'])[SEP]File <*>python3.7/site-packages/conda/gateways/disk/__init__.py, line 60, in mkdir_p makedirs(path)[SEP]File <*>python3.7/os.py, line 221, in makedirs mkdir(name, mode)[SEP]PermissionError: [Errno 13] Permission denied: '/usr/share/anaconda3/.condatmp'",,
411,55762759,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]ImportError: cannot import name 'estimator' from 'tensorflow' (/home/cjs/.conda/envs/my-env/lib/python3.7/site-packages/tensorflow/__init__.py)",,
412,55925068,0,1,,,"File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.7/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.7/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: /usr/lib/libcublas.so.10.0: version `libcublas.so.10.0' not found (required by /home/techievin/.local/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)",,
413,56094714,0,1,,,"File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in make_tensor_proto str_values = [compat.as_bytes(x) for x in proto_values][SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 527, in <listcomp> str_values = [compat.as_bytes(x) for x in proto_values][SEP]File <*>/site-packages/tensorflow/python/util/compat.py, line 61, in as_bytes (bytes_or_text,))[SEP]TypeError: Expected binary or unicode string, got Dimension(4)",,
414,56094714,0,1,,,"File <*>/extra_classes.py, line 31, in <module> model_out = MyLayer(2)(model_in)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 746, in __call__ self.build(input_shapes)[SEP]File <*>/extra_classes.py, line 20, in build trainable=True)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 609, in add_weight aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/training/checkpointable/base.py, line 639, in _add_variable_with_custom_getter **kwargs_for_getter)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1977, in make_variable aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 183, in __call__ return cls._variable_v1_call(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 146, in _variable_v1_call aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 125, in <lambda> previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variable_scope.py, line 2437, in default_variable_creator import_scope=import_scope)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 187, in __call__ return super(VariableMetaclass, cls).__call__(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 297, in __init__ constraint=constraint)[SEP]File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 409, in _init_from_args initial_value() if init_from_fn else initial_value,[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1959, in <lambda> shape, dtype=dtype, partition_info=partition_info)[SEP]File <*>/site-packages/tensorflow/python/ops/init_ops.py, line 255, in __call__ shape, self.minval, self.maxval, dtype, seed=self.seed)[SEP]File <*>/site-packages/tensorflow/python/ops/random_ops.py, line 235, in random_uniform shape = _ShapeTensor(shape)[SEP]File <*>/site-packages/tensorflow/python/ops/random_ops.py, line 44, in _ShapeTensor return ops.convert_to_tensor(shape, dtype=dtype, name=""shape"")[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 1050, in convert_to_tensor as_ref=False)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 1146, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 229, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 208, in constant value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 531, in make_tensor_proto ""supported type."" % (type(values), values))[SEP]TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (Dimension(4), 2). Consider casting elements to a supported type.",,
415,56244438,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.5/site-packages/tensorflow/__init__.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>python3.5/site-packages/tensorflow/python/__init__.py, line 52, in <module> from tensorflow.core.framework.graph_pb2 import *[SEP]File <*>python3.5/site-packages/tensorflow/core/framework/graph_pb2.py, line 6, in <module> from google.protobuf import descriptor as _descriptor[SEP]File <*>python3.5/site-packages/google/protobuf/descriptor.py, line 47, in <module> from google.protobuf.pyext import _message[SEP]ImportError: /home/work/.conda/envs/tensorflow/lib/python3.5/site-packages/google/protobuf/pyext/_message.cpython-35m-x86_64-linux-gnu.so: undefined symbol: _ZNK6google8protobuf10TextFormat17FieldValuePrinter9PrintBoolEb",,
416,56301426,0,1,,,"File classifier_model.py, line 115, in <module> model.fit_generator(generator.flow(train_images, train_labels, batch_size=BATCH_SIZE), epochs=num_epochs)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1426, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 191, in model_iteration batch_outs = batch_function(*batch_data)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1191, in train_on_batch outputs = self._fit_function(ins) # pylint: disable=not-callable[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/backend.py, line 3076, in __call__ run_metadata=self.run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1439, in __call__ run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: logits and labels must have the same first dimension, got logits shape [1,7] and labels shape [7] [[{{node loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]",,
417,56307656,0,1,,,"File <*>/site-packages/tensorflow/python/client/session.py, line 1334, in _do_call return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1319, in _run_fn options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1407, in _call_tf_sessionrun run_metadata)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[51200,2304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[{{node model/h0/attn/c_attn/MatMul}}]]",,
418,56307656,0,1,,,"File train.py, line 293, in <module> main()[SEP]File train.py, line 271, in main feed_dict={context: sample_batch()})[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 929, in run run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1152, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1328, in _do_run run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1348, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[51200,2304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[node model/h0/attn/c_attn/MatMul (defined at D:\Python and AI\Generative Chatbot\gpt-2\src\model.py:55) ]]",,
419,56410003,0,1,,,"File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]File <*>python3.5/imp.py, line 242, in load_module return load_dynamic(name, filename, file)[SEP]File <*>python3.5/imp.py, line 342, in load_dynamic return _load(spec)[SEP]ImportError: /usr/lib/aarch64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.22' not found (required by /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so)",,
420,56580538,0,1,,,"File TestServe.py, line 62, in <module> ts.train()[SEP]File TestServe.py, line 56, in train epochs=2, verbose=1, callbacks=callbacks, steps_per_epoch=20) #The steps_per_epoch is typically samples_per_epoch / batch_size[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 880, in fit validation_steps=validation_steps)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 364, in model_iteration validation_in_fit=True)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 202, in model_iteration steps_per_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 76, in _get_num_samples_or_steps 'steps_per_epoch')[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 230, in check_num_samples if check_steps_argument(ins, steps, steps_name):[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 960, in check_steps_argument input_type=input_type_str, steps_name=steps_name))[SEP]ValueError: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument.",,
421,56719867,0,1,,,"File <*>/mnist.py, line 69, in <module> train(epoch)[SEP]File <*>/mnist.py, line 60, in train loss = criterion(out, target)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 493, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/loss.py, line 942, in forward ignore_index=self.ignore_index, reduction=self.reduction)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 2056, in cross_entropy return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1869, in nll_loss .format(input.size(0), target.size(0)))[SEP]ValueError: Expected input batch_size (12) to match target batch_size (64).",,
422,56741108,0,1,,,"File <*>/pydevd.py, line 1758, in <module> main()[SEP]File <*>/pydevd.py, line 1752, in main globals = debugger.run(setup['file'], None, None, is_module)[SEP]File <*>/pydevd.py, line 1147, in run pydev_imports.execfile(file, globals, locals) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/deep_test_conv1d.py, line 231, in <module> main()[SEP]File <*>/deep_test_conv1d.py, line 149, in main for i, (images, labels) in enumerate(train_loader):[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 615, in __next__ batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 615, in <listcomp> batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>/deep_test_conv1d.py, line 102, in __getitem__ return self.transform(self.features[index]), self.transform(self.classes[index])[SEP]File <*>/site-packages/torchvision/transforms/transforms.py, line 60, in __call__ img = t(img)[SEP]File <*>/site-packages/torchvision/transforms/transforms.py, line 91, in __call__ return F.to_tensor(pic)[SEP]File <*>/site-packages/torchvision/transforms/functional.py, line 50, in to_tensor raise TypeError('pic should be PIL Image or ndarray. Got {}'.format(type(pic)))[SEP]TypeError: pic should be PIL Image or ndarray. Got <class 'numpy.ndarray'>",,
423,56759226,0,1,,,"File <*>/model.py, line 24, in <module> image = mnist_example[""image""][SEP]TypeError: 'DatasetV1Adapter' object is not subscriptable",,
424,56779949,0,1,,,"File <*>/toco, line 11, in <module> sys.exit(main())[SEP]File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 503, in main app.run(main=run_main, argv=sys.argv[:1])[SEP]File <*>python2.7/site-packages/tensorflow/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)[SEP]File <*>python2.7/site-packages/absl/app.py, line 300, in run _run_main(main, args)[SEP]File <*>python2.7/site-packages/absl/app.py, line 251, in _run_main sys.exit(main(argv))[SEP]File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 499, in run_main _convert_tf1_model(tflite_flags)[SEP]File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 124, in _convert_tf1_model converter = _get_toco_converter(flags)[SEP]File <*>python2.7/site-packages/tensorflow/lite/python/tflite_convert.py, line 111, in _get_toco_converter return converter_fn(**converter_kwargs)[SEP]File <*>python2.7/site-packages/tensorflow/lite/python/lite.py, line 628, in from_frozen_graph _import_graph_def(graph_def, name="""")[SEP]File <*>python2.7/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func return func(*args, **kwargs)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/importer.py, line 431, in import_graph_def raise ValueError(str(e))[SEP]ValueError: Input 0 of node dense_1/weights_quant/AssignMinLast was passed float from dense_1/weights_quant/min:0 incompatible with expected float_ref.",,
425,56847576,0,1,,,"File train.py, line 194, in <module> _main()[SEP]File train.py, line 69, in _main callbacks=[logging, checkpoint])[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/engine/training.py, line 1418, in fit_generator initial_epoch=initial_epoch)[SEP]File <*>/site-packages/keras/engine/training_generator.py, line 251, in fit_generator callbacks.on_epoch_end(epoch, epoch_logs)[SEP]File <*>/site-packages/keras/callbacks.py, line 79, in on_epoch_end callback.on_epoch_end(epoch, logs)[SEP]File <*>/site-packages/keras/callbacks.py, line 429, in on_epoch_end filepath = self.filepath.format(epoch=epoch + 1, **logs)[SEP]KeyError: 'val_loss'",,
426,56851298,0,1,,,"File <*>/train_fit.py, line 286, in <module> validation_steps=None) #devset_steps_per_epoch)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 780, in fit steps_name='steps_per_epoch')[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 374, in model_iteration callbacks._call_batch_hook(mode, 'end', batch_index, batch_logs)[SEP]File <*>/site-packages/tensorflow/python/keras/callbacks.py, line 248, in _call_batch_hook batch_hook(batch, logs)[SEP]File <*>/site-packages/tensorflow/python/keras/callbacks.py, line 531, in on_train_batch_end self.on_batch_end(batch, logs=logs)[SEP]File <*>/site-packages/tensorflow/python/keras/callbacks_v1.py, line 362, in on_batch_end profiler.save(self.log_dir, profiler.stop())[SEP]File <*>/site-packages/tensorflow/python/eager/profiler.py, line 144, in save gfile.MakeDirs(plugin_dir)[SEP]File <*>/site-packages/tensorflow/python/lib/io/file_io.py, line 438, in recursive_create_dir recursive_create_dir_v2(dirname)[SEP]File <*>/site-packages/tensorflow/python/lib/io/file_io.py, line 453, in recursive_create_dir_v2 pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(path))[SEP]tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: ./logs\plugins\profile\2019-07-02_13-04-26; No such file or directory",,
427,57117397,0,1,,,"File <*>python3.6/site-packages/tensorflow/python/framework/importer.py, line 427, in import_graph_def graph._c_graph, serialized, options) # pylint: disable=protected-access[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Input 1 of node StatefulPartitionedCall was passed float from conv2d/kernel:0 incompatible with expected resource.",,
428,57117397,0,1,,,"File <*>/tensorrt.py, line 23, in <module> converter.save(saved_model_dir_trt)[SEP]File <*>python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py, line 822, in save super(TrtGraphConverter, self).save(output_saved_model_dir)[SEP]File <*>python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py, line 432, in save importer.import_graph_def(self._converted_graph_def, name="""")[SEP]File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/importer.py, line 431, in import_graph_def raise ValueError(str(e))[SEP]ValueError: Input 1 of node StatefulPartitionedCall was passed float from conv2d/kernel:0 incompatible with expected resource.",,
429,57125099,0,1,,,"File <*>/debug_multiple_input_model.py, line 39, in <module> model.predict(zipped_input)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1054, in predict callbacks=callbacks)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training_generator.py, line 264, in model_iteration batch_outs = batch_function(*batch_data)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training_generator.py, line 536, in predict_on_batch return model.predict_on_batch(x)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1281, in predict_on_batch x, extract_tensors_from_dataset=True)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 2651, in _standardize_user_data exception_prefix='input')[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training_utils.py, line 346, in standardize_input_data str(len(data)) + ' arrays: ' + str(data)[:200] + '...')[SEP]ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [<tf.Tensor: id=71049, shape=(10, 100, 5), dtype=float64, numpy= array([[[0.54049765, 0.64218937, 0.31734092, 0.81307839, 0.75465237], [0.32371089, 0.85923477, 0.60619924, 0.68692891, 0.186234...",,
430,57207936,0,1,,,"File <*>/site-packages/tensorflow/python/platform/self_check.py, line 62, in preload_check ctypes.WinDLL(build_info.nvcuda_dll_name)[SEP]File <*>/__init__.py, line 356, in __init__ self._handle = _dlopen(self._name, mode)[SEP]OSError: [WinError 126] Das angegebene Modul wurde nicht gefunden",,
431,57207936,0,1,,,"File test_model.py, line 5, in <module> import tensorflow as tf[SEP]File <*>/site-packages/tensorflow/__init__.py, line 28, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 30, in <module> self_check.preload_check()[SEP]File <*>/site-packages/tensorflow/python/platform/self_check.py, line 70, in preload_check % build_info.nvcuda_dll_name)[SEP]ImportError: Could not find 'nvcuda.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Typically it is installed in 'C:\Windows\System32'. If it is not present, ensure that you have a CUDA-capable GPU with the correct driver installed.",,
432,57277214,0,1,,,"File <*>python3.6/managers.py, line 228, in serve_client request = recv()[SEP]File <*>python3.6/connection.py, line 251, in recv return _ForkingPickler.loads(buf.getbuffer())[SEP]File <*>python3.6/site-packages/torch/multiprocessing/reductions.py, line 276, in rebuild_storage_fd fd = df.detach()[SEP]File <*>python3.6/resource_sharer.py, line 58, in detach return reduction.recv_handle(conn)[SEP]File <*>python3.6/reduction.py, line 182, in recv_handle return recvfds(s, 1)[0][SEP]File <*>python3.6/reduction.py, line 161, in recvfds len(ancdata))[SEP]RuntimeError: received 0 items of ancdata",,
433,57284345,0,1,,,"File <*>python3.6/dist-packages/pip/_internal/cli/base_command.py, line 178, in main status = self.run(options, args)[SEP]File <*>python3.6/dist-packages/pip/_internal/commands/install.py, line 326, in run self.name, wheel_cache[SEP]File <*>python3.6/dist-packages/pip/_internal/cli/base_command.py, line 268, in populate_requirement_set wheel_cache=wheel_cache[SEP]File <*>python3.6/dist-packages/pip/_internal/req/constructors.py, line 248, in install_req_from_line ""nor 'pyproject.toml' found."" % name[SEP]pip._internal.exceptions.InstallationError: Directory './' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.",,
434,57391377,0,1,,,"File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1473, in __del__ self._session._session, self._handle)[SEP]tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')",,
435,57406870,0,1,,,"File <*>/bacteria_rcnn_train.py, line 53, in <module> import keras[SEP]File <*>python3.5/dist-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>python3.5/dist-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils[SEP]File <*>python3.5/dist-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K[SEP]File <*>python3.5/dist-packages/keras/backend/__init__.py, line 84, in <module> from .tensorflow_backend import *[SEP]File <*>python3.5/dist-packages/keras/backend/tensorflow_backend.py, line 5, in <module> import tensorflow as tf[SEP]File <*>python3.5/dist-packages/tensorflow/__init__.py, line 28, in <module> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import[SEP]File <*>python3.5/dist-packages/tensorflow/python/__init__.py, line 83, in <module> from tensorflow.python import keras[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/__init__.py, line 26, in <module> from tensorflow.python.keras import activations[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/activations/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.activations import elu[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/_impl/keras/__init__.py, line 21, in <module> from tensorflow.python.keras._impl.keras import activations[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/_impl/keras/activations.py, line 23, in <module> from tensorflow.python.keras._impl.keras import backend as K[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py, line 38, in <module> from tensorflow.python.layers import base as tf_base_layers[SEP]File <*>python3.5/dist-packages/tensorflow/python/layers/base.py, line 25, in <module> from tensorflow.python.keras import backend[SEP]File <*>python3.5/dist-packages/tensorflow/python/keras/backend/__init__.py, line 22, in <module> from tensorflow.python.keras._impl.keras.backend import abs[SEP]ImportError: cannot import name 'abs'",,
436,57506707,0,1,,,"File <*>/script3.py, line 9, in <module> model = load_model(model_path, custom_objects={'MyMeanPooling': MyMeanPooling})[SEP]File <*>/site-packages/keras/engine/saving.py, line 419, in load_model model = _deserialize_model(f, custom_objects, compile)[SEP]File <*>/site-packages/keras/engine/saving.py, line 225, in _deserialize_model model = model_from_config(model_config, custom_objects=custom_objects)[SEP]File <*>/site-packages/keras/engine/saving.py, line 458, in model_from_config return deserialize(config, custom_objects=custom_objects)[SEP]File <*>/site-packages/keras/layers/__init__.py, line 55, in deserialize printable_module_name='layer')[SEP]File <*>/site-packages/keras/utils/generic_utils.py, line 145, in deserialize_keras_object list(custom_objects.items())))[SEP]File <*>/site-packages/keras/engine/network.py, line 1022, in from_config process_layer(layer_data)[SEP]File <*>/site-packages/keras/engine/network.py, line 1008, in process_layer custom_objects=custom_objects)[SEP]File <*>/site-packages/keras/utils/generic_utils.py, line 147, in deserialize_keras_object return cls.from_config(config['config'])[SEP]File <*>/site-packages/keras/engine/base_layer.py, line 1109, in from_config return cls(**config)[SEP]TypeError: __init__() missing 1 required positional argument: 'pool_size'",,
437,57537474,0,1,,,"File <*>/main.py, line 41, in <module> predics = nmodel.predict([x_test])[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 821, in predict use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 705, in predict x, check_steps=True, steps_name='steps', steps=steps)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 2335, in _standardize_user_data self._set_inputs(cast_inputs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 2553, in _set_inputs outputs = self(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 662, in __call__ outputs = call_fn(inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/sequential.py, line 262, in call outputs = layer(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/core.py, line 580, in call inputs, (tensor_shape.dimension_value(inputs.shape[0]) or[SEP]AttributeError: 'list' object has no attribute 'shape'",,
438,57615258,0,1,,,"File <string>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/torch/cuda/__init__.py, line 163, in _lazy_init torch._C._cuda_init()[SEP]RuntimeError: cuda runtime error (38) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1556653099582/work/aten/src/THC/THCGeneral.cpp:51",,
439,57816305,0,1,,,"File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 41, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)[SEP]ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory",,
440,57985406,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>python3.6/site-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils[SEP]File <*>python3.6/site-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K[SEP]File <*>python3.6/site-packages/keras/backend/__init__.py, line 1, in <module> from .load_backend import epsilon[SEP]File <*>python3.6/site-packages/keras/backend/load_backend.py, line 90, in <module> from .tensorflow_backend import *[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 13, in <module> from tensorflow.python.keras.utils import tf_utils[SEP]ImportError: cannot import name 'tf_utils'",,
441,58015489,0,1,,,"File <*>/pathtoproject, line 75, in predict cm_prediction = self.model.predict([face, reye, leye, fg])[0][SEP]File <*>/pathtoproject, line 1462, in predict callbacks=callbacks)[SEP]File <*>/site-packages/keras/engine/training_arrays.py, line 276, in predict_loop callbacks.model.stop_training = False[SEP]File <*>/site-packages/keras/engine/network.py, line 323, in __setattr__ super(Network, self).__setattr__(name, value)[SEP]File <*>/site-packages/keras/engine/base_layer.py, line 1215, in __setattr__ if not _DISABLE_TRACKING.value:[SEP]AttributeError: '_thread._local' object has no attribute 'value'",,
442,58047454,0,1,,,"File train.py, line 6, in <module> import keras.backend as K[SEP]File <*>/site-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>/site-packages/keras/utils/__init__.py, line 27, in <module> from .multi_gpu_utils import multi_gpu_model[SEP]File <*>/site-packages/keras/utils/multi_gpu_utils.py, line 7, in <module> from ..layers.merge import concatenate[SEP]File <*>/site-packages/keras/layers/__init__.py, line 4, in <module> from ..engine.base_layer import Layer[SEP]File <*>/site-packages/keras/engine/__init__.py, line 8, in <module> from .training import Model[SEP]File <*>/site-packages/keras/engine/training.py, line 21, in <module> from . import training_arrays[SEP]File <*>/site-packages/keras/engine/training_arrays.py, line 14, in <module> from .. import callbacks as cbks[SEP]File <*>/site-packages/keras/callbacks/__init__.py, line 19, in <module> if K.backend() == 'tensorflow' and not K.tensorflow_backend._is_tf_1():[SEP]AttributeError: module 'keras.backend.tensorflow_backend' has no attribute '_is_tf_1'",,
443,58084535,0,1,,,"File file.py, line 2, in <module> from torch.utils.data import Dataset, DataLoader[SEP]ModuleNotFoundError: No module named 'torch'",,
444,58084535,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]ModuleNotFoundError: No module named 'torch'",,
445,58215056,0,1,,,"File test_transform.py, line 87, in <module> for batch_idx, image, mask in enumerate(train_loader):[SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 314, in __next__ batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 314, in <listcomp> batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>python3.6/site-packages/torch/utils/data/dataset.py, line 103, in __getitem__ return self.dataset[self.indices[idx]][SEP]File <*>/data.py, line 164, in __getitem__ img, mask = self.transforms(img, mask)[SEP]File <*>/augmentations.py, line 17, in __call__ img, mask = a(img, mask)[SEP]TypeError: __call__() takes 2 positional arguments but 3 were given",,
446,58461211,0,1,,,"File classify_in_out_tf2.py, line 81, in [FUNC] [CODE][SEP]AttributeError: 'AutoTrackable' object has no attribute 'summary'",,
447,58496858,0,1,,,"File <ipython-input-12-f8636d3ba083>, line 26, in <module> predict(model, ""/home/x/閺傚洦銆?Deep_Learning/pytorch/MNIST/test/2/QQ閹搭亜娴?0191022093955.png"")[SEP]File <ipython-input-12-f8636d3ba083>, line 9, in predict test_image_tensor = transform(test_image)[SEP]File <*>python3.6/site-packages/torchvision/transforms/transforms.py, line 61, in __call__ img = t(img)[SEP]File <*>python3.6/site-packages/torchvision/transforms/transforms.py, line 166, in __call__ return F.normalize(tensor, self.mean, self.std, self.inplace)[SEP]File <*>python3.6/site-packages/torchvision/transforms/functional.py, line 217, in normalize tensor.sub_(mean[:, None, None]).div_(std[:, None, None])[SEP]RuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0",,
448,58607787,0,1,,,"File <*>/prova_bert.py, line 230, in <module> model = baseline_model(output_size, max_seq_len, visualize=True)[SEP]File <*>/prova_bert.py, line 165, in baseline_model )(bert_embeddings)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/wrappers.py, line 473, in __call__ return super(Bidirectional, self).__call__(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 746, in __call__ self.build(input_shapes)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/wrappers.py, line 612, in build self.forward_layer.build(input_shape)[SEP]File <*>/site-packages/tensorflow/python/keras/utils/tf_utils.py, line 149, in wrapper output_shape = fn(instance, input_shape)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/recurrent.py, line 552, in build self.cell.build(step_input_shape)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/recurrent.py, line 1934, in build constraint=self.kernel_constraint)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 609, in add_weight aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/training/checkpointable/base.py, line 639, in _add_variable_with_custom_getter **kwargs_for_getter)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1977, in make_variable aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 183, in __call__ return cls._variable_v1_call(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 146, in _variable_v1_call aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 125, in <lambda> previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variable_scope.py, line 2437, in default_variable_creator import_scope=import_scope)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 187, in __call__ return super(VariableMetaclass, cls).__call__(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 297, in __init__ constraint=constraint)[SEP]File <*>/site-packages/tensorflow/python/ops/resource_variable_ops.py, line 409, in _init_from_args initial_value() if init_from_fn else initial_value,[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1959, in <lambda> shape, dtype=dtype, partition_info=partition_info)[SEP]File <*>/site-packages/tensorflow/python/ops/init_ops.py, line 473, in __call__ scale /= max(1., (fan_in + fan_out) / 2.)[SEP]TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'",,
449,58607787,0,1,,,"File <*>/site-packages/tensorflow/python/client/session.py, line 738, in __del__ [CODE][SEP]TypeError: 'NoneType' object is not callable",,
450,58636087,0,1,,,"File <*>/Program.py, line 88, in FitModel model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 224, in fit distribution_strategy=strategy)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 547, in _process_training_inputs use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 606, in _process_inputs use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 479, in __init__ batch_size=batch_size, shuffle=shuffle, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 321, in __init__ dataset_ops.DatasetV2.from_tensors(inputs).repeat()[SEP]File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 414, in from_tensors return TensorDataset(tensors)[SEP]File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 2335, in __init__ element = structure.normalize_element(element)[SEP]File <*>/site-packages/tensorflow_core/python/data/util/structure.py, line 111, in normalize_element ops.convert_to_tensor(t, name=""component_%d"" % i))[SEP]File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1184, in convert_to_tensor return convert_to_tensor_v2(value, dtype, preferred_dtype, name)[SEP]File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1242, in convert_to_tensor_v2 as_ref=False)[SEP]File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1296, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py, line 52, in _default_conversion_function return constant_op.constant(value, dtype, name=name)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 227, in constant allow_broadcast=True)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 235, in _constant_impl t = convert_to_eager_tensor(value, ctx, dtype)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 96, in convert_to_eager_tensor return ops.EagerTensor(value, ctx.device_name, dtype)[SEP]ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float).",,
451,58776787,0,1,,,"File <input>, line 1, in <module> [CODE][SEP]AttributeError: module 'keras.applications' has no attribute 'resnet_v2'",,
452,58776787,0,1,,,"File <input>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 495, in ResNet50V2 **kwargs)[SEP]File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 348, in ResNet data_format=backend.image_data_format(),[SEP]AttributeError: 'NoneType' object has no attribute 'image_data_format'",,
453,58933151,0,1,,,"File <input>, line 1, in <module> [CODE][SEP]File <*>/pydev_umd.py, line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/train_model_so.py, line 108, in <module> print(""x shape is"" , x.shape())[SEP]TypeError: 'TensorShape' object is not callable",,
454,58933151,0,1,,,"File <*>/train_model.py, line 110, in <module> model.fit(train_dataset, epochs=5)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit 1/Unknown - 0s 13ms/step 1/Unknown - 0s 13ms/step use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 324, in fit total_epochs=epochs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 123, in run_one_epoch batch_outs = execution_function(iterator)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 86, in execution_function distributed_function(input_fn))[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__ result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call self._initialize(args, kwds, add_initializers_to=initializer_map)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize *args, **kwds))[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function capture_by_value=self._capture_by_value),[SEP]File <*>/site-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 66, in distributed_function model, input_iterator, mode)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 112, in _prepare_feed_values inputs, targets, sample_weights = _get_input_from_iterator(inputs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 149, in _get_input_from_iterator distribution_strategy_context.get_strategy(), x, y, sample_weights)[SEP]File <*>/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py, line 308, in validate_distributed_dataset_inputs x_values_list = validate_per_replica_inputs(distribution_strategy, x)[SEP]File <*>/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py, line 356, in validate_per_replica_inputs validate_all_tensor_shapes(x, x_values)[SEP]File <*>/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py, line 373, in validate_all_tensor_shapes x_shape = x_values[0].shape.as_list()[SEP]File <*>/site-packages/tensorflow_core/python/framework/tensor_shape.py, line 1171, in as_list raise ValueError(""as_list() is not defined on an unknown TensorShape."")[SEP]ValueError: as_list() is not defined on an unknown TensorShape.",,
455,58984892,0,1,,,"File <ipython-input-1-f9d072fc6a73>, line 19, in <module> onnx_model = keras2onnx.convert_keras(model)[SEP]File <*>/site-packages/keras2onnx/main.py, line 67, in convert_keras "" Please set environment variable TF_KERAS = 1."")[SEP]Exception: This is a tensorflow keras model, but keras standalone converter is used. Please set environment variable TF_KERAS = 1.",,
456,59218671,0,1,,,"File <*>python3.6/dist-packages/torch/utils/data/_utils/worker.py, line 178, in _worker_loop data = fetcher.fetch(index)[SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp> data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <ipython-input-180-0b00b175e18c>, line 72, in __getitem__ image = self.transform(image)[SEP]File <*>python3.6/dist-packages/torchvision/transforms/transforms.py, line 70, in __call__ img = t(img)[SEP]File <*>python3.6/dist-packages/torchvision/transforms/transforms.py, line 175, in __call__ return F.normalize(tensor, self.mean, self.std, self.inplace)[SEP]File <*>python3.6/dist-packages/torchvision/transforms/functional.py, line 217, in normalize tensor.sub_(mean[:, None, None]).div_(std[:, None, None])[SEP]RuntimeError: output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]",,
457,59240556,0,1,,,"File tf_1_day_scikit_dnn.py, line 12, in <module> from sklearn import decomposition[SEP]File <*>python3.6/site-packages/sklearn/decomposition/__init__.py, line 19, in <module> from ._online_lda import LatentDirichletAllocation[SEP]ImportError: cannot import name 'LatentDirichletAllocation'",,
458,59253581,0,1,,,"File <*>python37/runpy.py, line 193, in _run_module_as_main ""__main__"", mod_spec)[SEP]File <*>python37/runpy.py, line 85, in _run_code exec(code, run_globals)[SEP]File <*>/__main__.py, line 9, in <module> [CODE][SEP]File <*>/site-packages/flask/cli.py, line 966, in main cli.main(prog_name=""python -m flask"" if as_module else None)[SEP]File <*>/site-packages/flask/cli.py, line 586, in main return super(FlaskGroup, self).main(*args, **kwargs)[SEP]File <*>/site-packages/click/core.py, line 717, in main rv = self.invoke(ctx)[SEP]File <*>/site-packages/click/core.py, line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx))[SEP]File <*>/site-packages/click/core.py, line 956, in invoke return ctx.invoke(self.callback, **ctx.params)[SEP]File <*>/site-packages/click/core.py, line 555, in invoke return callback(*args, **kwargs)[SEP]File <*>/site-packages/click/decorators.py, line 64, in new_func return ctx.invoke(f, obj, *args, **kwargs)[SEP]File <*>/site-packages/flask/cli.py, line 860, in run_command extra_files=extra_files,[SEP]File <*>/site-packages/werkzeug/serving.py, line 1008, in run_simple run_with_reloader(inner, extra_files, reloader_interval, reloader_type)[SEP]File <*>/site-packages/werkzeug/_reloader.py, line 337, in run_with_reloader reloader.run()[SEP]File <*>/site-packages/werkzeug/_reloader.py, line 202, in run for filename in chain(_iter_module_files(), self.extra_files):[SEP]File <*>/site-packages/werkzeug/_reloader.py, line 24, in _iter_module_files filename = getattr(module, ""__file__"", None)[SEP]File <*>/site-packages/tensorflow/__init__.py, line 50, in __getattr__ module = self._load()[SEP]File <*>/site-packages/tensorflow/__init__.py, line 44, in _load module = _importlib.import_module(self.__name__)[SEP]File <*>python37/__init__.py, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <frozen importlib._bootstrap>, line 1006, in _gcd_import [CODE][SEP]File <frozen importlib._bootstrap>, line 983, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 965, in _find_and_load_unlocked [CODE][SEP]ModuleNotFoundError: No module named 'tensorflow_core.keras'",,
459,59326551,0,1,,,"File main.py, line 69, in <module> pickle.dump(history, f)[SEP]TypeError: can't pickle _thread._local objects",,
460,59403281,0,1,,,"File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 61, in quick_execute num_outputs)[SEP]TypeError: An op outside of the function building code is being passed",,
461,59403281,0,1,,,"File <*>/N09.py, line 363, in <module> main()[SEP]File <*>/N09.py, line 343, in main args.save_interval)[SEP]File <*>/N09.py, line 92, in train_model verbose=self.verbose)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 1297, in fit_generator steps_name='steps_per_epoch')[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py, line 265, in model_iteration batch_outs = batch_function(*batch_data)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 973, in train_on_batch class_weight=class_weight, reset_metrics=reset_metrics)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch output_loss_metrics=model._output_loss_metrics)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch output_loss_metrics=output_loss_metrics))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 268, in _process_single_batch grads = tape.gradient(scaled_total_loss, trainable_weights)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/backprop.py, line 1014, in gradient unconnected_gradients=unconnected_gradients)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py, line 76, in imperative_grad compat.as_str(unconnected_gradients.value))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 911, in _backward_function_wrapper processed_args, remapped_captures)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1224, in _call_flat ctx, args, cancellation_manager=cancellation_manager)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 511, in call ctx=ctx)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 75, in quick_execute ""tensors, but found {}"".format(keras_symbolic_tensors))[SEP]tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'StridedSliceGrad:0' shape=(16, 64, 64, 3) dtype=float32>]",,
462,59409919,0,1,,,"File model_main.py, line 109, in [FUNC] [CODE][SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 125, in run _sys.exit(main(argv))[SEP]File model_main.py, line 105, in main tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 471, in train_and_evaluate return executor.run()[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 610, in run return self.run_local()[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 711, in run_local saving_listeners=saving_listeners)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 354, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 1207, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 1241, in _train_model_default saving_listeners)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 1471, in _train_with_estimator_spec _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 783, in exit self._close_internal(exception_type)[SEP]File <*>/site-packages/tensorflow/python/training/monitored_session.py, line 816, in _close_internal h.end(self._coordinated_creator.tf_sess)[SEP]File <*>/site-packages/tensorflow/python/training/basic_session_run_hooks.py, line 590, in end l.end(session, last_step)[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 531, in end self._evaluate(global_step_value)[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 537, in _evaluate self._evaluator.evaluate_and_export())[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 924, in evaluate_and_export is_the_final_export)[SEP]File <*>/site-packages/tensorflow/python/estimator/training.py, line 957, in _export_eval_result is_the_final_export=is_the_final_export))[SEP]File <*>/site-packages/tensorflow/python/estimator/exporter.py, line 418, in export is_the_final_export)[SEP]File <*>/site-packages/tensorflow/python/estimator/exporter.py, line 126, in export strip_default_attrs=self._strip_default_attrs)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 663, in export_savedmodel mode=model_fn_lib.ModeKeys.PREDICT)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 789, in _export_saved_model_for_mode strip_default_attrs=strip_default_attrs)[SEP]File <*>/site-packages/tensorflow/python/estimator/estimator.py, line 883, in _export_all_saved_models builder = saved_model_builder.SavedModelBuilder(temp_export_dir)[SEP]File <*>/site-packages/tensorflow/python/saved_model/builder_impl.py, line 97, in init file_io.recursive_create_dir(self._export_dir)[SEP]File <*>/site-packages/tensorflow/python/lib/io/file_io.py, line 379, in recursive_create_dir pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in exit c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: training/export\Servo\temp-b'1576742954'; No such file or directory",,
463,59567226,0,1,,,"File <*>/maxmem.py, line 11, in <module> dic[x]=tf.random.normal((nn,dd))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/ops/random_ops.py, line 76, in random_normal value = math_ops.add(mul, mean_tensor, name=name)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py, line 391, in add _six.raise_from(_core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1000,250000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add] name: random_normal/",,
464,59621736,0,1,,,"File <*>/data.py, line 4, in <module> import torchvision[SEP]ModuleNotFoundError: No module named 'torchvision'",,
465,59639633,0,1,,,"File DL_Ensemble.py, line 145, in <module> fused = concatenate([graph, graph_1], axis= 1 )[SEP]File <*>python3.8/site-packages/tensorflow_core/python/keras/layers/merge.py, line 705, in concatenate return Concatenate(axis=axis, **kwargs)(inputs)[SEP]File <*>python3.8/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 887, in __call__ self._maybe_build(inputs)[SEP]File <*>python3.8/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 2141, in _maybe_build self.build(input_shapes)[SEP]File <*>python3.8/site-packages/tensorflow_core/python/keras/utils/tf_utils.py, line 306, in wrapper output_shape = fn(instance, input_shape)[SEP]File <*>python3.8/site-packages/tensorflow_core/python/keras/layers/merge.py, line 378, in build raise ValueError('A `Concatenate` layer should be called '[SEP]ValueError: A `Concatenate` layer should be called on a list of at least 2 inputs",,
466,59639633,0,1,,,"File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1455, in __del__ self._session._session, self._handle, status)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__ c_api.TF_GetCode(self.status.status))[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: No such callable handle: 94697914208640",,
467,59718635,0,1,,,"File tf2_main.py, line 50, in <module> model = CycleGAN(args)[SEP]File <*>/tf2_model.py, line 55, in __init__ self._build_model(args)[SEP]File <*>/tf2_model.py, line 63, in _build_model name='Generator_A2B')[SEP]File <*>/tf2_module.py, line 154, in build_generator name='IN_1')(x)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 773, in __call__ outputs = call_fn(cast_inputs, *args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/keras/layers/core.py, line 847, in call self._check_variables(created_variables, tape.watched_variables())[SEP]File <*>python3.6/site-packages/tensorflow_core/python/keras/layers/core.py, line 873, in _check_variables raise ValueError(error_str)[SEP]ValueError: The following Variables were created within a Lambda layer (IN_1) but are not tracked by said layer: <tf.Variable 'IN_1/SCALE:0' shape=(64,) dtype=float32> <tf.Variable 'IN_1/OFFSET:0' shape=(64,) dtype=float32> The layer cannot safely ensure proper Variable reuse across multiple calls, and consquently this behavior is disallowed for safety. Lambda layers are not well suited to stateful computation; instead, writing a subclassed Layer is the recommend way to define layers with Variables.",,
468,59873568,0,1,,,"File <*>/cnn.py, line 70, in <module> validation_steps = 2000)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 1297, in fit_generator steps_name='steps_per_epoch')[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_generator.py, line 265, in model_iteration batch_outs = batch_function(*batch_data)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 973, in train_on_batch class_weight=class_weight, reset_metrics=reset_metrics)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch output_loss_metrics=model._output_loss_metrics)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch output_loss_metrics=output_loss_metrics))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 252, in _process_single_batch training=training))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 127, in _model_loss outs = model(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 891, in __call__ outputs = self.call(cast_inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/sequential.py, line 256, in call return super(Sequential, self).call(inputs, training=training, mask=mask)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 708, in call convert_kwargs_to_constants=base_layer_utils.call_context().saving)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 860, in _run_internal_graph output_tensors = layer(computed_tensors, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/layers/convolutional.py, line 197, in call outputs = self._convolution_op(inputs, self.kernel)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 1134, in __call__ return self.conv_op(inp, filter)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 639, in __call__ return self.call(inp, filter)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 238, in __call__ name=self.name)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 2010, in conv2d name=name)[SEP]File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1031, in conv2d data_format=data_format, dilations=dilations, name=name, ctx=_ctx)[SEP]File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1130, in conv2d_eager_fallback ctx=_ctx, name=name)[SEP]File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]",,
469,60022388,0,1,,,"File <*>/pydevd.py, line 1741, in <module> main()[SEP]File <*>/pydevd.py, line 1735, in main globals = debugger.run(setup['file'], None, None, is_module)[SEP]File <*>/pydevd.py, line 1135, in run pydev_imports.execfile(file, globals, locals) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/train_hopenet_with_validation_holdout.py, line 187, in <module> loss_reg_yaw = reg_criterion(yaw_predicted, label_yaw_cont)[SEP]File <*>/site-packages/torch/nn/modules/module.py, line 541, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>/site-packages/torch/nn/modules/loss.py, line 431, in forward return F.mse_loss(input, target, reduction=self.reduction)[SEP]File <*>/site-packages/torch/nn/functional.py, line 2204, in mse_loss ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))[SEP]RuntimeError: reduce failed to synchronize: cudaErrorAssert: device-side assert triggered",,
470,60101168,0,1,,,"File <*>/main.py, line 81, in <module> train(epoch)[SEP]File <*>/main.py, line 48, in train for iteration, batch in enumerate(training_data_loader, 1):[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 345, in __next__ data = self._next_data()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 841, in _next_data idx, data = self._get_data()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 808, in _get_data success, data = self._try_get_data()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 774, in _try_get_data raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str))[SEP]RuntimeError: DataLoader worker (pid(s) 16596, 9376, 12756, 9844) exited unexpectedly",,
471,60239051,0,1,,,"File <*>/Wrong.py, line 33, in <module> net.forward(dataset[0])[SEP]File <*>/Wrong.py, line 23, in forward x = F.relu(self.layer(x))[SEP]File <*>/site-packages/torch/nn/modules/module.py, line 532, in __call__ result = self.forward(*input, **kwargs)[SEP]File <*>/site-packages/torch/nn/modules/, line 87, in forward return F.linear(input, self.weight, self.bias)[SEP]File <*>/site-packages/torch/nn/functional.py, line 1372, in linear output = input.matmul(weight.t())[SEP]RuntimeError: Expected object of scalar type Double but got scalar type Float for argument #2 'mat2' in call to _th_mm",,
472,60414562,0,1,,,"File <*>/main.py, line 17, in <module> history = CNN.fit(TrainImages, TrainMasks, epochs = 3)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1239, in fit validation_freq=validation_freq)[SEP]File <*>python3.6/site-packages/keras/engine/training_arrays.py, line 196, in fit_loop outs = fit_function(ins_batch)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/keras/backend.py, line 3727, in __call__ outputs = self._graph_fn(*converted_inputs)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/eager/function.py, line 1551, in __call__ return self._call_impl(args, kwargs)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/eager/function.py, line 1591, in _call_impl return self._call_flat(args, self.captured_inputs, cancellation_manager)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>python3.6/site-packages/tensorflow_core/python/eager/function.py, line 545, in call ctx=ctx)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.**InvalidArgumentError: BiasGrad requires tensor size <= int32 max** [[node gradients/conv2d_22/BiasAdd_grad/BiasAddGrad (defined at /home/tomhalmos/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_5496]",,
473,60478749,0,1,,,"File <*>/test2.py, line 73, in <module> grads = gradients(model, x, y)[SEP]File <*>/test2.py, line 58, in gradients print(model.get_layer('minimalrnn').output)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 1553, in output raise AttributeError('Layer ' + self.name + ' has no inbound nodes.')[SEP]AttributeError: Layer minimalrnn has no inbound nodes.",,
474,60487683,0,1,,,"File <*>/unet_trainer.py, line 82, in <module> results = model.fit_generator(train_generator, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, validation_data=val_generator, validation_steps=VALIDATION_STEPS, callbacks=callbacks)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 1297, in fit_generator steps_name='steps_per_epoch')[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_generator.py, line 265, in model_iteration batch_outs = batch_function(*batch_data)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 973, in train_on_batch class_weight=class_weight, reset_metrics=reset_metrics)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch output_loss_metrics=model._output_loss_metrics)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch output_loss_metrics=output_loss_metrics))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 252, in _process_single_batch training=training))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 127, in _model_loss outs = model(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 891, in __call__ outputs = self.call(cast_inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 708, in call convert_kwargs_to_constants=base_layer_utils.call_context().saving)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 860, in _run_internal_graph output_tensors = layer(computed_tensors, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/layers/convolutional.py, line 197, in call outputs = self._convolution_op(inputs, self.kernel)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 1134, in __call__ return self.conv_op(inp, filter)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 639, in __call__ return self.call(inp, filter)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 238, in __call__ name=self.name)[SEP]File <*>/site-packages/tensorflow_core/python/ops/nn_ops.py, line 2010, in conv2d name=name)[SEP]File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1031, in conv2d data_format=data_format, dilations=dilations, name=name, ctx=_ctx)[SEP]File <*>/site-packages/tensorflow_core/python/ops/gen_nn_ops.py, line 1130, in conv2d_eager_fallback ctx=_ctx, name=name)[SEP]File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,16,1536,1536] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",,
475,60497294,0,1,,,"File TrainTest.py, line 71, in <module> model.save('test', save_format='tf')[SEP]File <*>/network.py, line 1008, in save signatures, options)[SEP]File <*>/save.py, line 115, in save_model signatures, options)[SEP]File <*>/save.py, line 78, in save save_lib.save(model, filepath, signatures, options)[SEP]File <*>/save.py, line 886, in save checkpoint_graph_view)[SEP]File <*>/signature_serialization.py, line 74, in find_function_to_export functions = saveable_view.list_functions(saveable_view.root)[SEP]File <*>/save.py, line 142, in list_functions self._serialization_cache)[SEP]File <*>/base_layer.py, line 2420, in _list_functions_for_serialization .list_functions_for_serialization(serialization_cache))[SEP]File <*>/base_serialization.py, line 91, in list_functions_for_serialization fns = self.functions_to_serialize(serialization_cache)[SEP]File <*>/layer_serialization.py, line 80, in functions_to_serialize serialization_cache).functions_to_serialize)[SEP]File <*>/layer_serialization.py, line 95, in _get_serialized_attributes serialization_cache)[SEP]File <*>/model_serialization.py, line 47, in _get_serialized_attributes_internal default_signature = save_impl.default_save_signature(self.obj)[SEP]File <*>/save_impl.py, line 212, in default_save_signature fn.get_concrete_function()[SEP]File <*>/def_function.py, line 909, in get_concrete_function self._initialize(args, kwargs, add_initializers_to=initializers)[SEP]File <*>/def_function.py, line 497, in _initialize *args, **kwds))[SEP]File <*>/function.py, line 2389, in _get_concrete_function_internal_garbage_collected graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/function.py, line 2703, in _maybe_define_function graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/function.py, line 2593, in _create_graph_function capture_by_value=self._capture_by_value),[SEP]File <*>/func_graph.py, line 978, in func_graph_from_py_func func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/def_function.py, line 439, in wrapped_fn return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/saving_utils.py, line 150, in _wrapped_model outputs_list = nest.flatten(model(inputs=inputs, training=False))[SEP]TypeError: __call__() missing 1 required positional argument: 'x'",,
476,60551145,0,1,,,"File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 61, in quick_execute num_outputs)[SEP]TypeError: An op outside of the function building code is being passed a ""Graph"" tensor. It is possible to have Graph tensors leak out of the function building context by including a tf.init_scope in your function building code.",,
477,60551145,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 1013, in predict use_multiprocessing=use_multiprocessing)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 498, in predict workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 475, in _model_iteration total_epochs=1)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch batch_outs = execution_function(iterator)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function distributed_function(input_fn))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__ result = self._call(*args, **kwds)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 638, in _call return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds) # pylint: disable=protected-access[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call self.captured_inputs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 545, in call ctx=ctx)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 75, in quick_execute ""tensors, but found {}"".format(keras_symbolic_tensors))[SEP]tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'conv_name_base_1/Identity:0' shape=(None, 160, 160, 64) dtype=float32>]",,
478,60562295,0,1,,,"File <*>/mmconvert, line 8, in <module> sys.exit(_main())[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/_script/convert.py, line 102, in _main ret = convertToIR._convert(ir_args)[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/_script/convertToIR.py, line 62, in _convert from mmdnn.conversion.tensorflow.tensorflow_parser import TensorflowParser[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/tensorflow/tensorflow_parser.py, line 15, in <module> from tensorflow.tools.graph_transforms import TransformGraph[SEP]ImportError: No module named 'tensorflow.tools.graph_transforms'",,
479,60562295,0,1,,,"File <*>/mmconvert, line 8, in <module> sys.exit(_main())[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/_script/convert.py, line 102, in _main ret = convertToIR._convert(ir_args)[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/_script/convertToIR.py, line 46, in _convert parser = Keras2Parser(model)[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/keras/keras2_parser.py, line 126, in __init__ model = self._load_model(model[0], model[1])[SEP]File <*>python3.5/dist-packages/mmdnn/conversion/keras/keras2_parser.py, line 78, in _load_model 'DepthwiseConv2D': layers.DepthwiseConv2D})[SEP]File <*>python3.5/dist-packages/keras/engine/saving.py, line 664, in model_from_json return deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.5/dist-packages/keras/layers/__init__.py, line 168, in deserialize printable_module_name='layer')[SEP]File <*>python3.5/dist-packages/keras/utils/generic_utils.py, line 147, in deserialize_keras_object list(custom_objects.items())))[SEP]File <*>python3.5/dist-packages/keras/engine/network.py, line 1056, in from_config process_layer(layer_data)[SEP]File <*>python3.5/dist-packages/keras/engine/network.py, line 1042, in process_layer custom_objects=custom_objects)[SEP]File <*>python3.5/dist-packages/keras/utils/generic_utils.py, line 149, in deserialize_keras_object return cls.from_config(config['config'])[SEP]File <*>python3.5/dist-packages/keras/engine/base_layer.py, line 1179, in from_config return cls(**config)[SEP]File <*>python3.5/dist-packages/keras/legacy/interfaces.py, line 91, in wrapper return func(*args, **kwargs)[SEP]File <*>python3.5/dist-packages/keras/layers/convolutional.py, line 484, in __init__ **kwargs)[SEP]File <*>python3.5/dist-packages/keras/layers/convolutional.py, line 117, in __init__ self.kernel_initializer = initializers.get(kernel_initializer)[SEP]File <*>python3.5/dist-packages/keras/initializers.py, line 515, in get return deserialize(identifier)[SEP]File <*>python3.5/dist-packages/keras/initializers.py, line 510, in deserialize printable_module_name='initializer')[SEP]File <*>python3.5/dist-packages/keras/utils/generic_utils.py, line 140, in deserialize_keras_object ': ' + class_name)[SEP]ValueError: Unknown initializer: GlorotUniform",,
480,60563115,0,1,,,"File <*>python3.7/site-packages/IPython/core/interactiveshell.py, line 3331, in run_code exec(code_obj, self.user_global_ns, self.user_ns)[SEP]File <ipython-input-55-cc0dd3d9cbb7>, line 1, in <module> net(cc)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 532, in __call__ result = self.forward(*input, **kwargs)[SEP]File <ipython-input-2-19e11966d1cd>, line 181, in forward out = self.layer1(x)[SEP]File <*>python3.7/site-packages/torch/nn/modules/container.py, line 100, in forward input = module(input)[SEP]File <*>python3.7/site-packages/torch/nn/modules/conv.py, line 480, in forward self.padding, self.dilation, self.groups)[SEP]RuntimeError: Could not run 'aten::slow_conv3d_forward' with arguments from the 'CUDATensorId' backend. 'aten::slow_conv3d_forward' is only available for these backends: [CPUTensorId, VariableTensorId].",,
481,60567183,0,1,,,"File <*>/3D_tf_data_generator.py, line 181, in <module> evaluation_ad = model.evaluate(ad_test, ad_test_labels, verbose=0)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 930, in evaluate use_multiprocessing=use_multiprocessing)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 490, in evaluate use_multiprocessing=use_multiprocessing, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 426, in _model_iteration use_multiprocessing=use_multiprocessing)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py, line 646, in _process_inputs x, y, sample_weight=sample_weights)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 2383, in _standardize_user_data batch_size=batch_size)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 2489, in _standardize_tensors y, self._feed_loss_fns, feed_output_shapes)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py, line 810, in check_loss_and_target_compatibility ' while using as loss `' + loss_name + '`. '[SEP]ValueError: A target array with shape (5, 2) was passed for an output of shape (None, 1) while using as loss `binary_crossentropy`. This loss expects targets to have the same shape as the output.",,
482,60664524,0,1,,,"File pytorch_test.py, line 14, in <module> a_copy.resize_(1, 1)[SEP]RuntimeError: set_sizes_contiguous is not allowed on a Tensor created from .data or .detach().",,
483,60664524,0,1,,,"File pytorch_test.py, line 21, in <module> a_copy.resize_(1, 1)[SEP]RuntimeError: cannot resize variables that require grad",,
484,60750288,0,1,,,"File <*>/train.py, line 74, in <module> model = nn.DataParallel(model, device_ids=[0, 1]).to(device)[SEP]File <*>/site-packages/torch/nn/parallel/data_parallel.py, line 133, in __init__ _check_balance(self.device_ids)[SEP]File <*>/site-packages/torch/nn/parallel/data_parallel.py, line 19, in _check_balance dev_props = [torch.cuda.get_device_properties(i) for i in device_ids][SEP]File <*>/site-packages/torch/nn/parallel/data_parallel.py, line 19, in <listcomp> dev_props = [torch.cuda.get_device_properties(i) for i in device_ids][SEP]File <*>/site-packages/torch/cuda/__init__.py, line 337, in get_device_properties raise AssertionError(""Invalid device id"")[SEP]AssertionError: Invalid device id",,
485,60771047,0,1,,,"File <*>/site-packages/IPython/core/interactiveshell.py, line 3296, in run_code exec(code_obj, self.user_global_ns, self.user_ns)[SEP]File <ipython-input-2-78553e2886de>, line 1, in <module> runfile('F:/experiment_code/U-net/train.py', wdir='F:/experiment_code/U-net')[SEP]File <*>/pydev_umd.py, line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/train.py, line 99, in <module> loss.backward()[SEP]File <*>/site-packages/torch/tensor.py, line 107, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>/site-packages/torch/autograd/__init__.py, line 93, in backward allow_unreachable=True) # allow_unreachable flag[SEP]RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [4, 2, 224, 224]], which is output 0 of SigmoidBackward, is at version 2; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",,
486,60905801,0,1,,,"File <*>python2.7/process.py, line 267, in _bootstrap self.run()[SEP]File <*>python2.7/process.py, line 114, in run self._target(*self._args, **self._kwargs)[SEP]File <*>python2.7/pool.py, line 102, in worker task = get()[SEP]File <*>python2.7/queues.py, line 376, in get return recv()[SEP]AttributeError: 'module' object has no attribute 'prediction'",,
487,60905801,0,1,,,"File stackoverflow.py, line 47, in <module> with multiprocessing.Pool() as p:[SEP]AttributeError: __exit__",,
488,60905801,0,1,,,"File trial_mult-ips.py, line 240, in <module> predops=p.map(prediction,new_all_t)[SEP]File <*>python2.7/pool.py, line 253, in map return self.map_async(func, iterable, chunksize).get()[SEP]File <*>python2.7/pool.py, line 572, in get raise self._value[SEP]NotImplementedError: numpy() is only available when eager execution is enabled.",,
489,60905801,0,1,,,"File the_other_end-mp.py, line 216, in <module> predops=p.map(prediction,modelon)[SEP]File <*>python2.7/pool.py, line 253, in map return self.map_async(func, iterable, chunksize).get()[SEP]File <*>python2.7/pool.py, line 572, in get raise self._value[SEP]ValueError: Resource handles are not convertible to numpy.",,
490,60948259,0,1,,,"File main.py, line 95, in <module> model.load_weights(checkpoint_dir)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 162, in load_weights return super(Model, self).load_weights(filepath, by_name)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/network.py, line 1398, in load_weights status.assert_nontrivial_match()[SEP]File <*>python3.7/site-packages/tensorflow/python/training/tracking/util.py, line 917, in assert_nontrivial_match return self.assert_consumed()[SEP]File <*>python3.7/site-packages/tensorflow/python/training/tracking/util.py, line 894, in assert_consumed (unused_attributes,))[SEP]AssertionError: Some objects had attributes which were not restored: {<tf.Variable 'embedding_1/embeddings:0' shape=(65, 256) dtype=float32, numpy= array([[-0.00044268, -0.02351714, -0.01139065, ..., -0.00327835, 0.00074228, -0.00383734], [-0.02313181, 0.04697707, -0.02350216, ..., 0.040385 , 0.03087702, 0.02765551], [ 0.0410727 , 0.00130001, 0.0051438 , ..., 0.02899202, 0.04258115, -0.03773504], ..., [-0.03134514, 0.01370119, 0.00993627, ..., -0.02257681, 0.02617678, 0.03761976], [-0.02954974, 0.02407967, 0.02768463, ..., -0.0056519 , -0.01507735, 0.04617763], [-0.04113789, -0.03544737, 0.01056757, ..., 0.01236727, -0.01791535, -0.01635399]], dtype=float32)>: ['embedding_1/embeddings'], <tf.Variable 'dense_1/kernel:0' shape=(1024, 65) dtype=float32, numpy= array([[-6.7811467e-02, -2.5536597e-02, 5.1763237e-02, ..., -6.9665730e-02, 3.9457709e-02, -5.3290475e-02], [ 1.5835620e-02, -3.0763537e-02, -7.4058644e-02, ..., 3.8087368e-05, -9.1508478e-03, 5.5485427e-02], [ 3.8143486e-02, 8.8131428e-04, -2.3478847e-02, ..., -1.5135627e-02, -5.2146181e-02, 7.1185097e-02], ..., [-6.6591002e-02, 4.7627889e-02, 5.7474524e-02, ..., 4.1528463e-02, 4.6467118e-02, -3.0670539e-02], [-5.0804108e-02, 5.4505378e-02, -1.5776977e-03, ..., 2.1875933e-02, -2.9637258e-02, 2.0201296e-02], [-4.7325939e-02, -8.0013275e-03, -3.6348965e-02, ..., -7.0560835e-02, -4.9752403e-02, 1.0509960e-02]], dtype=float32)>: ['dense_1/kernel'], <tf.Variable 'dense_1/bias:0' shape=(65,) dtype=float32, numpy= array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>: ['dense_1/bias'], <tf.Variable 'gru_1/kernel:0' shape=(256, 3072) dtype=float32, numpy= array([[ 0.00432818, 0.03131782, 0.00038544, ..., -0.00559966, 0.03458985, -0.03219106], [-0.00865119, 0.01648769, -0.00768028, ..., 0.01366192, -0.03043955, -0.01382086], [-0.01379537, 0.00547716, -0.00385967, ..., -0.00027269, -0.01285852, 0.0377048 ], ..., [-0.01940641, 0.01454895, 0.03349226, ..., -0.04234404, -0.02699661, 0.0376601 ], [ 0.00186675, -0.00547577, -0.02205843, ..., -0.01287581, -0.02314153, 0.04158166], [ 0.00954719, -0.02883693, -0.03259185, ..., -0.02587803, 0.02906795, -0.00559821]], dtype=float32)>: ['gru_1/kernel'], <tf.Variable 'gru_1/recurrent_kernel:0' shape=(1024, 3072) dtype=float32, numpy= array([[ 9.11542401e-03, 1.50135346e-02, 2.96630897e-02, ..., 2.25223936e-02, 2.31253020e-02, -2.96920985e-02], [-2.21075956e-02, -8.46013427e-06, -2.16848943e-02, ..., -1.26914177e-02, -3.49153839e-02, -3.01396102e-02], [-3.59148793e-02, 9.98445973e-03, 2.60963626e-02, ..., 3.15430500e-02, 1.28889643e-02, 3.37569825e-02], ..., [ 3.39106433e-02, 6.54980540e-03, -1.27352085e-02, ..., -4.14674729e-03, 3.53236459e-02, -1.36333425e-02], [-3.50691415e-02, -1.76392253e-02, 1.67468414e-02, ..., -2.06982102e-02, -1.06042419e-02, 2.26641595e-02], [-1.14825107e-02, -3.46554294e-02, -1.83847174e-03, ..., 2.25809850e-02, 2.45791934e-02, -2.70933360e-02]], dtype=float32)>: ['gru_1/recurrent_kernel'], <tf.Variable 'gru_1/bias:0' shape=(2, 3072) dtype=float32, numpy= array([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>: ['gru_1/bias']}",,
491,60954216,0,1,,,"File <*>/train.py, line 66, in <module> train(epochs=20, prefix='test_new_loss_fn')[SEP]File <*>/train.py, line 46, in train model = create_model((shape[0], shape[1], 3), backbone=backbone, loss_function=loss_fn, freeze_backbone=backbone_freeze, lr=learning_rate)[SEP]File <*>/__init__.py, line 48, in create_model loss=loss_function, metrics=[mean_relative_percentage_error, metrics.mean_absolute_error])[SEP]File <*>/site-packages/keras/engine/training.py, line 342, in compile sample_weight, mask)[SEP]File <*>/site-packages/keras/engine/training_utils.py, line 404, in weighted score_array = fn(y_true, y_pred)[SEP]File <*>/losses.py, line 8, in mean_relative_percentage_error diff = K.update_sub(ones, e)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 999, in update_sub return tf.assign_sub(x, decrement)[SEP]File <*>/site-packages/tensorflow/python/ops/state_ops.py, line 160, in assign_sub return ref.assign_sub(value)[SEP]AttributeError: 'Tensor' object has no attribute 'assign_sub'",,
492,60954216,0,1,,,"File <*>/train.py, line 66, in <module> train(epochs=20, prefix='test_new_loss_fn')[SEP]File <*>/train.py, line 46, in train model = create_model((shape[0], shape[1], 3), backbone=backbone, loss_function=loss_fn, freeze_backbone=backbone_freeze, lr=learning_rate)[SEP]File <*>/__init__.py, line 48, in create_model loss=loss_function, metrics=[mean_relative_percentage_error, metrics.mean_absolute_error])[SEP]File <*>/site-packages/keras/engine/training.py, line 342, in compile sample_weight, mask)[SEP]File <*>/site-packages/keras/engine/training_utils.py, line 404, in weighted score_array = fn(y_true, y_pred)[SEP]File <*>/losses.py, line 7, in mean_relative_percentage_error ones = K.variable(K.ones_like(err))[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 402, in variable v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 183, in __call__ return cls._variable_v1_call(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 146, in _variable_v1_call aggregation=aggregation)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 125, in <lambda> previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variable_scope.py, line 2444, in default_variable_creator expected_shape=expected_shape, import_scope=import_scope)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 187, in __call__ return super(VariableMetaclass, cls).__call__(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 1329, in __init__ constraint=constraint)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 1472, in _init_from_args self._initial_value)[SEP]ValueError: initial_value must have a shape specified: Tensor(""loss/dense_3_loss/ones_like:0"", shape=(?, ?), dtype=float32)",,
493,61094394,0,1,,,"File test_dist_1.py, line 25, in <module> dist.broadcast(tensor=a, src=0)[SEP]File <*>python3.7/site-packages/torch/distributed/distributed_c10d.py, line 806, in broadcast work = _default_pg.broadcast([tensor], opts)[SEP]RuntimeError: NCCL error in: /tmp/pip-req-build-58y_cjjl/torch/lib/c10d/ProcessGroupNCCL.cpp:290, unhandled system error",,
494,61104317,0,1,,,"File <*>/rks.py, line 14, in <module> from tf.keras.preprocessing.image import ImageDataGenerator[SEP]ModuleNotFoundError: No module named 'tf'",,
495,61756222,0,1,,,"File <*>/site-packages/torch/_utils_internal.py, line 46, in get_source_lines_and_file [CODE][SEP]File inspect.py, line 967, in getsourcelines [CODE][SEP]File inspect.py, line 798, in findsource [CODE][SEP]OSError: could not get source code",,
496,61756222,0,1,,,"File extractor.py, line 3, in <module> import torch[SEP]File <frozen importlib._bootstrap>, line 991, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 975, in _find_and_load_unlocked [CODE][SEP]File <frozen importlib._bootstrap>, line 671, in _load_unlocked [CODE][SEP]File <*>/site-packages/PyInstaller/loader/pyimod03_importers.py, line 623, in exec_module exec(bytecode, module.__dict__)[SEP]File <*>/site-packages/torch/__init__.py, line 367, in <module> [CODE][SEP]File <*>/site-packages/torch/distributions/__init__.py, line 112, in <module> [CODE][SEP]File <*>/site-packages/torch/distributions/von_mises.py, line 55, in <module> [CODE][SEP]File <*>/site-packages/torch/jit/__init__.py, line 1287, in script [CODE][SEP]File <*>/site-packages/torch/jit/frontend.py, line 164, in get_jit_def [CODE][SEP]File <*>/site-packages/torch/_utils_internal.py, line 53, in get_source_lines_and_file [CODE][SEP]OSError: Can't get source for <function _rejection_sample at 0x0000000006892F70>. TorchScript requires source access in order to carry out compilation, make sure original .py files are available.",,
497,61900138,0,1,,,"File <*>python3.6/dist-packages/torch/utils/data/_utils/worker.py, line 178, in _worker_loop data = fetcher.fetch(index)[SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp> data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <ipython-input-114-e0ccd94603fd>, line 31, in __getitem__ xs = label_data[:,0:8:2];[SEP]IndexError: too many indices for array",,
498,61968540,0,1,,,"File plot_parametric_pytorch_cifar100.py, line 130, in <module> loss_fn = F.nll_loss(ops, tgts)[SEP]File <*>python3.7/site-packages/torch/nn/functional.py, line 2115, in nll_loss ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)[SEP]IndexError: Target 42 is out of bounds.",,
499,62075321,0,1,,,"File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1365, in _do_call return fn(*args)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1350, in _run_fn target_list, run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1443, in _call_tf_sessionrun run_metadata)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found. (0) Invalid argument: {{function_node __inference_Dataset_map_transform_and_pad_input_data_fn_3047}} assertion failed: [[0.748][0.758]] [[0.67][0.67]] [[{{node Assert/AssertGuard/else/_123/Assert}}]] [[IteratorGetNext]] (1) Invalid argument: {{function_node __inference_Dataset_map_transform_and_pad_input_data_fn_3047}} assertion failed: [[0.748][0.758]] [[0.67][0.67]] [[{{node Assert/AssertGuard/else/_123/Assert}}]] [[IteratorGetNext]] [[IteratorGetNext/_8451]] 0 successful operations. 0 derived errors ignored.",,
500,62075321,0,1,,,"File <*>/model_main.py, line 114, in <module> tf.app.run()[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)[SEP]File <*>python3.6/dist-packages/absl/app.py, line 299, in run _run_main(main, args)[SEP]File <*>python3.6/dist-packages/absl/app.py, line 250, in _run_main sys.exit(main(argv))[SEP]File <*>/model_main.py, line 110, in main tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py, line 473, in train_and_evaluate return executor.run()[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py, line 613, in run return self.run_local()[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py, line 714, in run_local saving_listeners=saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py, line 370, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py, line 1161, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py, line 1195, in _train_model_default saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py, line 1494, in _train_with_estimator_spec _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 754, in run run_metadata=run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1259, in run run_metadata=run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1360, in run raise six.reraise(*original_exc_info)[SEP]File <*>python3.6/dist-packages/six.py, line 693, in reraise raise value[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1345, in run return self._sess.run(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1418, in run run_metadata=run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py, line 1176, in run return self._sess.run(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 956, in run run_metadata_ptr)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1180, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1359, in _do_run run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/client/session.py, line 1384, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found. (0) Invalid argument: assertion failed: [[0.748][0.758]] [[0.67][0.67]] [[{{node Assert/AssertGuard/else/_123/Assert}}]] [[IteratorGetNext]] (1) Invalid argument: assertion failed: [[0.748][0.758]] [[0.67][0.67]] [[{{node Assert/AssertGuard/else/_123/Assert}}]] [[IteratorGetNext]] [[IteratorGetNext/_8451]] 0 successful operations. 0 derived errors ignored.",,
501,62087214,0,1,,,"File <*>/tempCodeRunnerFile.python, line 1234, in <module> df_enc = tensorflow.one_hot(df, 2, on_value=None, off_value=None, axis=None, dtype=None, name=None)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/util/dispatch.py, line 180, in wrapper return target(*args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/ops/array_ops.py, line 3645, in one_hot name)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py, line 5549, in one_hot _ops.raise_from_not_ok_status(e, name)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/ops.py, line 6606, in raise_from_not_ok_status six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.NotFoundError: Could not find valid device for node.",,
502,62102912,0,1,,,"File trainer.py, line 629, in <module> clear_outputs=True[SEP]File <*>/utils.py, line 62, in wrapper result = func(*args, **kwargs)[SEP]File trainer.py, line 490, in train validation_data=valid_dataset,[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper return method(self, *args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1090, in fit tmp_logs = train_function(iterator)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 766, in __call__ result = self._call(*args, **kwds)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 826, in _call return self._stateless_fn(*args, **kwds)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 2811, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1838, in _filtered_call cancellation_manager=cancellation_manager)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1914, in _call_flat ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 549, in call ctx=ctx)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/execute.py, line 60, in quick_execute inputs, attrs, num_outputs)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [4,76,76,3,1] vs. [4,19,19,3,1] [[node yolo_loss/logistic_loss/mul (defined at ../Helpers/utils.py:260) ]] [Op:__inference_train_function_38735]",,
503,62102912,0,1,,,"File <*>/trainer.py, line 693, in <module> clear_outputs=True,[SEP]File <*>/utils.py, line 62, in wrapper result = func(*args, **kwargs)[SEP]File <*>/trainer.py, line 526, in train validation_data=valid_dataset,[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper return method(self, *args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow/python/keras/engine/training.py, line 848, in fit tmp_logs = train_function(iterator)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__ result = self._call(*args, **kwds)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/def_function.py, line 644, in _call return self._stateless_fn(*args, **kwds)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 2420, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 1665, in _filtered_call self.captured_inputs)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 1746, in _call_flat ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/function.py, line 598, in call ctx=ctx)[SEP]File <*>python3.7/site-packages/tensorflow/python/eager/execute.py, line 60, in quick_execute inputs, attrs, num_outputs)[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [8,13,13,3,2] vs. [8,52,52,3,2] [[node gradient_tape/yolo_loss/sub_5/BroadcastGradientArgs (defined at Users/emadboctor/Desktop/Code/yolov3-keras-tf2/Main/trainer.py:526) ]] [Op:__inference_train_function_42744]",,
504,62656411,0,1,,,"File <*>python3.6/dist-packages/optkeras/optkeras.py, line 230, in synch_with_optuna self.best_trial = self.study.best_trial[SEP]File <*>python3.6/dist-packages/optuna/study.py, line 97, in best_trial return copy.deepcopy(self._storage.get_best_trial(self._study_id))[SEP]File <*>python3.6/dist-packages/optuna/storages/in_memory.py, line 293, in get_best_trial raise ValueError(""No trials are completed yet."")[SEP]ValueError: No trials are completed yet.",,
505,62656411,0,1,,,"File <*>python3.6/dist-packages/optuna/study.py, line 734, in _run_trial result = func(trial)[SEP]File <*>python3.6/dist-packages/optkeras/optkeras.py, line 130, in fun_tf return fun(trial)[SEP]File <ipython-input-11-45495c9f2ae9>, line 65, in optima_run self.model.fit(self.train_images, self.train_labels, epochs=10, callbacks = self.ok.callbacks(trial), verbose = self.ok.keras_verbose)[SEP]File <*>python3.6/dist-packages/optkeras/optkeras.py, line 172, in callbacks self.synch_with_optuna()[SEP]File <*>python3.6/dist-packages/optkeras/optkeras.py, line 232, in synch_with_optuna self.best_trial = get_trial_default()[SEP]File <*>python3.6/dist-packages/optkeras/optkeras.py, line 367, in get_trial_default num_fields = optuna.structs.FrozenTrial._field_types.__len__()[SEP]AttributeError: type object 'FrozenTrial' has no attribute '_field_types'",,
506,62926022,0,1,,,"File <*>/train.py, line 17, in <module> from pegasus.data import infeed[SEP]ModuleNotFoundError: No module named 'pegasus'",,
507,62953477,0,1,,,"File <*>python3.6/site-packages/uvicorn/protocols/http/httptools_impl.py, line 385, in run_asgi result = await app(self.scope, self.receive, self.send)[SEP]File <*>python3.6/site-packages/uvicorn/middleware/proxy_headers.py, line 45, in __call__ return await self.app(scope, receive, send)[SEP]File <*>python3.6/site-packages/fastapi/applications.py, line 183, in __call__ await super().__call__(scope, receive, send) # pragma: no cover[SEP]File <*>python3.6/site-packages/starlette/applications.py, line 102, in __call__ await self.middleware_stack(scope, receive, send)[SEP]File <*>python3.6/site-packages/starlette/middleware/errors.py, line 181, in __call__ raise exc from None[SEP]File <*>python3.6/site-packages/starlette/middleware/errors.py, line 159, in __call__ await self.app(scope, receive, _send)[SEP]File <*>python3.6/site-packages/starlette/exceptions.py, line 82, in __call__ raise exc from None[SEP]File <*>python3.6/site-packages/starlette/exceptions.py, line 71, in __call__ await self.app(scope, receive, sender)[SEP]File <*>python3.6/site-packages/starlette/routing.py, line 550, in __call__ await route.handle(scope, receive, send)[SEP]File <*>python3.6/site-packages/starlette/routing.py, line 227, in handle await self.app(scope, receive, send)[SEP]File <*>python3.6/site-packages/starlette/routing.py, line 41, in app response = await func(request)[SEP]File <*>python3.6/site-packages/fastapi/routing.py, line 197, in app dependant=dependant, values=values, is_coroutine=is_coroutine[SEP]File <*>python3.6/site-packages/fastapi/routing.py, line 149, in run_endpoint_function return await run_in_threadpool(dependant.call, **values)[SEP]File <*>python3.6/site-packages/starlette/concurrency.py, line 34, in run_in_threadpool return await loop.run_in_executor(None, func, *args)[SEP]File <*>python3.6/thread.py, line 56, in run result = self.fn(*self.args, **self.kwargs)[SEP]File <*>/main.py, line 155, in API_call raise e[SEP]File <*>/main.py, line 129, in API_call model = pickle.load(open('models/' + current_model, 'rb'))[SEP]File <*>python3.6/site-packages/dill/_dill.py, line 270, in load return Unpickler(file, ignore=ignore, **kwds).load()[SEP]File <*>python3.6/site-packages/dill/_dill.py, line 473, in load obj = StockUnpickler.load(self)[SEP]File <*>python3.6/site-packages/dill/_dill.py, line 463, in find_class return StockUnpickler.find_class(self, module, name)[SEP]AttributeError: Can't get attribute 'Model_II_b' on <module '__mp_main__' from '/opt/apps/env/bin/uvicorn'>",,
508,63075594,0,1,,,"File <*>python3.6/pool.py, line 119, in worker result = (True, func(*args, **kwds))[SEP]File <*>python3.6/pool.py, line 44, in mapstar return list(map(*args))[SEP]File <ipython-input-35-6529ab6dac60>, line 11, in X_power_func X_power = X**j[SEP]RuntimeError: CUDA error: initialization error",,
509,63138030,0,1,,,"File <*>/site-packages/tensorflow/python/data/util/structure.py, line 93, in normalize_element spec = type_spec_from_value(t, use_fallback=False)[SEP]File <*>/site-packages/tensorflow/python/data/util/structure.py, line 466, in type_spec_from_value (element, type(element).__name__))[SEP]TypeError: Could not build a TypeSpec for 0 Tecmo Koei 1 Nippon Ichi Software 2 Ubisoft 3 Activision 4 Atari ... 6594 Kemco 6595 Infogrames 6596 Activision 6597 7G//AMES 6598 Wanadoo Name: Publisher, Length: 6599, dtype: object with type Series",,
510,63138030,0,1,,,"File <*>/main.py, line 45, in <module> linear_est.train(train_input_fn)[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 349, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1175, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners)[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1201, in _train_model_default self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1037, in _get_features_and_labels_from_input_fn self._call_input_fn(input_fn, mode))[SEP]File <*>/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1130, in _call_input_fn return input_fn(**kwargs)[SEP]File <*>/main.py, line 34, in input_function ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 682, in from_tensor_slices return TensorSliceDataset(tensors)[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 3001, in __init__ element = structure.normalize_element(element)[SEP]File <*>/site-packages/tensorflow/python/data/util/structure.py, line 98, in normalize_element ops.convert_to_tensor(t, name=""component_%d"" % i))[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 1499, in convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 338, in _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 264, in constant allow_broadcast=True)[SEP]File <*>/site-packages/tensorflow/python/framework/constant_op.py, line 282, in _constant_impl allow_broadcast=allow_broadcast))[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 563, in make_tensor_proto append_fn(tensor_proto, proto_values)[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 155, in SlowAppendObjectArrayToTensorProto tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])[SEP]File <*>/site-packages/tensorflow/python/framework/tensor_util.py, line 155, in <listcomp> tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])[SEP]File <*>/site-packages/tensorflow/python/util/compat.py, line 87, in as_bytes (bytes_or_text,))[SEP]TypeError: Expected binary or unicode string, got nan",,
511,63169445,0,1,,,"File imdb_classification.py, line 65, in <module> history = model.fit(x_train,y_train,epochs=50,batch_size=32,verbose=1)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 819, in fit use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 235, in fit use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 593, in _process_training_inputs use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 706, in _process_inputs use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 357, in __init__ dataset = self.slice_inputs(indices_dataset, inputs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/data_adapter.py, line 383, in slice_inputs dataset_ops.DatasetV2.from_tensors(inputs).repeat()[SEP]File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 566, in from_tensors return TensorDataset(tensors)[SEP]File <*>/site-packages/tensorflow_core/python/data/ops/dataset_ops.py, line 2765, in __init__ element = structure.normalize_element(element)[SEP]File <*>/site-packages/tensorflow_core/python/data/util/structure.py, line 113, in normalize_element ops.convert_to_tensor(t, name=""component_%d"" % i))[SEP]File <*>/site-packages/tensorflow_core/python/framework/ops.py, line 1314, in convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py, line 52, in _default_conversion_function return constant_op.constant(value, dtype, name=name)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 258, in constant allow_broadcast=True)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 266, in _constant_impl t = convert_to_eager_tensor(value, ctx, dtype)[SEP]File <*>/site-packages/tensorflow_core/python/framework/constant_op.py, line 96, in convert_to_eager_tensor return ops.EagerTensor(value, ctx.device_name, dtype)[SEP]ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list)",,
512,63182524,0,1,,,"File [FILE], line <*>, in [FUNC] [CODE][SEP]File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 349, in train loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1182, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners)[SEP]File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1208, in _train_model_default self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))[SEP]File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1044, in _get_features_and_labels_from_input_fn self._call_input_fn(input_fn, mode))[SEP]File <*>python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py, line 1137, in _call_input_fn return input_fn(**kwargs)[SEP]File [FILE], line 1137, in [FUNC] [CODE][SEP]File <*>python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 406, in __iter__ raise RuntimeError(""__iter__() is only supported inside of tf.function ""[SEP]RuntimeError: __iter__() is only supported inside of tf.function or when eager execution is enabled.",,
513,63486381,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/torch_xla/core/xla_model.py, line 231, in xla_device devkind=devkind if devkind is not None else None)[SEP]File <*>python3.6/site-packages/torch_xla/core/xla_model.py, line 136, in get_xla_supported_devices xla_devices = _DEVICES.value[SEP]File <*>python3.6/site-packages/torch_xla/utils/utils.py, line 32, in value self._value = self._gen_fn()[SEP]File <*>python3.6/site-packages/torch_xla/core/xla_model.py, line 18, in <lambda> _DEVICES = xu.LazyProperty(lambda: torch_xla._XLAC._xla_get_devices())[SEP]RuntimeError: tensorflow/compiler/xla/xla_client/computation_client.cc:274 : Missing XLA configuration",,
514,63652692,0,1,,,"File <*>/convert.py, line 13, in <module> tflite_model = converter.convert()[SEP]File <*>/site-packages/tensorflow/lite/python/lite.py, line 1076, in convert return super(TFLiteConverterV2, self).convert()[SEP]File <*>/site-packages/tensorflow/lite/python/lite.py, line 899, in convert return super(TFLiteFrozenGraphConverterV2,[SEP]File <*>/site-packages/tensorflow/lite/python/lite.py, line 629, in convert result = _toco_convert_impl([SEP]File <*>/site-packages/tensorflow/lite/python/convert.py, line 569, in toco_convert_impl data = toco_convert_protos([SEP]File <*>/site-packages/tensorflow/lite/python/convert.py, line 202, in toco_convert_protos raise ConverterError(str(e))[SEP]tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types <unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x?x?x3x!tf.quint8>) -> tensor<1x?x?x3xui8>",,
515,63763459,0,1,,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 64, in <module> from tensorflow.python._pywrap_tensorflow_internal import *[SEP]ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.",,
516,63809090,0,1,,,"File <*>/site-packages/IPython/core/interactiveshell.py, line 3331, in run_code exec(code_obj, self.user_global_ns, self.user_ns)[SEP]File <ipython-input-2-d2317d03e1c1>, line 1, in <module> runfile('F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news/bitcoin.py', wdir='F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news')[SEP]File <*>/pydev_umd.py, line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script[SEP]File <*>/_pydev_execfile.py, line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc)[SEP]File <*>/bitcoin.py, line 41, in <module> model.fit(x=x_train, y=y_train, batch_size=64, epochs=5, shuffle=True, validation_split=0.1)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 819, in fit use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 342, in fit total_epochs=epochs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch batch_outs = execution_function(iterator)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function distributed_function(input_fn))[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__ result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 632, in _call return self._stateless_fn(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2363, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call self.captured_inputs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 545, in call ctx=ctx)[SEP]File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Condition x == y did not hold element-wise:] [x (loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [64 1] [y (loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [64 14] [[node loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at F:/Pycharm_projects/my_fun_project/Fake or real news/fake-or-real-news/bitcoin.py:41) ]] [Op:__inference_distributed_function_2970]",,
517,64081214,0,1,,,"File <*>/model_main_tf2.py, line 113, in <module> tf.compat.v1.app.run()[SEP]File <*>python3.6/dist-packages/tensorflow/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)[SEP]File <*>python3.6/dist-packages/absl/app.py, line 300, in run _run_main(main, args)[SEP]File <*>python3.6/dist-packages/absl/app.py, line 251, in _run_main sys.exit(main(argv))[SEP]File <*>/model_main_tf2.py, line 110, in main record_summaries=FLAGS.record_summaries)[SEP]File <*>python3.6/dist-packages/object_detection/model_lib_v2.py, line 630, in train_loop manager.save()[SEP]File <*>python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py, line 819, in save self._record_state()[SEP]File <*>python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py, line 728, in _record_state save_relative_paths=True)[SEP]File <*>python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py, line 248, in update_checkpoint_state_internal text_format.MessageToString(ckpt))[SEP]File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 570, in atomic_write_string_to_file rename(temp_pathname, filename, overwrite)[SEP]File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 529, in rename rename_v2(oldname, newname, overwrite)[SEP]File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 546, in rename_v2 compat.as_bytes(src), compat.as_bytes(dst), overwrite)[SEP]tensorflow.python.framework.errors_impl.FailedPreconditionError: /content/drive/My Drive/Tensorflow/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint.tmp91048f3bf67645619be6603094546de1; Is a directory",,
518,64326568,0,1,,,"File <*>/site-packages/flask/app.py, line 2447, in wsgi_app response = self.full_dispatch_request()[SEP]File <*>/site-packages/flask/app.py, line 1952, in full_dispatch_request rv = self.handle_user_exception(e)[SEP]File <*>/site-packages/flask/app.py, line 1821, in handle_user_exception reraise(exc_type, exc_value, tb)[SEP]File <*>/site-packages/flask/_compat.py, line 39, in reraise raise value[SEP]File <*>/site-packages/flask/app.py, line 1950, in full_dispatch_request rv = self.dispatch_request()[SEP]File <*>/site-packages/flask/app.py, line 1936, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args)[SEP]File <*>/app.py, line 70, in predict out = model.predict(img)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 130, in _method_wrapper return method(self, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1562, in predict version_utils.disallow_legacy_graph('Model', 'predict')[SEP]File <*>/site-packages/tensorflow/python/keras/utils/version_utils.py, line 122, in disallow_legacy_graph raise ValueError(error_msg)[SEP]ValueError: Calling `Model.predict` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.predict` with eager mode enabled.",,
519,64334033,0,1,,,"File <*>/emotion.py, line 4, in <module> emotion_detector = EmotionRecognition(device='gpu', gpu_id=1)[SEP]File <*>python3.7/site-packages/facial_emotion_recognition/facial_emotion_recognition.py, line 25, in __init__ self.network = NetworkV2(in_c=1, nl=32, out_f=7).to(self.device)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 607, in to return self._apply(convert)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 354, in _apply module._apply(fn)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 376, in _apply param_applied = fn(param)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 605, in convert return t.to(device, dtype if t.is_floating_point() else None, non_blocking)[SEP]RuntimeError: CUDA error: invalid device ordinal",,
520,64506725,0,1,,,"File <*>/external_process.py, line 35, in <module> model.fit([SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper return method(self, *args, **kwargs)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/training.py, line 1098, in fit tmp_logs = train_function(iterator)[SEP]File <*>python3.8/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__ result = self._call(*args, **kwds)[SEP]File <*>python3.8/site-packages/tensorflow/python/eager/def_function.py, line 840, in _call return self._stateless_fn(*args, **kwds)[SEP]File <*>python3.8/site-packages/tensorflow/python/eager/function.py, line 2829, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>python3.8/site-packages/tensorflow/python/eager/function.py, line 1843, in _filtered_call return self._call_flat([SEP]File <*>python3.8/site-packages/tensorflow/python/eager/function.py, line 1923, in _call_flat return self._build_call_outputs(self._inference_function.call([SEP]File <*>python3.8/site-packages/tensorflow/python/eager/function.py, line 545, in call outputs = execute.execute([SEP]File <*>python3.8/site-packages/tensorflow/python/eager/execute.py, line 59, in quick_execute tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 1328 values, but the requested shape has 16 [[{{node TripletSemiHardLoss/PartitionedCall/Reshape}}]] [Op:__inference_train_function_13749]",,
521,64770600,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>/site-packages/tensorflow/__init__.py, line 101, in <module> from tensorflow_core import *[SEP]File <*>/site-packages/tensorflow_core/__init__.py, line 40, in <module> from tensorflow.python.tools import module_util as _module_util[SEP]File <frozen importlib._bootstrap>, line 983, in _find_and_load [CODE][SEP]File <frozen importlib._bootstrap>, line 959, in _find_and_load_unlocked [CODE][SEP]File <*>/site-packages/tensorflow/__init__.py, line 50, in __getattr__ module = self._load()[SEP]File <*>/site-packages/tensorflow/__init__.py, line 44, in _load module = _importlib.import_module(self.__name__)[SEP]File <*>/__init__.py, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level)[SEP]File <*>/site-packages/tensorflow_core/python/__init__.py, line 49, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow.py, line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import *[SEP]File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py, line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper()[SEP]File <*>/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py, line 15, in swig_import_helper import imp[SEP]ValueError: source code string cannot contain null bytes",,
522,64779719,0,1,,,"File foo_test.py, line 21, in test3 self.assertEqual(3,4)[SEP]AssertionError: 3 != 4",,
523,64809370,0,1,,,"File evaluate_spect.py, line 63, in <module> main()[SEP]File evaluate_spect.py, line 51, in main pred_audio = torchaudio.transforms.GriffinLim(n_fft=256)(inverse_mel_pred)[SEP]File <*>python3.8/site-packages/torch/nn/modules/module.py, line 727, in _call_impl result = self.forward(*input, **kwargs)[SEP]File <*>python3.8/site-packages/torchaudio/transforms.py, line 169, in forward return F.griffinlim(specgram, self.window, self.n_fft, self.hop_length, self.win_length, self.power,[SEP]File <*>python3.8/site-packages/torchaudio/functional.py, line 179, in griffinlim inverse = torch.istft(specgram * angles,[SEP]RuntimeError: The size of tensor a (256) must match the size of tensor b (129) at non-singleton dimension 1",,
524,64837376,0,1,,,"File ml_model.py, line 1, in <module> import torch[SEP]File <*>/site-packages/torch/__init__.py, line 117, in <module> import torch[SEP]File <*>/site-packages/torch/__init__.py, line 117, in <module> raise err[SEP]OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading ""C:\Users\user\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\lib\cudnn_cnn_infer64_8.dll"" or one of its dependencies. raise err",,
525,64867031,0,1,,,"File model_main_tf2.py, line 113, in <module> tf.compat.v1.app.run()[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)[SEP]File <*>/site-packages/absl/app.py, line 303, in run _run_main(main, args)[SEP]File <*>/site-packages/absl/app.py, line 251, in _run_main sys.exit(main(argv))[SEP]File model_main_tf2.py, line 104, in main model_lib_v2.train_loop([SEP]File <*>/site-packages/object_detection/model_lib_v2.py, line 639, in train_loop loss = _dist_train_step(train_input_iter)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__ result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 840, in _call return self._stateless_fn(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2829, in __call__ return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1843, in _filtered_call return self._call_flat([SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1923, in _call_flat return self._build_call_outputs(self._inference_function.call([SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 545, in call outputs = execute.execute([SEP]File <*>/site-packages/tensorflow/python/eager/execute.py, line 59, in quick_execute tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found. (0) Resource exhausted: OOM when allocating tensor with shape[64,256,17,17] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[node functional_3/conv2d_160/Conv2D (defined at \site-packages\object_detection\meta_architectures\faster_rcnn_meta_arch.py:1149) ]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. [[Identity_1/_432]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. (1) Resource exhausted: OOM when allocating tensor with shape[64,256,17,17] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[node functional_3/conv2d_160/Conv2D (defined at \site-packages\object_detection\meta_architectures\faster_rcnn_meta_arch.py:1149) ]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. 0 successful operations. 0 derived errors ignored. [Op:__inference__dist_train_step_79248]",,
526,65023526,0,1,,,"File <ipython-input-39-17211d5a107c>, line 8, in <module> train_loss, _ = modhelper.train(proc.train_dataloader)[SEP]File <*>/model.py, line 71, in train preds = self.model(sent_id, mask)[SEP]File <*>/site-packages/torch/nn/modules/module.py, line 727, in _call_impl result = self.forward(*input, **kwargs)[SEP]File <*>/model.py, line 181, in forward #pass the inputs to the model[SEP]File <*>/site-packages/transformers/modeling_bert.py, line 837, in forward embedding_output = self.embeddings([SEP]File <*>/site-packages/transformers/modeling_bert.py, line 201, in forward embeddings = inputs_embeds + position_embeddings + token_type_embeddings[SEP]RuntimeError: The size of tensor a (4000) must match the size of tensor b (512) at non-singleton dimension 1",,
527,65498782,0,1,,,"File <*>/site-packages/pytorch_lightning/trainer/trainer.py, line 521, in train self.train_loop.run_training_epoch()[SEP]File <*>/site-packages/pytorch_lightning/trainer/training_loop.py, line 588, in run_training_epoch self.trainer.run_evaluation(test_mode=False)[SEP]File <*>/site-packages/pytorch_lightning/trainer/trainer.py, line 613, in run_evaluation self.evaluation_loop.log_evaluation_step_metrics(output, batch_idx)[SEP]File <*>/site-packages/pytorch_lightning/trainer/evaluation_loop.py, line 346, in log_evaluation_step_metrics self.__log_result_step_metrics(step_log_metrics, step_pbar_metrics, batch_idx)[SEP]File <*>/site-packages/pytorch_lightning/trainer/evaluation_loop.py, line 350, in __log_result_step_metrics cached_batch_pbar_metrics, cached_batch_log_metrics = cached_results.update_logger_connector()[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 378, in update_logger_connector batch_log_metrics = self.get_latest_batch_log_metrics()[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 418, in get_latest_batch_log_metrics batch_log_metrics = self.run_batch_from_func_name(""get_batch_log_metrics"")[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 414, in run_batch_from_func_name results = [func(include_forked_originals=False) for func in results][SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 414, in <listcomp> results = [func(include_forked_originals=False) for func in results][SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 122, in get_batch_log_metrics return self.run_latest_batch_metrics_with_func_name(""get_batch_log_metrics"", *args, **kwargs)[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 115, in run_latest_batch_metrics_with_func_name for dl_idx in range(self.num_dataloaders)[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 115, in <listcomp> for dl_idx in range(self.num_dataloaders)[SEP]File <*>/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py, line 100, in get_latest_from_func_name results.update(func(*args, add_dataloader_idx=add_dataloader_idx, **kwargs))[SEP]File <*>/site-packages/pytorch_lightning/core/step_result.py, line 298, in get_batch_log_metrics result[dl_key] = self[k]._forward_cache.detach()[SEP]AttributeError: 'NoneType' object has no attribute 'detach'",,
528,65529897,0,1,,,"File <*>/site-packages/tensorflow/python/pywrap_tensorflow.py, line 64, in <module> from tensorflow.python._pywrap_tensorflow_internal import *[SEP]ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.",,
529,65679823,0,1,,,"File <stdin>, line 24, in <module> [CODE][SEP]TypeError: expected CPU (got CUDA)",,
530,65710713,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/site-packages/smdistributed/dataparallel/__init__.py, line 16, in <module> import smddpcommon as hc[SEP]ImportError: libc10.so: cannot open shared object file: No such file or directory",,
531,30236070,0,2,,,"File <*>python3.4/site-packages/theano/gof/op.py, line 517, in __call__(self, *inputs, **kwargs) storage_map[ins] = [self._get_test_value(ins)][SEP]File <*>python3.4/site-packages/theano/gof/op.py, line 479, in _get_test_value(cls, v) raise AttributeError('%s has no test value' % v)[SEP]AttributeError: x has no test value",,
532,30236070,0,2,,,"File [FILE], line 5, in <module>() z = x + y[SEP]File <*>python3.4/site-packages/theano/tensor/var.py, line 128, in __add__(self, other) return theano.tensor.basic.add(self, other)[SEP]File <*>python3.4/site-packages/theano/gof/op.py, line 525, in __call__(self, *inputs, **kwargs) raise ValueError('Cannot compute test value: input %i (%s) of Op %s missing default value' % (i, ins, node))[SEP]ValueError: Cannot compute test value: input 0 (x) of Op Elemwise{add,no_inplace}(x, y) missing default value",,
533,31936080,0,2,,,"File [FILE], line 16, in <module>() caffe.Net(net_param, caffe.TEST)[SEP]ArgumentError: Python argument types in Net.__init__(Net, NetParameter, int) did not match C++ signature: __init__(boost::python::api::object, std::string, std::string, int) __init__(boost::python::api::object, std::string, int)",,
534,32280071,0,2,,,"File [FILE], line 19, in <module>() rotate_x_axis_theano = theano.function([angle_var],rotate_x_axis_expr(angle_var))[SEP]File [FILE], line 14, in rotate_x_axis_expr(angle) R[1][1] = cosa; R[1][2] = -sina[SEP]TypeError: 'TensorVariable' object does not support item assignment",,
535,33474424,0,2,,,"File [FILE], line 2, in <module>() y_pred = model.predict(X_nn)[SEP]File <*>/site-packages/keras/models.pyc, line 493, in predict(self, X, batch_size, verbose) return self._predict_loop(self._predict, X, batch_size, verbose)[0][SEP]AttributeError: 'Sequential' object has no attribute '_predict'",,
536,33664651,0,2,,,"File [FILE], line 1, in <module>() import input_data[SEP]ImportError: No module named input_data",,
537,33808368,0,2,,,"File [FILE], line 9, in <module>() example, label = sess.run([features, col1])[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.pyc, line 345, in run(self, fetches, feed_dict) results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.pyc, line 419, in _do_run(self, target_list, fetch_list, feed_dict) e.code)[SEP]InvalidArgumentError: Field 1 in record 0 is not a valid int32: 0.766126609",,
538,34727431,0,2,,,"File [FILE], line 1, in <module>() saver.restore(sess, ""params.ckpt"")[SEP]File <*>python3.5/site-packages/tensorflow/python/training/saver.py, line 891, in restore(self, sess, save_path) sess.run([self._restore_op_name], {self._filename_tensor_name: save_path})[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 368, in run(self, fetches, feed_dict) results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)[SEP]File <*>python3.5/site-packages/tensorflow/python/client/session.py, line 428, in _do_run(self, target_list, fetch_list, feed_dict) target_list)[SEP]SystemError: <built-in function delete_Status> returned a result with an error set",,
539,35747388,0,2,,,"File [FILE], line 1, in <module>() T.grad(cost=cost, wrt=reg.weights)[SEP]File <*>python2.7/site-packages/theano/gradient.pyc, line 432, in grad(c ost, wrt, consider_constant, disconnected_inputs, add_names, known_grads, return_disconnected ) raise TypeError(""cost must be a scalar."")[SEP]TypeError: cost must be a scalar.",,
540,36927025,0,2,,,"File [FILE], line 3, in <module>() batch_size=16)[SEP]File <*>python2.7/site-packages/keras/models.pyc, line 402, in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs) sample_weight=sample_weight)[SEP]File <*>python2.7/site-packages/keras/engine/training.pyc, line 971, in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight) batch_size=batch_size)[SEP]File <*>python2.7/site-packages/keras/engine/training.pyc, line 911, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size) check_loss_and_target_compatibility(y, self.loss_functions, self.internal_output_shapes)[SEP]File <*>python2.7/site-packages/keras/engine/training.pyc, line 184, in check_loss_and_target_compatibility(targets, losses, output_shapes) ' while using as loss `categorical_crossentropy`. '[SEP]Exception: You are passing a target array of shape (10105, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via: ``` from keras.utils.np_utils import to_categorical y_binary = to_categorical(y_int) ``` Alternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",,
541,37267584,0,2,,,"File [FILE], line 30, in <module>() sess.run(optimizer, feed_dict={X: x, y: y})[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.pyc, line 340, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python2.7/site-packages/tensorflow/python/client/session.pyc, line 542, in _run(self, handle, fetches, feed_dict, options, run_metadata) + e.args[0])[SEP]TypeError: Cannot interpret feed_dict key as Tensor: Can not convert a float64 into a Tensor.",,
542,37337728,0,2,,,"File [FILE], line 2, in <module>() sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 340, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 564, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_string, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 637, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) target_list, options, run_metadata)[SEP]File <*>python2.7/dist-packages/tensorflow/python/client/session.pyc, line 659, in _do_call(self, fn, *args) e.code)[SEP]InternalError: Blas SGEMM launch failed : a.shape=(100, 784), b.shape=(784, 10), m=100, n=10, k=784 [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_Placeholder_0/_4, Variable/read)]]",,
543,37975861,0,2,,,"File [FILE], line 1, in <module>() biases = tf.get_variable('biases', [64], tf.constant_initializer(0.0))[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 732, in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape) partitioner=partitioner, validate_shape=validate_shape)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 596, in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape) partitioner=partitioner, validate_shape=validate_shape)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 161, in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape) caching_device=caching_device, validate_shape=validate_shape)[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc, line 425, in _get_single_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, validate_shape) dtype = dtypes.as_dtype(dtype)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/dtypes.pyc, line 536, in as_dtype(type_value) if key == type_value:[SEP]TypeError: data type not understood",,
544,38241758,0,2,,,"File [FILE], line 14, in <module>() p.fit(x=df_train, y=df_train, steps=10, batch_size=100)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 173, in fit(self, x, y, input_fn, steps, batch_size, monitors) input_fn, feed_fn = _get_input_fn(x, y, batch_size)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 67, in _get_input_fn(x, y, batch_size) x, y, n_classes=None, batch_size=batch_size)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.pyc, line 99, in setup_train_data_feeder(X, y, n_classes, batch_size, shuffle, epochs) X, y = _data_type_filter(X, y)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.pyc, line 67, in _data_type_filter(X, y) X = extract_pandas_data(X)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/pandas_io.pyc, line 53, in extract_pandas_data(data) raise ValueError('Data types for data must be int, float, or bool.')[SEP]ValueError: Data types for data must be int, float, or bool.",,
545,38618960,0,2,,,"File [FILE], line 7, in <module>() input_map={'import/pool5':out_pool})[SEP]File <*>python3.4/dist-packages/tensorflow/python/framework/importer.py, line 335, in import_graph_def(graph_def, input_map, return_elements, name, op_dict) ops.set_shapes_for_outputs(op)[SEP]File <*>python3.4/dist-packages/tensorflow/python/framework/ops.py, line 1612, in set_shapes_for_outputs(op) shapes = shape_func(op)[SEP]File <*>/roi_pooling_op_grad.py, line 15, in _roi_pool_shape(op) dims_rois = op.inputs[1].get_shape().as_list()[SEP]File <*>python3.4/dist-packages/tensorflow/python/framework/tensor_shape.py, line 747, in as_list(self) return [dim.value for dim in self._dims][SEP]TypeError: 'NoneType' object is not iterable",,
546,39352865,0,2,,,"File [FILE], line 7, in <module>() hidden1 = tf.nn.relu(tf.matmul(images_placeholder, weights) + biases)[SEP]File <*>python3.4/site-packages/tensorflow/python/ops/math_ops.py, line 1325, in matmul(a, b, transpose_a, transpose_b, a_is_sparse, b_is_sparse, name) with ops.op_scope([a, b], name, ""MatMul"") as name:[SEP]File <*>python3.4/contextlib.py, line 59, in __enter__(self) return next(self.gen)[SEP]File <*>python3.4/site-packages/tensorflow/python/framework/ops.py, line 4016, in op_scope(values, name, default_name) g = _get_graph_from_inputs(values)[SEP]File <*>python3.4/site-packages/tensorflow/python/framework/ops.py, line 3814, in _get_graph_from_inputs(op_input_list, graph) _assert_same_graph(original_graph_element, graph_element)[SEP]File <*>python3.4/site-packages/tensorflow/python/framework/ops.py, line 3759, in _assert_same_graph(original_item, item) ""%s must be from the same graph as %s."" % (item, original_item))[SEP]ValueError: Tensor(""weights:0"", shape=(1024, 200), dtype=float32_ref) must be from the same graph as Tensor(""Placeholder:0"", shape=(100, 1024), dtype=float32).`",,
547,39779184,0,2,,,"File [FILE], line 13, in <module>() m.fit(input_fn=train_input_fn, steps=200)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 240, in fit(self, x, y, input_fn, steps, batch_size, monitors, max_steps) max_steps=max_steps)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc, line 550, in _train_model(self, input_fn, steps, feed_fn, init_op, init_feed_fn, init_fn, device_fn, monitors, log_every_steps, fail_on_nan_loss, max_steps) train_op, loss_op = self._get_train_ops(features, targets)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.pyc, line 336, in _get_train_ops(self, features, targets) return super(LinearRegressor, self)._get_train_ops(features, targets)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.pyc, line 182, in _get_train_ops(self, features, targets) logits = self._logits(features, is_training=True)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.pyc, line 271, in _logits(self, features, is_training) logits = self._linear_logits(features, is_training)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.pyc, line 233, in _linear_logits(self, features, is_training) features, self._linear_feature_columns, is_training)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/composable_model.pyc, line 177, in build_model(self, features, feature_columns, is_training) scope=scope)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/feature_column_ops.pyc, line 178, in weighted_sum_from_feature_columns(columns_to_tensors, feature_columns, num_outputs, weight_collections, trainable, scope) transformed_tensor = transformer.transform(column)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/feature_column_ops.pyc, line 384, in transform(self, feature_column) feature_column.insert_transformed_feature(self._columns_to_tensors)[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/feature_column.pyc, line 364, in insert_transformed_feature(self, columns_to_tensors) name=self.name + ""_lookup"")[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/gen_string_ops.pyc, line 185, in string_to_hash_bucket_fast(input, num_buckets, name) num_buckets=num_buckets, name=name)[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc, line 463, in apply_op(self, op_type_name, name, **keywords) (prefix, dtypes.as_dtype(input_arg.type).name))[SEP]TypeError: Input 'input' of 'StringToHashBucketFast' Op has type int64 that does not match expected type of string.",,
548,40367923,0,2,,,"File [FILE], line 27, in () train = model.train(images, labels)[SEP]File [FILE], line 62, in train(self, images, labels) logits = model._create_model(images)[SEP]File [FILE], line 41, in _create_model(self, inputs) inputs = self._create_dense_layer(name, inputs, n_in, n_out)[SEP]File [FILE], line 27, in _create_dense_layer(self, name, inputs, n_in, n_out, activation) weights = self._weights([n_in, n_out])[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/template.py, line 267, in __call__(self, *args, **kwargs) return self._call_func(args, kwargs, check_for_new_variables=False)[SEP]File <*>python3.5/site-packages/tensorflow/python/ops/template.py, line 208, in _call_func(self, args, kwargs, check_for_new_variables) result = self._func(*args, **kwargs)[SEP]TypeError: _real_weights() missing 1 required positional argument: 'shape'",,
549,47347098,0,2,,,"File [FILE], line 1, in <module>() audiocnn(input)[SEP]File <*>python2.7/site-packages/torch/nn/modules/module.pyc, line 224, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File [FILE], line 17, in forward(self, x) _, (_, _) = self.lstm(x,(h_0,c_0)) # x dim : 2 x 1 x 256[SEP]File <*>python2.7/site-packages/torch/nn/modules/rnn.pyc, line 162, in forward(self, input, hx) output, hidden = func(input, self.all_weights, hx)[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 351, in forward(input, *fargs, **fkwargs) return func(input, *fargs, **fkwargs)[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 244, in forward(input, weight, hidden) nexth, output = func(input, hidden, weight)[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 84, in forward(input, hidden, weight) hy, output = inner(input, hidden[l], weight[l])[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 113, in forward(input, hidden, weight) hidden = inner(input[i], hidden, *weight)[SEP]File <*>python2.7/site-packages/torch/nn/_functions/rnn.pyc, line 31, in LSTMCell(input, hidden, w_ih, w_hh, b_ih, b_hh) gates = F.linear(input, w_ih, b_ih) + F.linear(hx, w_hh, b_hh)[SEP]File <*>python2.7/site-packages/torch/nn/functional.pyc, line 553, in linear(input, weight, bias) return torch.addmm(bias, input, weight.t())[SEP]File <*>python2.7/site-packages/torch/autograd/variable.pyc, line 924, in addmm(cls, *args) return cls._blas(Addmm, args, False)[SEP]File <*>python2.7/site-packages/torch/autograd/variable.pyc, line 920, in _blas(cls, args, inplace) return cls.apply(*(tensors + (alpha, beta, inplace)))[SEP]RuntimeError: save_for_backward can only save input or output tensors, but argument 0 doesn't satisfy this condition",,
550,47422817,0,2,,,"File [FILE], line 10, in <module>() left.save('left.h5') # creates a HDF5 file 'my_model.h5'[SEP]File <*>python3.4/dist-packages/keras/engine/topology.py, line 2506, in save(self, filepath, overwrite, include_optimizer) save_model(self, filepath, overwrite, include_optimizer)[SEP]File <*>python3.4/dist-packages/keras/models.py, line 55, in save_model(model, filepath, overwrite, include_optimizer) raise ImportError('`save_model` requires h5py.')[SEP]ImportError: `save_model` requires h5py.",,
551,48172953,0,2,,,"File [FILE], line 1, in <module>() from imagenet_utils import preprocess_input, decode_predictions[SEP]ImportError: No module named 'imagenet_utils'",,
552,48377214,0,2,,,"File [FILE], line 18, in <module>() curr_loss = train(train_loader, model, criterion, epoch, num_epochs)[SEP]File [FILE], line 18, in train(train_loader, model, criterion, epoch, num_epochs) loss = criterion(outputs, labels)[SEP]File <*>python3.5/dist-packages/torch/nn/modules/module.py, line 325, in _ _call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File [FILE], line 11, in forward(self, logits, targets) return self.crossEntropy_loss(probs_flat, targets_flat)[SEP]File <*>python3.5/dist-packages/torch/nn/modules/module.py, line 325, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.5/dist-packages/torch/nn/modules/loss.py, line 601, in f orward(self, input, target) self.ignore_index, self.reduce)[SEP]File <*>python3.5/dist-packages/torch/nn/functional.py, line 1140, in cross_entropy(input, target, weight, size_average, ignore_index, reduce) return nll_loss(log_softmax(input, 1), target, weight, size_average, ignore_index, reduce)[SEP]File <*>python3.5/dist-packages/torch/nn/functional.py, line 786, in log_softmax(input, dim, _stacklevel) return torch._C._nn.log_softmax(input, dim)[SEP]RuntimeError: dimension out of range (expected to be in range of [-1, 0], but got 1)",,
553,48482483,0,2,,,"File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn) input_tensors_as_shapes, status)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 4096 and 1000 for 'Assign_30' (op: 'Assign') with input shapes: [4096,3], [1000,3].",,
554,48482483,0,2,,,"File [FILE], line 2, in <module>() loaded_model = load_model('my_model_vgg16.h5')[SEP]File <*>/site-packages/keras/models.py, line 246, in load_model(filepath, custom_objects, compile) topology.load_weights_from_hdf5_group(f['model_weights'], model.layers)[SEP]File <*>/site-packages/keras/engine/topology.py, line 3166, in load_weights_from_hdf5_group(f, layers) K.batch_set_value(weight_value_tuples)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2365, in batch_set_value(tuples) assign_op = x.assign(assign_placeholder)[SEP]File <*>/site-packages/tensorflow/python/ops/variables.py, line 573, in assign(self, value, use_locking) return state_ops.assign(self._variable, value, use_locking=use_locking)[SEP]File <*>/site-packages/tensorflow/python/ops/state_ops.py, line 276, in assign(ref, value, validate_shape, use_locking, name) validate_shape=validate_shape)[SEP]File <*>/site-packages/tensorflow/python/ops/gen_state_ops.py, line 56, in assign(ref, value, validate_shape, use_locking, name) use_locking=use_locking, name=name)[SEP]File <*>/site-packages/tensorflow/python/framework/op_def_library.py, line 787, in _apply_op_helper(self, op_type_name, name, **keywords) op_def=op_def)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 2958, in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device) set_shapes_for_outputs(ret)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 2209, in set_shapes_for_outputs(op) shapes = shape_func(op)[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 2159, in call_with_requiring(op) return call_cpp_shape_fn(op, require_shape_fn=True)[SEP]File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 627, in call_cpp_shape_fn(op, require_shape_fn) require_shape_fn)[SEP]File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 691, in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn) raise ValueError(err.message)[SEP]ValueError: Dimension 0 in both shapes must be equal, but are 4096 and 1000 for 'Assign_30' (op: 'Assign') with input shapes: [4096,3], [1000,3].",,
555,48793510,0,2,,,"File <*>python3.6/dist-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn) input_tensors_as_shapes, status)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]InvalidArgumentError: Negative dimension size caused by subtracting 3 from 1 for 'conv1d_26/convolution/Conv2D' (op: 'Conv2D') with input shapes: [?,1,1,256], [1,3,256,256].",,
556,48842303,0,2,,,"File <*>python3.5/site-packages/keras/utils/vis_utils.py, line 27, in _check_pydot() raise ImportError('Failed to import pydot. You must install pydot'[SEP]AttributeError: 'NoneType' object has no attribute 'Dot'",,
557,48852696,0,2,,,"File [FILE], line 1, in <module>() import tensorflow as tf[SEP]ModuleNotFoundError: No module named 'tensorflow'",,
558,49088699,0,2,,,"File [FILE], line 4, in <module>() (x_train, y_train), (x_test, y_test) = mnist.load_data()[SEP]File <*>python3.6/site-packages/keras/datasets/mnist.py, line 23, in load_data(path) file_hash='8a61469f7ea1b51cbae51d4f78837e45')[SEP]File <*>python3.6/site-packages/keras/utils/data_utils.py, line 224, in get_file(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir) raise Exception(error_msg.format(origin, e.errno, e.reason))[SEP]Exception: URL fetch failure on https://s3.amazonaws.com/img-datasets/mnist.npz: None -- [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)",,
559,49089740,0,2,,,"File <*>/train.py, line 58, in <module>() flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.')[SEP]File <*>python3.6/dist-packages/tensorflow/python/platform/flags.py, line 58, in wrapper(*args, **kwargs) return original_function(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/absl/flags/_defines.py, line 241, in DEFINE_string(name, default, help, flag_values, **args) DEFINE(parser, name, default, help, flag_values, serializer, **args)[SEP]File <*>python3.6/dist-packages/absl/flags/_defines.py, line 82, in DEFINE(parser, name, default, help, flag_values, serializer, module_name, **args) flag_values, module_name)[SEP]File <*>python3.6/dist-packages/absl/flags/_defines.py, line 104, in DEFINE_flag(flag, flag_values, module_name) fv[flag.name] = flag[SEP]File <*>python3.6/dist-packages/absl/flags/_flagvalues.py, line 427, in __setitem__(self, name, flag) raise _exceptions.DuplicateFlagError.from_flag(name, self)[SEP]DuplicateFlagError: The flag 'master' is defined twice. First from object_detection/train.py, Second from object_detection/train.py. Description from first occurrence: Name of the TensorFlow master to use.",,
560,49089740,0,2,,,"File <*>/train.py, line 167, in <module>() tf.app.run()[SEP]File <*>python3.6/dist-packages/tensorflow/python/platform/app.py, line 126, in run(main, argv) _sys.exit(main(argv))[SEP]File <*>/train.py, line 107, in main(_) overwrite=True)[SEP]File <*>python3.6/dist-packages/tensorflow/python/lib/io/file_io.py, line 392, in copy(oldpath, newpath, overwrite) compat.as_bytes(oldpath), compat.as_bytes(newpath), overwrite, status)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]NotFoundError: ; No such file or directory",,
561,49137905,0,2,,,"File [FILE], line 35, in <module>() mean , variance = tf.nn.moments(X_train, axes = 1, keep_dims = True)[SEP]File <*>python2.7/nn_impl.pyc, line 666, in moments(x, axes, shift, name, keep_dims) y = math_ops.cast(x, dtypes.float32) if x.dtype == dtypes.float16 else x[SEP]TypeError: data type not understood",,
562,49161652,0,2,,,"File [FILE], line [NUM], in () [CODE][SEP]File [FILE], line [NUM], in [FUNC] [CODE][SEP]File <*>python3.6/site-packages/torch/autograd/variable.py, line [NUM], in setitem(self, key, value) [CODE][SEP]RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.",,
563,49192051,0,2,,,"File <*>/site-packages/tensorflow/python/client/session.py, line 1327, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1306, in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata) status, run_metadata)[SEP]File <*>/contextlib.py, line 89, in __exit__(self, type, value, traceback) next(self.gen)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 466, in raise_exception_on_not_ok_status() pywrap_tensorflow.TF_GetCode(status))[SEP]InvalidArgumentError: You must feed a value for placeholder tensor 'dense_84_target' with dtype float and shape [?,?] [[Node: dense_84_target = Placeholder[dtype=DT_FLOAT, shape=[?,?], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]",,
564,49237889,0,2,,,"File <*>/model_finegrained.py, line 1, in <module>() tf.Variable(2, name='a:b')[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/variables.py, line 213, in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint) constraint=constraint)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/variables.py, line 289, in _init_from_args(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint) [initial_value]) as name:[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 4932, in __enter__(self) return self._name_scope.__enter__()[SEP]File <*>python3.6/contextlib.py, line 81, in __enter__(self) return next(self.gen)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3514, in name_scope(self, name) raise ValueError(""'%s' is not a valid scope name"" % name)[SEP]ValueError: 'a:b' is not a valid scope name",,
565,49878836,0,2,,,"File [FILE], line 1, in <module>() for batch_idx, (data, target) in enumerate(train_loader):[SEP]File <*>python2.7/dist-packages/torch/utils/data/dataloader.pyc, line 259, in __next__(self) batch = self.collate_fn([self.dataset[i] for i in indices])[SEP]File <*>python2.7/dist-packages/torch/utils/data/dataloader.pyc, line 135, in default_collate(batch) return [default_collate(samples) for samples in transposed][SEP]File <*>python2.7/dist-packages/torch/utils/data/dataloader.pyc, line 112, in default_collate(batch) return torch.stack(batch, 0, out=out)[SEP]File <*>python2.7/dist-packages/torch/functional.pyc, line 64, in stack(sequence, dim, out) return torch.cat(inputs, dim)[SEP]RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 400 and 487 in dimension 2 at /pytorch/torch/lib/TH/generic/THTensorMath.c:2897",,
566,50190486,0,2,,,"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 282, in __init__(self, fetches, contraction_fn) fetch, allow_tensor=True, allow_operation=True))[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3590, in as_graph_element(self, obj, allow_tensor, allow_operation) return self._as_graph_element_locked(obj, allow_tensor, allow_operation)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3679, in _as_graph_element_locked(self, obj, allow_tensor, allow_operation) types_str))[SEP]TypeError: Can not convert a Iterator into a Tensor or Operation.",,
567,50190486,0,2,,,"File [FILE], line 49, in <module>() sess.run(train_iter)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 900, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1120, in _run(self, handle, fetches, feed_dict, options, run_metadata) self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 427, in __init__(self, graph, fetches, feeds, feed_handles) self._fetch_mapper = _FetchMapper.for_fetch(fetches)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 253, in for_fetch(fetch) return _ElementFetchMapper(fetches, contraction_fn)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 286, in __init__(self, fetches, contraction_fn) (fetch, type(fetch), str(e)))[SEP]TypeError: Fetch argument <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x7fa2c0697c88> has invalid type <class 'tensorflow.python.data.ops.iterator_ops.Iterator'>, must be a string or Tensor. (Can not convert a Iterator into a Tensor or Operation.)",,
568,50244706,0,2,,,"File [FILE], line 16, in <module>() grads = grad(model, x, y)[SEP]File [FILE], line 8, in grad(model, inputs, targets) return tape.gradient(loss_value, model.variables)[SEP]File <*>/site-packages/tensorflow/python/eager/backprop.py, line 767, in gradient(self, target, sources, output_gradients) output_gradients=output_gradients)[SEP]File <*>/site-packages/tensorflow/python/eager/imperative_grad.py, line 63, in imperative_grad(vspace, tape, target, sources, output_gradients) tape._tape, vspace, target, sources, output_gradients) # pylint: disable=protected-access[SEP]RuntimeError: Trying to call tape.gradient on a non-persistent tape while it is still active.",,
569,50321139,0,2,,,"File <*>/site-packages/tensorflow/python/client/session.py, line 1323, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1302, in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata) status, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]InvalidArgumentError: You must feed a value for placeholder tensor 'time_distributed_2_target' with dtype float and shape [?,?,?] [[Node: time_distributed_2_target = Placeholder[dtype=DT_FLOAT, shape=[?,?,?], _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]",,
570,50385447,0,2,,,"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1322, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1307, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1409, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata)[SEP]InvalidArgumentError: slice index 0 of dimension 0 out of bounds. [[Node: lstm_25/strided_slice_13 = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](lstm_25/transpose, loss_11/dense_58_loss/Const_2, lstm_25/strided_slice_9/stack_2, lstm_25/strided_slice_9/stack_2)]]",,
571,50420359,0,2,,,"File [FILE], line 57, in <module>() feed_dict=feed_dict)[SEP]TypeError: 'NoneType' object is not iterable",,
572,50546851,0,2,,,"File [FILE], line 2, in <module>() steps_per_epoch=1, epochs=15, verbose=2)[SEP]File <*>/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>/site-packages/keras/engine/training.py, line 2230, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1877, in train_on_batch(self, x, y, sample_weight, class_weight) class_weight=class_weight)[SEP]File <*>/site-packages/keras/engine/training.py, line 1480, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size) exception_prefix='target')[SEP]File <*>/site-packages/keras/engine/training.py, line 76, in _standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data][SEP]File <*>/site-packages/keras/engine/training.py, line 76, in <listcomp>(.0) data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data][SEP]AttributeError: 'Tensor' object has no attribute 'ndim'",,
573,50671948,0,2,,,"File <*>/site-packages/tensorflow/python/client/session.py, line 1322, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1307, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1409, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata)[SEP]InvalidArgumentError: Matrix size-incompatible: In[0]: [1,16384], In[1]: [1024,10] [[Node: dense_251/MatMul = MatMul[T=DT_FLOAT, _class=[""loc:@training_22/RMSprop/gradients/dense_251/MatMul_grad/MatMul""], transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](flatten_153/Reshape, dense_251/kernel/read)]] [[Node: loss_26/mul/_579 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1108_loss_26/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]",,
574,50825248,0,2,,,"File [FILE], line 7, in <module>() X = AttentionLayer()(X)[SEP]File <*>python3.6/site-packages/keras/engine/topology.py, line 619, in __call__(self, inputs, **kwargs) output = self.call(inputs, **kwargs)[SEP]File <*>/attention.py, line 51, in call(self, x) flatten_g = hw_flatten(g)[SEP]File <*>/attention.py, line 41, in hw_flatten(x) return K.reshape(x, shape=[x.shape[0], x.shape[1]*x.shape[2], x.shape[-1]])[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 1898, in reshape(x, shape) return tf.reshape(x, shape)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py, line 6113, in reshape(tensor, shape, name) ""Reshape"", tensor=tensor, shape=shape, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 513, in _apply_op_helper(self, op_type_name, name, **keywords) raise err[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 510, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1104, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 235, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/constant_op.py, line 214, in constant(value, dtype, shape, name, verify_shape) value, dtype=dtype, shape=shape, verify_shape=verify_shape))[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/tensor_util.py, line 521, in make_tensor_proto(values, dtype, shape, verify_shape) ""supported type."" % (type(values), values))[SEP]TypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [Dimension(None), Dimension(64), Dimension(8)]. Consider casting elements to a supported type.",,
575,51134105,0,2,,,"File [FILE], line 87, in <module>() initial_epoch=initial_epoch)[SEP]File <*>python36/site-packages/keras/legacy/interfaces.py, line 87, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python36/site-packages/keras/engine/training.py, line 2042, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) class_weight=class_weight)[SEP]File <*>python36/site-packages/keras/engine/training.py, line 1756, in train_on_batch(self, x, y, sample_weight, class_weight) check_batch_axis=True)[SEP]File <*>python36/site-packages/keras/engine/training.py, line 1378, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size) exception_prefix='input')[SEP]File <*>python36/site-packages/keras/engine/training.py, line 58, in _standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) 'expected no data, but got:', data)[SEP]ValueError: ('Error when checking model input: expected no data, but got:', [array([[[[1.62046947e+01, 0.00000000e+00, 0.00000000e+00, ...",,
576,51329159,0,2,,,"File [FILE], line 3, in <module>() plt.imshow(grid)[SEP]File <*>python3.6/site-packages/matplotlib/pyplot.py, line 3205, in imshow(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs) **kwargs)[SEP]File <*>python3.6/site-packages/matplotlib/__init__.py, line 1855, in inner(ax, *args, **kwargs) return func(ax, *args, **kwargs)[SEP]File <*>python3.6/site-packages/matplotlib/axes/_axes.py, line 5487, in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs) im.set_data(X)[SEP]File <*>python3.6/site-packages/matplotlib/image.py, line 653, in set_data(self, A) raise TypeError(""Invalid dimensions for image data"")[SEP]TypeError: Invalid dimensions for image data",,
577,51329159,0,2,,,"File [FILE], line 2, in <module>() grid = torchvision.utils.make_grid(w.permute(0,2,3,1), nrow=5)[SEP]File <*>python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/utils.py, line 85, in make_grid(tensor, nrow, padding, normalize, range, scale_each, pad_value) .copy_(tensor[k])[SEP]RuntimeError: The expanded size of the tensor (3) must match the existing size (640) at non-singleton dimension 0",,
578,51772042,0,2,,,"File [FILE], line 1, in <module>() df = pd.DataFrame((dataset))[SEP]File <*>python3.6/site-packages/pandas/core/frame.py, line 404, in __init__(self, data, index, columns, dtype, copy) raise ValueError('DataFrame constructor not properly called!')[SEP]ValueError: DataFrame constructor not properly called!",,
579,52227910,0,2,,,"File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1330, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1315, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1423, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) status, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 516, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]FailedPreconditionError: Attempting to use uninitialized value W_4 [[Node: W_4/read = Identity[T=DT_FLOAT, _class=[""loc:@W_4""], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](W_4)]]",,
580,52227910,0,2,,,"File [FILE], line 116, in <module>() print('Test_accuracy : ',sess.run(accuracy, feed_dict={input: x, output: y,keep_prob:1.0}))[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 908, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1143, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1324, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1343, in _do_call(self, fn, *args) raise type(e)(node_def, op, message)[SEP]FailedPreconditionError: Attempting to use uninitialized value W_4 [[Node: W_4/read = Identity[T=DT_FLOAT, _class=[""loc:@W_4""], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](W_4)]]",,
581,52277083,0,2,,,"File [FILE], line 4, in <module>() model = torch.load('checkpoint.pth')[SEP]File <*>python3.6/site-packages/torch/serialization.py, line 303, in load(f, map_location, pickle_module) return _load(f, map_location, pickle_module)[SEP]File <*>python3.6/site-packages/torch/serialization.py, line 469, in _load(f, map_location, pickle_module) result = unpickler.load()[SEP]AttributeError: Can't get attribute 'Network' on <module '__main__'>",,
582,52711895,0,2,,,"File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 510, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1144, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 981, in _TensorTensorConversionFunction(t, dtype, name, as_ref) (dtype.name, t.dtype.name, str(t)))[SEP]ValueError: Tensor conversion requested dtype float16 for Tensor with dtype float32: 'Tensor(""sampled_softmax_loss/Log:0"", shape=(64, 1), dtype=float32)'",,
583,52711895,0,2,,,"File [FILE], line 48, in <module>() labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1349, in sampled_softmax_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name, seed) seed=seed)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1128, in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed) true_logits -= math_ops.log(true_expected_count)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/math_ops.py, line 862, in binary_op_wrapper(x, y) return func(x, y, name=name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 8318, in sub(x, y, name) ""Sub"", x=x, y=y, name=name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 546, in _apply_op_helper(self, op_type_name, name, **keywords) inferred_from[input_arg.type_attr]))[SEP]TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type float16 of argument 'x'.",,
584,53003208,0,2,,,"File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1334, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1319, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) options, feed_dict, fetch_list, target_list, run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1407, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata)[SEP]UnimplementedError: File system scheme '[local]' not implemented (file: 'checkpointsBook2Vec5Inputs') [[{{node save/SaveV2}} = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, embeddings, embeddings/Shampoo, embeddings/Shampoo_1, embeddings/Shampoo_2, epochCount, softmax_biases, softmax_weights, softmax_weights/Shampoo, softmax_weights/Shampoo_1, softmax_weights/Shampoo_2)]]",,
585,53003208,0,2,,,"File [FILE], line 50, in <module>() save_path = saver.save(session, ""checkpointsBook2Vec5Inputs/Research2VecCS4.ckpt"") #Save checkpoint[SEP]File <*>python3.6/dist-packages/tensorflow/python/training/saver.py, line 1441, in save(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs) {self.saver_def.filename_tensor_name: checkpoint_file})[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 929, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1152, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1328, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata)[SEP]File <*>python3.6/dist-packages/tensorflow/python/client/session.py, line 1348, in _do_call(self, fn, *args) raise type(e)(node_def, op, message)[SEP]UnimplementedError: File system scheme '[local]' not implemented (file: 'checkpointsBook2Vec5Inputs') [[node save/SaveV2 (defined at <ipython-input-15-c14caac2081d>:45) = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, embeddings, embeddings/Shampoo, embeddings/Shampoo_1, embeddings/Shampoo_2, epochCount, softmax_biases, softmax_weights, softmax_weights/Shampoo, softmax_weights/Shampoo_1, softmax_weights/Shampoo_2)]]",,
586,53405657,0,2,,,"File [FILE], line 3, in <module>() steps=10)[SEP]File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 354, in train(self, input_fn, hooks, steps, max_steps, saving_listeners) loss = self._train_model(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1207, in _train_model(self, input_fn, hooks, saving_listeners) return self._train_model_default(input_fn, hooks, saving_listeners)[SEP]File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1237, in _train_model_default(self, input_fn, hooks, saving_listeners) features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)[SEP]File <*>python3.6/dist-packages/tensorflow/python/estimator/estimator.py, line 1195, in _call_model_fn(self, features, labels, mode, config) model_fn_results = self._model_fn(features=features, **kwargs)[SEP]File [FILE], line 35, in my_model(features, labels, mode, params) num_classes=vocabulary_size))[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1248, in nce_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name) name=name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/nn_impl.py, line 1031, in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed) if labels.dtype != dtypes.int64:[SEP]TypeError: data type not understood",,
587,53410419,0,2,,,"File [FILE], line 8, in <module>() concat = tf.keras.layers.Concatenate()((features['a'], features['b']))[SEP]File <*>/base_layer.py, line 753, in __call__(self, inputs, *args, **kwargs) self.build(input_shapes)[SEP]File <*>/tf_utils.py, line 150, in wrapper(instance, input_shape) input_shape = tuple(tensor_shape.TensorShape(input_shape).as_list())[SEP]File <*>/tensor_shape.py, line 690, in __init__(self, dims) self._dims = [as_dimension(d) for d in dims_iter][SEP]File <*>/tensor_shape.py, line 632, in as_dimension(value) return Dimension(value)[SEP]File <*>/tensor_shape.py, line 185, in __init__(self, value) self._value = int(value)[SEP]TypeError: int() argument must be a string or a number, not 'TensorShapeV1'",,
588,53588623,0,2,,,"File [FILE], line 5, in <module>() for i, data in enumerate(trainloader, 0):[SEP]File <*>python3.7/site-packages/torch/utils/data/dataloader.py, line 313, in __next__(self) indices = next(self.sample_iter) # may raise StopIteration[SEP]File <*>python3.7/site-packages/torch/utils/data/sampler.py, line 138, in __iter__(self) for idx in self.sampler:[SEP]File <*>python3.7/site-packages/torch/utils/data/sampler.py, line 34, in __iter__(self) return iter(range(len(self.data_source)))[SEP]TypeError: 'torch.Size' object cannot be interpreted as an integer",,
589,53879567,0,2,,,"File [FILE], line 3, in <module>() epochs = range(epochs)[SEP]NameError: name 'epochs' is not defined",,
590,53938962,0,2,,,"File [FILE], line 16, in <module>() dataset = dataset.padded_batch(2, padded_shapes=([None],[None]), padding_values=-1)[SEP]File <*>python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py, line 945, in padded_batch(self, batch_size, padded_shapes, padding_values, drop_remainder) drop_remainder)[SEP]File <*>python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py, line 2528, in __init__(self, input_dataset, batch_size, padded_shapes, padding_values, drop_remainder) input_dataset.output_types)[SEP]File <*>python3.6/dist-packages/tensorflow/python/data/util/nest.py, line 467, in map_structure_up_to(shallow_tree, func, *inputs) assert_shallow_structure(shallow_tree, input_tree)[SEP]File <*>python3.6/dist-packages/tensorflow/python/data/util/nest.py, line 301, in assert_shallow_structure(shallow_tree, input_tree, check_types) ""Input has type: %s."" % type(input_tree))[SEP]TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'int'>.",,
591,54029556,0,2,,,"File [FILE], line 4, in <module>() module_spec=""https://tfhub.dev/google/nnlm-en-dim128/1"")[SEP]File <*>python3.6/site-packages/tensorflow_hub/feature_column.py, line 74, in text_embedding_column(key, module_spec, trainable) module_spec = module.as_module_spec(module_spec)[SEP]File <*>python3.6/site-packages/tensorflow_hub/module.py, line 33, in as_module_spec(spec) return load_module_spec(spec)[SEP]File <*>python3.6/site-packages/tensorflow_hub/module.py, line 58, in load_module_spec(path) return registry.loader(path)[SEP]File <*>python3.6/site-packages/tensorflow_hub/registry.py, line 45, in __call__(self, *args, **kwargs) self._name, args, kwargs))[SEP]RuntimeError: Missing implementation that supports: loader(*('/var/folders/pc/h0fr0z2x1pjbmdb63mhn84_w0000gn/T/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997',), **{})",,
592,54112504,0,2,,,"File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 511, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1175, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 304, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 245, in constant(value, dtype, shape, name) allow_broadcast=True)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast))[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/tensor_util.py, line 454, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) raise ValueError(""None values not supported."")[SEP]ValueError: None values not supported.",,
593,54112504,0,2,,,"File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 525, in _apply_op_helper(self, op_type_name, name, **keywords) values, as_ref=input_arg.is_ref).dtype.name[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1175, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 304, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 245, in constant(value, dtype, shape, name) allow_broadcast=True)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast))[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/tensor_util.py, line 454, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) raise ValueError(""None values not supported."")[SEP]ValueError: None values not supported.",,
594,54112504,0,2,,,"File [FILE], line 5, in <module> hessian = tf.hessians(f, xy)[SEP]File <*>python3.7/site-packages/tensorflow/python/ops/gradients_impl.py, line 1407, in hessians(ys, xs, name, colocate_gradients_with_ops, gate_gradients, aggregation_method) gradient = array_ops.reshape(gradient, [-1])[SEP]File <*>python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py, line 7180, in reshape(tensor, shape, name) ""Reshape"", tensor=tensor, shape=shape, name=name)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 529, in _apply_op_helper(self, op_type_name, name, **keywords) (input_name, err))[SEP]ValueError: Tried to convert 'tensor' to a tensor and failed. Error: None values not supported.",,
595,54218604,0,2,,,"File [FILE], line 1, in () output = model(data)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line [NUM], in call(self, *input, **kwargs) [CODE][SEP]File <*>python3.6/dist-packages/torch/nn/functional.py, line 1354, in linear(input, weight, bias) output = input.matmul(weight.t())[SEP]RuntimeError: size mismatch, m1: [3584 x 28], m2: [784 x 128] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:940",,
596,54366265,0,2,,,"File [FILE], line 14, in <module>() random_search.fit(X_train, y_train)[SEP]File <*>python3.6/site-packages/sklearn/model_selection/_search.py, line 677, in fit(self, X, y, groups, **fit_params) base_estimator = clone(self.estimator)[SEP]File <*>python3.6/site-packages/sklearn/base.py, line 58, in clone(estimator, safe) % (repr(estimator), type(estimator)))[SEP]TypeError: Cannot clone object '<keras.engine.sequential.Sequential object at 0x7fc268d8abe0>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods.",,
597,54417736,0,2,,,"File [FILE], line 1, in <module> modl(x)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 477, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File [FILE], line 223, in forward(self, x) de2 = torch.cat([en6add,de2_],1)[SEP]RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 5 and 4 in dimension 2 at /opt/conda/conda-bld/pytorch_1535491974311/work/aten/src/TH/generic/THTensorMath.cpp:3616",,
598,54440859,0,2,,,"File [FILE], line 1, in <module>() tf.enable_eager_execution()[SEP]AttributeError: module 'tensorflow' has no attribute 'enable_eager_execution'",,
599,54441603,0,2,,,"File [FILE], line 1, in <module>() create_record()[SEP]File [FILE], line 17, in create_record() ""mfcc"":tf.train.Feature(float_list=tf.train.FloatList(value=mfcc.tolist()))[SEP]TypeError: [-389.381029172618, -393.08814551655723, -404.7248725876356, -407.1006984237564, -409.22695909850626 has type list, but expected one of: int, long, float",,
600,54479547,0,2,,,"File [FILE], line 6, in <module>() print(char_OneHotEncoding(torch.tensor(x_train, dtype=torch.long).cuda()).shape)[SEP]File [FILE], line 4, in char_OneHotEncoding(x) coded[:,i] = scatter(x[:,i])[SEP]File [FILE], line 9, in scatter(x) return torch.zeros(x.shape[0], 101).scatter_(1, x.view(-1,1), 1)[SEP]RuntimeError: Expected object of backend CPU but got backend CUDA for argument #3 'index'",,
601,54823475,0,2,,,"File [FILE], line 1, in <module> tflite_quantized_model = converter.convert()[SEP]File <*>python3.5/site-packages/tensorflow/contrib/lite/python/lite.py, line 453, in convert(self) **converter_kwargs)[SEP]File <*>python3.5/site-packages/tensorflow/contrib/lite/python/convert.py, line 342, in toco_convert_impl(input_data, input_tensors, output_tensors, *args, **kwargs) input_data.SerializeToString())[SEP]File <*>python3.5/site-packages/tensorflow/contrib/lite/python/convert.py, line 135, in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str) (stdout, stderr))[SEP]RuntimeError: TOCO failed see console for info.",,
602,55060736,0,2,,,"File [FILE], line 34, in <module>() train_op.minimize(cost, var_list=[w])[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py, line 296, in minimize(self, loss, var_list, grad_loss, name) loss, var_list=var_list, grad_loss=grad_loss)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py, line 328, in _compute_gradients(self, loss, var_list, grad_loss) loss_value = loss()[SEP]TypeError: 'tensorflow.python.framework.ops.EagerTensor' object is not callable",,
603,55210684,0,2,,,"File [FILE], line 51, in <module> model.fit([x_img_train, x_transform_train], y_train, batch_size=8)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1039, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs) validation_steps=validation_steps)[SEP]File <*>python3.6/site-packages/keras/engine/training_arrays.py, line 199, in fit_loop(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps) outs = f(ins_batch)[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 2715, in __call__(self, inputs) return self._call(inputs)[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 2675, in _call(self, inputs) fetched = self._callable_fn(*array_vals)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1439, in __call__(self, *args, **kwargs) run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/errors_impl.py, line 528, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]InvalidArgumentError: Incompatible shapes: [8,28,28,32] vs. [8,32] [[{{node training_5/Adam/gradients/affine_transform_18/mul_grad/BroadcastGradientArgs}} = BroadcastGradientArgs[T=DT_INT32, _class=[""loc:@training_5/Adam/gradients/batch_normalization_22/cond/Merge_grad/cond_grad""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](training_5/Adam/gradients/affine_transform_18/mul_grad/Shape, training_5/Adam/gradients/affine_transform_18/mul_grad/Shape_1)]]",,
604,55244001,0,2,,,"File [FILE], line 4, in <module>() validation_steps=10, verbose=1, callbacks=[lr_reduction])[SEP]File <*>python3.6/site-packages/keras/legacy/interfaces.py, line 91, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 1418, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/keras/engine/training_generator.py, line 181, in fit_generator(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) generator_output = next(output_generator)[SEP]File <*>python3.6/site-packages/keras/utils/data_utils.py, line 601, in get(self) six.reraise(*sys.exc_info())[SEP]File <*>python3.6/site-packages/six.py, line 693, in reraise(tp, value, tb) raise value[SEP]File <*>python3.6/site-packages/keras/utils/data_utils.py, line 595, in get(self) inputs = self.queue.get(block=True).get()[SEP]File <*>python3.6/pool.py, line 644, in get(self, timeout) raise self._value[SEP]File <*>python3.6/pool.py, line 119, in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception) result = (True, func(*args, **kwds))[SEP]File <*>python3.6/site-packages/keras/utils/data_utils.py, line 401, in get_index(uid, i) return _SHARED_SEQUENCES[uid][i][SEP]File <*>python3.6/site-packages/keras_preprocessing/image/iterator.py, line 65, in __getitem__(self, idx) return self._get_batches_of_transformed_samples(index_array)[SEP]File <*>python3.6/site-packages/keras_preprocessing/image/iterator.py, line 235, in _get_batches_of_transformed_samples(self, index_array) x = self.image_data_generator.standardize(x)[SEP]File <*>python3.6/site-packages/keras_preprocessing/image/image_data_generator.py, line 697, in standardize(self, x) x = self.preprocessing_function(x)[SEP]File [FILE], line 2, in preprocess(im) im = cv2.imread(im, 1)[SEP]TypeError: bad argument type for built-in operation",,
606,55645953,0,2,,,"File [FILE], line 1, in <module> model.fit(dataset, epochs=10, steps_per_epoch=10)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 791, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1515, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch')[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py, line 257, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) batch_outs = batch_function(*batch_data)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 1238, in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics) extract_tensors_from_dataset=True)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 2596, in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset) exception_prefix='input')[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 349, in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) str(data_shape))[SEP]ValueError: Error when checking input: expected input_1 to have shape (32,) but got array with shape (1,)",,
607,55650121,0,2,,,"File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1659, in _create_c_op(graph, node_def, inputs, control_inputs) c_op = c_api.TF_FinishOperation(op_desc)[SEP]InvalidArgumentError: Shapes must be equal rank, but are 2 and 3 for 'ScatterUpdate' (op: 'ScatterUpdate') with input shapes: [?,10], [?,2], [?,2].",,
608,55650121,0,2,,,"File [FILE], line 29, in <module>() output_data = top_n_filter_layer(input_layer)[SEP]File [FILE], line 20, in top_n_filter_layer(input_data, n, tf_dtype) output = tf.scatter_update(zeros_variable, indices_to_keep, values_to_keep)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/state_ops.py, line 299, in scatter_update(ref, indices, updates, use_locking, name) use_locking=use_locking, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py, line 1275, in scatter_update(ref, indices, updates, use_locking, name) use_locking=use_locking, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 788, in _apply_op_helper(self, op_type_name, name, **keywords) op_def=op_def)[SEP]File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3300, in create_op(***failed resolving arguments***) op_def=op_def)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1823, in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def) control_input_ops)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1662, in _create_c_op(graph, node_def, inputs, control_inputs) raise ValueError(str(e))[SEP]ValueError: Shapes must be equal rank, but are 2 and 3 for 'ScatterUpdate' (op: 'ScatterUpdate') with input shapes: [?,10], [?,2], [?,2].",,
609,55665689,0,2,,,"File [FILE], line 32, in <module> loss = loss_func(output, b_y)[SEP]File <*>python3.5/site-packages/torch/nn/modules/module.py, line 489, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.5/site-packages/torch/nn/modules/loss.py, line 504, in forward(self, input, target) return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)[SEP]File <*>python3.5/site-packages/torch/nn/functional.py, line 2027, in binary_cross_entropy(input, target, weight, size_average, reduce, reduction) input, target, weight, reduction_enum)[SEP]RuntimeError: Expected object of scalar type Float but got scalar type Long for argument #2 'target'",,
610,55720464,0,2,,,"File [FILE], line 23, in <module>() print(model(torch.tensor(X)).size)[SEP]File [FILE], line 14, in forward(self, x) x = self.layer1(x)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 489, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/conv.py, line 187, in forward(self, input) self.padding, self.dilation, self.groups)[SEP]RuntimeError: Expected 3-dimensional input for 3-dimensional weight [20, 7, 5], but got 2-dimensional input of size [10, 7] instead",,
611,55734820,0,2,,,"File <*>python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py, line 612, in __call__(self, inputs, *args, **kwargs) outputs = self.call(inputs, *args, **kwargs)[SEP]File [FILE], line 8, in call(self, data_input) model = self.input_layer(data_input)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/input_layer.py, line 233, in Input(shape, batch_size, name, dtype, sparse, tensor, **kwargs) input_tensor=tensor)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/input_layer.py, line 94, in __init__(self, input_shape, batch_size, dtype, input_tensor, sparse, name, **kwargs) batch_input_shape = (batch_size,) + tuple(input_shape)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 449, in __iter__(self) ""Tensor objects are only iterable when eager execution is ""[SEP]TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.",,
612,55734820,0,2,,,"File [FILE], line 5, in <module>() train_step(x_sample=x_point, y_sample=y_point)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 418, in __call__(self, *args, **kwds) results = self._stateful_fn(*args, **kwds)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1287, in __call__(self, *args, **kwargs) graph_function, args, kwargs = self._maybe_define_function(args, kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1611, in _maybe_define_function(self, args, kwargs) args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/function.py, line 1512, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/func_graph.py, line 694, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/eager/def_function.py, line 317, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/func_graph.py, line 686, in wrapper(*args, **kwargs) ), args, kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/autograph/impl/api.py, line 392, in converted_call(f, owner, options, args, kwargs) result = converted_f(*effective_args, **kwargs)[SEP]File <*>/tmpluzodr7d.py, line 4, in tf__train_step(x_sample, y_sample) predictions = ag__.converted_call(nn_regressor, None, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (x_sample,), {})[SEP]File <*>python3.6/site-packages/tensorflow/python/autograph/impl/api.py, line 267, in converted_call(f, owner, options, args, kwargs) return _call_unconverted(f, args, kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/autograph/impl/api.py, line 188, in _call_unconverted(f, args, kwargs) return f(*args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py, line 625, in __call__(self, inputs, *args, **kwargs) exception_str + '\n""""""')[SEP]TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.",,
613,55762581,0,2,,,"File [FILE], line 72, in <module>() validate=True, resume=False, flow=True, use_cuda=cuda)[SEP]File <*>/train_helper.py, line 109, in train(model, num_epochs, train_set, dev_set, lr, batch_size, start_epoch, log, checkpoint_path, validate, resume, flow, use_cuda) loss = criterion(outputs, labels)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 489, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/loss.py, line 904, in forward(self, input, target) ignore_index=self.ignore_index, reduction=self.reduction)[SEP]File <*>python3.6/dist-packages/torch/nn/functional.py, line 1970, in cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction) return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)[SEP]File <*>python3.6/dist-packages/torch/nn/functional.py, line 1790, in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction) ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)[SEP]RuntimeError: Expected object of scalar type Long but got scalar type Byte for argument #2 'target'",,
614,55863106,0,2,,,"File [FILE], line 3, in <module> act([a,b])[SEP]File <*>python36/site-packages/keras/engine/base_layer.py, line 431, in __call__(self, inputs, **kwargs) self.build(unpack_singleton(input_shapes))[SEP]TypeError: build() takes 1 positional argument but 2 were given",,
615,55904359,0,2,,,"File [FILE], line 17, in <module>() d1, d2 = sess.run((d_fx1, d_fx2))[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 929, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1137, in _run(self, handle, fetches, feed_dict, options, run_metadata) self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 471, in __init__(self, graph, fetches, feeds, feed_handles) self._fetch_mapper = _FetchMapper.for_fetch(fetches)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 261, in for_fetch(fetch) return _ListFetchMapper(fetch)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 370, in __init__(self, fetches) self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches][SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 370, in <listcomp>(.0) self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches][SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 258, in for_fetch(fetch) type(fetch)))[SEP]TypeError: Fetch argument None has invalid type <class 'NoneType'>",,
616,55904359,0,2,,,"File [FILE], line 27, in <module>() grads = sess.run(d_fx)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 929, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 1137, in _run(self, handle, fetches, feed_dict, options, run_metadata) self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 471, in __init__(self, graph, fetches, feeds, feed_handles) self._fetch_mapper = _FetchMapper.for_fetch(fetches)[SEP]File <*>/site-packages/tensorflow/python/client/session.py, line 258, in for_fetch(fetch) type(fetch)))[SEP]TypeError: Fetch argument None has invalid type <class 'NoneType'>",,
617,56069319,0,2,,,"File [FILE], line 70, in <module>() filtered_output = keras.layers.merge.Multiply()([output, actions_input])[SEP]File <*>python3.6/dist-packages/keras/layers/merge.py, line 61, in _compute_elemwise_op_output_shape(self, shape1, shape2) str(shape1) + ' ' + str(shape2))[SEP]ValueError: Operands could not be broadcast together with shapes (2592,) (4,)",,
618,56133254,0,2,,,"File [FILE], line [NUM], in <module> [CODE][SEP]File <*>python3.7/site-packages/keras/engine/training.py, line 952, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs) batch_size=batch_size)[SEP]File <*>python3.7/site-packages/keras/engine/training.py, line 677, in _standardize_user_data(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size) self._set_inputs(x)[SEP]File <*>python3.7/site-packages/keras/engine/training.py, line 589, in _set_inputs(self, inputs, outputs, training) self.build(input_shape=(None,) + inputs.shape[1:])[SEP]File <*>python3.7/site-packages/keras/engine/sequential.py, line 221, in build(self, input_shape) x = layer(x)[SEP]File <*>python3.7/site-packages/keras/engine/base_layer.py, line 457, in __call__(self, inputs, **kwargs) output = self.call(inputs, **kwargs)[SEP]File <*>python3.7/site-packages/keras/layers/core.py, line 126, in call(self, inputs, training) training=training)[SEP]File <*>python3.7/site-packages/keras/backend/tensorflow_backend.py, line 3105, in in_train_phase(x, alt, training) training = learning_phase()[SEP]File <*>python3.7/site-packages/keras/backend/tensorflow_backend.py, line 135, in learning_phase() name='keras_learning_phase')[SEP]File <*>python3.7/site-packages/tensorflow/python/ops/array_ops.py, line 2093, in placeholder_with_default(input, shape, name) return gen_array_ops.placeholder_with_default(input, shape, name)[SEP]File <*>python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py, line 5925, in placeholder_with_default(input, shape, name) ""PlaceholderWithDefault"", input=input, shape=shape, name=name)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/op_def_library.py, line 511, in _apply_op_helper(self, op_type_name, name, **keywords) preferred_dtype=default_dtype)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1175, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors) ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 304, in _constant_tensor_conversion_function(v, dtype, name, as_ref) return constant(v, dtype=dtype, name=name)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 245, in constant(value, dtype, shape, name) allow_broadcast=True)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/constant_op.py, line 283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast))[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/tensor_util.py, line 573, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) append_fn(tensor_proto, proto_values)[SEP]File <*>/fast_tensor_util.pyxintensorflow.python, line [NUM], in tensorflow.python.framework.fast_tensor_util.AppendBoolArrayToTensorProto() [CODE][SEP]File <*>python3.7/site-packages/numpy/lib/type_check.py, line 547, in asscalar(***failed resolving arguments***) return a.item()[SEP]UnboundLocalError: local variable 'a' referenced before assignment",,
619,56222435,0,2,,,"File [FILE], line 11, in <module>() model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])[SEP]File <*>python3.6/dist-packages/tensorflow/python/training/checkpointable/base.py, line 442, in _method_wrapper(self, *args, **kwargs) method(self, *args, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 449, in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs) output_loss = weighted_loss(y_true, y_pred, sample_weight, mask)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py, line 676, in weighted(y_true, y_pred, weights, mask) score_array = math_ops.div_no_nan(score_array, weights)[SEP]File <*>python3.6/dist-packages/tensorflow/python/util/dispatch.py, line 180, in wrapper(*args, **kwargs) return target(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/math_ops.py, line 1027, in div_no_nan(x, y, name) return gen_math_ops.div_no_nan(x, y, name=name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py, line 3022, in div_no_nan(x, y, name) ""DivNoNan"", x=x, y=y, name=name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 610, in _apply_op_helper(self, op_type_name, name, **keywords) param_name=input_name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/op_def_library.py, line 60, in _SatisfiesTypeConstraint(dtype, attr_def, param_name) "", "".join(dtypes.as_dtype(x).name for x in allowed_list)))[SEP]TypeError: Value passed to parameter 'x' has DataType float16 not in list of allowed values: float32, float64",,
620,56251267,0,2,,,"File [FILE], line 9, in <module>() for i in train_iter:[SEP]File <*>python3.6/site-packages/torchtext/data/iterator.py, line 157, in __iter__(self) yield Batch(minibatch, self.dataset, self.device)[SEP]File <*>python3.6/site-packages/torchtext/data/batch.py, line 34, in __init__(self, data, dataset, device) setattr(self, name, field.process(batch, device=device))[SEP]File <*>python3.6/site-packages/torchtext/data/field.py, line 201, in process(self, batch, device) tensor = self.numericalize(padded, device=device)[SEP]File <*>python3.6/site-packages/torchtext/data/field.py, line 302, in numericalize(self, arr, device) arr = [self.vocab.stoi[x] for x in arr][SEP]File <*>python3.6/site-packages/torchtext/data/field.py, line 302, in <listcomp>(.0) arr = [self.vocab.stoi[x] for x in arr][SEP]AttributeError: 'Field' object has no attribute 'vocab'",,
621,56302243,0,2,,,"File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1659, in _create_c_op(graph, node_def, inputs, control_inputs) c_op = c_api.TF_FinishOperation(op_desc)[SEP]InvalidArgumentError: Dimensions must be equal, but are 1 and 64 for 'loss_1/zero_padding2d_5_loss/MatMul' (op: 'BatchMatMul') with input shapes: [?,64,64,1], [1,64,64,?].",,
622,56302243,0,2,,,"File [FILE], line 42, in <module> autoencoder.compile(optimizer='adadelta', loss=[custom_loss1,custom_loss2])[SEP]File <*>python3.6/site-packages/keras/engine/training.py, line 342, in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs) sample_weight, mask)[SEP]File <*>python3.6/site-packages/keras/engine/training_utils.py, line 404, in weighted(y_true, y_pred, weights, mask) score_array = fn(y_true, y_pred)[SEP]File [FILE], line 4, in custom_loss1(y_true, y_pred) dcor = -1*distance_correlation(y_true,encoded_layer)[SEP]File [FILE], line 4, in distance_correlation(y_true, y_pred) pred_d = pred_r - 2*tf.matmul(y_pred,tf.transpose(y_pred))+tf.transpose(pred_r)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/math_ops.py, line 2417, in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name) a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py, line 1423, in batch_mat_mul(x, y, adj_x, adj_y, name) ""BatchMatMul"", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/op_def_library.py, line 788, in _apply_op_helper(self, op_type_name, name, **keywords) op_def=op_def)[SEP]File <*>python3.6/site-packages/tensorflow/python/util/deprecation.py, line 507, in new_func(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 3300, in create_op(***failed resolving arguments***) op_def=op_def)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1823, in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def) control_input_ops)[SEP]File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1662, in _create_c_op(graph, node_def, inputs, control_inputs) raise ValueError(str(e))[SEP]ValueError: Dimensions must be equal, but are 1 and 64 for 'loss_1/zero_padding2d_5_loss/MatMul' (op: 'BatchMatMul') with input shapes: [?,64,64,1], [1,64,64,?].",,
623,56612386,0,2,,,"File [FILE], line 4, in <module> steps=20)[SEP]File <*>python3.7/site-packages/tensorflow/python/framework/ops.py, line 1185, in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors) raise RuntimeError(""Attempting to capture an EagerTensor without ""[SEP]RuntimeError: Attempting to capture an EagerTensor without building a function.",,
624,56783182,0,2,,,"File [FILE], line 3, in <module> train(n_epochs,net,loaders,optimizer,criterion,'saved_model/dog_model.pt')[SEP]File [FILE], line 24, in train(n_epochs, model, loader, optimizer, criterion, save_path) loss = criterion(outputs,target)[SEP]RuntimeError: The size of tensor a (133) must match the size of tensor b (10) at non-singleton dimension 1.",,
625,56886442,0,2,,,"File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 1969, in __setattr__(self, name, value) super(tracking.AutoTrackable, self).__setattr__(name, value)[SEP]AttributeError: can't set attribute",,
626,56886442,0,2,,,"File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 1974, in __setattr__(self, name, value) 'different name.').format(name))[SEP]AttributeError: Can't set the attribute ""name"", likely because it conflicts with an existing read-only @property of the object. Please choose a different name.",,
627,56935876,0,2,,,"File [FILE], line 1, in <module> import tensorflow_probability as tfp[SEP]ModuleNotFoundError: No module named 'tensorflow_probability'.",,
628,56999387,0,2,,,"File [FILE], line 1, in <module> train_image_ds = train_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 1146, in map(self, map_func, num_parallel_calls) self, map_func, num_parallel_calls, preserve_cardinality=True)[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 3264, in __init__(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function) use_legacy_function=use_legacy_function)[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 2591, in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs) self._function = wrapper_fn._get_concrete_function_internal()[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1366, in _get_concrete_function_internal(self, *args, **kwargs) *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1360, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1648, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1541, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 716, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 2585, in wrapper_fn(*args) ret = _wrapper_helper(*args)[SEP]File <*>/site-packages/tensorflow/python/data/ops/dataset_ops.py, line 2530, in _wrapper_helper(*args) ret = func(*nested_args)[SEP]File [FILE], line 3, in load_and_preprocess_image(path) return preprocess_image(image)[SEP]File [FILE], line 13, in preprocess_image(image) image = tf.image.central_crop(image, hor_scale_factor)[SEP]File <*>/site-packages/tensorflow/python/ops/image_ops_impl.py, line 643, in central_crop(image, central_fraction) if central_fraction <= 0.0 or central_fraction > 1.0:[SEP]File <*>/site-packages/tensorflow/python/framework/ops.py, line 698, in __bool__(self) raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""[SEP]TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",,
629,57237381,0,2,,,"File [FILE], line 35, in <module>() output = model(data)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/conv.py, line 338, in forward(self, input) self.padding, self.dilation, self.groups)[SEP]RuntimeError: Expected 4-dimensional input for 4-dimensional weight 32 3 3, but got 3-dimensional input of size [3, 224, 224] instead",,
630,57250679,0,2,,,"File [FILE], line 17, in <module>() opt.minimize(lambda: loss_function(intercept,slope,price_batch,size_batch),var_list=[intercept,slope])[SEP]File <*>python3.6/dist-packages/tensorflow/python/eager/tape.py, line 59, in watch(tape, tensor) pywrap_tensorflow.TFE_Py_TapeWatch(tape._tape, tensor) # pylint: disable=protected-access[SEP]SystemError: <built-in function TFE_Py_TapeWatch> returned a result with an error set",,
631,57443026,0,2,,,"File [FILE], line 1, in <module>() process_image('IMG_PATH')[SEP]File [FILE], line 5, in process_image(img_path) pImg = MobileNetV2.preprocess_input(img_array)[SEP]AttributeError: 'function' object has no attribute 'preprocess_input'",,
632,57476279,0,2,,,"File [FILE], line 23, in <module> optimizer = nlp.resume_training()[SEP]TypeError: Model() got multiple values for argument 'nr_class'",,
633,57478698,0,2,,,"File [FILE], line 22, in <module> dydx = tape.gradient(y, YIELDS)[SEP]File <*>/site-packages/tensorflow/python/eager/backprop.py, line 1002, in gradient(self, target, sources, output_gradients, unconnected_gradients) unconnected_gradients=unconnected_gradients)[SEP]File <*>/site-packages/tensorflow/python/eager/imperative_grad.py, line 76, in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients) compat.as_str(unconnected_gradients.value))[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 906, in backward_function(*args) list(args) + side_outputs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 612, in _call_flat(self, args) ""but got CompositeTensor: %r"" % args)[SEP]AssertionError: Expected all args to be Tensors or Variables; but got CompositeTensor: [<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x00000203013C2128>, <tf.Tensor: id=1024, shape=(), dtype=float32, numpy=-1.0>, <tf.Tensor: id=1025, shape=(10,), dtype=float32, numpy= array([0.04153733, 0.0851776 , 0.13988876, 0.27034396, 0.40101147, dtype=float32)>, <tf.Tensor: id=1026, shape=(10,), dtype=float32, numpy=array([ 1., 2., 3., 5., 7., 10., 12., 15., 20., 25.], dtype=float32)>, <tf.Tensor: id=1027, shape=(10,), dtype=float32, numpy= array([0.04153733, 0.0425888 , 0.04662959, 0.05406879, 0.05728735, dtype=float32)>]",,
634,57500582,0,2,,,"File [FILE], line 29, in <module> global_loss_list = global_training(lstm2)[SEP]File [FILE], line 5, in global_training(optimizee) _, global_loss_1 = learn2(LSTM_Optimizee, training_steps, retain_graph_flag=True, reset_theta=True)[SEP]File [FILE], line 45, in learn2(optimizee, unroll_train_steps, retain_graph_flag, reset_theta) loss.backward(retain_graph = retain_graph_flag) #The default is False, when the optimized LSTM is set to True[SEP]File <*>python3.7/site-packages/torch/tensor.py, line 118, in backward(self, gradient, retain_graph, create_graph) torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>python3.7/site-packages/torch/autograd/__init__.py, line 93, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables) allow_unreachable=True) # allow_unreachable flag[SEP]RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 10]] is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",,
635,57703808,0,2,,,"File [FILE], line 2, in <module> x.forward(torch.tensor([0,2,5,8]), higgs_bosson=2)[SEP]TypeError: forward() got an unexpected keyword argument 'higgs_bosson'",,
636,57779022,0,2,,,"File [FILE], line [NUM], in <module> [CODE][SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 458, in load_wrapper(*args, **kwargs) return load_function(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 550, in load_model(filepath, custom_objects, compile) model = _deserialize_model(h5dict, custom_objects, compile)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 292, in _deserialize_model(h5dict, custom_objects, compile) reshape=False)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 811, in convert_nested_model(weights) original_backend=original_backend))[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 823, in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape) weights = convert_nested_model(weights)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 799, in convert_nested_model(weights) original_backend=original_backend))[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 942, in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape) weights[0] = np.transpose(weights[0], (3, 2, 0, 1))[SEP]File <*>python3.6/site-packages/numpy/core/fromnumeric.py, line 639, in transpose(a, axes) return _wrapfunc(a, 'transpose', axes)[SEP]File <*>python3.6/site-packages/numpy/core/fromnumeric.py, line 56, in _wrapfunc(obj, method, *args, **kwds) return getattr(obj, method)(*args, **kwds)[SEP]ValueError: axes don't match array",,
637,57931067,0,2,,,"File <*>python3.6/site-packages/keras/engine/topology.py, line 425, in assert_input_compatibility(self, inputs) K.is_keras_tensor(x)[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 400, in is_keras_tensor(x) raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '[SEP]ValueError: Unexpectedly found an instance of type `<class 'keras.layers.normalization.BatchNormalization'>`. Expected a symbolic tensor instance.",,
638,57931067,0,2,,,"File [FILE], line 7, in <module>() A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')[SEP]File [FILE], line 45, in identity_block(X, f, filters, stage, block) X = Add()([X_shortcut,X])[SEP]File <*>python3.6/site-packages/keras/engine/topology.py, line 558, in __call__(self, inputs, **kwargs) self.assert_input_compatibility(inputs)[SEP]File <*>python3.6/site-packages/keras/engine/topology.py, line 431, in assert_input_compatibility(self, inputs) str(inputs) + '. All inputs to the layer '[SEP]ValueError: Layer add_1 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.normalization.BatchNormalization'>. Full input: [<tf.Tensor 'Placeholder:0' shape=(3, 4, 4, 6) dtype=float32>, <keras.layers.normalization.BatchNormalization object at 0x7f169c6d9668>]. All inputs to the layer should be tensors.",,
639,57935988,0,2,,,"File [FILE], line 16, in <module> print(stock_prediction())[SEP]File [FILE], line 25, in stock_prediction() model.fit(trainX, trainY, batch_size=1, epochs=200, verbose=2)[SEP]File <*>/site-packages/keras/engine/training.py, line 1178, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) validation_freq=validation_freq)[SEP]File <*>/site-packages/keras/engine/training_arrays.py, line 213, in fit_loop(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq) if batch_index == len(batches) - 1: # Last batch.[SEP]UnboundLocalError: local variable 'batch_index' referenced before assignment",,
640,57988897,0,2,,,"File [FILE], line 8, in <module> train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](root='./.data', ngrams=NGRAMS, vocab=None)[SEP]File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 170, in AG_NEWS(*args, **kwargs) return _setup_datasets(*((""AG_NEWS"",) + args), **kwargs)[SEP]File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 128, in _setup_datasets(dataset_name, root, ngrams, vocab, include_unk) vocab = build_vocab_from_iterator(_csv_iterator(train_csv_path, ngrams))[SEP]File <*>python36/site-packages/torchtext/vocab.py, line 557, in build_vocab_from_iterator(iterator) for tokens in iterator:[SEP]File <*>python36/site-packages/torchtext/datasets/text_classification.py, line 35, in _csv_iterator(data_path, ngrams, yield_cls) for row in reader:[SEP]File <*>python36/site-packages/torchtext/utils.py, line 130, in unicode_csv_reader(unicode_csv_data, **kwargs) csv.field_size_limit(sys.maxsize)[SEP]OverflowError: Python int too large to convert to C long",,
641,58143135,0,2,,,"File [FILE], line 1, in <module> import acgan[SEP]File <*>/acgan.py, line 3, in <module> from keras.datasets import mnist[SEP]File <*>python3.6/site-packages/keras/__init__.py, line 3, in <module> from . import utils[SEP]File <*>python3.6/site-packages/keras/utils/__init__.py, line 6, in <module> from . import conv_utils[SEP]File <*>python3.6/site-packages/keras/utils/conv_utils.py, line 9, in <module> from .. import backend as K[SEP]File <*>python3.6/site-packages/keras/backend/__init__.py, line 1, in <module> from .load_backend import epsilon[SEP]File <*>python3.6/site-packages/keras/backend/load_backend.py, line 90, in <module> from .tensorflow_backend import *[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 54, in <module> get_graph = tf_keras_backend.get_graph[SEP]File [FILE], line [NUM], in [FUNC] [CODE][SEP]AttributeError: module 'tensorflow.python.keras.backend' has no attribute 'get_graph'",,
642,58189394,0,2,,,"File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1356, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1339, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) self._extend_graph()[SEP]File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1374, in _extend_graph(self) tf_session.ExtendSession(self._session)[SEP]InvalidArgumentError: Cannot assign a device for operation MatMul: {{node MatMul}}was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.",,
643,58189394,0,2,,,"File [FILE], line 8, in <module> print (sess.run(c))[SEP]File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 950, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1173, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1350, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata)[SEP]File <*>python3.7/site-packages/tensorflow/python/client/session.py, line 1370, in _do_call(self, fn, *args) raise type(e)(node_def, op, message)[SEP]InvalidArgumentError: Cannot assign a device for operation MatMul: node MatMul (defined at <ipython-input-9-b145a02709f7>:5) was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.",,
644,58239781,0,2,,,"File <*>python3.6/dist-packages/pandas/core/indexes/base.py, line 2657, in get_loc(self, key, method, tolerance) return self._engine.get_loc(key)[SEP]File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE][SEP]File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE][SEP]KeyError: 'filename'",,
645,58239781,0,2,,,"File [FILE], line 20, in <module> subset='training')[SEP]File <*>python3.6/dist-packages/keras/preprocessing/image.py, line 594, in flow_from_dataframe(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs) **kwargs[SEP]File <*>python3.6/dist-packages/keras/preprocessing/image.py, line 235, in __init__(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames) validate_filenames=validate_filenames)[SEP]File <*>python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py, line 129, in __init__(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames) self._check_params(df, x_col, y_col, weight_col, classes)[SEP]File <*>python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py, line 181, in _check_params(self, df, x_col, y_col, weight_col, classes) if not all(df[x_col].apply(lambda x: isinstance(x, str))):[SEP]File <*>python3.6/dist-packages/pandas/core/frame.py, line 2927, in __getitem__(self, key) indexer = self.columns.get_loc(key)[SEP]File <*>python3.6/dist-packages/pandas/core/indexes/base.py, line 2659, in get_loc(self, key, method, tolerance) return self._engine.get_loc(self._maybe_cast_indexer(key))[SEP]File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE][SEP]File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE][SEP]KeyError: 'filename'",,
646,58343293,0,2,,,"File [FILE], line 4, in <module>() feature_extractor = hub.KerasLayer(_URL, input_shape=(_TARGET_SIZE, _TARGET_SIZE,3))[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py, line 167, in _variable_handle_from_shape_and_dtype(shape, dtype, shared_name, name, graph_mode, initial_value) handle_data.shape_and_type.append([SEP]AttributeError: 'google.protobuf.pyext._message.RepeatedCompositeCo' object has no attribute 'append'",,
647,58454157,0,2,,,"File [FILE], line 28, in <module> loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]TypeError: forward() got an unexpected keyword argument 'labels'",,
648,58612453,0,2,,,"File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 2897, in get_loc(self, key, method, tolerance) return self._engine.get_loc(key)[SEP]File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE][SEP]File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE][SEP]KeyError: 40592",,
649,58612453,0,2,,,"File [FILE], line 1, in <module> for batch_idx, (data, _) in enumerate(trainDL):[SEP]File <*>python3.6/site-packages/torch/utils/data/dataloader.py, line 346, in __next__(self) data = self._dataset_fetcher.fetch(index) # may raise StopIteration[SEP]File <*>python3.6/site-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch(self, possibly_batched_index) data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <*>python3.6/site-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp>(.0) data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <*>python3.6/site-packages/pandas/core/frame.py, line 2995, in __getitem__(self, key) indexer = self.columns.get_loc(key)[SEP]File <*>python3.6/site-packages/pandas/core/indexes/base.py, line 2899, in get_loc(self, key, method, tolerance) return self._engine.get_loc(self._maybe_cast_indexer(key))[SEP]File <*>/index.pyx, line [NUM], in pandas._libs.index.IndexEngine.get_loc() [CODE][SEP]File <*>/hashtable_class_helper.pxi, line [NUM], in pandas._libs.hashtable.PyObjectHashTable.get_item() [CODE][SEP]KeyError: 40592",,
650,58685572,0,2,,,"File [FILE], line 1, in <module> loaded_model.summary()[SEP]AttributeError: 'NoneType' object has no attribute 'summary'",,
651,58685572,0,2,,,"File [FILE], line 24, in <module> loaded_regressor.load_weights(latest_checkpoint(checkpoint_path))[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 162, in load_weights(self, filepath, by_name) return super(Model, self).load_weights(filepath, by_name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/network.py, line 1377, in load_weights(self, filepath, by_name) if _is_hdf5_filepath(filepath):[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/network.py, line 1672, in _is_hdf5_filepath(filepath) return (filepath.endswith('.h5') or filepath.endswith('.keras') or[SEP]AttributeError: 'NoneType' object has no attribute 'endswith'",,
652,58686400,0,2,,,"File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 2, in [FUNC] from tensorboard.summary.writer.record_writer import RecordWriter # noqa F401[SEP]ModuleNotFoundError: No module named 'tensorboard.summary'; 'tensorboard' is not a package",,
653,58686400,0,2,,,"File <*>/tensorboard.py, line 1, in [FUNC] from torch.utils.tensorboard import SummaryWriter[SEP]File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 4, in [FUNC] raise ImportError('TensorBoard logging requires TensorBoard with Python summary writer installed. '[SEP]ImportError: TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above.",,
654,58799212,0,2,,,"File [FILE], line 4, in <module>() pred = model(x)[SEP]File <*>python3.6/sequential.py, line 256, in call(self, inputs, training, mask) return super(Sequential, self).call(inputs, training=training, mask=mask)[SEP]File <*>python3.6/network.py, line 708, in call(self, inputs, training, mask) convert_kwargs_to_constants=base_layer_utils.call_context().saving)[SEP]File <*>python3.6/network.py, line 860, in _run_internal_graph(self, inputs, training, mask, convert_kwargs_to_constants) output_tensors = layer(computed_tensors, **kwargs)[SEP]File <*>python3.6/wrappers.py, line 528, in __call__(self, inputs, initial_state, constants, **kwargs) return super(Bidirectional, self).__call__(inputs, **kwargs)[SEP]File <*>python3.6/base_layer.py, line 891, in __call__(self, inputs, *args, **kwargs) outputs = self.call(cast_inputs, *args, **kwargs)[SEP]File <*>python3.6/wrappers.py, line 642, in call(self, inputs, training, mask, initial_state, constants) initial_state=forward_state, **kwargs)[SEP]File <*>python3.6/recurrent.py, line 623, in __call__(self, inputs, initial_state, constants, **kwargs) return super(RNN, self).__call__(inputs, **kwargs)[SEP]File <*>python3.6/recurrent_v2.py, line 961, in call(self, inputs, mask, training, initial_state) **cudnn_lstm_kwargs)[SEP]File <*>python3.6/recurrent_v2.py, line 1174, in cudnn_lstm(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards) rnn_mode='lstm')[SEP]File <*>python3.6/gen_cudnn_rnn_ops.py, line 109, in cudnn_rnn(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name) ctx=_ctx)[SEP]File <*>python3.6/gen_cudnn_rnn_ops.py, line 198, in cudnn_rnn_eager_fallback(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx) attrs=_attrs, ctx=_ctx, name=name)[SEP]File <*>python3.6/execute.py, line 67, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <*>python3.6/dist-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE][SEP]InvalidArgumentError: Invalid input_h shape: [1,64,1024] [1,54,1024] [Op:CudnnRNN]",,
655,58799486,0,2,,,"File [FILE], line 9, in <module>() train(test_net, train_loader, 10, batch_size, optimiser, clip, criterion)[SEP]File [FILE], line 59, in train(SNN, dataloader, epochs, batch_size, optimiser, clip, criterion) loss = criterion(output1, output2, labels)[SEP]File [FILE], line 51, in forward(self, output1, output2, labels) pred, loss = estimate_loss(self.d)[SEP]File [FILE], line 45, in estimate_loss(forward) distance = dimensional_reduction(self.d)[SEP]File [FILE], line 38, in dimensional_reduction(forward) self.d = self.linear(self.d)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/linear.py, line 87, in forward(self, input) return F.linear(input, self.weight, self.bias)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1370, in linear(input, weight, bias) ret = torch.addmm(bias, input, weight.t())[SEP]RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_addmm",,
656,58947679,0,2,,,"File [FILE], line 1001, in <module>() train_step(group, inp, tar, label)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializer_map)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize(self, args, kwds, add_initializers_to) *args, **kwds))[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py, line 905, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]ValueError: in converted code: <ipython-input-1-81054f0385cb>:856 train_step * optimizer.apply_gradients(zip(gradients, transformer.trainable_variables)) /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:427 apply_gradients grads_and_vars = _filter_grads(grads_and_vars) /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:1025 _filter_grads ([v.name for _, v in grads_and_vars],)) ValueError: No gradients provided for any variable: ['transformer_1/encoder_1/embedding_2/embeddings:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_98/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_98/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_99/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_99/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_100/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_100/bias:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_101/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/multi_head_attention_18/dense_101/bias:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_102/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_102/bias:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_103/kernel:0', 'transformer_1/encoder_1/encoder_layer_6/sequential_12/dense_103/bias:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_30/gamma:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_30/beta:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_31/gamma:0', 'transformer_1/encoder_1/encoder_layer_6/layer_normalization_31/beta:0', 'transformer_1/encoder_1/encoder_layer_7/multi_head_attention_19/dense_104/kernel:0', 'transformer_1/encoder_1/encoder...",,
657,58958437,0,2,,,"File [FILE], line 10, in <module>() scan_object = ta.Scan(x_train, y_train, params=p, model=iris_model, experiment_name='test', x_val=x_val, y_val=y_val, fraction_limit=0.1)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 1815, in _validate_or_infer_batch_size(self, batch_size, steps, x) x, batch_size))[SEP]ValueError: The `batch_size` argument must not be specified for the given input type. Received input: <DatasetV1Adapter shapes: ((512, 4), (512, 3)), types: (tf.float32, tf.float32)>, batch_size: 512",,
658,58958437,0,2,,,"File [FILE], line 10, in <module>() scan_object = ta.Scan(x_train, y_train, params=p, model=iris_model, experiment_name='test', x_val=x_val, y_val=y_val, fraction_limit=0.1)[SEP]File <*>python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py, line 2309, in _distribution_standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, validation_split, shuffle, epochs, allow_partial_batch) if dataset_size % batch_size == 0:[SEP]TypeError: unsupported operand type(s) for %: 'int' and 'NoneType'",,
659,59249563,0,2,,,"File [FILE], line 48, in <module> prediction = model(X)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 493, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/parallel/data_parallel.py, line 146, in forward(self, *inputs, **kwargs) ""them on device: {}"".format(self.src_device_obj, t.device))[SEP]RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:2",,
660,59305514,0,2,,,"File [FILE], line 3, in <module> epochs=10)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 324, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs) total_epochs=epochs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 123, in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs) batch_outs = execution_function(iterator)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 86, in execution_function(input_fn) distributed_function(input_fn))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializer_map)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize(self, args, kwds, add_initializers_to) *args, **kwds))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 73, in distributed_function(input_iterator) per_replica_function, args=(model, x, y, sample_weights))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 760, in experimental_run_v2(self, fn, args, kwargs) return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 1787, in call_for_each_replica(self, fn, args, kwargs) return self._call_for_each_replica(fn, args, kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 2132, in _call_for_each_replica(self, fn, args, kwargs) return fn(*args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py, line 292, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics) output_loss_metrics=model._output_loss_metrics)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 315, in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics) model, outs, targets, sample_weights=sample_weights, masks=masks)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 74, in _eager_metrics_fn(model, outputs, targets, sample_weights, masks) skip_target_masks=model._prepare_skip_target_masks())[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 2063, in _handle_metrics(self, outputs, targets, skip_target_masks, sample_weights, masks, return_weighted_metrics, return_weighted_and_unweighted_metrics) target, output, output_mask))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 2014, in _handle_per_output_metrics(self, metrics_dict, y_true, y_pred, mask, weights) metric_fn, y_true, y_pred, weights=weights, mask=mask)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py, line 1067, in call_metric_function(metric_fn, y_true, y_pred, weights, mask) return metric_fn(y_true, y_pred, sample_weight=weights)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/metrics.py, line 193, in __call__(self, *args, **kwargs) replica_local_fn, *args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py, line 1135, in call_replica_local_fn(fn, *args, **kwargs) return fn(*args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/metrics.py, line 176, in replica_local_fn(*args, **kwargs) update_op = self.update_state(*args, **kwargs) # pylint: disable=not-callable[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py, line 75, in decorated(metric_obj, *args, **kwargs) update_op = update_state_fn(*args, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/metrics.py, line 883, in update_state(self, y_true, y_pred, sample_weight) sample_weight=sample_weight)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py, line 278, in update_confusion_matrix_variables(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight) y_pred.shape.assert_is_compatible_with(y_true.shape)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py, line 1115, in assert_is_compatible_with(self, other) raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))[SEP]ValueError: Shapes (None, 4) and (None, 1) are incompatible",,
661,59384131,0,2,,,"File [FILE], line 2, in <module> model = make_feed_forward_model()[SEP]File [FILE], line 20, in make_feed_forward_model() dense_layer_1 = tf.keras.layers.Dense(HPARAMS.num_fc_units, activation='relu')(inputs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 616, in __call__(self, inputs, *args, **kwargs) self._maybe_build(inputs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/base_layer.py, line 1966, in _maybe_build(self, inputs) self.build(input_shapes)[SEP]File <*>/site-packages/tensorflow/python/keras/layers/core.py, line 1005, in build(self, input_shape) raise ValueError('The last dimension of the inputs to `Dense` '[SEP]ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.",,
662,59441355,0,2,,,"File [FILE], line 8, in <module> es.tell(X, eval_all(X, NPARAMS))[SEP]File [FILE], line 16, in _evaluate2(self, X, *args) return [job.get() for job in jobs][SEP]File [FILE], line 16, in <listcomp>(.0) return [job.get() for job in jobs][SEP]File <*>python3.7/pool.py, line 657, in get(self, timeout) raise self._value[SEP]File <*>python3.7/pool.py, line 431, in _handle_tasks(taskqueue, put, outqueue, pool, cache) put(task)[SEP]File <*>python3.7/connection.py, line 206, in send(self, obj) self._send_bytes(_ForkingPickler.dumps(obj))[SEP]File <*>python3.7/reduction.py, line 51, in dumps(cls, obj, protocol) cls(buf, protocol).dump(obj)[SEP]TypeError: can't pickle _thread.lock objects",,
663,59520705,0,2,,,"File [FILE], line 1, in <module>() learn.lr_find()[SEP]File <*>python3.6/dist-packages/fastai/train.py, line 41, in lr_find(learn, start_lr, end_lr, num_it, stop_div, wd) learn.fit(epochs, start_lr, callbacks=[cb], wd=wd)[SEP]File <*>python3.6/dist-packages/fastai/basic_train.py, line 200, in fit(self, epochs, lr, wd, callbacks) fit(epochs, self, metrics=self.metrics, callbacks=self.callbacks+callbacks)[SEP]File <*>python3.6/dist-packages/fastai/basic_train.py, line 101, in fit(epochs, learn, callbacks, metrics) loss = loss_batch(learn.model, xb, yb, learn.loss_func, learn.opt, cb_handler)[SEP]File <*>python3.6/dist-packages/fastai/basic_train.py, line 30, in loss_batch(model, xb, yb, loss_func, opt, cb_handler) loss = loss_func(out, *yb)[SEP]File <*>python3.6/dist-packages/fastai/layers.py, line 243, in __call__(self, input, target, **kwargs) return self.func.__call__(input, target.view(-1), **kwargs)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/loss.py, line 916, in forward(self, input, target) ignore_index=self.ignore_index, reduction=self.reduction)[SEP]File <*>python3.6/dist-packages/torch/nn/functional.py, line 2009, in cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction) return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)[SEP]File <*>python3.6/dist-packages/torch/nn/functional.py, line 1838, in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction) ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)[SEP]RuntimeError: Assertion `cur_target >= 0 &amp;&amp; cur_target < n_classes' failed. at /pytorch/aten/src/THNN/generic/ClassNLLCriterion.c:97",,
664,59525014,0,2,,,"File [FILE], line 1, in <module> foo[0][SEP]TypeError: 'TakeDataset' object does not support indexing",,
665,59555168,0,2,,,"File [FILE], line 2, in <module> (X_train_full, y_train_full), (X_test, y_test) = (fashion_mnist)[SEP]TypeError: cannot unpack non-iterable module object",,
666,59582663,0,2,,,"File [FILE], line 7, in <module>() loss_log = train(net, train_set, EPOCHS, LEARNING_RATE, BATCH_SIZE)[SEP]File [FILE], line 15, in train(net, training_set, EPOCHS, LEARNING_RATE, BATCH_SIZE) output, sm = net(x_batch)[SEP]File [FILE], line 43, in forward(self, x) x = self.convs(x)[SEP]File [FILE], line 33, in convs(self, x) x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=(2, 2))[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 541, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/conv.py, line 345, in forward(self, input) return self.conv2d_forward(input, self.weight)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/conv.py, line 342, in conv2d_forward(self, input, weight) self.padding, self.dilation, self.groups)[SEP]RuntimeError: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same",,
667,59864710,0,2,,,"File [FILE], line 4, in <module> model.fit(train_encoded, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(test_encoded,test_labels))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 728, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 324, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs) total_epochs=epochs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 123, in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs) batch_outs = execution_function(iterator)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 86, in execution_function(input_fn) distributed_function(input_fn))[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 457, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 503, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializer_map)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 408, in _initialize(self, args, kwds, add_initializers_to) *args, **kwds))[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1848, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2150, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2041, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>/site-packages/tensorflow_core/python/framework/func_graph.py, line 915, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 358, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 73, in distributed_function(input_iterator) per_replica_function, args=(model, x, y, sample_weights))[SEP]File <*>/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 760, in experimental_run_v2(self, fn, args, kwargs) return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 1787, in call_for_each_replica(self, fn, args, kwargs) return self._call_for_each_replica(fn, args, kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/distribute/distribute_lib.py, line 2132, in _call_for_each_replica(self, fn, args, kwargs) return fn(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/autograph/impl/api.py, line 292, in wrapper(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 264, in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics) output_loss_metrics=model._output_loss_metrics)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 311, in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics) output_loss_metrics=output_loss_metrics))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 252, in _process_single_batch(model, inputs, targets, output_loss_metrics, sample_weights, training) training=training))[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_eager.py, line 127, in _model_loss(model, inputs, targets, output_loss_metrics, sample_weights, training) outs = model(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 847, in __call__(self, inputs, *args, **kwargs) outputs = call_fn(cast_inputs, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/sequential.py, line 270, in call(self, inputs, training, mask) outputs = layer(inputs, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/base_layer.py, line 812, in __call__(self, inputs, *args, **kwargs) self.name)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/input_spec.py, line 213, in assert_input_compatibility(input_spec, inputs, layer_name) ' but received input with shape ' + str(shape))[SEP]ValueError: Input 0 of layer dense_3 is incompatible with the layer: expected axis -1 of input shape to have value 6022 but received input with shape [None, 512]",,
668,59887851,0,2,,,"File <*>/site-packages/tensorflow_datasets/core/download/extractor.py, line 89, in _sync_extract(self, from_path, method, to_path) for path, handle in iter_archive(from_path, method):[SEP]File <*>/site-packages/tensorflow_datasets/core/download/extractor.py, line 177, in iter_zip(arch_f) z = zipfile.ZipFile(fobj)[SEP]File <*>/zipfile.py, line 1131, in __init__(self, file, mode, compression, allowZip64) self._RealGetContents()[SEP]File <*>/zipfile.py, line 1194, in _RealGetContents(self) endrec = _EndRecData(fp)[SEP]File <*>/zipfile.py, line 264, in _EndRecData(fpin) fpin.seek(0, 2)[SEP]File <*>/site-packages/tensorflow_core/python/util/deprecation.py, line 507, in new_func(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/lib/io/file_io.py, line 167, in seek(self, offset, whence, position) offset += self.size()[SEP]File <*>/site-packages/tensorflow_core/python/lib/io/file_io.py, line 102, in size(self) return stat(self.__name).length[SEP]File <*>/site-packages/tensorflow_core/python/lib/io/file_io.py, line 727, in stat(filename) return stat_v2(filename)[SEP]File <*>/site-packages/tensorflow_core/python/lib/io/file_io.py, line 744, in stat_v2(path) pywrap_tensorflow.Stat(compat.as_bytes(path), file_statistics)[SEP]OutOfRangeError: C:\Users\%user%\tensorflow_datasets\downloads\images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip; Unknown error",,
669,59887851,0,2,,,"File [FILE], line 3, in <module> cocoBuilder.download_and_prepare()[SEP]File <*>/site-packages/tensorflow_datasets/core/api_utils.py, line 52, in disallow_positional_args_dec(fn, instance, args, kwargs) return fn(*args, **kwargs)[SEP]File <*>/site-packages/tensorflow_datasets/core/dataset_builder.py, line 287, in download_and_prepare(self, download_dir, download_config) download_config=download_config)[SEP]File <*>/site-packages/tensorflow_datasets/core/dataset_builder.py, line 948, in _download_and_prepare(self, dl_manager, download_config) max_examples_per_split=download_config.max_examples_per_split,[SEP]File <*>/site-packages/tensorflow_datasets/core/dataset_builder.py, line 804, in _download_and_prepare(self, dl_manager, **prepare_split_kwargs) for split_generator in self._split_generators(dl_manager):[SEP]File <*>/site-packages/tensorflow_datasets/image/coco.py, line 239, in _split_generators(self, dl_manager) key: root_url + url for key, url in urls.items()[SEP]File <*>/site-packages/tensorflow_datasets/core/download/download_manager.py, line 359, in download_and_extract(self, url_or_urls) return _map_promise(self._download_extract, url_or_urls)[SEP]File <*>/site-packages/tensorflow_datasets/core/download/download_manager.py, line 395, in _map_promise(map_fn, all_inputs) res = utils.map_nested(_wait_on_promise, all_promises)[SEP]File <*>/site-packages/tensorflow_datasets/core/utils/py_utils.py, line 129, in map_nested(function, data_struct, dict_only, map_tuple) for k, v in data_struct.items()[SEP]File <*>/site-packages/tensorflow_datasets/core/utils/py_utils.py, line 129, in <dictcomp>(.0) for k, v in data_struct.items()[SEP]File <*>/site-packages/tensorflow_datasets/core/utils/py_utils.py, line 143, in map_nested(function, data_struct, dict_only, map_tuple) return function(data_struct)[SEP]File <*>/site-packages/tensorflow_datasets/core/download/download_manager.py, line 379, in _wait_on_promise(p) return p.get()[SEP]File <*>/site-packages/promise/promise.py, line 510, in get(self, timeout) return self._target_settled_value(_raise=True)[SEP]File <*>/site-packages/promise/promise.py, line 514, in _target_settled_value(self, _raise) return self._target()._settled_value(_raise)[SEP]File <*>/site-packages/promise/promise.py, line 224, in _settled_value(self, _raise) reraise(type(raise_val), raise_val, self._traceback)[SEP]File <*>/site-packages/six.py, line 696, in reraise(tp, value, tb) raise value[SEP]File <*>/site-packages/promise/promise.py, line 842, in handle_future_result(future) resolve(future.result())[SEP]File <*>/_base.py, line 425, in result(self, timeout) return self.__get_result()[SEP]File <*>/_base.py, line 384, in __get_result(self) raise self._exception[SEP]File <*>/thread.py, line 56, in run(self) result = self.fn(*self.args, **self.kwargs)[SEP]File <*>/site-packages/tensorflow_datasets/core/download/extractor.py, line 94, in _sync_extract(self, from_path, method, to_path) raise ExtractError(msg)[SEP]ExtractError: Error while extracting C:\Users\%user%\tensorflow_datasets\downloads\images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip to C:\Users\%user%\tensorflow_datasets\downloads\extracted\ZIP.images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip : C:\Users\%user%\tensorflow_datasets\downloads\images.cocodataset.org_zips_train20147eQIfmQL3bpVDgkOrnAQklNLVUtCsFrDPwMAuYSzF3U.zip; Unknown error",,
670,59938419,0,2,,,"File [FILE], line 1, in <module>() addn = tf.add(mul, div)[SEP]File <*>python3.5/site-packages/tensorflow_core/python/ops/gen_math_ops.py, line 343, in add(x, y, name) _ops.raise_from_not_ok_status(e, name)[SEP]File <*>python3.5/site-packages/tensorflow_core/python/framework/ops.py, line 6606, in raise_from_not_ok_status(e, name) six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <*>python3.5/site-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE][SEP]InvalidArgumentError: cannot compute Add as input #1(zero-based) was expected to be a int32 tensor but is a double tensor [Op:Add]",,
671,60048397,0,2,,,"File [FILE], line 19, in <module> transformed_dataset, transform_fn = (raw_dataset | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))[SEP]File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 863, in expand(self, dataset) dataset | 'AnalyzeDataset' >> AnalyzeDataset(self._preprocessing_fn))[SEP]File <*>python3.7/site-packages/apache_beam/transforms/ptransform.py, line 989, in __ror__(self, pvalueish, _unused) return self.transform.__ror__(pvalueish, self.label)[SEP]File <*>python3.7/site-packages/apache_beam/transforms/ptransform.py, line 549, in __ror__(self, left, label) result = p.apply(self, pvalueish, label)[SEP]File <*>python3.7/site-packages/apache_beam/pipeline.py, line 536, in apply(self, transform, pvalueish, label) return self.apply(transform, pvalueish)[SEP]File <*>python3.7/site-packages/apache_beam/pipeline.py, line 577, in apply(self, transform, pvalueish, label) pvalueish_result = self.runner.apply(transform, pvalueish, self._options)[SEP]File <*>python3.7/site-packages/apache_beam/runners/runner.py, line 195, in apply(self, transform, input, options) return m(transform, input, options)[SEP]File <*>python3.7/site-packages/apache_beam/runners/runner.py, line 225, in apply_PTransform(self, transform, input, options) return transform.expand(input)[SEP]File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 810, in expand(self, dataset) None, input_metadata))[SEP]File <*>python3.7/site-packages/tensorflow_transform/beam/impl.py, line 683, in expand(self, dataset) output_signature = self._preprocessing_fn(copied_inputs)[SEP]File [FILE], line 11, in preprocessing_fn(inputs) tf.constant(value, shape=outputs[key].shape),[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/constant_op.py, line 258, in constant(value, dtype, shape, name) allow_broadcast=True)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/constant_op.py, line 296, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) allow_broadcast=allow_broadcast))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py, line 448, in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast) if shape is not None and np.prod(shape, dtype=np.int64) == 0:[SEP]File [FILE], line [NUM], in prod(*args, **kwargs) [CODE][SEP]File <*>python3.7/site-packages/numpy/core/fromnumeric.py, line 2962, in prod(a, axis, dtype, out, keepdims, initial, where) keepdims=keepdims, initial=initial, where=where)[SEP]File <*>python3.7/site-packages/numpy/core/fromnumeric.py, line 90, in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs) return ufunc.reduce(obj, axis, dtype, out, **passkwargs)[SEP]TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'",,
672,60119041,0,2,,,"File [FILE], line 3, in <module> pooling='avg')[SEP]File <*>python3.6/site-packages/keras/applications/__init__.py, line 20, in wrapper(*args, **kwargs) return base_fun(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/applications/resnet.py, line 14, in ResNet50(*args, **kwargs) return resnet.ResNet50(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 435, in ResNet50(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs) **kwargs)[SEP]File <*>python3.6/site-packages/keras_applications/resnet_common.py, line 413, in ResNet(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs) model.load_weights(weights)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 492, in load_wrapper(*args, **kwargs) return load_function(*args, **kwargs)[SEP]File <*>python3.6/site-packages/keras/engine/network.py, line 1230, in load_weights(self, filepath, by_name, skip_mismatch, reshape) f, self.layers, reshape=reshape)[SEP]File <*>python3.6/site-packages/keras/engine/saving.py, line 1237, in load_weights_from_hdf5_group(f, layers, reshape) K.batch_set_value(weight_value_tuples)[SEP]File <*>python3.6/site-packages/keras/backend/tensorflow_backend.py, line 2960, in batch_set_value(tuples) tf_keras_backend.batch_set_value(tuples)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/keras/backend.py, line 3323, in batch_set_value(tuples) x.assign(np.asarray(value, dtype=dtype(x)))[SEP]File <*>python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py, line 819, in assign(self, value, use_locking, name, read_value) self._shape.assert_is_compatible_with(value_tensor.shape)[SEP]File <*>python3.6/site-packages/tensorflow_core/python/framework/tensor_shape.py, line 1110, in assert_is_compatible_with(self, other) raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))[SEP]ValueError: Shapes (1, 1, 256, 512) and (512, 128, 1, 1) are incompatible",,
673,60205829,0,2,,,"File [FILE], line 26, in <module>() images, labels = next(iter(train_loader))[SEP]File <*>python3.6/dist-packages/torch/utils/data/dataloader.py, line 345, in __next__(self) data = self._next_data()[SEP]File <*>python3.6/dist-packages/torch/utils/data/dataloader.py, line 385, in _next_data(self) data = self._dataset_fetcher.fetch(index) # may raise StopIteration[SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in fetch(self, possibly_batched_index) data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <*>python3.6/dist-packages/torch/utils/data/_utils/fetch.py, line 44, in <listcomp>(.0) data = [self.dataset[idx] for idx in possibly_batched_index][SEP]File <*>python3.6/dist-packages/torchvision/datasets/mnist.py, line 97, in __getitem__(self, index) img = self.transform(img)[SEP]File <*>python3.6/dist-packages/torchvision/transforms/transforms.py, line 70, in __call__(self, img) img = t(img)[SEP]File <*>python3.6/dist-packages/torchvision/transforms/transforms.py, line 1003, in __call__(self, img) return F.rotate(img, angle, self.resample, self.expand, self.center, self.fill)[SEP]File <*>python3.6/dist-packages/torchvision/transforms/functional.py, line 729, in rotate(img, angle, resample, expand, center, fill) return img.rotate(angle, resample, expand, center, fillcolor=fill)[SEP]File <*>python3.6/dist-packages/PIL/Image.py, line 2005, in rotate(self, angle, resample, expand, center, translate, fillcolor) return self.transform((w, h), AFFINE, matrix, resample, fillcolor=fillcolor)[SEP]File <*>python3.6/dist-packages/PIL/Image.py, line 2299, in transform(self, size, method, data, resample, fill, fillcolor) im = new(self.mode, size, fillcolor)[SEP]File <*>python3.6/dist-packages/PIL/Image.py, line 2505, in new(mode, size, color) return im._new(core.fill(mode, size, color))[SEP]TypeError: function takes exactly 1 argument (3 given)",,
674,60309505,0,2,,,"File [FILE], line 6, in <module> num_epochs=25)[SEP]File [FILE], line 33, in train_model(model, criterion, optimizer, scheduler, num_epochs) _, preds = torch.max(outputs, 1)[SEP]TypeError: max() received an invalid combination of arguments - got (Linear, int), but expected one of: * (Tensor input) * (Tensor input, name dim, bool keepdim, tuple of Tensors out) * (Tensor input, Tensor other, Tensor out) * (Tensor input, int dim, bool keepdim, tuple of Tensors out)",,
675,60440292,0,2,,,"File [FILE], line 13, in <module> loss = criterion(output, labels)[SEP]File <*>python3.6/site-packages/torch/nn/modules/module.py, line 532, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/site-packages/torch/nn/modules/loss.py, line 204, in forward(self, input, target) return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)[SEP]File <*>python3.6/site-packages/torch/nn/functional.py, line 1838, in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction) ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)[SEP]RuntimeError: expected scalar type Long but found Float",,
676,60675024,0,2,,,"File [FILE], line 13, in <module> model = FullyConnectedLayer (512, dist, 0.99, 0.5 ) # 4 LAYERS[SEP]File [FILE], line 58, in FullyConnectedLayer(denseUnits, seluDistribution, batchMomentum, alphaDropRate) model.add(Activation(gelu(x=seluDistribution)))[SEP]File <*>/site-packages/tensorflow_core/python/keras/layers/core.py, line 378, in __init__(self, activation, **kwargs) self.activation = activations.get(activation)[SEP]File <*>/site-packages/tensorflow_core/python/keras/activations.py, line 454, in get(identifier) repr(identifier)))[SEP]TypeError: Could not interpret activation function identifier: <tf.Tensor: shape=(5, 5, 1, 32), dtype=float32, numpy= array([[[[-1.26586094e-01, -1.02963023e-01, 3.14652212e-02, -1.39087364e-01, 1.13992631e-01, 1.52557418e-01, -1.09972686e-01, -5.12595251e-02, -1.58538278e-02, -1.29528284e-01, 1.63152684e-02, 1.01518132e-01, -4.35875840e-02, 1.46785110e-01, -2.23108958e-02, -2.09968127e-02, -8.54036435e-02, 9.01642349e-03, -4.25574742e-02, 4.80710454e-02]], [[ 9.34263412e-03, 1.06001608e-01, -7.65870064e-02, -8.02185014e-02, 6.67698979e-02, -8.98385793e-02, -6.12295903e-02, 7.36039877e-02, -1.33156419e-01, [[-1.38585389e-01, 1.03538044e-01, 1.76681668e-01, -6.94317510e-03, 6.14152141e-02, -3.92788239e-02, -5.83523549e-02, 6.68111816e-02, 5.49897328e-02, -5.77139147e-02, -7.64194950e-02, -7.55715296e-02, -4.95074578e-02, 7.71198049e-02, 5.40203564e-02, -9.74030495e-02, -1.00650810e-01, 1.23783059e-01, -8.46874043e-02, -1.04908131e-01, -2.63819955e-02, -1.31487399e-01, 1.30674899e-01]], [[ 6.60606772e-02, 1.46065757e-01, 1.59279909e-02, -1.20391339e-01, -7.02986643e-02, -2.74278801e-02, -1.29030854e-01, -7.62277395e-02, -1.19075023e-01, -9.22646299e-02, 7.98776373e-02, 6.54103830e-02, -6.72401339e-02, -4.81364317e-02, -6.03620708e-02, -2.84200851e-02, -9.10447016e-02]], [[-1.23140588e-01, 1.10491589e-01, -9.61843282e-02, -8.91052186e-02, 4.01075035e-01, 1.94666237e-02, -2.61222124e-02, -1.56512097e-01, 9.74281505e-02, -3.66279632e-02, 6.65708026e-03, 9.61058680e-03, -1.21156186e-01, -2.98077669e-02, 1.66137442e-02, -3.38280275e-02, -9.28360224e-02, -7.76154548e-02, -7.96113610e-02, -2.57881228e-02, -1.58247918e-01, [[[-1.13160208e-01, -1.98329911e-02, 1.20878376e-01, -1.13716172e-02, -5.21509871e-02, 7.25255907e-02, -1.12730011e-01, -7.29970336e-02, 6.37045652e-02, -8.64603445e-02, -2.22087242e-02, -2.47925967e-02, -6.44451613e-03, -1.73095725e-02, -6.07393086e-02, -4.96991165e-02, -3.15147117e-02, 2.43039820e-02, -7.35211000e-02, -6.92363605e-02]], [[ 3.96580771e-02, 1.26118317e-01, 1.16271339e-01, -5.80145419e-02, -2.15136074e-03, -9.12490934e-02, -1.27457187e-01, 3.60154063e-02, 9.91806835e-02, -4.64559309e-02, -2.11531147e-02, 4.10205543e-01, -4.43787202e-02, 4.39099297e-02, 3.06370091e-02, -9.87873599e-02, -5.10304309e-02]], [[ 2.13202462e-02, 1.41525701e-01, -4.84775938e-02, -1.43082231e-01, 4.21900637e-02, -1.17563821e-01, -3.71489525e-02, -1.45584494e-01, -1.12884097e-01, -7.87854716e-02, -2.01713406e-02, -3.49416770e-02, -6.53499886e-02, -2.09143162e-02, 2.94101406e-02, -5.27165644e-02, 1.19348057e-02, -4.39126566e-02, -6.26288429e-02, 4.20925207e-02]], [[-8.23830441e-02, 2.23106906e-01, 8.56178179e-02, -5.99831380e-02, -1.71386788e-03, -3.62357125e-02, -1.59021363e-01, -2.17766548e-03, 2.16864720e-01, -5.73305860e-02, -1.80698894e-02, 1.36940643e-01, -1.97473206e-02, 8.14313069e-02, 1.96376622e-01, -6.43103570e-02, -3.85615453e-02]], [[-3.53560485e-02, 4.35038935e-03, -7.06349090e-02, -2.80691660e-03, -6.92954510e-02, 1.11481667e-01, -4.58219610e-02, -2.38394644e-02, -7.87800774e-02, -1.67009607e-02, 6.01479635e-02, 1.56740978e-01, -9.78638828e-02, -4.29860055e-02, 1.38192121e-02, -1.36006713e-01, -1.05418041e-01, -2.51792613e-02, -1.22639257e-02, -1.21888302e-01, -5.46660051e-02, -7.12147309e-03, -6.58531636e-02, -7.14808479e-02, [[[ 6.32937178e-02, 2.72242278e-01, -3.74731459e-02, -2.62564681e-02, -1.54855132e-01, 7.81283434e-03, -8.01301673e-02, 7.47360140e-02, -5.00108190e-02, -7.64894933e-02, 8.45131949e-02, -3.27355303e-02, -3.79370786e-02, -6.93783676e-03, -4.87477183e-02, [[-7.98909813e-02, 2.59152979e-01, 1.75541520e-01, -8.12215135e-02, -9.54297185e-02, 1.99518725e-03, -3.72358635e-02, -1.39946237e-01, -5.76626435e-02, -7.13582858e-02, 5.86171262e-02, -1.39267772e-01, -1.00216493e-01, 2.68728107e-01, 1.63495377e-01, -2.24205833e-02, 1.44553408e-01, -9.67240557e-02, -1.24277532e-01, -1.40620157e-01]], [[-5.69531657e-02, 1.71630532e-01, 2.86230773e-01, -5.93378842e-02, -1.71954520e-02, -3.26295868e-02, -3.98173966e-02, 7.21049905e-02, -6.91456124e-02, -1.23138815e-01, 1.33402884e-01, -1.02245316e-01, -4.69203852e-02, -1.75676849e-02, 1.40360445e-01, -3.40559036e-02, 3.35928686e-02, -1.04908220e-01, [[-7.85556585e-02, -1.18466914e-01, 1.53003752e-01, -4.67218924e-03, -1.16112582e-01, 5.51390201e-02, -1.52055770e-02, 3.54320277e-03, 3.42624858e-02, -1.05386212e-01, 1.98949352e-02, 2.73315758e-02, -7.58572146e-02, 1.03625186e-01, 2.05493998e-03, -1.01805991e-02, 2.19766423e-02]], [[-1.00509115e-02, 2.22494956e-02, -9.08879191e-02, -8.11229870e-02, 9.98405516e-02, -5.72074987e-02, -1.33951874e-02, 3.92576605e-02, 1.16789080e-01, -1.89318452e-02, -1.59033425e-02, 9.48152542e-02, -2.66773477e-02, 1.37753570e-02, 1.79445334e-02, -6.62883669e-02, -9.37851295e-02, 1.94142580e-01, -1.28269400e-02, 1.25869989e-01, 1.50878415e-01, -2.11219154e-02, -1.05045862e-01, -2.73662023e-02, [[[ 1.83003962e-01, -4.02955636e-02, 7.92874582e-03, -1.04859909e-02, 1.41754048e-02, -1.52763631e-02, -9.11424682e-02, 3.24082047e-01, 1.05546042e-02, -1.30687788e-01, -3.98224816e-02, 1.38061410e-02, [[ 2.33758405e-01, -9.26907063e-02, 1.65917858e-01, -1.22203723e-01, -2.83196904e-02, 1.02213569e-01, -5.63387433e-03, -3.08787469e-02, 1.96257643e-02, -7.37890229e-02, -1.93086471e-02, 1.30984381e-01, [[-5.09779751e-02, 6.08728305e-02, -8.07061568e-02, -1.26804784e-01, -1.43676013e-01, -3.28507088e-02, -1.66144117e-03, -7.41888210e-03, 1.42028257e-01, -4.99214791e-02, -1.86899900e-02, -1.09298825e-02, -8.03249031e-02, -1.00237548e-01]], [[-7.80191123e-02, 4.05082256e-02, 7.47731477e-02, -8.76973122e-02, -2.91744564e-02, 1.23694569e-01, -1.49070352e-01, 2.42730626e-03, 3.52480598e-02, -5.62792830e-03, -2.28355639e-02, -1.27415329e-01, -8.48858505e-02, -3.52028869e-02, -7.95315206e-02, -3.92727107e-02, -4.16678861e-02, 2.39140958e-01, -1.44019471e-02, -8.69576260e-03]], [[-1.67441964e-02, -1.43177100e-02, -9.23768803e-02, -2.72830930e-02, 7.51334131e-02, -2.28366554e-02, -5.57800010e-02, -1.31770581e-01, 9.31192283e-03, -1.38517320e-02, -1.41043484e-01, -6.42404705e-02, -4.86476049e-02, -1.12639852e-01, 7.89660513e-02, -1.09081008e-01, -3.03610712e-02]]], [[[-1.40361011e-01, 1.21919084e-02, 4.36685272e-02, -3.61564793e-02, -1.11773185e-01, 2.25092173e-02, -1.02469876e-01, 1.76996499e-01, 4.30173017e-02, -2.26258971e-02, 2.11037025e-01, 9.66922417e-02, -4.83587980e-02, 4.68245940e-04, -1.47096828e-01, -2.91392524e-02, 8.22411999e-02, 2.07852814e-02, -4.12134677e-02, 5.33621386e-02, 9.24792588e-02, [[ 1.66879535e-01, 6.54919222e-02, -3.27483788e-02, -1.43241754e-03, -1.14416316e-01, -2.12962832e-02, -4.46583293e-02, 2.71647628e-02, -5.61558232e-02, -1.24854170e-01, 1.25476092e-01, -7.09585026e-02, -4.40548174e-02, 7.21732453e-02, 7.45785460e-02, -1.17296316e-01, -1.46051958e-01, 1.88378561e-02, [[ 2.60874778e-01, -1.45940065e-01, -9.79427770e-02, -8.68195742e-02, 2.04389215e-01, -2.24198923e-02, -8.38927086e-03, -4.99465019e-02, 4.69646640e-02, -7.15569034e-02, -1.78242605e-02, -8.51068646e-03, -3.08227092e-02, -4.82530929e-02, 8.31630453e-02, -4.16018628e-02, -7.55471215e-02]], [[ 2.24076852e-01, -1.39667824e-01, 7.93220941e-03, -1.78845283e-02, -5.64770252e-02, -7.84719810e-02, -1.81565285e-02, 1.24106847e-01, -6.28474308e-03, -1.72791779e-02, -3.47166769e-02, -4.92920280e-02, -9.12440866e-02, 6.42236844e-02, -1.16013244e-01, -7.96606317e-02, 1.50838092e-01, -4.71229590e-02, -4.02066261e-02, 1.17019311e-01]], [[-3.95799540e-02, -4.35096361e-02, -9.93420109e-02, -6.20126911e-02, 1.93700612e-01, 5.02851121e-02, -9.00325775e-02, 1.32245719e-01, 2.68575907e-01, -8.08344856e-02, -4.56905663e-02, 1.26069590e-01, -6.64912462e-02, 9.61613879e-02, -1.48803489e-02, "", 'Error', 'Error', '', '')",,
677,60870008,0,2,,,"File [FILE], line 7, in <module>() print(x[tensor(0)])[SEP]KeyError: tensor(0)",,
678,60870008,0,2,,,"File [FILE], line 11, in <module>() print(x[0])[SEP]KeyError: 0",,
679,61039700,0,2,,,"File [FILE], line 8, in <module> layers['flatten'] = nn.Flatten()[SEP]AttributeError: module 'torch.nn' has no attribute 'Flatten'",,
680,61176084,0,2,,,"File [FILE], line 8, in <module>() callbacks=[ccall, esd3][SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 813, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) callbacks.on_epoch_end(epoch, epoch_logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 365, in on_epoch_end(self, epoch, logs) callback.on_epoch_end(epoch, logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 1485, in on_epoch_end(self, epoch, logs) self.model.set_weights(self.best_weights)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 1519, in set_weights(self, weights) if expected_num_weights != len(weights):[SEP]TypeError: object of type 'NoneType' has no len()",,
681,61213493,0,2,,,"File [FILE], line 9, in <module> train_loss, train_acc = train(model, train_iterator, optimizer, criterion)[SEP]File [FILE], line 8, in train(model, iterator, optimizer, criterion) for batch in iterator:[SEP]File <*>python3.7/site-packages/torchtext/data/iterator.py, line 142, in __iter__(self) for idx, minibatch in enumerate(self.batches):[SEP]File <*>python3.7/site-packages/torchtext/data/iterator.py, line 286, in pool(data, batch_size, key, batch_size_fn, random_shuffler, shuffle, sort_within_batch) if sort_within_batch \[SEP]TypeError: '<' not supported between instances of 'Example' and 'Example'",,
682,61334483,0,2,,,"File [FILE], line 70, in <module>() loss = torch.nn.MSELoss(out, target)[SEP]File <*>python3.6/dist-packages/torch/nn/_reduction.py, line 36, in legacy_get_string(size_average, reduce, emit_warning) if size_average and reduce:[SEP]RuntimeError: bool value of Tensor with more than one value is ambiguous",,
683,61742556,0,2,,,"File [FILE], line 13, in <module>() validation_steps = validation_steps,[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]ValueError: in user code: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function * outputs = self.distribute_strategy.run( /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run ** return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica return fn(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step ** y, y_pred, sample_weight, regularization_losses=self.losses) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__ loss_value = loss_obj(y_t, y_p, sample_weight=sw) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:143 __call__ losses = self.call(y_true, y_pred) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:246 call return self.fn(y_true, y_pred, **self._fn_kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1527 categorical_crossentropy return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4561 categorical_crossentropy target.shape.assert_is_compatible_with(output.shape) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1117 assert_is_compatible_with raise ValueError(""Shapes %s and %s are incompatible"" % (self, other)) ValueError: Shapes (None, 1) and (None, 2) are incompatible",,
684,61810231,0,2,,,"File [FILE], line 6, in <module> from tensorflow.keras.models import Sequential[SEP]File <*>/site-packages/tensorflow/keras/__init__.py, line 14, in <module> from . import activations[SEP]File <*>/site-packages/tensorflow/keras/activations/__init__.py, line 23, in <module> from tensorflow.python.keras.activations import swish[SEP]ImportError: cannot import name 'swish' from 'tensorflow.python.keras.activations' (C:\Users\FlamePrinz\Anaconda3\lib\site-packages\tensorflow\python\keras\activations.py)",,
685,61882720,0,2,,,"File [FILE], line 16, in <module> model.fit(X_train, y_train, epochs=3)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training.py, line 819, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 342, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) total_epochs=epochs)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs) batch_outs = execution_function(iterator)[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function(input_fn) distributed_function(input_fn))[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/def_function.py, line 632, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 2363, in __call__(self, *args, **kwargs) return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call(self, args, kwargs) self.captured_inputs)[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat(self, args, captured_inputs, cancellation_manager) ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>/site-packages/tensorflow_core/python/eager/function.py, line 545, in call(self, ctx, args, cancellation_manager) ctx=ctx)[SEP]File <*>/site-packages/tensorflow_core/python/eager/execute.py, line 67, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) six.raise_from(core._status_to_exception(e.code, message), None)[SEP]File <*>/site-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE][SEP]UnimplementedError: Cast string to int64 is not supported [[node loss/output_1_loss/Cast (defined at <ipython-input-111-1a89f1d94518>:16) ]] [Op:__inference_distributed_function_544280]",,
686,61956893,0,2,,,"File [FILE], line 14, in <module> Y = torch.masked_select(X, (mask == 1))[SEP]RuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2",,
687,61997378,0,2,,,"File [FILE], line 5, in <module> verbose = 1)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 872, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) return_dict=True)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1081, in evaluate(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict) tmp_logs = test_function(iterator)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 618, in _call(self, *args, **kwds) results = self._stateful_fn(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2419, in __call__(self, *args, **kwargs) graph_function, args, kwargs = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2774, in _maybe_define_function(self, args, kwargs) return self._define_function_with_shape_relaxation(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2706, in _define_function_with_shape_relaxation(self, args, kwargs) args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2667, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) capture_by_value=self._capture_by_value),[SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 981, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 441, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]AssertionError: in user code: c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\training.py:941 test_function * outputs = self.distribute_strategy.run( c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:951 run ** return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2290 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2649 _call_for_each_replica return fn(*args, **kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\training.py:909 test_step ** y_pred = self(x, training=False) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:927 __call__ outputs = call_fn(cast_inputs, *args, **kwargs) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\ etwork.py:719 call convert_kwargs_to_constants=base_layer_utils.call_context().saving) c:\users\aniket\documents\aniket\learning-ml\ml_env\lib\site-packages\tensorflow\python\keras\engine\ etwork.py:899 _run_internal_graph assert str(id(x)) in tensor_dict, 'Could not compute output ' + str(x) AssertionError: Could not compute output Tensor(""O1_6/Identity:0"", shape=(None, 2), dtype=float32)",,
688,62136244,0,2,,,"File [FILE], line 58, in <module>() optimizer.step()[SEP]File <*>python3.6/dist-packages/torch/autograd/grad_mode.py, line 15, in decorate_context(*args, **kwargs) return func(*args, **kwargs)[SEP]File <*>python3.6/dist-packages/torch/optim/adam.py, line 99, in step(self, closure) exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)[SEP]RuntimeError: expected device cpu but got device cuda:0",,
689,62136814,0,2,,,"File [FILE], line 4, in <module>() model = encoder_model(k)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1113, in op(self) ""Tensor.op is meaningless when eager execution is enabled."")[SEP]AttributeError: Tensor.op is meaningless when eager execution is enabled.",,
690,62169315,0,2,,,"File [FILE], line 9, in <module>() model.save(outdir+'model.h5')[SEP]File <*>python3.6/dist-packages/h5py/_hl/group.py, line 373, in __setitem__(self, name, obj) h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl)[SEP]File <*>/_objects.pyx, line [NUM], in h5py._objects.with_phil.wrapper() [CODE][SEP]File <*>/h5o.pyx, line [NUM], in h5py.h5o.link() [CODE][SEP]RuntimeError: Unable to create link (name already exists)",,
691,62182427,0,2,,,"File [FILE], line 8, in <module>() ds = ds.filter(filter_fn)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]OperatorNotAllowedInGraphError: in user code: <ipython-input-52-52131b5369b6>:5 filter_fn * return features['department'] in ['FERRAMENTAS', 'MERCEARIA', 'MOVEIS'] /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:778 __bool__ self._disallow_bool_casting() /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:545 _disallow_bool_casting ""using a `tf.Tensor` as a Python `bool`"") /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:532 _disallow_when_autograph_enabled "" decorating it directly with @tf.function."".format(task)) OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.",,
692,62188532,0,2,,,"File <*>/site-packages/tensorflow_core/python/client/session.py, line 1365, in _do_call(self, fn, *args) return fn(*args)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1350, in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata) target_list, run_metadata)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1443, in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata) run_metadata)[SEP]InvalidArgumentError: indices[24,0] = 335 is not in [0, 304) [[{{node user-embedding-mlp_1/GatherV2}}]]",,
693,62188532,0,2,,,"File [FILE], line 1, in <module> history = model.fit([train.id, train.user_id], train.user_like, nb_epoch=3)[SEP]File <*>/site-packages/keras/engine/training.py, line 1657, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs) validation_steps=validation_steps)[SEP]File <*>/site-packages/keras/engine/training.py, line 1213, in _fit_loop(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps) outs = f(ins_batch)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2357, in __call__(self, inputs) **self.session_kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 956, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1180, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1359, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1384, in _do_call(self, fn, *args) session_config.graph_options.rewrite_options.' raise type(e)(node_def, op, message)[SEP]InvalidArgumentError: indices[24,0] = 335 is not in [0, 304) [[node user-embedding-mlp_1/GatherV2 (defined at E:\My\Ananconda\envs\tensor\lib\site-packages\tensorflow_core\python\framework\ops.py:1748) ]]",,
694,62279886,0,2,,,"File [FILE], line 4, in <module> history = comp_lstm.fit(train,[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>python3.8/site-packages/tensorflow/python/keras/engine/training.py, line 848, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) tmp_logs = train_function(iterator)[SEP]File <*>python3.8/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>python3.8/site-packages/tensorflow/python/eager/def_function.py, line 611, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) # pylint: disable=not-callable[SEP]TypeError: 'NoneType' object is not callable",,
695,62285475,0,2,,,"File [FILE], line 1, in <module>() model.fit(train_dataset, epochs=15)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]TypeError: in user code: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function * outputs = self.distribute_strategy.run( /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run ** return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica return fn(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step ** y, y_pred, sample_weight, regularization_losses=self.losses) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__ loss_value = loss_obj(y_t, y_p, sample_weight=sw) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:145 __call__ losses, sample_weight, reduction=self._get_reduction()) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:104 compute_weighted_loss losses = ops.convert_to_tensor_v2(losses) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1283 convert_to_tensor_v2 as_ref=False) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1341 convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:321 _constant_tensor_conversion_function return constant(v, dtype=dtype, name=name) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:262 constant allow_broadcast=True) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:300 _constant_impl allow_broadcast=allow_broadcast)) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py:547 make_tensor_proto ""supported type."" % (type(values), values)) TypeError: Failed to convert object of type <class 'tensorflow.python.keras.losses.BinaryCrossentropy'> to Tensor. Contents: <tensorflow.python.keras.losses.BinaryCrossentropy object at 0x7f76215279b0>. Consider casting elements to a supported type.",,
696,62386682,0,2,,,"File [FILE], line 29, in <module> interpreter.allocate_tensors()[SEP]File <*>/interpreter.py, line 242, in allocate_tensors(self) return self._interpreter.AllocateTensors()[SEP]File <*>/tensorflow_wrap_interpreter_wrapper.py, line 110, in AllocateTensors(self) return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)[SEP]RuntimeError: tensorflow/lite/kernels/reshape.cc:66 num_input_elements != num_output_elements (1536 != 768)Node number 3 (RESHAPE) failed to prepare.",,
697,62399243,0,2,,,"File [FILE], line 1, in <module> output = encoder(src, src_mask)[SEP]File <*>python3.7/site-packages/torch/nn/modules/transformer.py, line 167, in forward(self, src, mask, src_key_padding_mask) src_key_padding_mask=src_key_padding_mask)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 547, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.7/site-packages/torch/nn/modules/transformer.py, line 266, in forward(self, src, src_mask, src_key_padding_mask) key_padding_mask=src_key_padding_mask)[0][SEP]File <*>python3.7/site-packages/torch/nn/modules/activation.py, line 783, in forward(self, query, key, value, key_padding_mask, need_weights, attn_mask) attn_mask=attn_mask)[SEP]File <*>python3.7/site-packages/torch/nn/functional.py, line 3252, in multi_head_attention_forward(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v) attn_output_weights += attn_mask[SEP]RuntimeError: The size of tensor a (20) must match the size of tensor b (95) at non-singleton dimension 2",,
698,62449191,0,2,,,"File [FILE], line 8, in <module>() h = model.fit(x_train, y_train, epochs=10, batch_size=256)[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 968, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]ValueError: in user code: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function * outputs = self.distribute_strategy.run( /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run ** return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica return fn(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step ** y, y_pred, sample_weight, regularization_losses=self.losses) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__ loss_value = loss_obj(y_t, y_p, sample_weight=sw) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:143 __call__ losses = self.call(y_true, y_pred) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:246 call return self.fn(y_true, y_pred, **self._fn_kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1527 categorical_crossentropy return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4561 categorical_crossentropy target.shape.assert_is_compatible_with(output.shape) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1117 assert_is_compatible_with raise ValueError(""Shapes %s and %s are incompatible"" % (self, other)) ValueError: Shapes (None, 1) and (None, 10) are incompatible",,
699,62586443,0,2,,,"File [FILE], line 3, in <module> validation_data=validation_batches)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 66, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 848, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) tmp_logs = train_function(iterator)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 580, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 611, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) # pylint: disable=not-callable[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2420, in __call__(self, *args, **kwargs) return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1665, in _filtered_call(self, args, kwargs) self.captured_inputs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 1746, in _call_flat(self, args, captured_inputs, cancellation_manager) ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 598, in call(self, ctx, args, cancellation_manager) ctx=ctx)[SEP]File <*>/site-packages/tensorflow/python/eager/execute.py, line 60, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) inputs, attrs, num_outputs)[SEP]InvalidArgumentError: 2 root error(s) found. (0) Invalid argument: Invalid JPEG data or crop window, data size 34228 [[{{node DecodeJpeg}}]] [[IteratorGetNext]] (1) Invalid argument: Invalid JPEG data or crop window, data size 34228 [[{{node DecodeJpeg}}]] [[IteratorGetNext]] [[IteratorGetNext/_4]]",,
700,62744659,0,2,,,"File [FILE], line 11, in <module> validation_steps=nb_val_steps)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1063, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) steps_per_execution=self._steps_per_execution)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/data_adapter.py, line 1110, in __init__(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution) model=model)[SEP]File <*>/site-packages/tensorflow/python/keras/engine/data_adapter.py, line 798, in __init__(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs) output_shapes = nest.map_structure(_get_dynamic_shape, peek)[SEP]File <*>/site-packages/tensorflow/python/util/est.py, line 635, in map_structure(func, *structure, **kwargs) structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/util/est.py, line 635, in <listcomp>(.0) structure[0], [func(*x) for x in entries],[SEP]File <*>/site-packages/tensorflow/python/keras/engine/data_adapter.py, line 794, in _get_dynamic_shape(t) if shape.rank is None:[SEP]AttributeError: 'tuple' object has no attribute 'rank'",,
701,62746381,0,2,,,"File [FILE], line 21, in <module>() history = m.fit([X, y, W], y, epochs=10)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 819, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 235, in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) use_multiprocessing=use_multiprocessing)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 593, in _process_training_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing) use_multiprocessing=use_multiprocessing)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc, line 646, in _process_inputs(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing) x, y, sample_weight=sample_weights)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 2383, in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset) batch_size=batch_size)[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc, line 2469, in _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size) exception_prefix='target')[SEP]File <*>python2.7/site-packages/tensorflow_core/python/keras/engine/training_utils.pyc, line 496, in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) 'expected no data, but got:', data)[SEP]ValueError: ('Error when checking model target: expected no data, but got:', array([3.39102071e-01, 1.23122638e-01, 7.54209531e-01, 8.10110230e-01,",,
702,62771868,0,2,,,"File [FILE], line 4, in <module>() y_true = np.argmax(testdata, axis=1)[SEP]File [FILE], line [NUM], in argmax(*args, **kwargs) [CODE][SEP]File <*>python3.6/dist-packages/numpy/core/fromnumeric.py, line 47, in _wrapit(obj, method, *args, **kwds) result = getattr(asarray(obj), method)(*args, **kwds)[SEP]AxisError: axis 1 is out of bounds for array of dimension 1",,
703,62861107,0,2,,,"File [FILE], line 2, in <module> model.save(""network.h5"")[SEP]File <*>/site-packages/tensorflow_core/python/keras/engine/network.py, line 1008, in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options) signatures, options)[SEP]File <*>/site-packages/tensorflow_core/python/keras/saving/save.py, line 99, in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options) (h5py is not None and isinstance(filepath, h5py.File)) or[SEP]AttributeError: module 'h5py' has no attribute 'File'",,
704,62870656,0,2,,,"File [FILE], line 1, in <module>() load_image('/content/train2017/000000000009.jpg')[SEP]File [FILE], line 4, in load_image(image_path) img = tf.image.resize(img, (299, 299))[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py, line 1517, in resize_images_v2(images, size, method, preserve_aspect_ratio, antialias, name) skip_resize_if_same=False)[SEP]File <*>python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py, line 1185, in _resize_images_common(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same) if images.get_shape().ndims is None:[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1073, in get_shape(self) return self.shape[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/ops.py, line 1067, in shape(self) six.raise_from(core._status_to_exception(e.code, e.message), None)[SEP]File <*>python3.6/dist-packages/six.py, line [NUM], in raise_from(value, from_value) [CODE][SEP]UnimplementedError: File system scheme '[local]' not implemented (file: '/content/train2017/000000000009.jpg')",,
705,62887574,0,2,,,"File [FILE], line 1, in <module>() X_prime_class_split = np.array_split(X_prime_class.numpy(),[SEP]TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",,
706,62922324,0,2,,,"File [FILE], line 22, in [FUNC] train_iter.next()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 345, in __next__(self) data = self._next_data()[SEP]File <*>/site-packages/torch/utils/data/dataloader.py, line 385, in _next_data(self) data = self._dataset_fetcher.fetch(index) # may raise StopIteration[SEP]File <*>/site-packages/torch/utils/data/_utils/fetch.py, line 47, in fetch(self, possibly_batched_index) return self.collate_fn(data)[SEP]File <*>/site-packages/torch/utils/data/_utils/collate.py, line 79, in default_collate(batch) return [default_collate(samples) for samples in transposed][SEP]File <*>/site-packages/torch/utils/data/_utils/collate.py, line 79, in (.0) return [default_collate(samples) for samples in transposed][SEP]File <*>/site-packages/torch/utils/data/_utils/collate.py, line 81, in default_collate(batch) raise TypeError(default_collate_err_msg_format.format(elem_type))[SEP]TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found",,
707,62985943,0,2,,,"File [FILE], line 27, in <module> loss = criterion(pred, y)[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 550, in __call__(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.7/site-packages/torch/nn/modules/loss.py, line 432, in forward(self, input, target) return F.mse_loss(input, target, reduction=self.reduction)[SEP]File <*>python3.7/site-packages/torch/nn/functional.py, line 2530, in mse_loss(input, target, size_average, reduce, reduction) if not (target.size() == input.size()):[SEP]File <*>python3.7/site-packages/torch/nn/modules/module.py, line 594, in __getattr__(self, name) type(self).__name__, name))[SEP]AttributeError: 'UNet3D' object has no attribute 'size'",,
708,63068639,0,2,,,"File [FILE], line 5, in <module>() loaded_model = load_model('save_at_47.h5')[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/saving/save.py, line 184, in load_model(filepath, custom_objects, compile) return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py, line 178, in load_model_from_hdf5(filepath, custom_objects, compile) custom_objects=custom_objects)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/saving/model_config.py, line 55, in model_from_config(config, custom_objects) return deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py, line 109, in deserialize(config, custom_objects) printable_module_name='layer')[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py, line 362, in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name) config, module_objects, custom_objects, printable_module_name)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py, line 321, in class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name) raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)[SEP]ValueError: Unknown layer: Functional",,
709,63141267,0,2,,,"File [FILE], line 1, in <module> from transformers import AutoModelWithLMHead, AutoTokenizer[SEP]ImportError: cannot import name 'AutoModelWithLMHead' from 'transformers' (c:\python38\lib\site-packages\transformers\__init__.py)",,
710,63289566,0,2,,,"File [FILE], line 30, in <module>() attn_out, attn_states = tf.keras.layers.Attention()([encoder_output, decoder_output])[SEP]File <*>python3.6/site-packages/tensorflow_core/python/framework/ops.py, line 548, in __iter__(self) ""Cannot iterate over a tensor with unknown first dimension."")[SEP]TypeError: Cannot iterate over a tensor with unknown first dimension.",,
711,63357718,0,2,,,"File [FILE], line 1, in <module> writer.add_graph(net, images)[SEP]File <*>/site-packages/tensorboardX/writer.py, line 793, in add_graph(self, model, input_to_model, verbose) from torch.utils.tensorboard._pytorch_graph import graph[SEP]File <*>/site-packages/torch/utils/tensorboard/__init__.py, line 4, in <module> raise ImportError('TensorBoard logging requires TensorBoard version 1.15 or above')[SEP]ImportError: TensorBoard logging requires TensorBoard version 1.15 or above",,
712,63372487,0,2,,,"File [FILE], line 6, in <module> train_step(image_x, image_y)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 823, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializers)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 696, in _initialize(self, args, kwds, add_initializers_to) self._stateful_fn._get_concrete_function_internal_garbage_collected( # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2855, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 3213, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 3065, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) func_graph_module.func_graph_from_py_func([SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 986, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 600, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 973, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]OperatorNotAllowedInGraphError: in user code: <ipython-input-160-538af916a6fd>:28 train_step * total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_losss(real_y, cycled_y) <ipython-input-151-74a790ebcddf>:2 calc_cycle_loss * loss1 = tf.reduce_mean(tf.abs(real_image, cycled_image)) C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\util\dispatch.py:201 wrapper ** return target(*args, **kwargs) C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\ops\math_ops.py:388 abs with ops.name_scope(name, ""Abs"", [x]) as name: C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:6492 __enter__ return self._name_scope.__enter__() c:\users\astro\appdata\local\programs\python\python38\lib\contextlib.py:113 __enter__ return next(self.gen) C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:4176 name_scope if name: C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:877 __bool__ self._disallow_bool_casting() C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:486 _disallow_bool_casting self._disallow_when_autograph_enabled( C:\Users\astro\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\framework\ops.py:472 _disallow_when_autograph_enabled raise errors.OperatorNotAllowedInGraphError( OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.",,
713,63406138,0,2,,,"File [FILE], line 16, in <module>() abc = model.predict(img)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py, line 971, in select_data_adapter(x, y) _type_name(x), _type_name(y)))[SEP]ValueError: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>",,
714,63415102,0,2,,,"File [FILE], line [NUM], in apache_beam.runners.common.DoFnRunner.process() [CODE][SEP]File [FILE], line [NUM], in apache_beam.runners.common.PerWindowInvoker.invoke_process() [CODE][SEP]File [FILE], line [NUM], in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window() [CODE][SEP]File [FILE], line [NUM], in apache_beam.runners.common._OutputProcessor.process_outputs() [CODE][SEP]File [FILE], line [NUM], in apache_beam.runners.worker.operations.SingletonConsumerSet.receive() [CODE][SEP]File [FILE], line [NUM], in apache_beam.runners.worker.operations.PGBKCVOperation.process() [CODE][SEP]File <*>python3.7/site-packages/tensorflow_model_analysis/evaluators/metrics_and_plots_evaluator_v2.py, line 356, in add_input(self, accumulator, element) result = c.add_input(a, get_combiner_input(elements[0], i))[SEP]File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/calibration_histogram.py, line 142, in add_input(self, accumulator, element) class_weights=self._class_weights)):[SEP]File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py, line 284, in to_label_prediction_example_weight(inputs, eval_config, model_name, output_name, sub_key, class_weights, flatten, squeeze, allow_none) label, prediction = select_top_k(sub_key.top_k, label, prediction)[SEP]File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py, line 622, in select_top_k(top_k, labels, predictions, scores) labels = one_hot(labels, predictions)[SEP]File <*>python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py, line 672, in one_hot(tensor, target) tensor = np.delete(np.eye(target.shape[-1] + 1)[tensor], -1, axis=-1)[SEP]IndexError: arrays used as indices must be of integer (or boolean) type",,
715,63542803,0,2,,,"File <*>/site-packages/keras/__init__.py, line 3, in <module> from tensorflow.keras.layers.experimental.preprocessing import RandomRotation[SEP]ModuleNotFoundError: No module named 'tensorflow.keras.layers.experimental.preprocessing'",,
716,63542803,0,2,,,"File [FILE], line 8, in <module> from keras.models import Sequential[SEP]File <*>/site-packages/keras/__init__.py, line 6, in <module> 'Keras requires TensorFlow 2.2 or higher. '[SEP]ImportError: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow",,
717,63756773,0,2,,,"File [FILE], line 5, in <module>() out = vae.generate(model, mean, var)[SEP]File <*>/vae.py, line 92, in generate(model, mean, var) out = model.decode(z)[SEP]File <*>/vae.py, line 58, in decode(self, z) out = self.z_develop(z)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 722, in _call_impl(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.6/dist-packages/torch/nn/modules/linear.py, line 91, in forward(self, input) return F.linear(input, self.weight, self.bias)[SEP]File <*>python3.6/dist-packages/torch/nn/functional.py, line 1676, in linear(input, weight, bias) output = input.matmul(weight.t())[SEP]RuntimeError: mat1 dim 1 must match mat2 dim 0",,
718,63779927,0,2,,,"File [FILE], line 3, in <module>() loss = keras.losses.categorical_crossentropy()[SEP]File <*>python3.6/dist-packages/tensorflow/python/util/dispatch.py, line 201, in wrapper(*args, **kwargs) return target(*args, **kwargs)[SEP]TypeError: categorical_crossentropy() missing 2 required positional arguments: 'y_true' and 'y_pred'",,
719,63789810,0,2,,,"File [FILE], line 29, in <module>() model.add(Bidirectional(LSTM(150, return_sequences=True)))[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py, line 180, in assert_input_compatibility(input_spec, inputs, layer_name) str(x.shape.as_list()))[SEP]ValueError: Input 0 of layer bidirectional is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, 1, 1, 80]",,
720,63822152,0,2,,,"File [FILE], line 1, in <module> batch_first[:,1:].view(-1, embedding) # slicing out the first time step[SEP]RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",,
721,63850359,0,2,,,"File [FILE], line 4, in <module>() validation_data = validation_dataset)[SEP]File <*>python3.6/dist-packages/tensorflow/python/eager/def_function.py, line 807, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) # pylint: disable=not-callable[SEP]TypeError: 'NoneType' object is not callable",,
722,64053840,0,2,,,"File [FILE], line 1, in <module> import deeplabcut as dlc[SEP]File <*>python3.7/site-packages/deeplabcut/__init__.py, line 38, in <module> from deeplabcut import generate_training_dataset[SEP]File <*>python3.7/site-packages/deeplabcut/generate_training_dataset/__init__.py, line 18, in <module> from deeplabcut.generate_training_dataset.labeling_toolbox import *[SEP]File <*>python3.7/site-packages/deeplabcut/generate_training_dataset/labeling_toolbox.py, line 33, in <module> from deeplabcut.utils import auxiliaryfunctions[SEP]File <*>python3.7/site-packages/deeplabcut/utils/__init__.py, line 6, in <module> from deeplabcut.utils.make_labeled_video import *[SEP]File <*>python3.7/site-packages/deeplabcut/utils/make_labeled_video.py, line 28, in <module> from matplotlib.animation import FFMpegWriter[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 737, in <module> class ImageMagickWriter(ImageMagickBase, MovieWriter):[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 120, in wrapper(writerClass) if writerClass.isAvailable():[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 730, in isAvailable(cls) return super().isAvailable()[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 427, in isAvailable(cls) return shutil.which(cls.bin_path()) is not None[SEP]File <*>python3.7/site-packages/matplotlib/animation.py, line 724, in bin_path(cls) binpath = mpl._get_executable_info('magick').executable[SEP]File <*>python3.7/site-packages/matplotlib/__init__.py, line 385, in _get_executable_info(name) return impl([path, ""--version""], r""^Version: ImageMagick (\S*)"")[SEP]File <*>python3.7/site-packages/matplotlib/__init__.py, line 330, in impl(args, regex, min_ver, ignore_exit_code) raise _cpe[SEP]File <*>python3.7/site-packages/matplotlib/__init__.py, line 325, in impl(args, regex, min_ver, ignore_exit_code) universal_newlines=True, errors=""replace"")[SEP]File <*>python3.7/subprocess.py, line 411, in check_output(timeout, *popenargs, **kwargs) **kwargs).stdout[SEP]File <*>python3.7/subprocess.py, line 512, in run(input, capture_output, timeout, check, *popenargs, **kwargs) output=stdout, stderr=stderr)[SEP]CalledProcessError: Command '['convert', '--version']' returned non-zero exit status 1.",,
723,64175246,0,2,,,"File [FILE], line 1, in <module>() model.fit([images, negatives], positives, epochs=10, batch_size=8, verbose=2)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 108, in _method_wrapper(self, *args, **kwargs) return method(self, *args, **kwargs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 1098, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing) tmp_logs = train_function(iterator)[SEP]File <*>python3.6/dist-packages/tensorflow/python/eager/def_function.py, line 780, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>python3.6/dist-packages/tensorflow/python/eager/def_function.py, line 807, in _call(self, *args, **kwds) return self._stateless_fn(*args, **kwds) # pylint: disable=not-callable[SEP]TypeError: 'NoneType' object is not callable",,
724,64206070,0,2,,,"File [FILE], line 3, in <module> torch.load(cachefile)[SEP]File <*>python3.8/site-packages/torch/serialization.py, line 584, in load(f, map_location, pickle_module, **pickle_load_args) return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)[SEP]File <*>python3.8/site-packages/torch/serialization.py, line 839, in _load(zip_file, map_location, pickle_module, **pickle_load_args) data_file = io.BytesIO(zip_file.get_record('data.pkl'))[SEP]RuntimeError: [enforce fail at inline_container.cc:209] . file not found: archive/data.pkl",,
725,64272718,0,2,,,"File [FILE], line 15, in <module> outi.backward(torch.tensor([0.,1.]))[SEP]File <*>python3.8/site-packages/torch/tensor.py, line 185, in backward(self, gradient, retain_graph, create_graph) torch.autograd.backward(self, gradient, retain_graph, create_graph)[SEP]File <*>python3.8/site-packages/torch/autograd/__init__.py, line 125, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables) Variable._execution_engine.run_backward([SEP]RuntimeError: leaf variable has been moved into the graph interior",,
726,64337087,0,2,,,"File [FILE], line 1, in <module>() model = tf.keras.models.load_model('/content/saved_models/model_best.h5',custom_objects={'TemporalReshape':TemporalReshape})[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/saving/save.py, line 182, in load_model(filepath, custom_objects, compile, options) return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py, line 178, in load_model_from_hdf5(filepath, custom_objects, compile) custom_objects=custom_objects)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/saving/model_config.py, line 55, in model_from_config(config, custom_objects) return deserialize(config, custom_objects=custom_objects)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py, line 358, in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name) list(custom_objects.items())))[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/functional.py, line 617, in from_config(cls, config, custom_objects) config, custom_objects)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/functional.py, line 1204, in reconstruct_from_config(config, custom_objects, created_layers) process_layer(layer_data)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/functional.py, line 1186, in process_layer(layer_data) layer = deserialize_layer(layer_data, custom_objects=custom_objects)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py, line 175, in deserialize(config, custom_objects) printable_module_name='layer')[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py, line 360, in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name) return cls.from_config(cls_config)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py, line 697, in from_config(cls, config) return cls(**config)[SEP]TypeError: __init__() got an unexpected keyword argument 'name'",,
727,64401570,0,2,,,"File [FILE], line 3, in <module> shap_values = explainer.shap_values(X_train)[SEP]File <*>/site-packages/shap/explainers/deep/__init__.py, line 119, in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity) return self.explainer.shap_values(X, ranked_outputs, output_rank_order, check_additivity=check_additivity)[SEP]File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 304, in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity) sample_phis = self.run(self.phi_symbolic(feature_ind), self.model_inputs, joint_input)[SEP]File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 361, in run(self, out, model_inputs, X) return self.execute_with_overridden_gradients(anon)[SEP]File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 397, in execute_with_overridden_gradients(self, f) out = f()[SEP]File <*>/site-packages/shap/explainers/deep/deep_tf.py, line 357, in anon() final_out = out(inputs)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 780, in __call__(self, *args, **kwds) result = self._call(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 823, in _call(self, *args, **kwds) self._initialize(args, kwds, add_initializers_to=initializers)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 696, in _initialize(self, args, kwds, add_initializers_to) self._stateful_fn._get_concrete_function_internal_garbage_collected( # pylint: disable=protected-access[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 2855, in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs) graph_function, _, _ = self._maybe_define_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 3213, in _maybe_define_function(self, args, kwargs) graph_function = self._create_graph_function(args, kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/function.py, line 3065, in _create_graph_function(self, args, kwargs, override_flat_arg_shapes) func_graph_module.func_graph_from_py_func([SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 986, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes) func_outputs = python_func(*func_args, **func_kwargs)[SEP]File <*>/site-packages/tensorflow/python/eager/def_function.py, line 600, in wrapped_fn(*args, **kwds) return weak_wrapped_fn().__wrapped__(*args, **kwds)[SEP]File <*>/site-packages/tensorflow/python/framework/func_graph.py, line 973, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]StagingError: in user code: C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\shap\explainers\deep\deep_tf.py:244 grad_graph * x_grad = tape.gradient(out, shap_rAnD) C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\backprop.py:1067 gradient ** flat_grad = imperative_grad.imperative_grad( C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\imperative_grad.py:71 imperative_grad return pywrap_tfe.TFE_Py_TapeGradient( C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\backprop.py:151 _gradient_function grad_fn = ops._gradient_registry.lookup(op_name) # pylint: disable=protected-access C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\framework\registry.py:96 lookup raise LookupError( LookupError: gradient registry has no entry for: shap_TensorListStack",,
728,64405461,0,2,,,"File [FILE], line 1, in <module>() x = build_img_encod()[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py, line 166, in assert_input_compatibility(input_spec, inputs, layer_name) if x.shape.ndims is None:[SEP]AttributeError: 'Functional' object has no attribute 'shape'",,
729,64436023,0,2,,,"File [FILE], line 6, in <module>() validation_data=(x_test, y_test),[SEP]File <*>python3.6/dist-packages/tensorflow/python/framework/func_graph.py, line 973, in wrapper(*args, **kwargs) raise e.ag_error_metadata.to_exception(e)[SEP]ValueError: in user code: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function * return step_function(self, iterator) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function ** outputs = model.distribute_strategy.run(run_step, args=(data,)) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica return fn(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step ** outputs = model.train_step(data) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step y_pred = self(x, training=True) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__ outputs = call_fn(inputs, *args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call inputs, training=training, mask=mask) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph outputs = node.layer(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__ outputs = call_fn(inputs, *args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py:183 call return self._merge_function(inputs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py:522 _merge_function return K.concatenate(inputs, axis=self.axis) /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper return target(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:2881 concatenate return array_ops.concat([to_dense(x) for x in tensors], axis) /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper return target(*args, **kwargs) /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1654 concat return gen_array_ops.concat_v2(values=values, axis=axis, name=name) /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:1222 concat_v2 ""ConcatV2"", values=values, axis=axis, name=name) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper attrs=attr_protos, op_def=op_def) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal compute_device) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3485 _create_op_internal op_def=op_def) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1975 __init__ control_input_ops, op_def) /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1815 _create_c_op raise ValueError(str(e)) ValueError: Dimension 2 in both shapes must be equal, but are 512 and 511. Shapes are [?,384,512] and [?,384,511]. for '{{node functional_3/decoder_stage3_concat/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](functional_3/decoder_stage3_upsampling/resize/ResizeNearestNeighbor, functional_3/relu0/Relu, functional_3/decoder_stage3_concat/concat/axis)' with input shapes: [?,384,512,64], [?,384,511,64], [] and with computed input tensors: input[2] = <3>.",,
730,64508203,0,2,,,"File <*>python3.6/dist-packages/tensorflow/python/util/nest.py, line 402, in assert_same_structure(nest1, nest2, check_types, expand_composites) % (str(e), str1, str2))[SEP]ValueError: The two structures don't have the same nested structure.",,
731,64635630,0,2,,,"File [FILE], line 49, in <module> logps = model(images) #log probabilities[SEP]File <*>python3.8/site-packages/torch/nn/modules/container.py, line 117, in forward(self, input) input = module(input)[SEP]File <*>python3.8/site-packages/torch/nn/modules/module.py, line 727, in _call_impl(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>python3.8/site-packages/torch/nn/modules/linear.py, line 93, in forward(self, input) return F.linear(input, self.weight, self.bias)[SEP]File <*>python3.8/site-packages/torch/nn/functional.py, line 1690, in linear(input, weight, bias) ret = torch.addmm(bias, input, weight.t())[SEP]RuntimeError: expected scalar type Float but found Byte",,
732,64745900,0,2,,,"File [FILE], line 7, in <module>() gen.load_state_dict(torch.load(os.path.join(workspace_dir, 'dcgan_g.pth')))[SEP]File <*>python3.6/dist-packages/torch/nn/modules/module.py, line 1052, in load_state_dict(self, state_dict, strict) self.__class__.__name__, ""\n\t"".join(error_msgs)))[SEP]***RuntimeError: Error(s) in loading state_dict for Generator: Missing key(s) in state_dict***: ""gen.0.0.weight"", ""gen.0.1.weight"", ""gen.0.1.bias"", ""gen.0.1.running_mean"", ""gen.0.1.running_var"", ""gen.1.0.weight"", ""gen.1.1.weight"", ""gen.1.1.bias"", ""gen.1.1.running_mean"", ""gen.1.1.running_var"", ""gen.2.0.weight"", ""gen.2.1.weight"", ""gen.2.1.bias"", ""gen.2.1.running_mean"", ""gen.2.1.running_var"", ""gen.3.0.weight"", ""gen.3.1.weight"", ""gen.3.1.bias"", ""gen.3.1.running_mean"", ""gen.3.1.running_var"", ""gen.4.weight"", ""gen.4.bias"". Unexpected key(s) in state_dict: ""disc.0.weight"", ""disc.0.bias"", ""disc.2.0.weight"", ""disc.2.1.weight"", ""disc.2.1.bias"", ""disc.2.1.running_mean"", ""disc.2.1.running_var"", ""disc.2.1.num_batches_tracked"", ""disc.3.0.weight"", ""disc.3.1.weight"", ""disc.3.1.bias"", ""disc.3.1.running_mean"", ""disc.3.1.running_var"", ""disc.3.1.num_batches_tracked"", ""disc.4.0.weight"", ""disc.4.1.weight"", ""disc.4.1.bias"", ""disc.4.1.running_mean"", ""disc.4.1.running_var"", ""disc.4.1.num_batches_tracked"", ""disc.5.weight"", ""disc.5.bias"".",,
733,65144346,0,2,,,"File [FILE], line 8, in <module> optimization.train(x_train, y_train, x_val, y_val,[SEP]File [FILE], line 70, in train(self, x_train, y_train, x_val, y_val, batch_size, n_epochs, dropout, do_teacher_forcing) y_pred = self._predict(x_batch, y_batch, seq_len, do_teacher_forcing)[SEP]File [FILE], line 95, in _predict(self, x_batch, y_batch, seq_len, do_teacher_forcing) y_pred = self.model(x_batch)[SEP]File [FILE], line 19, in forward(self, input, future, y) h_t, c_t = self.lstm(input_t, (h_t, c_t))[SEP]File <*>/site-packages/torch/nn/modules/module.py, line 727, in _call_impl(self, *input, **kwargs) result = self.forward(*input, **kwargs)[SEP]File <*>/site-packages/torch/nn/modules/rnn.py, line 965, in forward(self, input, hx) self.check_forward_input(input)[SEP]File <*>/site-packages/torch/nn/modules/rnn.py, line 791, in check_forward_input(self, input) raise RuntimeError([SEP]RuntimeError: input has inconsistent input_size: got 1, expected 3",,
734,65417497,0,2,,,"File [FILE], line 8, in <module> model.save(""temp_model"")[SEP]File <*>/site-packages/tensorflow/python/keras/engine/training.py, line 1979, in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options) signatures, options)[SEP]File <*>/site-packages/tensorflow/python/keras/saving/save.py, line 134, in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options) signatures, options)[SEP]File <*>/site-packages/tensorflow/python/keras/saving/saved_model/save.py, line 80, in save(model, filepath, overwrite, include_optimizer, signatures, options) save_lib.save(model, filepath, signatures, options)[SEP]File <*>/site-packages/tensorflow/python/saved_model/save.py, line 976, in save(obj, export_dir, signatures, options) obj, export_dir, signatures, options, meta_graph_def)[SEP]File <*>/site-packages/tensorflow/python/saved_model/save.py, line 1061, in _build_meta_graph(obj, export_dir, signatures, options, meta_graph_def) _ = _SaveableView(checkpoint_graph_view)[SEP]File <*>/site-packages/tensorflow/python/saved_model/save.py, line 178, in __init__(self, checkpoint_view, wrapped_functions) self.checkpoint_view.objects_ids_and_slot_variables())[SEP]File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 426, in objects_ids_and_slot_variables(self) object_names[obj] = _object_prefix_from_path(path)[SEP]File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 64, in _object_prefix_from_path(path_to_root) for trackable in path_to_root))[SEP]File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 64, in <genexpr>(.0) for trackable in path_to_root))[SEP]File <*>/site-packages/tensorflow/python/training/tracking/graph_view.py, line 57, in _escape_local_name(name) return (name.replace(_ESCAPE_CHAR, _ESCAPE_CHAR + _ESCAPE_CHAR)[SEP]AttributeError: 'NoneType' object has no attribute 'replace'",,
735,62656411,0,2,,,"File <*>python3.6/dist-packages/optkeras/optkeras.py, line 230, in synch_with_optuna(self) self.best_trial = self.study.best_trial[SEP]ValueError: No trials are completed yet.",,
736,62656411,0,2,,,"File <*>python3.6/dist-packages/optkeras/optkeras.py, line 367, in get_trial_default() num_fields = optuna.structs.FrozenTrial._field_types.__len__()[SEP]AttributeError: type object 'FrozenTrial' has no attribute '_field_types'",,
737,63075594,0,2,,,"File [FILE], line 16, in <module>() results = p.map(X_power_func, range(8))[SEP]File <*>python3.6/pool.py, line 644, in get(self, timeout) raise self._value[SEP]RuntimeError: CUDA error: initialization error",,
738,57391377,0,2,,,"File [FILE], line 7, in <module>() validation_steps = valid_step , callbacks = [metrics], verbose=2)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 673, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 1433, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch')[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py, line 331, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) callbacks.on_epoch_end(epoch, epoch_logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 311, in on_epoch_end(self, epoch, logs) callback.on_epoch_end(epoch, logs)[SEP]File [FILE], line 16, in on_epoch_end(self, batch, logs) X_val, y_val = self.validation_data[0], self.validation_data[1][SEP]TypeError: 'NoneType' object is not subscriptable",,
739,57391377,0,2,,,"File [FILE], line 7, in <module>() validation_steps = valid_step , callbacks = [metrics], verbose=2)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 673, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) initial_epoch=initial_epoch)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training.py, line 1433, in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch) steps_name='steps_per_epoch')[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py, line 260, in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs) callbacks._call_batch_hook(mode, 'begin', step, batch_logs)[SEP]File <*>python3.6/dist-packages/tensorflow/python/keras/callbacks.py, line 247, in _call_batch_hook(self, mode, hook, batch, logs) batch_hook = getattr(callback, hook_name)[SEP]AttributeError: 'Metrics' object has no attribute 'on_train_batch_begin'",,
740,64779719,0,2,,,"File [FILE], line 11, in <module> foo_test.main()[SEP]File <*>/foo_test.py, line 25, in main() tf.test.main()[SEP]File <*>/site-packages/tensorflow/python/platform/test.py, line 58, in main(argv) return _googletest.main(argv)[SEP]File <*>/site-packages/tensorflow/python/platform/googletest.py, line 66, in main(argv) benchmark.benchmarks_main(true_main=main_wrapper)[SEP]File <*>/site-packages/tensorflow/python/platform/benchmark.py, line 486, in benchmarks_main(true_main, argv) true_main()[SEP]File <*>/site-packages/tensorflow/python/platform/googletest.py, line 65, in main_wrapper() return app.run(main=g_main, argv=args)[SEP]File <*>/site-packages/tensorflow/python/platform/app.py, line 40, in run(main, argv) _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)[SEP]File <*>/site-packages/absl/app.py, line 303, in run(main, argv, flags_parser) _run_main(main, args)[SEP]File <*>/site-packages/absl/app.py, line 251, in _run_main(main, argv) sys.exit(main(argv))[SEP]File <*>/site-packages/tensorflow/python/platform/googletest.py, line 56, in g_main(argv) absltest_main(argv=argv)[SEP]File <*>/site-packages/absl/testing/absltest.py, line 2002, in main(*args, **kwargs) _run_in_app(run_tests, args, kwargs)[SEP]File <*>/site-packages/absl/testing/absltest.py, line 2105, in _run_in_app(function, args, kwargs) argv = FLAGS(sys.argv)[SEP]File <*>/site-packages/absl/flags/_flagvalues.py, line 654, in __call__(self, argv, known_only) raise _exceptions.UnrecognizedFlagError([SEP]UnrecognizedFlagError: Unknown command line flag 'f'",,
741,59218671,0,2,,,"File [FILE], line 49, in <module>() for images, labels in myTrain_dataloader:[SEP]File <*>python3.6/dist-packages/torch/utils/data/dataloader.py, line 819, in __next__(self) return self._process_data(data)[SEP]File <*>python3.6/dist-packages/torch/utils/data/dataloader.py, line 846, in _process_data(self, data) data.reraise()[SEP]File <*>python3.6/dist-packages/torch/_utils.py, line 385, in reraise(self) raise self.exc_type(msg)[SEP]RuntimeError: Caught RuntimeError in DataLoader worker process 0.",,
