eventId,post_id,label,Pattern,type,Unnamed: 5,Templates,Unnamed: 7,Unnamed: 8
7,35735162,1,1,TPL-LLL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python2.7/site-packages/tensorflow/__init__.py, line 23, in <module> from tensorflow.python import *[SEP]File <*>python2.7/site-packages/tensorflow/python/__init__.py, line 49, in <module> from tensorflow import contrib[SEP]File <*>python2.7/site-packages/tensorflow/contrib/__init__.py, line 23, in <module> from tensorflow.contrib import layers[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/__init__.py, line 68, in <module> from tensorflow.contrib.layers.python.layers import *[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/__init__.py, line 22, in <module> from tensorflow.contrib.layers.python.layers.initializers import *[SEP]File <*>python2.7/site-packages/tensorflow/contrib/layers/python/layers/initializers.py, line 24, in <module> from tensorflow.python.ops import random_ops[SEP]File <*>python2.7/site-packages/tensorflow/python/ops/random_ops.py, line 23, in <module> from tensorflow.python.framework import ops[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/ops.py, line 39, in <module> from tensorflow.python.framework import versions[SEP]File <*>python2.7/site-packages/tensorflow/python/framework/versions.py, line 22, in <module> from tensorflow.python import pywrap_tensorflow[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 28, in <module> _pywrap_tensorflow = swig_import_helper()[SEP]File <*>python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)[SEP]ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory",,
103,59226533,1,2,CORE-TPL,,"File [FILE], line 1, in <module> var_init_1 = tf.get_variable(""var_init_1"", [1, 2], dtype=tf.int32, initializer=tf.zeros_initializer)[SEP]AttributeError: module 'tensorflow' has no attribute 'get_variable'",,
97,58770347,1,1,TPL-LLL,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.6/dist-packages/torch/cuda/__init__.py, line 386, in current_device _lazy_init()[SEP]File <*>python3.6/dist-packages/torch/cuda/__init__.py, line 192, in _lazy_init _check_driver()[SEP]File <*>python3.6/dist-packages/torch/cuda/__init__.py, line 111, in _check_driver of the CUDA driver."""""".format(str(torch._C._cuda_getDriverVersion())))[SEP]AssertionError: The NVIDIA driver on your system is too old (found version 10000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",,
100,58833945,1,2,TPL-TPL,,"File [FILE], line 3, in <module> model.add(tensorflow.keras.layers.GlobalMaxPooling2D(name=""gap""))[SEP]File <*>/site-packages/keras/engine/sequential.py, line 133, in add(self, layer) 'Found: ' + str(layer))[SEP]TypeError: The added layer must be an instance of class Layer. Found: <tensorflow.python.keras.layers.core.Flatten object at 0x00000000B74364A8>",,
580,52227910,0,2,,,"File [FILE], line 116, in <module>() print('Test_accuracy : ',sess.run(accuracy, feed_dict={input: x, output: y,keep_prob:1.0}))[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 908, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1143, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1324, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata)[SEP]File <*>python3.6/site-packages/tensorflow/python/client/session.py, line 1343, in _do_call(self, fn, *args) raise type(e)(node_def, op, message)[SEP]FailedPreconditionError: Attempting to use uninitialized value W_4 [[Node: W_4/read = Identity[T=DT_FLOAT, _class=[""loc:@W_4""], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](W_4)]]",,
400,55375416,0,1,,,"File <*>/min_working_example.py, line 37, in <module> model.fit(data_generator)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 880, in fit validation_steps=validation_steps)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 310, in model_iteration ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]][SEP]File <*>python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 526, in slice_arrays return [None if x is None else x[start] for x in arrays][SEP]File <*>python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py, line 526, in <listcomp> return [None if x is None else x[start] for x in arrays][SEP]File <*>python3.6/site-packages/tensorflow/python/ops/array_ops.py, line 654, in _slice_helper name=name)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/array_ops.py, line 820, in strided_slice shrink_axis_mask=shrink_axis_mask)[SEP]File <*>python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py, line 9334, in strided_slice _six.raise_from(_core._status_to_exception(e.code, message), None)[SEP]File <string>, line 3, in raise_from [CODE][SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Attr shrink_axis_mask has value 4294967295 out of range for an int32 [Op:StridedSlice] name: strided_slice/",,
498,61968540,0,1,,,"File plot_parametric_pytorch_cifar100.py, line 130, in <module> loss_fn = F.nll_loss(ops, tgts)[SEP]File <*>python3.7/site-packages/torch/nn/functional.py, line 2115, in nll_loss ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)[SEP]IndexError: Target 42 is out of bounds.",,
209,39462343,0,1,,,"File dummy.py, line 16, in <module> features = tf.pack([col1, col2, col3])[SEP]File <*>python2.7/dist-packages/tensorflow/python/ops/array_ops.py, line 487, in pack return gen_array_ops._pack(values, axis=axis, name=name)[SEP]File <*>python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py, line 1462, in _pack result = _op_def_lib.apply_op(""Pack"", values=values, axis=axis, name=name)[SEP]File <*>python2.7/dist-packages/tensorflow/python/framework/op_def_library.py, line 437, in apply_op raise TypeError(""%s that don't all match."" % prefix)[SEP]TypeError: Tensors in list passed to 'values' of 'Pack' Op have types [int32, int32, float32] that don't all match.",,
294,49033008,0,1,,,"File eval.py, line 146, in <module> tf.app.run()[SEP]File <*>python3.5/dist-packages/tensorflow/python/platform/app.py, line 124, in run _sys.exit(main(argv))[SEP]File eval.py, line 142, in main FLAGS.checkpoint_dir, FLAGS.eval_dir)[SEP]File <*>/evaluator.py, line 240, in evaluate save_graph_dir=(eval_dir if eval_config.save_graph else ''))[SEP]File <*>/eval_util.py, line 407, in repeated_checkpoint_run save_graph_dir)[SEP]File <*>/eval_util.py, line 286, in _run_checkpoint_once result_dict = batch_processor(tensor_dict, sess, batch, counters)[SEP]File <*>/evaluator.py, line 183, in _process_batch result_dict = sess.run(tensor_dict)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 895, in run run_metadata_ptr)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1128, in _run feed_dict_tensor, options, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1344, in _do_run options, run_metadata)[SEP]File <*>python3.5/dist-packages/tensorflow/python/client/session.py, line 1363, in _do_call raise type(e)(node_def, op, message)[SEP]tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,32,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[Node: FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Preprocessor/sub, FeatureExtractor/MobilenetV1/Conv2d_0/weights/read)]]",,
607,55650121,0,2,,,"File <*>python3.6/site-packages/tensorflow/python/framework/ops.py, line 1659, in _create_c_op(graph, node_def, inputs, control_inputs) c_op = c_api.TF_FinishOperation(op_desc)[SEP]InvalidArgumentError: Shapes must be equal rank, but are 2 and 3 for 'ScatterUpdate' (op: 'ScatterUpdate') with input shapes: [?,10], [?,2], [?,2].",,
420,56580538,0,1,,,"File TestServe.py, line 62, in <module> ts.train()[SEP]File TestServe.py, line 56, in train epochs=2, verbose=1, callbacks=callbacks, steps_per_epoch=20) #The steps_per_epoch is typically samples_per_epoch / batch_size[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training.py, line 880, in fit validation_steps=validation_steps)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 364, in model_iteration validation_in_fit=True)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 202, in model_iteration steps_per_epoch)[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py, line 76, in _get_num_samples_or_steps 'steps_per_epoch')[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 230, in check_num_samples if check_steps_argument(ins, steps, steps_name):[SEP]File <*>python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py, line 960, in check_steps_argument input_type=input_type_str, steps_name=steps_name))[SEP]ValueError: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument.",,
451,58776787,0,1,,,"File <input>, line 1, in <module> [CODE][SEP]AttributeError: module 'keras.applications' has no attribute 'resnet_v2'",,
690,62169315,0,2,,,"File [FILE], line 9, in <module>() model.save(outdir+'model.h5')[SEP]File <*>python3.6/dist-packages/h5py/_hl/group.py, line 373, in __setitem__(self, name, obj) h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl)[SEP]File <*>/_objects.pyx, line [NUM], in h5py._objects.with_phil.wrapper() [CODE][SEP]File <*>/h5o.pyx, line [NUM], in h5py.h5o.link() [CODE][SEP]RuntimeError: Unable to create link (name already exists)",,
553,48482483,0,2,,,"File <*>/site-packages/tensorflow/python/framework/common_shapes.py, line 686, in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn) input_tensors_as_shapes, status)[SEP]File <*>/site-packages/tensorflow/python/framework/errors_impl.py, line 473, in __exit__(self, type_arg, value_arg, traceback_arg) c_api.TF_GetCode(self.status.status))[SEP]InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 4096 and 1000 for 'Assign_30' (op: 'Assign') with input shapes: [4096,3], [1000,3].",,
477,60551145,0,1,,,"File <stdin>, line 1, in <module> [CODE][SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training.py, line 1013, in predict use_multiprocessing=use_multiprocessing)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 498, in predict workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 475, in _model_iteration total_epochs=1)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py, line 128, in run_one_epoch batch_outs = execution_function(iterator)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py, line 98, in execution_function distributed_function(input_fn))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 568, in __call__ result = self._call(*args, **kwds)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/def_function.py, line 638, in _call return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds) # pylint: disable=protected-access[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1611, in _filtered_call self.captured_inputs)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 1692, in _call_flat ctx, args, cancellation_manager=cancellation_manager))[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/function.py, line 545, in call ctx=ctx)[SEP]File <*>python3.7/site-packages/tensorflow_core/python/eager/execute.py, line 75, in quick_execute ""tensors, but found {}"".format(keras_symbolic_tensors))[SEP]tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'conv_name_base_1/Identity:0' shape=(None, 160, 160, 64) dtype=float32>]",,
693,62188532,0,2,,,"File [FILE], line 1, in <module> history = model.fit([train.id, train.user_id], train.user_like, nb_epoch=3)[SEP]File <*>/site-packages/keras/engine/training.py, line 1657, in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs) validation_steps=validation_steps)[SEP]File <*>/site-packages/keras/engine/training.py, line 1213, in _fit_loop(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps) outs = f(ins_batch)[SEP]File <*>/site-packages/keras/backend/tensorflow_backend.py, line 2357, in __call__(self, inputs) **self.session_kwargs)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 956, in run(self, fetches, feed_dict, options, run_metadata) run_metadata_ptr)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1180, in _run(self, handle, fetches, feed_dict, options, run_metadata) feed_dict_tensor, options, run_metadata)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1359, in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata) run_metadata)[SEP]File <*>/site-packages/tensorflow_core/python/client/session.py, line 1384, in _do_call(self, fn, *args) session_config.graph_options.rewrite_options.' raise type(e)(node_def, op, message)[SEP]InvalidArgumentError: indices[24,0] = 335 is not in [0, 304) [[node user-embedding-mlp_1/GatherV2 (defined at E:\My\Ananconda\envs\tensor\lib\site-packages\tensorflow_core\python\framework\ops.py:1748) ]]",,
427,57117397,0,1,,,"File <*>python3.6/site-packages/tensorflow/python/framework/importer.py, line 427, in import_graph_def graph._c_graph, serialized, options) # pylint: disable=protected-access[SEP]tensorflow.python.framework.errors_impl.InvalidArgumentError: Input 1 of node StatefulPartitionedCall was passed float from conv2d/kernel:0 incompatible with expected resource.",,
677,60870008,0,2,,,"File [FILE], line 7, in <module>() print(x[tensor(0)])[SEP]KeyError: tensor(0)",,
457,59240556,0,1,,,"File tf_1_day_scikit_dnn.py, line 12, in <module> from sklearn import decomposition[SEP]File <*>python3.6/site-packages/sklearn/decomposition/__init__.py, line 19, in <module> from ._online_lda import LatentDirichletAllocation[SEP]ImportError: cannot import name 'LatentDirichletAllocation'",,
624,56783182,0,2,,,"File [FILE], line 3, in <module> train(n_epochs,net,loaders,optimizer,criterion,'saved_model/dog_model.pt')[SEP]File [FILE], line 24, in train(n_epochs, model, loader, optimizer, criterion, save_path) loss = criterion(outputs,target)[SEP]RuntimeError: The size of tensor a (133) must match the size of tensor b (10) at non-singleton dimension 1.",,
